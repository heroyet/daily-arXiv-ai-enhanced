<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 222]
- [cs.LG](#cs.LG) [Total: 111]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.RO](#cs.RO) [Total: 42]
- [cs.GT](#cs.GT) [Total: 5]
- [cs.NE](#cs.NE) [Total: 4]
- [cs.GR](#cs.GR) [Total: 11]
- [cs.HC](#cs.HC) [Total: 30]
- [eess.SY](#eess.SY) [Total: 28]
- [cs.SD](#cs.SD) [Total: 15]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Neural Cellular Automata: From Cells to Pixels](https://arxiv.org/abs/2506.22899)
*Ehsan Pajouheshgar,Yitao Xu,Ali Abbasi,Alexander Mordvintsev,Wenzel Jakob,Sabine Süsstrunk*

Main category: cs.CV

TL;DR: 本文提出了一种结合隐式解码器的神经细胞自动机（NCA）方法，解决了高分辨率输出的限制，实现了实时生成高清图像的能力。


<details>
  <summary>Details</summary>
Motivation: NCA在低分辨率网格上表现良好，但在高分辨率下存在训练时间长、信息传播局限和计算需求高的问题。本文旨在通过隐式解码器和新型损失函数解决这些问题。

Method: 将NCA与小型共享隐式解码器结合，在粗网格上进行演化，通过轻量级解码器生成任意分辨率的输出图像。同时设计了针对高分辨率任务的损失函数。

Result: 该方法显著提升了NCA在高分辨率下的质量和效率，实现了实时生成高清图像的能力，并保持了自组织和涌现特性。

Conclusion: 通过隐式解码器和新型损失函数，NCA能够高效扩展到高分辨率输出，适用于多种任务和网格类型。

Abstract: Neural Cellular Automata (NCAs) are bio-inspired systems in which identical
cells self-organize to form complex and coherent patterns by repeatedly
applying simple local rules. NCAs display striking emergent behaviors including
self-regeneration, generalization and robustness to unseen situations, and
spontaneous motion. Despite their success in texture synthesis and
morphogenesis, NCAs remain largely confined to low-resolution grids. This
limitation stems from (1) training time and memory requirements that grow
quadratically with grid size, (2) the strictly local propagation of information
which impedes long-range cell communication, and (3) the heavy compute demands
of real-time inference at high resolution. In this work, we overcome this
limitation by pairing NCA with a tiny, shared implicit decoder, inspired by
recent advances in implicit neural representations. Following NCA evolution on
a coarse grid, a lightweight decoder renders output images at arbitrary
resolution. We also propose novel loss functions for both morphogenesis and
texture synthesis tasks, specifically tailored for high-resolution output with
minimal memory and computation overhead. Combining our proposed architecture
and loss functions brings substantial improvement in quality, efficiency, and
performance. NCAs equipped with our implicit decoder can generate full-HD
outputs in real time while preserving their self-organizing, emergent
properties. Moreover, because each MLP processes cell states independently,
inference remains highly parallelizable and efficient. We demonstrate the
applicability of our approach across multiple NCA variants (on 2D, 3D grids,
and 3D meshes) and multiple tasks, including texture generation and
morphogenesis (growing patterns from a seed), showing that with our proposed
framework, NCAs seamlessly scale to high-resolution outputs with minimal
computational overhead.

</details>


### [2] [Robust Perspective Correction for Real-World Crack Evolution Tracking in Image-Based Structural Health Monitoring](https://arxiv.org/abs/2506.22437)
*Xinxin Sun,Peter Chang*

Main category: cs.CV

TL;DR: 提出了一种基于物理信息的图像对齐框架，用于结构健康监测中的裂纹定位，解决了传统方法在高频边缘和复杂环境下的不足。


<details>
  <summary>Details</summary>
Motivation: 传统特征检测方法（如SIFT、SURF）在高频边缘抑制和复杂环境（如阴影、遮挡）下表现不佳，需要一种更适应结构健康监测需求的解决方案。

Method: 采用非线性各向异性扩散构建裂纹保留尺度空间，结合RANSAC单应性估计，无需训练或参数调优。

Result: 在多种实际条件下，裂纹面积和长度误差分别减少70%和90%，对齐误差低于5%。

Conclusion: 该方法为结构健康监测提供了一种无监督、轻量且物理基础强的裂纹跟踪方案。

Abstract: Accurate image alignment is essential for monitoring crack evolution in
structural health monitoring (SHM), particularly under real-world conditions
involving perspective distortion, occlusion, and low contrast. However,
traditional feature detectors such as SIFT and SURF, which rely on
Gaussian-based scale spaces, tend to suppress high-frequency edges, making them
unsuitable for thin crack localization. Lightweight binary alternatives like
ORB and BRISK, while computationally efficient, often suffer from poor keypoint
repeatability on textured or shadowed surfaces. This study presents a
physics-informed alignment framework that adapts the open KAZE architecture to
SHM-specific challenges. By utilizing nonlinear anisotropic diffusion to
construct a crack-preserving scale space, and integrating RANSAC-based
homography estimation, the framework enables accurate geometric correction
without the need for training, parameter tuning, or prior calibration. The
method is validated on time-lapse images of masonry and concrete acquired via
handheld smartphone under varied field conditions, including shadow
interference, cropping, oblique viewing angles, and surface clutter. Compared
to classical detectors, the proposed framework reduces crack area and spine
length errors by up to 70 percent and 90 percent, respectively, while
maintaining sub-5 percent alignment error in key metrics. Unsupervised,
interpretable, and computationally lightweight, this approach supports scalable
deployment via UAVs and mobile platforms. By tailoring nonlinear scale-space
modeling to SHM image alignment, this work offers a robust and physically
grounded alternative to conventional techniques for tracking real-world crack
evolution.

</details>


### [3] [Counting with Confidence: Accurate Pest Monitoring in Water Traps](https://arxiv.org/abs/2506.22438)
*Xumin Gao,Mark Stevens,Grzegorz Cielniak*

Main category: cs.CV

TL;DR: 该论文提出了一种基于计数结果和外部环境条件信息的方法，用于全面评估害虫计数置信度，并通过实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉自动害虫计数研究缺乏对计数结果可靠性的评估，尤其是在无真实数据的情况下。

Method: 结合害虫检测网络、图像质量评估、图像复杂度评估、害虫分布均匀性评估，并通过回归模型预测计数置信度。

Result: 实验表明，该方法在害虫计数置信度测试集上，MSE降低了31.7%，R2提高了15.2%。

Conclusion: 该研究首次全面评估计数置信度，并通过模型量化影响因素与置信度的关系，为精准农业决策提供了可靠工具。

Abstract: Accurate pest population monitoring and tracking their dynamic changes are
crucial for precision agriculture decision-making. A common limitation in
existing vision-based automatic pest counting research is that models are
typically evaluated on datasets with ground truth but deployed in real-world
scenarios without assessing the reliability of counting results due to the lack
of ground truth. To this end, this paper proposed a method for comprehensively
evaluating pest counting confidence in the image, based on information related
to counting results and external environmental conditions. First, a pest
detection network is used for pest detection and counting, extracting counting
result-related information. Then, the pest images undergo image quality
assessment, image complexity assessment, and pest distribution uniformity
assessment. And the changes in image clarity caused by stirring during image
acquisition are quantified by calculating the average gradient magnitude.
Notably, we designed a hypothesis-driven multi-factor sensitivity analysis
method to select the optimal image quality assessment and image complexity
assessment methods. And we proposed an adaptive DBSCAN clustering algorithm for
pest distribution uniformity assessment. Finally, the obtained information
related to counting results and external environmental conditions is input into
a regression model for prediction, resulting in the final pest counting
confidence. To the best of our knowledge, this is the first study dedicated to
comprehensively evaluating counting confidence in counting tasks, and
quantifying the relationship between influencing factors and counting
confidence through a model. Experimental results show our method reduces MSE by
31.7% and improves R2 by 15.2% on the pest counting confidence test set,
compared to the baseline built primarily on information related to counting
results.

</details>


### [4] [Modulated Diffusion: Accelerating Generative Modeling with Modulated Quantization](https://arxiv.org/abs/2506.22463)
*Weizhi Gao,Zhichao Hou,Junqi Yin,Feiyi Wang,Linyu Peng,Xiaorui Liu*

Main category: cs.CV

TL;DR: MoDiff是一种创新的扩散模型加速框架，通过调制量化和误差补偿提高生成效率，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 扩散模型的计算成本高，现有加速技术（如缓存和量化）在计算误差和生成质量方面存在局限。

Method: 提出MoDiff框架，结合调制量化和误差补偿，适用于所有扩散模型。

Result: 实验证明MoDiff将激活量化从8位降至3位，且无性能损失。

Conclusion: MoDiff是一种高效且通用的扩散模型加速解决方案。

Abstract: Diffusion models have emerged as powerful generative models, but their high
computation cost in iterative sampling remains a significant bottleneck. In
this work, we present an in-depth and insightful study of state-of-the-art
acceleration techniques for diffusion models, including caching and
quantization, revealing their limitations in computation error and generation
quality. To break these limits, this work introduces Modulated Diffusion
(MoDiff), an innovative, rigorous, and principled framework that accelerates
generative modeling through modulated quantization and error compensation.
MoDiff not only inherents the advantages of existing caching and quantization
methods but also serves as a general framework to accelerate all diffusion
models. The advantages of MoDiff are supported by solid theoretical insight and
analysis. In addition, extensive experiments on CIFAR-10 and LSUN demonstrate
that MoDiff significant reduces activation quantization from 8 bits to 3 bits
without performance degradation in post-training quantization (PTQ). Our code
implementation is available at https://github.com/WeizhiGao/MoDiff.

</details>


### [5] [ViFusionTST: Deep Fusion of Time-Series Image Representations from Load Signals for Early Bed-Exit Prediction](https://arxiv.org/abs/2506.22498)
*Hao Liu,Yu Hu,Rakiba Rayhana,Ling Bai,Zheng Liu*

Main category: cs.CV

TL;DR: 论文提出了一种基于低成本传感器的床离意图预测方法，通过图像融合技术实现高精度预测。


<details>
  <summary>Details</summary>
Motivation: 床离相关跌倒事故频发，现有警报系统反应滞后，需提前预测意图以减少伤害。

Method: 使用四个低成本负载传感器采集信号，转换为互补图像，并设计双流Swin Transformer进行多模态融合。

Result: 在真实数据集上，ViFusionTST达到0.885准确率和0.794 F1分数，优于现有基线。

Conclusion: 图像融合负载信号是一种实用且有效的实时隐私保护跌倒预防方案。

Abstract: Bed-related falls remain a leading source of injury in hospitals and
long-term-care facilities, yet many commercial alarms trigger only after a
patient has already left the bed. We show that early bed-exit intent can be
predicted using only four low-cost load cells mounted under the bed legs. The
resulting load signals are first converted into a compact set of complementary
images: an RGB line plot that preserves raw waveforms and three texture maps -
recurrence plot, Markov transition field, and Gramian angular field - that
expose higher-order dynamics. We introduce ViFusionTST, a dual-stream Swin
Transformer that processes the line plot and texture maps in parallel and fuses
them through cross-attention to learn data-driven modality weights.
  To provide a realistic benchmark, we collected six months of continuous data
from 95 beds in a long-term-care facility. On this real-world dataset
ViFusionTST reaches an accuracy of 0.885 and an F1 score of 0.794, surpassing
recent 1D and 2D time-series baselines across F1, recall, accuracy, and AUPRC.
The results demonstrate that image-based fusion of load-sensor signals for time
series classification is a practical and effective solution for real-time,
privacy-preserving fall prevention.

</details>


### [6] [Scalable Dynamic Origin-Destination Demand Estimation Enhanced by High-Resolution Satellite Imagery Data](https://arxiv.org/abs/2506.22499)
*Jiachao Liu,Pablo Guarda,Koichiro Niinuma,Sean Qian*

Main category: cs.CV

TL;DR: 提出了一种结合卫星影像和传统交通数据的多类动态起讫点需求估计框架，显著提升了估计性能，特别是在缺乏本地传感器的路段。


<details>
  <summary>Details</summary>
Motivation: 传统交通数据稀疏且覆盖有限，卫星影像能提供更全面的城市交通信息，克服数据可用性限制。

Method: 设计计算机视觉流程提取车辆类别信息，构建基于计算图的动态需求估计模型，结合卫星影像和本地传感器数据校准网络状态。

Result: 实验表明，补充卫星数据显著提升估计性能，框架能处理大规模网络，适用于不同规模城市。

Conclusion: 该框架具有实际部署潜力，卫星数据质量对结果有显著影响。

Abstract: This study presents a novel integrated framework for dynamic
origin-destination demand estimation (DODE) in multi-class mesoscopic network
models, leveraging high-resolution satellite imagery together with conventional
traffic data from local sensors. Unlike sparse local detectors, satellite
imagery offers consistent, city-wide road and traffic information of both
parking and moving vehicles, overcoming data availability limitations. To
extract information from imagery data, we design a computer vision pipeline for
class-specific vehicle detection and map matching, generating link-level
traffic density observations by vehicle class. Building upon this information,
we formulate a computational graph-based DODE model that calibrates dynamic
network states by jointly matching observed traffic counts and travel times
from local sensors with density measurements derived from satellite imagery. To
assess the accuracy and scalability of the proposed framework, we conduct a
series of numerical experiments using both synthetic and real-world data. The
results of out-of-sample tests demonstrate that supplementing traditional data
with satellite-derived density significantly improves estimation performance,
especially for links without local sensors. Real-world experiments also confirm
the framework's capability to handle large-scale networks, supporting its
potential for practical deployment in cities of varying sizes. Sensitivity
analysis further evaluates the impact of data quality related to satellite
imagery data.

</details>


### [7] [Visual-Semantic Knowledge Conflicts in Operating Rooms: Synthetic Data Curation for Surgical Risk Perception in Multimodal Large Language Models](https://arxiv.org/abs/2506.22500)
*Weiyi Zhao,Xiaoyu Tan,Liang Liu,Sijia Li,Youwei Song,Xihe Qiu*

Main category: cs.CV

TL;DR: 论文提出了一种解决多模态大语言模型（MLLMs）在手术室风险检测中视觉-语义知识冲突（VS-KC）的方法，通过生成合成数据集OR-VSKC，并验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 手术风险识别对患者安全和减少医疗错误至关重要，但MLLMs在视觉安全违规检测中存在知识冲突问题。

Method: 使用扩散模型生成34,000张合成图像和214张人工标注图像，构建OR-VSKC数据集，用于训练和验证MLLMs。

Result: 微调后的MLLMs在训练过的冲突实体检测上表现显著提升，但对未训练实体类型效果不佳。

Conclusion: OR-VSKC数据集和基准测试为研究VS-KC提供了资源，但需更全面的训练以提升模型泛化能力。

Abstract: Surgical risk identification is critical for patient safety and reducing
preventable medical errors. While multimodal large language models (MLLMs) show
promise for automated operating room (OR) risk detection, they often exhibit
visual-semantic knowledge conflicts (VS-KC), failing to identify visual safety
violations despite understanding textual rules. To address this, we introduce a
dataset comprising over 34,000 synthetic images generated by diffusion models,
depicting operating room scenes containing entities that violate established
safety rules. These images were created to alleviate data scarcity and examine
MLLMs vulnerabilities. In addition, the dataset includes 214 human-annotated
images that serve as a gold-standard reference for validation. This
comprehensive dataset, spanning diverse perspectives, stages, and
configurations, is designed to expose and study VS-KC. Fine-tuning on OR-VSKC
significantly improves MLLMs' detection of trained conflict entities and
generalizes well to new viewpoints for these entities, but performance on
untrained entity types remains poor, highlighting learning specificity and the
need for comprehensive training. The main contributions of this work include:
(1) a data generation methodology tailored for rule-violation scenarios; (2)
the release of the OR-VSKC dataset and its associated benchmark as open-source
resources; and (3) an empirical analysis of violation-sensitive knowledge
consistency in representative MLLMs. The dataset and appendix are available at
https://github.com/zgg2577/VS-KC.

</details>


### [8] [How Can Multimodal Remote Sensing Datasets Transform Classification via SpatialNet-ViT?](https://arxiv.org/abs/2506.22501)
*Gautam Siddharth Kashyap,Manaswi Kulahara,Nipun Joshi,Usman Naseem*

Main category: cs.CV

TL;DR: 提出了一种名为SpatialNet-ViT的新模型，结合Vision Transformers和多任务学习，以提高遥感分类任务的泛化能力和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有研究多局限于特定任务或数据集，缺乏泛化能力，因此需要一种更通用的分类方法。

Method: 采用Vision Transformers和多任务学习，结合数据增强、迁移学习等技术，提升模型的鲁棒性和泛化能力。

Result: 模型在分类准确性和可扩展性方面表现更优。

Conclusion: SpatialNet-ViT为遥感分类任务提供了一种更通用且高效的解决方案。

Abstract: Remote sensing datasets offer significant promise for tackling key
classification tasks such as land-use categorization, object presence
detection, and rural/urban classification. However, many existing studies tend
to focus on narrow tasks or datasets, which limits their ability to generalize
across various remote sensing classification challenges. To overcome this, we
propose a novel model, SpatialNet-ViT, leveraging the power of Vision
Transformers (ViTs) and Multi-Task Learning (MTL). This integrated approach
combines spatial awareness with contextual understanding, improving both
classification accuracy and scalability. Additionally, techniques like data
augmentation, transfer learning, and multi-task learning are employed to
enhance model robustness and its ability to generalize across diverse datasets

</details>


### [9] [What Makes a Dribble Successful? Insights From 3D Pose Tracking Data](https://arxiv.org/abs/2506.22503)
*Michiel Schepers,Pieter Robberechts,Jan Van Haaren,Jesse Davis*

Main category: cs.CV

TL;DR: 研究利用三维姿态追踪数据改进足球盘带技能评估，发现平衡和方向对齐等姿态特征能提升预测盘带成功率的模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统2D位置数据无法全面捕捉盘带中的平衡、方向和控球等关键因素，限制了评估深度。

Method: 从2022/23赛季欧冠的1,736次盘带中提取姿态特征，结合传统2D数据评估其对盘带成功率的影响。

Result: 姿态特征（如平衡和方向对齐）能显著提升预测盘带成功率的模型性能。

Conclusion: 三维姿态数据为盘带技能评估提供了更深入的洞察，补充了传统2D数据的不足。

Abstract: Data analysis plays an increasingly important role in soccer, offering new
ways to evaluate individual and team performance. One specific application is
the evaluation of dribbles: one-on-one situations where an attacker attempts to
bypass a defender with the ball. While previous research has primarily relied
on 2D positional tracking data, this fails to capture aspects like balance,
orientation, and ball control, limiting the depth of current insights. This
study explores how pose tracking data (capturing players' posture and movement
in three dimensions) can improve our understanding of dribbling skills. We
extract novel pose-based features from 1,736 dribbles in the 2022/23 Champions
League season and evaluate their impact on dribble success. Our results
indicate that features capturing the attacker's balance and the alignment of
the orientation between the attacker and defender are informative for
predicting dribble success. Incorporating these pose-based features on top of
features derived from traditional 2D positional data leads to a measurable
improvement in model performance.

</details>


### [10] [Patch2Loc: Learning to Localize Patches for Unsupervised Brain Lesion Detection](https://arxiv.org/abs/2506.22504)
*Hassan Baker,Austin J. Brockmeier*

Main category: cs.CV

TL;DR: 提出了一种无监督学习方法Patch2Loc，通过训练神经网络从正常脑部MRI中学习空间位置映射，检测异常脑组织。


<details>
  <summary>Details</summary>
Motivation: 脑部病变检测对诊断和治疗至关重要，但现有监督学习方法需要标注数据，限制了应用。

Method: 训练神经网络将MRI图像块映射回其空间位置，异常区域通过预测误差或方差检测。

Result: 在多个数据集上验证，Patch2Loc在无监督分割中优于现有方法。

Conclusion: Patch2Loc为无监督脑部病变检测提供了高效解决方案。

Abstract: Detecting brain lesions as abnormalities observed in magnetic resonance
imaging (MRI) is essential for diagnosis and treatment. In the search of
abnormalities, such as tumors and malformations, radiologists may benefit from
computer-aided diagnostics that use computer vision systems trained with
machine learning to segment normal tissue from abnormal brain tissue. While
supervised learning methods require annotated lesions, we propose a new
unsupervised approach (Patch2Loc) that learns from normal patches taken from
structural MRI. We train a neural network model to map a patch back to its
spatial location within a slice of the brain volume. During inference, abnormal
patches are detected by the relatively higher error and/or variance of the
location prediction. This generates a heatmap that can be integrated into
pixel-wise methods to achieve finer-grained segmentation. We demonstrate the
ability of our model to segment abnormal brain tissues by applying our approach
to the detection of tumor tissues in MRI on T2-weighted images from BraTS2021
and MSLUB datasets and T1-weighted images from ATLAS and WMH datasets. We show
that it outperforms the state-of-the art in unsupervised segmentation. The
codebase for this work can be found on our
\href{https://github.com/bakerhassan/Patch2Loc}{GitHub page}.

</details>


### [11] [Weakly Supervised Object Segmentation by Background Conditional Divergence](https://arxiv.org/abs/2506.22505)
*Hassan Baker,Matthew S. Emigh,Austin J. Brockmeier*

Main category: cs.CV

TL;DR: 提出了一种利用弱监督（图像级标签）训练掩码网络进行二值目标分割的方法，通过生成反事实背景图像提升分割效果。


<details>
  <summary>Details</summary>
Motivation: 在缺乏大量标注数据的专业图像领域（如合成孔径声纳图像、遥感、生物医学图像等），自动目标分割仍具挑战性。像素级标注成本高，而图像级标签更易获取。

Method: 通过将分割目标放置到背景图像中生成反事实图像，利用背景聚类和样本差异损失进行训练。

Result: 在合成孔径声纳和侧扫声纳图像上表现优于无监督基线方法，并在自然图像上验证了方法的通用性。

Conclusion: 该方法避免了预训练网络、生成对抗网络和对抗判别器，展示了在弱监督下实现有效分割的潜力。

Abstract: As a computer vision task, automatic object segmentation remains challenging
in specialized image domains without massive labeled data, such as synthetic
aperture sonar images, remote sensing, biomedical imaging, etc. In any domain,
obtaining pixel-wise segmentation masks is expensive. In this work, we propose
a method for training a masking network to perform binary object segmentation
using weak supervision in the form of image-wise presence or absence of an
object of interest, which provides less information but may be obtained more
quickly from manual or automatic labeling. A key step in our method is that the
segmented objects can be placed into background-only images to create
realistic, images of the objects with counterfactual backgrounds. To create a
contrast between the original and counterfactual background images, we propose
to first cluster the background-only images, and then during learning create
counterfactual images that blend objects segmented from their original source
backgrounds to backgrounds chosen from a targeted cluster. One term in the
training loss is the divergence between these counterfactual images and the
real object images with backgrounds of the target cluster. The other term is a
supervised loss for background-only images. While an adversarial critic could
provide the divergence, we use sample-based divergences. We conduct experiments
on side-scan and synthetic aperture sonar in which our approach succeeds
compared to previous unsupervised segmentation baselines that were only tested
on natural images. Furthermore, to show generality we extend our experiments to
natural images, obtaining reasonable performance with our method that avoids
pretrained networks, generative networks, and adversarial critics. The basecode
for this work can be found at
\href{GitHub}{https://github.com/bakerhassan/WSOS}.

</details>


### [12] [FreeDNA: Endowing Domain Adaptation of Diffusion-Based Dense Prediction with Training-Free Domain Noise Alignment](https://arxiv.org/abs/2506.22509)
*Hang Xu,Jie Huang,Linjiang Huang,Dong Li,Yidi Liu,Feng Zhao*

Main category: cs.CV

TL;DR: 提出了一种无需训练的领域噪声对齐（DNA）方法，用于增强扩散密集预测（DDP）模型的领域适应能力。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在建模包含领域信息的分布转换方面表现优异，但噪声统计偏差会导致领域偏移，因此需要一种方法对齐噪声统计以实现领域适应。

Method: 提出DNA方法，通过对齐目标域和源域的噪声统计实现领域适应；在无源域情况下，利用高置信区域的统计逐步调整噪声。

Result: 在四种密集预测任务中验证了DNA方法的有效性。

Conclusion: DNA方法无需训练即可显著提升DDP模型的领域适应能力。

Abstract: Domain Adaptation(DA) for dense prediction tasks is an important topic, which
enhances the dense prediction model's performance when tested on its unseen
domain. Recently, with the development of Diffusion-based Dense Prediction
(DDP) models, the exploration of DA designs tailored to this framework is worth
exploring, since the diffusion model is effective in modeling the distribution
transformation that comprises domain information. In this work, we propose a
training-free mechanism for DDP frameworks, endowing them with DA capabilities.
Our motivation arises from the observation that the exposure bias (e.g., noise
statistics bias) in diffusion brings domain shift, and different domains in
conditions of DDP models can also be effectively captured by the noise
prediction statistics. Based on this, we propose a training-free Domain Noise
Alignment (DNA) approach, which alleviates the variations of noise statistics
to domain changes during the diffusion sampling process, thereby achieving
domain adaptation. Specifically, when the source domain is available, we
directly adopt the DNA method to achieve domain adaptation by aligning the
noise statistics of the target domain with those of the source domain. For the
more challenging source-free DA, inspired by the observation that regions
closer to the source domain exhibit higher confidence meeting variations of
sampling noise, we utilize the statistics from the high-confidence regions
progressively to guide the noise statistic adjustment during the sampling
process. Notably, our method demonstrates the effectiveness of enhancing the DA
capability of DDP models across four common dense prediction tasks. Code is
available at
\href{https://github.com/xuhang07/FreeDNA}{https://github.com/xuhang07/FreeDNA}.

</details>


### [13] [Lightning the Night with Generative Artificial Intelligence](https://arxiv.org/abs/2506.22511)
*Tingting Zhou,Feng Zhang,Haoyang Fu,Baoxiang Pan,Renhe Zhang,Feng Lu,Zhixin Yang*

Main category: cs.CV

TL;DR: 该研究利用生成扩散模型，基于FY4B卫星的多波段热红外数据，开发了RefDiff模型，实现了夜间可见光反射率的高精度反演，显著提升了复杂云结构区域的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决夜间因缺乏可见光而无法进行全天候气象观测的问题。

Method: 基于FY4B卫星的AGRI多波段热红外数据，开发了生成扩散模型RefDiff，用于夜间可见光反射率反演。

Result: RefDiff的SSIM指数达到0.90，在复杂云结构区域表现显著优于传统模型，并通过VIIRS夜间产品验证了其性能。

Conclusion: 该研究显著提升了夜间可见光反射率反演能力，拓展了夜间可见光数据的应用潜力。

Abstract: The visible light reflectance data from geostationary satellites is crucial
for meteorological observations and plays an important role in weather
monitoring and forecasting. However, due to the lack of visible light at night,
it is impossible to conduct continuous all-day weather observations using
visible light reflectance data. This study pioneers the use of generative
diffusion models to address this limitation. Based on the multi-band thermal
infrared brightness temperature data from the Advanced Geostationary Radiation
Imager (AGRI) onboard the Fengyun-4B (FY4B) geostationary satellite, we
developed a high-precision visible light reflectance retrieval model, called
Reflectance Diffusion (RefDiff), which enables 0.47~\mu\mathrm{m},
0.65~\mu\mathrm{m}, and 0.825~\mu\mathrm{m} bands visible light reflectance
retrieval at night. Compared to the classical models, RefDiff not only
significantly improves accuracy through ensemble averaging but also provides
uncertainty estimation. Specifically, the SSIM index of RefDiff can reach 0.90,
with particularly significant improvements in areas with complex cloud
structures and thick clouds. The model's nighttime retrieval capability was
validated using VIIRS nighttime product, demonstrating comparable performance
to its daytime counterpart. In summary, this research has made substantial
progress in the ability to retrieve visible light reflectance at night, with
the potential to expand the application of nighttime visible light data.

</details>


### [14] [Automated Defect Identification and Categorization in NDE 4.0 with the Application of Artificial Intelligence](https://arxiv.org/abs/2506.22513)
*Aditya Sharma*

Main category: cs.CV

TL;DR: 该研究开发了一个用于现代放射摄影的自动化故障检测和组织框架，通过虚拟缺陷增强和数据扩展优化数据集，并利用改进的U-net模型实现语义故障分割，最终在缺陷检测中表现出高灵敏度和效率。


<details>
  <summary>Details</summary>
Motivation: 解决现代放射摄影中信息解释不足的问题，优化虚拟缺陷增强方法，并通过NDE测量验证框架的可行性。

Method: 收集并分类223张飞机焊缝的CR照片，使用虚拟缺陷增强和数据扩展技术优化数据集，训练改进的U-net模型进行语义故障分割。

Result: 模型在缺陷检测中表现出高灵敏度（a90/95特性），且数据扩展方法显著优于其他方法，框架具有快速推理能力。

Conclusion: 该框架在实际测试中表现出潜力，可作为支持工具，不受特定设备或软件限制。

Abstract: This investigation attempts to create an automated framework for fault
detection and organization for usage in contemporary radiography, as per NDE
4.0. The review's goals are to address the lack of information that is
sufficiently explained, learn how to make the most of virtual defect increase,
and determine whether the framework is viable by using NDE measurements. As its
basic information source, the technique consists of compiling and categorizing
223 CR photographs of airplane welds. Information expansion systems, such as
virtual defect increase and standard increase, are used to work on the
preparation dataset. A modified U-net model is prepared using the improved data
to produce semantic fault division veils. To assess the effectiveness of the
model, NDE boundaries such as Case, estimating exactness, and misleading call
rate are used. Tiny a90/95 characteristics, which provide strong
differentiating evidence of flaws, reveal that the suggested approach achieves
exceptional awareness in defect detection. Considering a 90/95, size error, and
fake call rate in the weld area, the consolidated expansion approach clearly
wins. Due to the framework's fast derivation speed, large images can be broken
down efficiently and quickly. Professional controllers evaluate the transmitted
system in the field and believe that it has a guarantee as a support device in
the testing cycle, irrespective of particular equipment cut-off points and
programming resemblance.

</details>


### [15] [Container damage detection using advanced computer vision model Yolov12 vs Yolov11 vs RF-DETR A comparative analysis](https://arxiv.org/abs/2506.22517)
*Subhadip Kumar*

Main category: cs.CV

TL;DR: 比较了Yolov12、Yolov11和RF-DETR三种计算机视觉模型在集装箱损伤检测中的性能，发现RF-DETR在罕见损伤检测中表现更优。


<details>
  <summary>Details</summary>
Motivation: 集装箱损伤检测对延长使用寿命和避免安全隐患至关重要，需高效模型。

Method: 使用278张标注图像训练和测试三种模型，比较mAP和精度。

Result: Yolov11和12的mAP@50为81.9%，RF-DETR为77.7%，但后者在罕见损伤检测中表现更优。

Conclusion: RF-DETR更适合复杂场景下的集装箱损伤检测。

Abstract: Containers are an integral part of the logistics industry and act as a
barrier for cargo. A typical service life for a container is more than 20
years. However, overtime containers suffer various types of damage due to the
mechanical as well as natural factors. A damaged container is a safety hazard
for the employees handling it and a liability for the logistic company.
Therefore, a timely inspection and detection of the damaged container is a key
for prolonging service life as well as avoiding safety hazards. In this paper,
we will compare the performance of the damage detection by three
state-of-the-art advanced computer vision models Yolov12, Yolov11 and RF-DETR.
We will use a dataset of 278 annotated images to train, validate and test the
model. We will compare the mAP and precision of the model. The objective of
this paper is to identify the model that is best suited for container damage
detection. The result is mixed. mAP@50 score of Yolov11 and 12 was 81.9%
compared to RF-DETR, which was 77.7%. However, while testing the model for
not-so-common damaged containers, the RF-DETR model outperformed the others
overall, exhibiting superiority to accurately detecting both damaged containers
as well as damage occurrences with high confidence.

</details>


### [16] [MagShield: Towards Better Robustness in Sparse Inertial Motion Capture Under Magnetic Disturbances](https://arxiv.org/abs/2506.22907)
*Yunzhe Shao,Xinyu Yi,Lu Yin,Shihui Guo,Junhai Yong,Feng Xu*

Main category: cs.CV

TL;DR: MagShield是一种新方法，用于解决稀疏惯性运动捕捉系统中的磁干扰问题，通过检测和校正策略提高准确性。


<details>
  <summary>Details</summary>
Motivation: 现有IMU系统在磁干扰环境中容易产生方向估计错误，限制了实际应用。

Method: 采用“检测-校正”策略，通过多IMU联合分析检测磁干扰，并利用人体运动先验校正方向误差。

Result: 实验表明，MagShield显著提高了磁干扰下的运动捕捉准确性，并具有良好的兼容性。

Conclusion: MagShield是一种有效的解决方案，可提升稀疏惯性运动捕捉系统在磁干扰环境中的性能。

Abstract: This paper proposes a novel method called MagShield, designed to address the
issue of magnetic interference in sparse inertial motion capture (MoCap)
systems. Existing Inertial Measurement Unit (IMU) systems are prone to
orientation estimation errors in magnetically disturbed environments, limiting
their practical application in real-world scenarios. To address this problem,
MagShield employs a "detect-then-correct" strategy, first detecting magnetic
disturbances through multi-IMU joint analysis, and then correcting orientation
errors using human motion priors. MagShield can be integrated with most
existing sparse inertial MoCap systems, improving their performance in
magnetically disturbed environments. Experimental results demonstrate that
MagShield significantly enhances the accuracy of motion capture under magnetic
interference and exhibits good compatibility across different sparse inertial
MoCap systems.

</details>


### [17] [VisionScores -- A system-segmented image score dataset for deep learning tasks](https://arxiv.org/abs/2506.23030)
*Alejandro Romero Amezcua,Mariano José Juan Rivera Meraz*

Main category: cs.CV

TL;DR: VisionScores是首个系统分割的图像乐谱数据集，专注于双钢琴曲目，提供高信息密度的图像，支持机器和深度学习任务。


<details>
  <summary>Details</summary>
Motivation: 为机器和深度学习任务提供结构丰富、信息密集的图像乐谱数据，同时考虑图形相似性和作曲模式。

Method: 构建包含24.8k样本的数据集，分为两种场景：同一作曲类型不同作者（14k样本）和同一作者不同作曲类型（10.8k样本）。样本为128×512像素的灰度图像。

Result: 提供格式化样本、系统顺序、元数据、未分割全页乐谱和预格式化图像。

Conclusion: VisionScores为乐谱分析提供了全面的数据集，支持进一步研究。

Abstract: VisionScores presents a novel proposal being the first system-segmented image
score dataset, aiming to offer structure-rich, high information-density images
for machine and deep learning tasks. Delimited to two-handed piano pieces, it
was built to consider not only certain graphic similarity but also composition
patterns, as this creative process is highly instrument-dependent. It provides
two scenarios in relation to composer and composition type. The first, formed
by 14k samples, considers works from different authors but the same composition
type, specifically, Sonatinas. The latter, consisting of 10.8K samples,
presents the opposite case, various composition types from the same author,
being the one selected Franz Liszt. All of the 24.8k samples are formatted as
grayscale jpg images of $128 \times 512$ pixels. VisionScores supplies the
users not only the formatted samples but the systems' order and pieces'
metadata. Moreover, unsegmented full-page scores and the pre-formatted images
are included for further analysis.

</details>


### [18] [Preserve Anything: Controllable Image Synthesis with Object Preservation](https://arxiv.org/abs/2506.22531)
*Prasen Kumar Sharma,Neeraj Matiyali,Siddharth Srivastava,Gaurav Sharma*

Main category: cs.CV

TL;DR: 提出了一种名为“Preserve Anything”的新方法，通过N通道ControlNet解决文本到图像生成中的对象保存和语义一致性问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在保存多个对象、语义对齐和场景控制方面存在不足，需要一种更高效的解决方案。

Method: 采用N通道ControlNet，结合对象保存、背景引导和高频覆盖模块，确保细节保留和语义一致性。

Result: 在FID和CLIP-S指标上达到最优性能，用户研究显示在多个方面显著优于现有方法。

Conclusion: 该方法在对象保存、语义一致性和用户控制方面表现卓越，为图像合成提供了新方向。

Abstract: We introduce \textit{Preserve Anything}, a novel method for controlled image
synthesis that addresses key limitations in object preservation and semantic
consistency in text-to-image (T2I) generation. Existing approaches often fail
(i) to preserve multiple objects with fidelity, (ii) maintain semantic
alignment with prompts, or (iii) provide explicit control over scene
composition. To overcome these challenges, the proposed method employs an
N-channel ControlNet that integrates (i) object preservation with size and
placement agnosticism, color and detail retention, and artifact elimination,
(ii) high-resolution, semantically consistent backgrounds with accurate
shadows, lighting, and prompt adherence, and (iii) explicit user control over
background layouts and lighting conditions. Key components of our framework
include object preservation and background guidance modules, enforcing lighting
consistency and a high-frequency overlay module to retain fine details while
mitigating unwanted artifacts. We introduce a benchmark dataset consisting of
240K natural images filtered for aesthetic quality and 18K 3D-rendered
synthetic images with metadata such as lighting, camera angles, and object
relationships. This dataset addresses the deficiencies of existing benchmarks
and allows a complete evaluation. Empirical results demonstrate that our method
achieves state-of-the-art performance, significantly improving feature-space
fidelity (FID 15.26) and semantic alignment (CLIP-S 32.85) while maintaining
competitive aesthetic quality. We also conducted a user study to demonstrate
the efficacy of the proposed work on unseen benchmark and observed a remarkable
improvement of $\sim25\%$, $\sim19\%$, $\sim13\%$, and $\sim14\%$ in terms of
prompt alignment, photorealism, the presence of AI artifacts, and natural
aesthetics over existing works.

</details>


### [19] [JAM-Flow: Joint Audio-Motion Synthesis with Flow Matching](https://arxiv.org/abs/2506.23552)
*Mingi Kwon,Joonghyuk Shin,Jaeseok Jung,Jaesik Park,Youngjung Uh*

Main category: cs.CV

TL;DR: JAM-Flow是一个统一框架，通过流匹配和多模态扩散变换器（MM-DiT）同时合成面部运动和语音，支持多种输入条件。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常将面部运动合成和语音合成视为独立任务，忽略了二者的内在联系。

Method: 采用流匹配和MM-DiT架构，结合Motion-DiT和Audio-DiT模块，通过选择性联合注意力层实现跨模态交互。

Result: JAM-Flow支持多种输入条件（如文本、参考音频和运动），实现了同步的多模态合成。

Conclusion: JAM-Flow为音频-视觉合成提供了实用的整体解决方案，推动了多模态生成建模的发展。

Abstract: The intrinsic link between facial motion and speech is often overlooked in
generative modeling, where talking head synthesis and text-to-speech (TTS) are
typically addressed as separate tasks. This paper introduces JAM-Flow, a
unified framework to simultaneously synthesize and condition on both facial
motion and speech. Our approach leverages flow matching and a novel Multi-Modal
Diffusion Transformer (MM-DiT) architecture, integrating specialized Motion-DiT
and Audio-DiT modules. These are coupled via selective joint attention layers
and incorporate key architectural choices, such as temporally aligned
positional embeddings and localized joint attention masking, to enable
effective cross-modal interaction while preserving modality-specific strengths.
Trained with an inpainting-style objective, JAM-Flow supports a wide array of
conditioning inputs-including text, reference audio, and reference
motion-facilitating tasks such as synchronized talking head generation from
text, audio-driven animation, and much more, within a single, coherent model.
JAM-Flow significantly advances multi-modal generative modeling by providing a
practical solution for holistic audio-visual synthesis. project page:
https://joonghyuk.com/jamflow-web

</details>


### [20] [Seamless Interaction: Dyadic Audiovisual Motion Modeling and Large-Scale Dataset](https://arxiv.org/abs/2506.22554)
*Vasu Agrawal,Akinniyi Akinyemi,Kathryn Alvero,Morteza Behrooz,Julia Buffalini,Fabio Maria Carlucci,Joy Chen,Junming Chen,Zhang Chen,Shiyang Cheng,Praveen Chowdary,Joe Chuang,Antony D'Avirro,Jon Daly,Ning Dong,Mark Duppenthaler,Cynthia Gao,Jeff Girard,Martin Gleize,Sahir Gomez,Hongyu Gong,Srivathsan Govindarajan,Brandon Han,Sen He,Denise Hernandez,Yordan Hristov,Rongjie Huang,Hirofumi Inaguma,Somya Jain,Raj Janardhan,Qingyao Jia,Christopher Klaiber,Dejan Kovachev,Moneish Kumar,Hang Li,Yilei Li,Pavel Litvin,Wei Liu,Guangyao Ma,Jing Ma,Martin Ma,Xutai Ma,Lucas Mantovani,Sagar Miglani,Sreyas Mohan,Louis-Philippe Morency,Evonne Ng,Kam-Woh Ng,Tu Anh Nguyen,Amia Oberai,Benjamin Peloquin,Juan Pino,Jovan Popovic,Omid Poursaeed,Fabian Prada,Alice Rakotoarison,Alexander Richard,Christophe Ropers,Safiyyah Saleem,Vasu Sharma,Alex Shcherbyna,Jia Shen,Jie Shen,Anastasis Stathopoulos,Anna Sun,Paden Tomasello,Tuan Tran,Arina Turkatenko,Bo Wan,Chao Wang,Jeff Wang,Mary Williamson,Carleigh Wood,Tao Xiang,Yilin Yang,Julien Yao,Chen Zhang,Jiemin Zhang,Xinyue Zhang,Jason Zheng,Pavlo Zhyzheria,Jan Zikes,Michael Zollhoefer*

Main category: cs.CV

TL;DR: 论文介绍了Seamless Interaction Dataset，一个大规模面对面互动数据集，用于开发能理解和生成双向行为动态的AI模型，并展示了一系列相关模型及其应用。


<details>
  <summary>Details</summary>
Motivation: 开发能够理解和生成人类双向行为动态的AI技术，以推动社交智能AI的发展。

Method: 利用Seamless Interaction Dataset开发模型，生成与人类语音对齐的双向动作和面部表情，并结合LLM模型和2D/3D渲染方法。

Result: 模型能够生成情感响应和表达水平可控的动作，并展示出更直观的人机交互潜力。

Conclusion: 该研究为虚拟代理和多模态内容分析工具的发展提供了重要支持，推动了人机交互的进步。

Abstract: Human communication involves a complex interplay of verbal and nonverbal
signals, essential for conveying meaning and achieving interpersonal goals. To
develop socially intelligent AI technologies, it is crucial to develop models
that can both comprehend and generate dyadic behavioral dynamics. To this end,
we introduce the Seamless Interaction Dataset, a large-scale collection of over
4,000 hours of face-to-face interaction footage from over 4,000 participants in
diverse contexts. This dataset enables the development of AI technologies that
understand dyadic embodied dynamics, unlocking breakthroughs in virtual agents,
telepresence experiences, and multimodal content analysis tools. We also
develop a suite of models that utilize the dataset to generate dyadic motion
gestures and facial expressions aligned with human speech. These models can
take as input both the speech and visual behavior of their interlocutors. We
present a variant with speech from an LLM model and integrations with 2D and 3D
rendering methods, bringing us closer to interactive virtual agents.
Additionally, we describe controllable variants of our motion models that can
adapt emotional responses and expressivity levels, as well as generating more
semantically-relevant gestures. Finally, we discuss methods for assessing the
quality of these dyadic motion models, which are demonstrating the potential
for more intuitive and responsive human-AI interactions.

</details>


### [21] [HiNeuS: High-fidelity Neural Surface Mitigating Low-texture and Reflective Ambiguity](https://arxiv.org/abs/2506.23854)
*Yida Wang,Xueyang Zhang,Kun Zhan,Peng Jia,Xianpeng Lang*

Main category: cs.CV

TL;DR: HiNeuS是一个统一的神经表面重建框架，解决了多视角辐射不一致、无纹理区域关键点缺失和Eikonal约束过强导致的结构退化问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂场景下难以同时满足几何保真度和光度一致性，HiNeuS旨在通过统一框架解决这些核心限制。

Method: HiNeuS引入了三种技术：1) SDF引导的射线追踪进行微分可见性验证；2) 平面共形正则化；3) 基于物理的Eikonal松弛。

Result: 实验表明，HiNeuS在Chamfer距离上比反射感知基线减少21.4%，PSNR提高2.32 dB，并能恢复镜面反射、城市布局和无纹理表面。

Conclusion: HiNeuS通过协同优化外观和几何约束，实现了高性能的表面重建，并在逆渲染任务中展示了良好的泛化能力。

Abstract: Neural surface reconstruction faces persistent challenges in reconciling
geometric fidelity with photometric consistency under complex scene conditions.
We present HiNeuS, a unified framework that holistically addresses three core
limitations in existing approaches: multi-view radiance inconsistency, missing
keypoints in textureless regions, and structural degradation from over-enforced
Eikonal constraints during joint optimization. To resolve these issues through
a unified pipeline, we introduce: 1) Differential visibility verification
through SDF-guided ray tracing, resolving reflection ambiguities via continuous
occlusion modeling; 2) Planar-conformal regularization via ray-aligned geometry
patches that enforce local surface coherence while preserving sharp edges
through adaptive appearance weighting; and 3) Physically-grounded Eikonal
relaxation that dynamically modulates geometric constraints based on local
radiance gradients, enabling detail preservation without sacrificing global
regularity. Unlike prior methods that handle these aspects through sequential
optimizations or isolated modules, our approach achieves cohesive integration
where appearance-geometry constraints evolve synergistically throughout
training. Comprehensive evaluations across synthetic and real-world datasets
demonstrate state-of-the-art performance, including a 21.4% reduction in
Chamfer distance over reflection-aware baselines and 2.32 dB PSNR improvement
against neural rendering counterparts. Qualitative analyses reveal superior
capability in recovering specular instruments, urban layouts with
centimeter-scale infrastructure, and low-textured surfaces without local patch
collapse. The method's generalizability is further validated through successful
application to inverse rendering tasks, including material decomposition and
view-consistent relighting.

</details>


### [22] [Recomposed realities: animating still images via patch clustering and randomness](https://arxiv.org/abs/2506.22556)
*Markus Juvonen,Samuli Siltanen*

Main category: cs.CV

TL;DR: 提出了一种基于图像块的重建与动画方法，通过运动让静态图像生动起来。


<details>
  <summary>Details</summary>
Motivation: 利用现有图像数据，通过运动赋予静态图像生命力，强调重新诠释而非简单复制。

Method: 使用k-means聚类对图像块进行分组，通过匹配和随机采样从这些聚类中重建新目标图像。

Result: 实现了源域和目标域在概念上不同但局部结构共享的图像重建与动画效果。

Conclusion: 该方法通过重新诠释图像块，实现了静态图像到动态效果的转换，具有灵活性和创造性。

Abstract: We present a patch-based image reconstruction and animation method that uses
existing image data to bring still images to life through motion. Image patches
from curated datasets are grouped using k-means clustering and a new target
image is reconstructed by matching and randomly sampling from these clusters.
This approach emphasizes reinterpretation over replication, allowing the source
and target domains to differ conceptually while sharing local structures.

</details>


### [23] [Improving Token-based Object Detection with Video](https://arxiv.org/abs/2506.22562)
*Abhineet Singh,Nilanjan Ray*

Main category: cs.CV

TL;DR: 本文扩展了Pix2Seq目标检测器，提出了一种新的端到端视频目标检测方法，通过将对象表示为离散标记序列，解决了传统检测器的稀疏损失和后处理问题，并直接输出3D框或轨迹。


<details>
  <summary>Details</summary>
Motivation: 改进现有视频目标检测方法，解决传统方法中稀疏损失、后处理复杂以及2D框链接的问题。

Method: 将视频对象表示为可变长度的离散标记序列，直接输出3D框或轨迹，无需训练中的定位提示或后处理。

Result: 在多个数据集上优于Pix2Seq静态检测器，并在UA-DETRAC上与当前最优方法竞争。

Conclusion: 提出的方法在视频目标检测中表现优异，但受限于计算资源，仍有提升空间。

Abstract: This paper improves upon the Pix2Seq object detector by extending it for
videos. In the process, it introduces a new way to perform end-to-end video
object detection that improves upon existing video detectors in two key ways.
First, by representing objects as variable-length sequences of discrete tokens,
we can succinctly represent widely varying numbers of video objects, with
diverse shapes and locations, without having to inject any localization cues in
the training process. This eliminates the need to sample the space of all
possible boxes that constrains conventional detectors and thus solves the dual
problems of loss sparsity during training and heuristics-based postprocessing
during inference. Second, it conceptualizes and outputs the video objects as
fully integrated and indivisible 3D boxes or tracklets instead of generating
image-specific 2D boxes and linking these boxes together to construct the video
object, as done in most conventional detectors. This allows it to scale
effortlessly with available computational resources by simply increasing the
length of the video subsequence that the network takes as input, even
generalizing to multi-object tracking if the subsequence can span the entire
video. We compare our video detector with the baseline Pix2Seq static detector
on several datasets and demonstrate consistent improvement, although with
strong signs of being bottlenecked by our limited computational resources. We
also compare it with several video detectors on UA-DETRAC to show that it is
competitive with the current state of the art even with the computational
bottleneck. We make our code and models publicly available.

</details>


### [24] [Unifying Biomedical Vision-Language Expertise: Towards a Generalist Foundation Model via Multi-CLIP Knowledge Distillation](https://arxiv.org/abs/2506.22567)
*Shansong Wang,Zhecheng Jin,Mingzhe Hu,Mojtaba Safari,Feng Zhao,Chih-Wei Chang,Richard LJ Qiu,Justin Roper,David S. Yu,Xiaofeng Yang*

Main category: cs.CV

TL;DR: MMKD-CLIP通过多教师知识蒸馏构建高性能生物医学基础模型，克服数据稀缺和异构性问题，在58个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 生物医学领域缺乏大规模图像-文本数据，且数据模态和标准不统一，阻碍了通用基础模型的开发。

Method: 采用两阶段训练：首先在290万生物医学图像-文本对上预训练，然后从9个教师模型中提取1920万特征对进行特征级蒸馏。

Result: 在58个数据集上评估，涵盖1080万图像和9种模态，MMKD-CLIP在所有任务中均优于教师模型。

Conclusion: 多教师知识蒸馏是构建高性能生物医学基础模型的有效方法，适用于实际数据限制场景。

Abstract: CLIP models pretrained on natural images with billion-scale image-text pairs
have demonstrated impressive capabilities in zero-shot classification,
cross-modal retrieval, and open-ended visual answering. However, transferring
this success to biomedicine is hindered by the scarcity of large-scale
biomedical image-text corpora, the heterogeneity of image modalities, and
fragmented data standards across institutions. These limitations hinder the
development of a unified and generalizable biomedical foundation model trained
from scratch. To overcome this, we introduce MMKD-CLIP, a generalist biomedical
foundation model developed via Multiple Medical CLIP Knowledge Distillation.
Rather than relying on billion-scale raw data, MMKD-CLIP distills knowledge
from nine state-of-the-art domain-specific or generalist biomedical CLIP
models, each pretrained on millions of biomedical image-text pairs. Our
two-stage training pipeline first performs CLIP-style pretraining on over 2.9
million biomedical image-text pairs from 26 image modalities, followed by
feature-level distillation using over 19.2 million feature pairs extracted from
teacher models. We evaluate MMKD-CLIP on 58 diverse biomedical datasets,
encompassing over 10.8 million biomedical images across nine image modalities.
The evaluation spans six core task types: zero-shot classification, linear
probing, cross-modal retrieval, visual question answering, survival prediction,
and cancer diagnosis. MMKD-CLIP consistently outperforms all teacher models
while demonstrating remarkable robustness and generalization across image
domains and task settings. These results underscore that multi-teacher
knowledge distillation is a scalable and effective paradigm for building
high-performing biomedical foundation models under the practical constraints of
real-world data availability.

</details>


### [25] [Dual Atrous Separable Convolution for Improving Agricultural Semantic Segmentation](https://arxiv.org/abs/2506.22570)
*Chee Mei Ling,Thangarajah Akilan,Aparna Ravinda Phalke*

Main category: cs.CV

TL;DR: 提出了一种基于DeepLabV3的高效农业图像语义分割方法，通过DAS Conv模块和优化的跳跃连接，在性能和效率上取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 农业图像语义分割对精准农业至关重要，但现有方法在效率和性能上难以兼顾。

Method: 集成Dual Atrous Separable Convolution (DAS Conv)模块，优化跳跃连接，平衡扩张率和填充大小。

Result: 在Agriculture Vision数据集上表现优于基线，效率提升66%，性能接近复杂Transformer模型。

Conclusion: 提供了一种高效轻量的农业图像分割解决方案，适用于遥感应用。

Abstract: Agricultural image semantic segmentation is a pivotal component of modern
agriculture, facilitating accurate visual data analysis to improve crop
management, optimize resource utilization, and boost overall productivity. This
study proposes an efficient image segmentation method for precision
agriculture, focusing on accurately delineating farmland anomalies to support
informed decision-making and proactive interventions. A novel Dual Atrous
Separable Convolution (DAS Conv) module is integrated within the
DeepLabV3-based segmentation framework. The DAS Conv module is meticulously
designed to achieve an optimal balance between dilation rates and padding size,
thereby enhancing model performance without compromising efficiency. The study
also incorporates a strategic skip connection from an optimal stage in the
encoder to the decoder to bolster the model's capacity to capture fine-grained
spatial features. Despite its lower computational complexity, the proposed
model outperforms its baseline and achieves performance comparable to highly
complex transformer-based state-of-the-art (SOTA) models on the Agriculture
Vision benchmark dataset. It achieves more than 66% improvement in efficiency
when considering the trade-off between model complexity and performance,
compared to the SOTA model. This study highlights an efficient and effective
solution for improving semantic segmentation in remote sensing applications,
offering a computationally lightweight model capable of high-quality
performance in agricultural imagery.

</details>


### [26] [LIGHT: Multi-Modal Text Linking on Historical Maps](https://arxiv.org/abs/2506.22589)
*Yijun Lin,Rhett Olson,Junhan Wu,Yao-Yi Chiang,Jerod Weinman*

Main category: cs.CV

TL;DR: LIGHT是一种多模态方法，结合语言、图像和几何特征，用于链接历史地图上的文本，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 历史地图上的文本信息对多领域研究有价值，但现有方法难以有效链接文本片段，尤其是多词地名。

Method: LIGHT整合几何、视觉和语言特征，通过几何感知嵌入模块和多模态学习预测文本阅读顺序。

Result: LIGHT在ICDAR 2024/2025 MapText竞赛数据上表现优于现有方法。

Conclusion: 多模态学习对历史地图文本链接有效，LIGHT展示了其优势。

Abstract: Text on historical maps provides valuable information for studies in history,
economics, geography, and other related fields. Unlike structured or
semi-structured documents, text on maps varies significantly in orientation,
reading order, shape, and placement. Many modern methods can detect and
transcribe text regions, but they struggle to effectively ``link'' the
recognized text fragments, e.g., determining a multi-word place name. Existing
layout analysis methods model word relationships to improve text understanding
in structured documents, but they primarily rely on linguistic features and
neglect geometric information, which is essential for handling map text. To
address these challenges, we propose LIGHT, a novel multi-modal approach that
integrates linguistic, image, and geometric features for linking text on
historical maps. In particular, LIGHT includes a geometry-aware embedding
module that encodes the polygonal coordinates of text regions to capture
polygon shapes and their relative spatial positions on an image. LIGHT unifies
this geometric information with the visual and linguistic token embeddings from
LayoutLMv3, a pretrained layout analysis model. LIGHT uses the cross-modal
information to predict the reading-order successor of each text instance
directly with a bi-directional learning strategy that enhances sequence
robustness. Experimental results show that LIGHT outperforms existing methods
on the ICDAR 2024/2025 MapText Competition data, demonstrating the
effectiveness of multi-modal learning for historical map text linking.

</details>


### [27] [BrainMT: A Hybrid Mamba-Transformer Architecture for Modeling Long-Range Dependencies in Functional MRI Data](https://arxiv.org/abs/2506.22591)
*Arunkumar Kannan,Martin A. Lindquist,Brian Caffo*

Main category: cs.CV

TL;DR: BrainMT是一种新型混合框架，通过结合双向Mamba块和Transformer块，高效学习fMRI数据中的长程时空依赖关系，在分类和回归任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如CNN或Transformer）难以建模fMRI数据中的复杂关系，尤其是长程时空依赖。

Method: BrainMT采用两阶段框架：1) 双向Mamba块捕获全局时间交互；2) Transformer块建模全局空间关系。

Result: 在UKBioBank和Human Connectome Project数据集上，BrainMT在性别预测和认知智力预测任务中显著优于现有方法。

Conclusion: BrainMT通过高效学习时空依赖，为fMRI数据分析提供了新思路，代码将开源。

Abstract: Recent advances in deep learning have made it possible to predict phenotypic
measures directly from functional magnetic resonance imaging (fMRI) brain
volumes, sparking significant interest in the neuroimaging community. However,
existing approaches, primarily based on convolutional neural networks or
transformer architectures, often struggle to model the complex relationships
inherent in fMRI data, limited by their inability to capture long-range spatial
and temporal dependencies. To overcome these shortcomings, we introduce
BrainMT, a novel hybrid framework designed to efficiently learn and integrate
long-range spatiotemporal attributes in fMRI data. Our framework operates in
two stages: (1) a bidirectional Mamba block with a temporal-first scanning
mechanism to capture global temporal interactions in a computationally
efficient manner; and (2) a transformer block leveraging self-attention to
model global spatial relationships across the deep features processed by the
Mamba block. Extensive experiments on two large-scale public datasets,
UKBioBank and the Human Connectome Project, demonstrate that BrainMT achieves
state-of-the-art performance on both classification (sex prediction) and
regression (cognitive intelligence prediction) tasks, outperforming existing
methods by a significant margin. Our code and implementation details will be
made publicly available at this
https://github.com/arunkumar-kannan/BrainMT-fMRI

</details>


### [28] [Seg-R1: Segmentation Can Be Surprisingly Simple with Reinforcement Learning](https://arxiv.org/abs/2506.22624)
*Zuyao You,Zuxuan Wu*

Main category: cs.CV

TL;DR: Seg-R1利用强化学习提升大型多模态模型的像素级理解能力，通过GRPO方法在分割任务中表现优异，无需复杂修改即可实现高精度和强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过强化学习增强大型多模态模型在像素级任务（如前景分割）中的理解和推理能力。

Method: 采用Group Relative Policy Optimization (GRPO)方法，结合点提示和边界框提示，指导SAM2生成分割掩码。

Result: 在COD10K上达到0.873 S-measure，并在零样本任务中表现优异，如RefCOCOg（71.4 cIoU）和ReasonSeg（56.7 gIoU）。

Conclusion: 纯强化学习训练在分割任务中具有高效性和泛化能力，为像素级理解提供了新思路。

Abstract: We present Seg-R1, a preliminary exploration of using reinforcement learning
(RL) to enhance the pixel-level understanding and reasoning capabilities of
large multimodal models (LMMs). Starting with foreground segmentation tasks,
specifically camouflaged object detection (COD) and salient object detection
(SOD), our approach enables the LMM to generate point and bounding box prompts
in the next-token fashion, which are then used to guide SAM2 in producing
segmentation masks. We introduce Group Relative Policy Optimization (GRPO) into
the segmentation domain, equipping the LMM with pixel-level comprehension
through a carefully designed training strategy. Notably, Seg-R1 achieves
remarkable performance with purely RL-based training, achieving .873 S-measure
on COD10K without complex model modification. Moreover, we found that pure RL
training demonstrates strong open-world generalization. Despite being trained
solely on foreground segmentation image-mask pairs without text supervision,
Seg-R1 achieves impressive zero-shot performance on referring segmentation and
reasoning segmentation tasks, with 71.4 cIoU on RefCOCOg test and 56.7 gIoU on
ReasonSeg test, outperforming models fully supervised on these datasets.

</details>


### [29] [ReCo: Reminder Composition Mitigates Hallucinations in Vision-Language Models](https://arxiv.org/abs/2506.22636)
*Sotirios Panagiotis Chytas,Miso Choi,Hyunwoo J. Kim,Vikas Singh*

Main category: cs.CV

TL;DR: 论文提出了一种轻量级模块ReCo，用于缓解视觉语言模型（VLMs）中的幻觉问题，通过几何代数和关系组合的方法，显著提升了多个基准测试的性能。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLMs）在生成文本时容易产生幻觉（即生成与视觉输入无关或矛盾的文本），主要原因是模型对语言的过度依赖和视觉输入的‘记忆消退效应’。

Method: 提出了一种名为ReCo的小型可训练模块，基于几何代数和关系组合的思想，无需修改现有VLM结构即可直接应用。

Result: 在三种广泛使用的VLMs（InstructBLIP、LlaVA、MiniGPT4）上，ReCo模块显著缓解了记忆消退效应，并在多个基准测试中提升了性能。此外，ReCo还能与其他减少幻觉的方法结合使用，进一步提升效果。

Conclusion: ReCo模块是一种轻量级且通用的解决方案，能够有效减少VLMs中的幻觉问题，同时兼容其他方法，具有广泛的应用潜力。

Abstract: Vision Language Models (VLMs) show impressive capabilities in integrating and
reasoning with both visual and language data. But these models make mistakes. A
common finding -- similar to LLMs -- is their tendency to hallucinate, i.e.,
generate plausible sounding text which is not grounded in the visual input, or
at worst, is contradictory. A growing consensus attributes this behavior to an
over-reliance on language -- especially as the generation progresses, the model
suffers from a ``fading memory effect'' with respect to the provided visual
input. We study mechanisms by which this behavior can be controlled.
Specifically, using ideas from geometric algebra and relational compositions,
we propose the addition of a small, trainable module (named ReCo) on top of any
VLM -- no other modification is needed. We show that such a lightweight module
is able to mitigate the fading memory effect on three of the most widely used
VLMs (InstructBLIP, LlaVA, MiniGPT4), where we see performance improvements on
multiple benchmarks. Additionally, we show that our module can be combined with
many of the other approaches for reducing hallucination where we achieve
improved results for each one.

</details>


### [30] [CaO$_2$: Rectifying Inconsistencies in Diffusion-Based Dataset Distillation](https://arxiv.org/abs/2506.22637)
*Haoxuan Wang,Zhenghao Zhao,Junyi Wu,Yuzhang Shang,Gaowen Liu,Yan Yan*

Main category: cs.CV

TL;DR: 论文提出了一种名为CaO$_2$的两阶段扩散框架，解决了当前基于扩散的数据集蒸馏方法中的目标不一致和条件不一致问题，并在ImageNet上取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散的数据集蒸馏方法存在目标不一致和条件不一致的问题，影响了蒸馏效果和评估准确性。

Method: 提出了CaO$_2$框架，包括概率信息样本选择管道和潜在表示细化两阶段，以对齐蒸馏过程与评估目标。

Result: 在ImageNet及其子集上表现优异，平均准确率超过基线方法2.3%。

Conclusion: CaO$_2$通过优化蒸馏过程，显著提升了数据集蒸馏的性能和一致性。

Abstract: The recent introduction of diffusion models in dataset distillation has shown
promising potential in creating compact surrogate datasets for large,
high-resolution target datasets, offering improved efficiency and performance
over traditional bi-level/uni-level optimization methods. However, current
diffusion-based dataset distillation approaches overlook the evaluation process
and exhibit two critical inconsistencies in the distillation process: (1)
Objective Inconsistency, where the distillation process diverges from the
evaluation objective, and (2) Condition Inconsistency, leading to mismatches
between generated images and their corresponding conditions. To resolve these
issues, we introduce Condition-aware Optimization with Objective-guided
Sampling (CaO$_2$), a two-stage diffusion-based framework that aligns the
distillation process with the evaluation objective. The first stage employs a
probability-informed sample selection pipeline, while the second stage refines
the corresponding latent representations to improve conditional likelihood.
CaO$_2$ achieves state-of-the-art performance on ImageNet and its subsets,
surpassing the best-performing baselines by an average of 2.3% accuracy.

</details>


### [31] [3D Shape Generation: A Survey](https://arxiv.org/abs/2506.22678)
*Nicolas Caytuiro,Ivan Sipiran*

Main category: cs.CV

TL;DR: 本文综述了深度学习在3D形状生成领域的最新进展，重点讨论了形状表示、生成方法和评估协议，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 深度学习的发展推动了3D形状生成技术的进步，但目前缺乏对这一领域的系统综述，本文旨在填补这一空白。

Method: 文章围绕形状表示（显式、隐式和混合）、生成方法（前馈架构）和评估协议（数据集和指标）展开讨论。

Result: 总结了当前3D形状生成的技术现状，并提出了评估生成形状保真度、多样性和真实性的常用方法。

Conclusion: 本文为研究人员提供了3D形状生成领域的全面参考，并指出了可控性、高效性和高质量生成等未来研究方向。

Abstract: Recent advances in deep learning have significantly transformed the field of
3D shape generation, enabling the synthesis of complex, diverse, and
semantically meaningful 3D objects. This survey provides a comprehensive
overview of the current state of the art in 3D shape generation, organizing the
discussion around three core components: shape representations, generative
modeling approaches, and evaluation protocols. We begin by categorizing 3D
representations into explicit, implicit, and hybrid setups, highlighting their
structural properties, advantages, and limitations. Next, we review a wide
range of generation methods, focusing on feedforward architectures. We further
summarize commonly used datasets and evaluation metrics that assess fidelity,
diversity, and realism of generated shapes. Finally, we identify open
challenges and outline future research directions that could drive progress in
controllable, efficient, and high-quality 3D shape generation. This survey aims
to serve as a valuable reference for researchers and practitioners seeking a
structured and in-depth understanding of this rapidly evolving field.

</details>


### [32] [LightBSR: Towards Lightweight Blind Super-Resolution via Discriminative Implicit Degradation Representation Learning](https://arxiv.org/abs/2506.22710)
*Jiang Yuan,JI Ma,Bo Wang,Guanzhou Ke,Weiming Hu*

Main category: cs.CV

TL;DR: 论文提出了一种基于隐式退化估计的轻量级盲超分辨率模型LightBSR，通过优化隐式退化表示（IDR）的区分性，结合知识蒸馏和对比学习技术，实现了高性能且低复杂度的盲超分辨率任务。


<details>
  <summary>Details</summary>
Motivation: 现有IDE-BSR方法忽视了IDR区分性的重要性，且模型复杂度高，因此需要一种更高效且轻量的解决方案。

Method: 采用知识蒸馏框架，结合退化先验约束的对比学习技术（教师阶段）和特征对齐技术（学生阶段），优化IDR区分性。

Result: LightBSR在多种盲超分辨率任务中表现出色，且模型复杂度显著降低。

Conclusion: 优化IDR区分性是提升盲超分辨率性能的关键，LightBSR为轻量级高效模型设计提供了有效方案。

Abstract: Implicit degradation estimation-based blind super-resolution (IDE-BSR) hinges
on extracting the implicit degradation representation (IDR) of the LR image and
adapting it to LR image features to guide HR detail restoration. Although
IDE-BSR has shown potential in dealing with noise interference and complex
degradations, existing methods ignore the importance of IDR discriminability
for BSR and instead over-complicate the adaptation process to improve effect,
resulting in a significant increase in the model's parameters and computations.
In this paper, we focus on the discriminability optimization of IDR and propose
a new powerful and lightweight BSR model termed LightBSR. Specifically, we
employ a knowledge distillation-based learning framework. We first introduce a
well-designed degradation-prior-constrained contrastive learning technique
during teacher stage to make the model more focused on distinguishing different
degradation types. Then we utilize a feature alignment technique to transfer
the degradation-related knowledge acquired by the teacher to the student for
practical inferencing. Extensive experiments demonstrate the effectiveness of
IDR discriminability-driven BSR model design. The proposed LightBSR can achieve
outstanding performance with minimal complexity across a range of blind SR
tasks. Our code is accessible at: https://github.com/MJ-NCEPU/LightBSR.

</details>


### [33] [Part Segmentation and Motion Estimation for Articulated Objects with Dynamic 3D Gaussians](https://arxiv.org/abs/2506.22718)
*Jun-Jee Chao,Qingyuan Jiang,Volkan Isler*

Main category: cs.CV

TL;DR: 提出一种联合解决分割和运动估计的方法，通过3D高斯模型表示物体，适用于点云动态采样场景。


<details>
  <summary>Details</summary>
Motivation: 解决动态点云序列中因遮挡或多传感器异步采集导致点对应跟踪失效的问题。

Method: 使用时间依赖的3D高斯模型表示物体，通过高斯参数共享实现分割和运动估计。

Result: 在遮挡场景下，分割性能优于现有方法13%，且对缺失点更鲁棒。

Conclusion: 该方法在动态点云分析中表现优越，尤其在遮挡和点缺失情况下。

Abstract: Part segmentation and motion estimation are two fundamental problems for
articulated object motion analysis. In this paper, we present a method to solve
these two problems jointly from a sequence of observed point clouds of a single
articulated object. The main challenge in our problem setting is that the point
clouds are not assumed to be generated by a fixed set of moving points.
Instead, each point cloud in the sequence could be an arbitrary sampling of the
object surface at that particular time step. Such scenarios occur when the
object undergoes major occlusions, or if the dataset is collected using
measurements from multiple sensors asynchronously. In these scenarios, methods
that rely on tracking point correspondences are not appropriate. We present an
alternative approach based on a compact but effective representation where we
represent the object as a collection of simple building blocks modeled as 3D
Gaussians. We parameterize the Gaussians with time-dependent rotations,
translations, and scales that are shared across all time steps. With our
representation, part segmentation can be achieved by building correspondences
between the observed points and the Gaussians. Moreover, the transformation of
each point across time can be obtained by following the poses of the assigned
Gaussian (even when the point is not observed). Experiments show that our
method outperforms existing methods that solely rely on finding point
correspondences. Additionally, we extend existing datasets to emulate
real-world scenarios by considering viewpoint occlusions. We further
demonstrate that our method is more robust to missing points as compared to
existing approaches on these challenging datasets, even when some parts are
completely occluded in some time-steps. Notably, our part segmentation
performance outperforms the state-of-the-art method by 13% on point clouds with
occlusions.

</details>


### [34] [Deterministic Object Pose Confidence Region Estimation](https://arxiv.org/abs/2506.22720)
*Jinghao Wang,Zhang Li,Zi Wang,Banglei Guan,Yang Shang,Qifeng Yu*

Main category: cs.CV

TL;DR: 提出了一种确定性方法，用于高效估计6D姿态置信区域，解决了采样方法的速度慢和区域过大的问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于采样的6D姿态置信区域估计方法存在速度慢和置信区域过大的问题，限制了实际应用。

Method: 使用归纳共形预测校准高斯关键点分布，并通过隐函数定理将2D关键点置信区域直接传播到6D姿态置信区域。

Result: 在LineMOD Occlusion和SPEED数据集上，方法提高了姿态估计精度，减少了计算时间，置信区域体积显著减小（旋转减少99.9%，平移减少99.8%）。

Conclusion: 该方法提供了紧凑且高效的6D姿态置信区域估计，优于传统采样方法。

Abstract: 6D pose confidence region estimation has emerged as a critical direction,
aiming to perform uncertainty quantification for assessing the reliability of
estimated poses. However, current sampling-based approach suffers from critical
limitations that severely impede their practical deployment: 1) the sampling
speed significantly decreases as the number of samples increases. 2) the
derived confidence regions are often excessively large. To address these
challenges, we propose a deterministic and efficient method for estimating pose
confidence regions. Our approach uses inductive conformal prediction to
calibrate the deterministically regressed Gaussian keypoint distributions into
2D keypoint confidence regions. We then leverage the implicit function theorem
to propagate these keypoint confidence regions directly into 6D pose confidence
regions. This method avoids the inefficiency and inflated region sizes
associated with sampling and ensembling. It provides compact confidence regions
that cover the ground-truth poses with a user-defined confidence level.
Experimental results on the LineMOD Occlusion and SPEED datasets show that our
method achieves higher pose estimation accuracy with reduced computational
time. For the same coverage rate, our method yields significantly smaller
confidence region volumes, reducing them by up to 99.9\% for rotations and
99.8\% for translations. The code will be available soon.

</details>


### [35] [XTransfer: Cross-Modality Model Transfer for Human Sensing with Few Data at the Edge](https://arxiv.org/abs/2506.22726)
*Yu Zhang,Xi Zhang,Hualin zhou,Xinyuan Chen,Shang Gao,Hong Jia,Jianfei Yang,Yuankai Qi,Tao Gu*

Main category: cs.CV

TL;DR: XTransfer是一种资源高效、模态无关的模型迁移方法，通过模型修复和层重组解决边缘系统中深度学习模型的模态偏移和资源限制问题。


<details>
  <summary>Details</summary>
Motivation: 边缘系统中深度学习模型的训练和开发受限于传感器数据的稀缺性和资源约束，现有方法存在模态偏移和高资源需求的问题。

Method: XTransfer通过模型修复（修复模态偏移）和层重组（高效搜索和重组源模型层）实现资源高效的模型迁移。

Result: XTransfer在多种人类感知任务中达到最先进性能，同时显著降低数据收集、训练和部署成本。

Conclusion: XTransfer为边缘系统中的人类感知任务提供了一种高效、适应性强的解决方案。

Abstract: Deep learning for human sensing on edge systems offers significant
opportunities for smart applications. However, its training and development are
hindered by the limited availability of sensor data and resource constraints of
edge systems. Current methods that rely on transferring pre-trained models
often encounter issues such as modality shift and high resource demands,
resulting in substantial accuracy loss, resource overhead, and poor
adaptability across different sensing applications. In this paper, we propose
XTransfer, a first-of-its-kind method for resource-efficient, modality-agnostic
model transfer. XTransfer freely leverages single or multiple pre-trained
models and transfers knowledge across different modalities by (i) model
repairing that safely repairs modality shift in pre-trained model layers with
only few sensor data, and (ii) layer recombining that efficiently searches and
recombines layers of interest from source models in a layer-wise manner to
create compact models. We benchmark various baselines across diverse human
sensing datasets spanning different modalities. Comprehensive results
demonstrate that XTransfer achieves state-of-the-art performance on human
sensing tasks while significantly reducing the costs of sensor data collection,
model training, and edge deployment.

</details>


### [36] [UniFuse: A Unified All-in-One Framework for Multi-Modal Medical Image Fusion Under Diverse Degradations and Misalignments](https://arxiv.org/abs/2506.22736)
*Dayong Su,Yafei Zhang,Huafeng Li,Jinxing Li,Yu Liu*

Main category: cs.CV

TL;DR: UniFuse是一个通用的多模态医学图像融合框架，通过降解感知提示学习模块和Omni统一特征表示方案，解决了传统方法对高质量和对齐图像的依赖问题，实现了对齐、恢复和融合的联合优化。


<details>
  <summary>Details</summary>
Motivation: 当前多模态医学图像融合方法通常假设源图像质量高且像素级对齐，但在处理未对齐或降级图像时效果不佳。UniFuse旨在解决这一问题。

Method: UniFuse通过降解感知提示学习模块和Omni统一特征表示方案，结合Spatial Mamba编码多方向特征，并利用ALSN实现单阶段恢复与融合。

Result: 实验结果表明，UniFuse在多个数据集上表现优于现有方法，实现了对齐、恢复和融合的统一优化。

Conclusion: UniFuse通过统一框架解决了传统方法的局限性，为多模态医学图像融合提供了更高效的解决方案。

Abstract: Current multimodal medical image fusion typically assumes that source images
are of high quality and perfectly aligned at the pixel level. Its effectiveness
heavily relies on these conditions and often deteriorates when handling
misaligned or degraded medical images. To address this, we propose UniFuse, a
general fusion framework. By embedding a degradation-aware prompt learning
module, UniFuse seamlessly integrates multi-directional information from input
images and correlates cross-modal alignment with restoration, enabling joint
optimization of both tasks within a unified framework. Additionally, we design
an Omni Unified Feature Representation scheme, which leverages Spatial Mamba to
encode multi-directional features and mitigate modality differences in feature
alignment. To enable simultaneous restoration and fusion within an All-in-One
configuration, we propose a Universal Feature Restoration & Fusion module,
incorporating the Adaptive LoRA Synergistic Network (ALSN) based on LoRA
principles. By leveraging ALSN's adaptive feature representation along with
degradation-type guidance, we enable joint restoration and fusion within a
single-stage framework. Compared to staged approaches, UniFuse unifies
alignment, restoration, and fusion within a single framework. Experimental
results across multiple datasets demonstrate the method's effectiveness and
significant advantages over existing approaches.

</details>


### [37] [Intervening in Black Box: Concept Bottleneck Model for Enhancing Human Neural Network Mutual Understanding](https://arxiv.org/abs/2506.22803)
*Nuoye Xiong,Anqi Dong,Ning Wang,Cong Hua,Guangming Zhu,Mei Lin,Peiyi Shen,Liang Zhang*

Main category: cs.CV

TL;DR: 提出CBM-HNMU模型，通过概念瓶颈模型提升深度模型的可解释性和准确性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型复杂度增加导致可解释性下降，现有方法缺乏有效干预或仅针对样本级别。

Method: 利用概念瓶颈模型（CBM）近似黑盒推理，自动识别并修正有害概念，将修正后的知识蒸馏回原模型。

Result: 在多个数据集和模型上测试，最高准确率提升2.64%，平均准确率提升1.03%。

Conclusion: CBM-HNMU有效提升了模型的可解释性和性能。

Abstract: Recent advances in deep learning have led to increasingly complex models with
deeper layers and more parameters, reducing interpretability and making their
decisions harder to understand. While many methods explain black-box reasoning,
most lack effective interventions or only operate at sample-level without
modifying the model itself. To address this, we propose the Concept Bottleneck
Model for Enhancing Human-Neural Network Mutual Understanding (CBM-HNMU).
CBM-HNMU leverages the Concept Bottleneck Model (CBM) as an interpretable
framework to approximate black-box reasoning and communicate conceptual
understanding. Detrimental concepts are automatically identified and refined
(removed/replaced) based on global gradient contributions. The modified CBM
then distills corrected knowledge back into the black-box model, enhancing both
interpretability and accuracy. We evaluate CBM-HNMU on various CNN and
transformer-based models across Flower-102, CIFAR-10, CIFAR-100, FGVC-Aircraft,
and CUB-200, achieving a maximum accuracy improvement of 2.64% and a maximum
increase in average accuracy across 1.03%. Source code is available at:
https://github.com/XiGuaBo/CBM-HNMU.

</details>


### [38] [Deep Learning based Joint Geometry and Attribute Up-sampling for Large-Scale Colored Point Clouds](https://arxiv.org/abs/2506.22749)
*Yun Zhang,Feifan Chen,Na Li,Zhiwei Guo,Xu Wang,Fen Miao,Sam Kwong*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的联合几何和属性上采样方法（JGAU），用于生成大规模且更密集的彩色点云，并在实验中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 彩色点云是现实和沉浸式3D应用的主流表示，但生成高质量的大规模密集点云仍具挑战性。

Method: 提出JGAU框架，包括几何上采样网络和属性上采样网络，利用几何辅助信息建模属性邻域相关性，并引入两种粗属性上采样方法和属性增强模块。

Result: 在4倍、8倍、12倍和16倍上采样率下，PSNR分别达到33.90、32.10、31.10和30.39分贝，平均提升2.11至2.47分贝。

Conclusion: JGAU方法在彩色点云上采样中表现出显著优势，为高质量点云生成提供了有效解决方案。

Abstract: Colored point cloud, which includes geometry and attribute components, is a
mainstream representation enabling realistic and immersive 3D applications. To
generate large-scale and denser colored point clouds, we propose a deep
learning-based Joint Geometry and Attribute Up-sampling (JGAU) method that
learns to model both geometry and attribute patterns while leveraging spatial
attribute correlations. First, we establish and release a large-scale dataset
for colored point cloud up-sampling called SYSU-PCUD, containing 121
large-scale colored point clouds with diverse geometry and attribute
complexities across six categories and four sampling rates. Second, to improve
the quality of up-sampled point clouds, we propose a deep learning-based JGAU
framework that jointly up-samples geometry and attributes. It consists of a
geometry up-sampling network and an attribute up-sampling network, where the
latter leverages the up-sampled auxiliary geometry to model neighborhood
correlations of the attributes. Third, we propose two coarse attribute
up-sampling methods, Geometric Distance Weighted Attribute Interpolation
(GDWAI) and Deep Learning-based Attribute Interpolation (DLAI), to generate
coarse up-sampled attributes for each point. Then, an attribute enhancement
module is introduced to refine these up-sampled attributes and produce
high-quality point clouds by further exploiting intrinsic attribute and
geometry patterns. Extensive experiments show that the Peak Signal-to-Noise
Ratio (PSNR) achieved by the proposed JGAU method is 33.90 decibels, 32.10
decibels, 31.10 decibels, and 30.39 decibels for up-sampling rates of 4 times,
8 times, 12 times, and 16 times, respectively. Compared to state-of-the-art
methods, JGAU achieves average PSNR gains of 2.32 decibels, 2.47 decibels, 2.28
decibels, and 2.11 decibels at these four up-sampling rates, demonstrating
significant improvement.

</details>


### [39] [Degradation-Modeled Multipath Diffusion for Tunable Metalens Photography](https://arxiv.org/abs/2506.22753)
*Jianing Zhang,Jiayi Zhu,Feiyu Ji,Xiaokang Yang,Xiaoyun Yuan*

Main category: cs.CV

TL;DR: 提出了一种基于预训练模型的金属透镜摄影方法，通过多路径扩散和伪数据增强实现高保真图像重建。


<details>
  <summary>Details</summary>
Motivation: 金属透镜在超紧凑计算成像中潜力巨大，但面临光学退化和计算恢复的挑战，现有方法依赖精确校准或大量配对数据，难以实际应用。

Method: 采用Degradation-Modeled Multipath Diffusion框架，结合正、中、负提示路径平衡细节生成与退化抑制，并引入SVDA模块建模复杂退化。

Result: 实验表明，该方法优于现有技术，实现了高保真和锐利的图像重建。

Conclusion: 该方法为金属透镜摄影提供了一种无需大规模数据的高效解决方案，具有实际应用潜力。

Abstract: Metalenses offer significant potential for ultra-compact computational
imaging but face challenges from complex optical degradation and computational
restoration difficulties. Existing methods typically rely on precise optical
calibration or massive paired datasets, which are non-trivial for real-world
imaging systems. Furthermore, a lack of control over the inference process
often results in undesirable hallucinated artifacts. We introduce
Degradation-Modeled Multipath Diffusion for tunable metalens photography,
leveraging powerful natural image priors from pretrained models instead of
large datasets. Our framework uses positive, neutral, and negative-prompt paths
to balance high-frequency detail generation, structural fidelity, and
suppression of metalens-specific degradation, alongside \textit{pseudo} data
augmentation. A tunable decoder enables controlled trade-offs between fidelity
and perceptual quality. Additionally, a spatially varying degradation-aware
attention (SVDA) module adaptively models complex optical and sensor-induced
degradation. Finally, we design and build a millimeter-scale MetaCamera for
real-world validation. Extensive results show that our approach outperforms
state-of-the-art methods, achieving high-fidelity and sharp image
reconstruction. More materials: https://dmdiff.github.io/.

</details>


### [40] [RoboPearls: Editable Video Simulation for Robot Manipulation](https://arxiv.org/abs/2506.22756)
*Tao Tang,Likui Zhang,Youpeng Wen,Kaidong Zhang,Jia-Wang Bian,xia zhou,Tianyi Yan,Kun Zhan,Peng Jia,Hefeng Wu,Liang Lin,Xiaodan Liang*

Main category: cs.CV

TL;DR: RoboPearls是一个基于3D高斯散射的可编辑视频仿真框架，用于机器人操作，通过结合大语言模型和视觉语言模型，实现高效仿真和性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决真实世界演示数据采集成本高、效率低的问题，以及仿真与现实的差距。

Method: 利用3D高斯散射构建逼真仿真，结合增量语义蒸馏和3D正则化NNFM损失，并通过大语言模型和视觉语言模型自动化仿真流程。

Result: 在多个数据集和场景中验证了RoboPearls的有效性，包括RLBench、COLOSSEUM等。

Conclusion: RoboPearls提供了一种高效、用户友好的仿真解决方案，显著提升了机器人操作的学习效率。

Abstract: The development of generalist robot manipulation policies has seen
significant progress, driven by large-scale demonstration data across diverse
environments. However, the high cost and inefficiency of collecting real-world
demonstrations hinder the scalability of data acquisition. While existing
simulation platforms enable controlled environments for robotic learning, the
challenge of bridging the sim-to-real gap remains. To address these challenges,
we propose RoboPearls, an editable video simulation framework for robotic
manipulation. Built on 3D Gaussian Splatting (3DGS), RoboPearls enables the
construction of photo-realistic, view-consistent simulations from demonstration
videos, and supports a wide range of simulation operators, including various
object manipulations, powered by advanced modules like Incremental Semantic
Distillation (ISD) and 3D regularized NNFM Loss (3D-NNFM). Moreover, by
incorporating large language models (LLMs), RoboPearls automates the simulation
production process in a user-friendly manner through flexible command
interpretation and execution. Furthermore, RoboPearls employs a vision-language
model (VLM) to analyze robotic learning issues to close the simulation loop for
performance enhancement. To demonstrate the effectiveness of RoboPearls, we
conduct extensive experiments on multiple datasets and scenes, including
RLBench, COLOSSEUM, Ego4D, Open X-Embodiment, and a real-world robot, which
demonstrate our satisfactory simulation performance.

</details>


### [41] [Foundation Models for Zero-Shot Segmentation of Scientific Images without AI-Ready Data](https://arxiv.org/abs/2506.24039)
*Shubhabrata Mukherjee,Jack Lang,Obeen Kwon,Iryna Zenyuk,Valerie Brogden,Adam Weber,Daniela Ushizima*

Main category: cs.CV

TL;DR: Zenesis是一个无需代码的交互式平台，通过轻量级多模态适应技术和人机协作优化，显著提升科学图像分析的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决零样本和提示技术在稀缺科学图像数据上的局限性，降低科学图像数据准备的门槛。

Method: 开发轻量级多模态适应技术，支持零样本操作，并结合人机协作和启发式时间增强。

Result: 在FIB-SEM数据上，Zenesis表现优异，准确率、IOU和Dice分数均显著优于基线方法。

Conclusion: Zenesis是科学图像分析的强大工具，尤其适用于缺乏高质量标注数据的领域。

Abstract: Zero-shot and prompt-based technologies capitalized on using frequently
occurring images to transform visual reasoning tasks, which explains why such
technologies struggle with valuable yet scarce scientific image sets. In this
work, we propose Zenesis, a comprehensive no-code interactive platform designed
to minimize barriers posed by data readiness for scientific images. We develop
lightweight multi-modal adaptation techniques that enable zero-shot operation
on raw scientific data, along with human-in-the-loop refinement and
heuristic-based temporal enhancement options. We demonstrate the performance of
our approach through comprehensive comparison and validation on challenging
Focused Ion Beam Scanning Electron Microscopy (FIB-SEM) data of catalyst-loaded
membranes. Zenesis significantly outperforms baseline methods, achieving an
average accuracy of 0.947, an Intersection over Union (IOU) of 0.858, and a
Dice score of 0.923 for amorphous catalyst samples and accuracy of 0.987, an
IOU of 0.857, and a Dice score of 0.923 for crystalline samples. These results
mark a substantial improvement over traditional methods like Otsu thresholding
and even advanced models like Segment Anything Model (SAM) when used in
isolation. Our results demonstrate that Zenesis is a powerful tool for
scientific applications, particularly in fields where high-quality annotated
datasets are unavailable, accelerating accurate analysis of experimental
imaging.

</details>


### [42] [VSRM: A Robust Mamba-Based Framework for Video Super-Resolution](https://arxiv.org/abs/2506.22762)
*Dinh Phu Tran,Dao Duy Hung,Daeyoung Kim*

Main category: cs.CV

TL;DR: VSRM是一个基于Mamba的视频超分辨率框架，通过引入空间到时间和时间到空间的Mamba块以及可变形交叉Mamba对齐模块，实现了高效的长范围时空特征提取和动态帧对齐，同时提出频率Charbonnier-like损失以提升视觉质量。


<details>
  <summary>Details</summary>
Motivation: 解决CNN和Transformer在视频超分辨率任务中的局限性（CNN的局部感受野和Transformer的二次复杂度），利用Mamba的长序列建模能力和线性复杂度优势。

Method: 提出VSRM框架，包括空间到时间和时间到空间的Mamba块、可变形交叉Mamba对齐模块，以及频率Charbonnier-like损失函数。

Result: 在多个基准测试中取得了最先进的性能。

Conclusion: VSRM为视频超分辨率任务提供了高效且强大的解决方案，为未来研究奠定了基础。

Abstract: Video super-resolution remains a major challenge in low-level vision tasks.
To date, CNN- and Transformer-based methods have delivered impressive results.
However, CNNs are limited by local receptive fields, while Transformers
struggle with quadratic complexity, posing challenges for processing long
sequences in VSR. Recently, Mamba has drawn attention for its long-sequence
modeling, linear complexity, and large receptive fields. In this work, we
propose VSRM, a novel \textbf{V}ideo \textbf{S}uper-\textbf{R}esolution
framework that leverages the power of \textbf{M}amba. VSRM introduces
Spatial-to-Temporal Mamba and Temporal-to-Spatial Mamba blocks to extract
long-range spatio-temporal features and enhance receptive fields efficiently.
To better align adjacent frames, we propose Deformable Cross-Mamba Alignment
module. This module utilizes a deformable cross-mamba mechanism to make the
compensation stage more dynamic and flexible, preventing feature distortions.
Finally, we minimize the frequency domain gaps between reconstructed and
ground-truth frames by proposing a simple yet effective Frequency
Charbonnier-like loss that better preserves high-frequency content and enhances
visual quality. Through extensive experiments, VSRM achieves state-of-the-art
results on diverse benchmarks, establishing itself as a solid foundation for
future research.

</details>


### [43] [PhonemeFake: Redefining Deepfake Realism with Language-Driven Segmental Manipulation and Adaptive Bilevel Detection](https://arxiv.org/abs/2506.22783)
*Oguzhan Baser,Ahmet Ege Tanriverdi,Sriram Vishwanath,Sandeep P. Chinchali*

Main category: cs.CV

TL;DR: 论文提出PhonemeFake（PF）攻击方法，通过语言推理操纵关键语音片段，显著降低人类感知和基准准确率，并开源了检测模型和数据集。


<details>
  <summary>Details</summary>
Motivation: 现有Deepfake（DF）数据集未能真实反映攻击对人类感知的影响，需要更现实的攻击向量。

Method: 引入PF攻击方法，操纵关键语音片段，并开发自适应优先计算的双层DF片段检测模型。

Result: PF攻击降低人类感知42%，基准准确率94%；检测模型降低EER 91%，速度提升90%，计算开销小。

Conclusion: PF攻击和检测模型为DF攻击提供了更现实的评估和高效解决方案。

Abstract: Deepfake (DF) attacks pose a growing threat as generative models become
increasingly advanced. However, our study reveals that existing DF datasets
fail to deceive human perception, unlike real DF attacks that influence public
discourse. It highlights the need for more realistic DF attack vectors. We
introduce PhonemeFake (PF), a DF attack that manipulates critical speech
segments using language reasoning, significantly reducing human perception by
up to 42% and benchmark accuracies by up to 94%. We release an easy-to-use PF
dataset on HuggingFace and open-source bilevel DF segment detection model that
adaptively prioritizes compute on manipulated regions. Our extensive
experiments across three known DF datasets reveal that our detection model
reduces EER by 91% while achieving up to 90% speed-up, with minimal compute
overhead and precise localization beyond existing models as a scalable
solution.

</details>


### [44] [Single-Frame Point-Pixel Registration via Supervised Cross-Modal Feature Matching](https://arxiv.org/abs/2506.22784)
*Yu Han,Zhiwei Huang,Yanting Zhang,Fangjun Ding,Shen Cai,Rui Fan*

Main category: cs.CV

TL;DR: 提出了一种基于无检测器匹配框架的点像素配准方法，通过投影LiDAR强度图并使用注意力网络直接匹配，解决了单帧LiDAR稀疏性和噪声问题。


<details>
  <summary>Details</summary>
Motivation: 点云与图像之间的模态差异及单帧LiDAR的稀疏性导致现有方法效果不佳，需要改进。

Method: 将LiDAR强度图投影到2D视图，通过注意力网络进行跨模态匹配，并引入可重复性评分机制提升可靠性。

Result: 在KITTI、nuScenes和MIAS-LCEC-TF70基准测试中达到最优性能，优于依赖多帧点云的方法。

Conclusion: 无检测器匹配框架有效解决了单帧LiDAR的稀疏性问题，提升了点像素配准的鲁棒性和准确性。

Abstract: Point-pixel registration between LiDAR point clouds and camera images is a
fundamental yet challenging task in autonomous driving and robotic perception.
A key difficulty lies in the modality gap between unstructured point clouds and
structured images, especially under sparse single-frame LiDAR settings.
Existing methods typically extract features separately from point clouds and
images, then rely on hand-crafted or learned matching strategies. This separate
encoding fails to bridge the modality gap effectively, and more critically,
these methods struggle with the sparsity and noise of single-frame LiDAR, often
requiring point cloud accumulation or additional priors to improve reliability.
Inspired by recent progress in detector-free matching paradigms (e.g.
MatchAnything), we revisit the projection-based approach and introduce the
detector-free framework for direct point-pixel matching between LiDAR and
camera views. Specifically, we project the LiDAR intensity map into a 2D view
from the LiDAR perspective and feed it into an attention-based detector-free
matching network, enabling cross-modal correspondence estimation without
relying on multi-frame accumulation. To further enhance matching reliability,
we introduce a repeatability scoring mechanism that acts as a soft visibility
prior. This guides the network to suppress unreliable matches in regions with
low intensity variation, improving robustness under sparse input. Extensive
experiments on KITTI, nuScenes, and MIAS-LCEC-TF70 benchmarks demonstrate that
our method achieves state-of-the-art performance, outperforming prior
approaches on nuScenes (even those relying on accumulated point clouds),
despite using only single-frame LiDAR.

</details>


### [45] [RGE-GS: Reward-Guided Expansive Driving Scene Reconstruction via Diffusion Priors](https://arxiv.org/abs/2506.22800)
*Sicong Du,Jiarun Liu,Qifeng Chen,Hao-Xiang Chen,Tai-Jiang Mu,Sheng Yang*

Main category: cs.CV

TL;DR: RGE-GS是一种新型扩展重建框架，结合扩散生成和奖励引导的高斯积分，解决了3D高斯泼溅技术扩展中的物理不一致性和训练效率问题。


<details>
  <summary>Details</summary>
Motivation: 单次驾驶片段常导致道路结构扫描不完整，传感器模拟器需要扩展重建以有效回归驾驶行为。现有3D高斯泼溅技术扩展时引入物理不一致性并降低效率。

Method: 提出RGE-GS框架，包含奖励网络（优先选择一致性生成模式）和差异化训练策略（根据场景收敛指标调整高斯优化进度）。

Result: 在公开数据集上，RGE-GS在重建质量上达到最优性能。

Conclusion: RGE-GS通过奖励引导和差异化训练，显著提升了重建质量和收敛效率。

Abstract: A single-pass driving clip frequently results in incomplete scanning of the
road structure, making reconstructed scene expanding a critical requirement for
sensor simulators to effectively regress driving actions. Although contemporary
3D Gaussian Splatting (3DGS) techniques achieve remarkable reconstruction
quality, their direct extension through the integration of diffusion priors
often introduces cumulative physical inconsistencies and compromises training
efficiency. To address these limitations, we present RGE-GS, a novel expansive
reconstruction framework that synergizes diffusion-based generation with
reward-guided Gaussian integration. The RGE-GS framework incorporates two key
innovations: First, we propose a reward network that learns to identify and
prioritize consistently generated patterns prior to reconstruction phases,
thereby enabling selective retention of diffusion outputs for spatial
stability. Second, during the reconstruction process, we devise a
differentiated training strategy that automatically adjust Gaussian
optimization progress according to scene converge metrics, which achieving
better convergence than baseline methods. Extensive evaluations of publicly
available datasets demonstrate that RGE-GS achieves state-of-the-art
performance in reconstruction quality. Our source-code will be made publicly
available at https://github.com/CN-ADLab/RGE-GS. (Camera-ready version
incorporating reviewer suggestions will be updated soon.)

</details>


### [46] [Concept Pinpoint Eraser for Text-to-image Diffusion Models via Residual Attention Gate](https://arxiv.org/abs/2506.22806)
*Byung Hyun Lee,Sungjin Lim,Seunggyu Lee,Dong Un Kang,Se Young Chun*

Main category: cs.CV

TL;DR: 本文提出了一种名为Concept Pinpoint Eraser (CPE)的新框架，通过非线性模块选择性删除目标概念，同时保护其他概念，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅通过微调交叉注意力层删除目标概念，可能导致其他概念失真，因此需要更有效的方法。

Method: CPE通过添加非线性Residual Attention Gates (ResAGs)和注意力锚定损失，选择性删除目标概念并保护其他概念，同时采用对抗训练增强鲁棒性。

Result: 实验表明，CPE在删除名人、艺术风格和敏感内容等目标概念时，能更好地保护其他概念，并对抗攻击提示具有鲁棒性。

Conclusion: CPE通过非线性模块和对抗训练，显著提升了概念删除的效果和鲁棒性，优于现有方法。

Abstract: Remarkable progress in text-to-image diffusion models has brought a major
concern about potentially generating images on inappropriate or trademarked
concepts. Concept erasing has been investigated with the goals of deleting
target concepts in diffusion models while preserving other concepts with
minimal distortion. To achieve these goals, recent concept erasing methods
usually fine-tune the cross-attention layers of diffusion models. In this work,
we first show that merely updating the cross-attention layers in diffusion
models, which is mathematically equivalent to adding \emph{linear} modules to
weights, may not be able to preserve diverse remaining concepts. Then, we
propose a novel framework, dubbed Concept Pinpoint Eraser (CPE), by adding
\emph{nonlinear} Residual Attention Gates (ResAGs) that selectively erase (or
cut) target concepts while safeguarding remaining concepts from broad
distributions by employing an attention anchoring loss to prevent the
forgetting. Moreover, we adversarially train CPE with ResAG and learnable text
embeddings in an iterative manner to maximize erasing performance and enhance
robustness against adversarial attacks. Extensive experiments on the erasure of
celebrities, artistic styles, and explicit contents demonstrated that the
proposed CPE outperforms prior arts by keeping diverse remaining concepts while
deleting the target concepts with robustness against attack prompts. Code is
available at https://github.com/Hyun1A/CPE

</details>


### [47] [FreqDGT: Frequency-Adaptive Dynamic Graph Networks with Transformer for Cross-subject EEG Emotion Recognition](https://arxiv.org/abs/2506.22807)
*Yueyang Li,Shengyu Gong,Weiming Zeng,Nizhuan Wang,Wai Ting Siok*

Main category: cs.CV

TL;DR: FreqDGT是一种频率自适应动态图变换器，通过整合频率自适应处理、动态图学习和多尺度时间解缠网络，显著提高了跨被试情绪识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决跨被试情绪识别中的个体差异问题，利用EEG信号的高时间分辨率和真实性优势。

Method: 提出FreqDGT框架，包括频率自适应处理（FAP）、自适应动态图学习（ADGL）和多尺度时间解缠网络（MTDN）。

Result: 实验表明FreqDGT显著提高了跨被试情绪识别的准确性。

Conclusion: FreqDGT通过整合频率、空间和时间建模，有效解决了跨被试情绪识别的挑战。

Abstract: Electroencephalography (EEG) serves as a reliable and objective signal for
emotion recognition in affective brain-computer interfaces, offering unique
advantages through its high temporal resolution and ability to capture
authentic emotional states that cannot be consciously controlled. However,
cross-subject generalization remains a fundamental challenge due to individual
variability, cognitive traits, and emotional responses. We propose FreqDGT, a
frequency-adaptive dynamic graph transformer that systematically addresses
these limitations through an integrated framework. FreqDGT introduces
frequency-adaptive processing (FAP) to dynamically weight emotion-relevant
frequency bands based on neuroscientific evidence, employs adaptive dynamic
graph learning (ADGL) to learn input-specific brain connectivity patterns, and
implements multi-scale temporal disentanglement network (MTDN) that combines
hierarchical temporal transformers with adversarial feature disentanglement to
capture both temporal dynamics and ensure cross-subject robustness.
Comprehensive experiments demonstrate that FreqDGT significantly improves
cross-subject emotion recognition accuracy, confirming the effectiveness of
integrating frequency-adaptive, spatial-dynamic, and temporal-hierarchical
modeling while ensuring robustness to individual differences. The code is
available at https://github.com/NZWANG/FreqDGT.

</details>


### [48] [Efficient Multi-Crop Saliency Partitioning for Automatic Image Cropping](https://arxiv.org/abs/2506.22814)
*Andrew Hamara,Andrew C. Freeman*

Main category: cs.CV

TL;DR: 提出了一种高效提取多个非重叠裁剪区域的图像裁剪方法，扩展了固定纵横比裁剪算法。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅优化单个边界框，无法满足需要多个不连续裁剪区域的应用需求。

Method: 动态调整注意力阈值，无需重新计算整个显著性图即可移除已选裁剪区域。

Result: 方法在定性结果中表现良好，并具备未来数据集和基准的潜力。

Conclusion: 该方法高效且适用于多裁剪区域需求，为未来研究提供了方向。

Abstract: Automatic image cropping aims to extract the most visually salient regions
while preserving essential composition elements. Traditional saliency-aware
cropping methods optimize a single bounding box, making them ineffective for
applications requiring multiple disjoint crops. In this work, we extend the
Fixed Aspect Ratio Cropping algorithm to efficiently extract multiple
non-overlapping crops in linear time. Our approach dynamically adjusts
attention thresholds and removes selected crops from consideration without
recomputing the entire saliency map. We discuss qualitative results and
introduce the potential for future datasets and benchmarks.

</details>


### [49] [Unleashing the Multi-View Fusion Potential: Noise Correction in VLM for Open-Vocabulary 3D Scene Understanding](https://arxiv.org/abs/2506.22817)
*Xingyilang Yin,Jiale Wang,Xi Yang,Mutian Xu,Xu Gu,Nannan Wang*

Main category: cs.CV

TL;DR: MVOV3D提出了一种新方法，通过减少2D多视图融合中的噪声，提升开放词汇3D场景理解性能，无需训练即可实现。


<details>
  <summary>Details</summary>
Motivation: 现有方法在开放词汇3D场景理解中受限于3D数据量不足，且2D多视图融合因噪声问题表现不佳。

Method: MVOV3D利用CLIP编码的精确区域级图像和文本特征，结合3D几何先验优化多视图融合。

Result: 在ScanNet200和Matterport160上分别取得14.7%和16.2%的mIoU，显著优于现有方法。

Conclusion: MVOV3D通过减少噪声和优化融合，显著提升了开放词汇3D场景理解的性能。

Abstract: Recent open-vocabulary 3D scene understanding approaches mainly focus on
training 3D networks through contrastive learning with point-text pairs or by
distilling 2D features into 3D models via point-pixel alignment. While these
methods show considerable performance in benchmarks with limited vocabularies,
they struggle to handle diverse object categories as the limited amount of 3D
data upbound training strong open-vocabulary 3d models. We observe that 2D
multi-view fusion methods take precedence in understanding diverse concepts in
3D scenes. However, inherent noises in vision-language models lead multi-view
fusion to sub-optimal performance. To this end, we introduce MVOV3D, a novel
approach aimed at unleashing the potential of 2D multi-view fusion for
open-vocabulary 3D scene understanding. We focus on reducing the inherent
noises without training, thereby preserving the generalizability while
enhancing open-world capabilities. Specifically, MVOV3D improves multi-view 2D
features by leveraging precise region-level image features and text features
encoded by CLIP encoders and incorporates 3D geometric priors to optimize
multi-view fusion. Extensive experiments on various datasets demonstrate the
effectiveness of our method. Notably, our MVOV3D achieves a new record with
14.7% mIoU on ScanNet200 and 16.2% mIoU on Matterport160 for challenge
open-vocabulary semantic segmentation, outperforming current leading trained 3D
networks by a significant margin.

</details>


### [50] [Prompting without Panic: Attribute-aware, Zero-shot, Test-Time Calibration](https://arxiv.org/abs/2506.22819)
*Ramya Hebbalaguppe,Tamoghno Kandar,Abhinav Nagpal,Chetan Arora*

Main category: cs.CV

TL;DR: 本文提出了一种改进测试时间提示调优（TPT）的方法，通过利用大语言模型（LLM）初始化提示并引入正则化损失，显著提升了视觉语言模型（VLM）的置信度校准性能。


<details>
  <summary>Details</summary>
Motivation: TPT方法在提升准确率的同时忽视了置信度校准，导致在关键应用中受限。本文旨在解决这一问题。

Method: 1. 使用LLM初始化测试时间提示以避免过拟合；2. 提出正则化损失以减少类内距离并增加类间距离。

Result: 在15个数据集上的实验显示，本文方法（TCA）的平均预期校准误差（ECE）为4.11，显著优于其他方法。

Conclusion: TCA方法有效解决了TPT的校准问题，为关键应用提供了更可靠的模型。

Abstract: Vision-language models (VLM) have demonstrated impressive performance in
image recognition by leveraging self-supervised training on large datasets.
Their performance can be further improved by adapting to the test sample using
test-time prompt tuning (TPT). Unfortunately, the singular focus of TPT
approaches on improving the accuracy suffers from tunnel vision, and leads to
degradation in confidence calibration. This limits the applicability of TPT in
critical applications.
  We make three contributions in this work. (1) We posit that random or naive
initialization of prompts leads to overfitting on a particular test sample, and
is the main reason for miscalibration of the VLM after TPT. To mitigate the
problem, we propose careful initialization of test time prompt using prior
knowledge about the target label attributes from a large language model (LLM);
(2) To further maintain the quality of prompts during \tpt, we propose a novel
regularization loss to reduce intraclass distance, and increase inter-class
distance between the learnt
  Through extensive experiments on different CLIP architectures and 15
datasets, we show that our approach can effectively improve the calibration
after TPT. We report an average expected calibration error (ECE) of 4.11 with
our method, TCA, compared to 11.7 for vanilla TPT, 6.12 for C-TPT (ICLR'24),
6.78 for DiffTPT (CVPR'23), and 8.43 for PromptAlign (NeurIPS'23). The code is
publicly accessible at:
https://github.com/rhebbalaguppe/TCA_PromptWithoutPanic.

</details>


### [51] [RoboScape: Physics-informed Embodied World Model](https://arxiv.org/abs/2506.23135)
*Yu Shang,Xin Zhang,Yinzhou Tang,Lei Jin,Chen Gao,Wei Wu,Yong Li*

Main category: cs.CV

TL;DR: RoboScape是一个统一的物理感知世界模型，通过联合学习RGB视频生成和物理知识，解决了现有模型在3D几何和运动动态建模上的不足。


<details>
  <summary>Details</summary>
Motivation: 当前的世界模型在物理感知方面表现有限，尤其是在3D几何和运动动态建模上，导致生成的视频在接触丰富的机器人场景中不真实。

Method: RoboScape通过两个关键物理感知联合训练任务（时间深度预测和关键点动态学习）来提升视频生成的几何一致性和运动建模。

Result: 实验表明，RoboScape生成的视频在视觉保真度和物理合理性上表现优异，并在下游应用中验证了其实用性。

Conclusion: RoboScape为构建高效的物理感知世界模型提供了新思路，推动了具身智能研究的进展。

Abstract: World models have become indispensable tools for embodied intelligence,
serving as powerful simulators capable of generating realistic robotic videos
while addressing critical data scarcity challenges. However, current embodied
world models exhibit limited physical awareness, particularly in modeling 3D
geometry and motion dynamics, resulting in unrealistic video generation for
contact-rich robotic scenarios. In this paper, we present RoboScape, a unified
physics-informed world model that jointly learns RGB video generation and
physics knowledge within an integrated framework. We introduce two key
physics-informed joint training tasks: temporal depth prediction that enhances
3D geometric consistency in video rendering, and keypoint dynamics learning
that implicitly encodes physical properties (e.g., object shape and material
characteristics) while improving complex motion modeling. Extensive experiments
demonstrate that RoboScape generates videos with superior visual fidelity and
physical plausibility across diverse robotic scenarios. We further validate its
practical utility through downstream applications including robotic policy
training with generated data and policy evaluation. Our work provides new
insights for building efficient physics-informed world models to advance
embodied intelligence research. The code is available at:
https://github.com/tsinghua-fib-lab/RoboScape.

</details>


### [52] [Listener-Rewarded Thinking in VLMs for Image Preferences](https://arxiv.org/abs/2506.22832)
*Alexander Gambashidze,Li Pengyi,Matvey Skripkin,Andrey Galichin,Anton Gusarov,Konstantin Sobolev,Andrey Kuznetsov,Ivan Oseledets*

Main category: cs.CV

TL;DR: 论文提出了一种基于听众增强的GRPO框架，通过校准置信度分数改进奖励模型，显著提升了泛化性能和推理一致性。


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型泛化能力不足，监督微调易导致记忆化，需复杂标注流程。强化学习（如GRPO）虽提升泛化性，但推理准确性因与独立视觉语言模型矛盾而下降。

Method: 引入听众增强的GRPO框架，听众重新评估推理链并提供校准置信度分数，形成密集奖励信号，促使推理模型生成更具说服力的解释。

Result: 在ImageReward基准上达到67.4%的最佳准确率，大规模人类偏好数据集上OOD性能提升6%，推理矛盾减少。

Conclusion: 听众增强的奖励机制为视觉语言模型与人类偏好对齐提供了可扩展且数据高效的路径。

Abstract: Training robust and generalizable reward models for human visual preferences
is essential for aligning text-to-image and text-to-video generative models
with human intent. However, current reward models often fail to generalize, and
supervised fine-tuning leads to memorization, demanding complex annotation
pipelines. While reinforcement learning (RL), specifically Group Relative
Policy Optimization (GRPO), improves generalization, we uncover a key failure
mode: a significant drop in reasoning accuracy occurs when a model's reasoning
trace contradicts that of an independent, frozen vision-language model
("listener") evaluating the same output. To address this, we introduce a
listener-augmented GRPO framework. Here, the listener re-evaluates the
reasoner's chain-of-thought to provide a dense, calibrated confidence score,
shaping the RL reward signal. This encourages the reasoner not only to answer
correctly, but to produce explanations that are persuasive to an independent
model. Our listener-shaped reward scheme achieves best accuracy on the
ImageReward benchmark (67.4%), significantly improves out-of-distribution (OOD)
performance on a large-scale human preference dataset (1.2M votes, up to +6%
over naive reasoner), and reduces reasoning contradictions compared to strong
GRPO and SFT baselines. These results demonstrate that listener-based rewards
provide a scalable, data-efficient path to aligning vision-language models with
nuanced human preferences. We will release our reasoning model here:
https://huggingface.co/alexgambashidze/qwen2.5vl_image_preference_reasoner.

</details>


### [53] [Towards foundational LiDAR world models with efficient latent flow matching](https://arxiv.org/abs/2506.23434)
*Tianran Liu,Shengwen Zhao,Nicholas Rhinehart*

Main category: cs.CV

TL;DR: 论文提出了一种基于LiDAR的世界模型，通过域转移研究展示了其跨域适应性，并提出了一种新的CFM框架，显著提升了性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有LiDAR世界模型局限于单一领域，缺乏跨域适应性，且依赖大量标注数据。研究旨在开发具有强迁移能力的模型，减少对标注数据的依赖。

Method: 通过域转移研究（户外到室内、稀疏到密集光束、非语义到语义转移），提出基于条件流匹配（CFM）的框架，优化数据压缩和训练目标。

Result: 单一预训练模型在30/36的比较中优于从头训练，仅需5%标注数据即可超越现有语义占用预测模型。CFM框架在重建精度和计算效率上达到SOTA。

Conclusion: 提出的CFM框架显著提升了LiDAR世界模型的跨域适应性和计算效率，为减少标注数据需求提供了有效解决方案。

Abstract: LiDAR-based world models offer more structured and geometry-aware
representations than their image-based counterparts. However, existing LiDAR
world models are narrowly trained; each model excels only in the domain for
which it was built. Can we develop LiDAR world models that exhibit strong
transferability across multiple domains? We conduct the first systematic domain
transfer study across three demanding scenarios: (i) outdoor to indoor
generalization, (ii) sparse-beam \& dense-beam adaptation, and (iii)
non-semantic to semantic transfer. Given different amounts of fine-tuning data,
our experiments show that a single pre-trained model can achieve up to 11%
absolute improvement (83\% relative) over training from scratch and outperforms
training from scratch in 30/36 of our comparisons. This transferability of
dynamic learning significantly reduces the reliance on manually annotated data
for semantic occupancy forecasting: our method exceed the previous semantic
occupancy forecasting models with only 5% of the labeled training data required
by prior models. We also observed inefficiencies of current LiDAR world models,
mainly through their under-compression of LiDAR data and inefficient training
objectives. To address this, we propose a latent conditional flow matching
(CFM)-based frameworks that achieves state-of-the-art reconstruction accuracy
using only half the training data and a compression ratio 6 times higher than
that of prior methods. Our model achieves SOTA performance on
future-trajectory-conditioned semantic occupancy forecasting while being 23x
more computationally efficient (a 28x FPS speedup); and achieves SOTA
performance on semantic occupancy forecasting while being 2x more
computationally efficient (a 1.1x FPS speedup).

</details>


### [54] [SemFaceEdit: Semantic Face Editing on Generative Radiance Manifolds](https://arxiv.org/abs/2506.22833)
*Shashikant Verma,Shanmuganathan Raman*

Main category: cs.CV

TL;DR: SemFaceEdit是一种基于生成辐射流形的新方法，通过语义场实现面部图像的局部编辑，同时保持其他区域的完整性。


<details>
  <summary>Details</summary>
Motivation: 现有3D感知GAN技术虽提供多视角一致性，但缺乏局部编辑能力，因此需要一种能够精确编辑特定面部语义的方法。

Method: SemFaceEdit通过几何模块生成语义辐射和占据场，外观模块预测RGB辐射，两者在对抗训练中联合学习语义感知的几何和外观描述符。

Result: 实验表明，SemFaceEdit在语义场编辑方面表现优异，实现了更好的辐射场解耦。

Conclusion: SemFaceEdit通过语义场和辐射流形的结合，为面部图像的局部编辑提供了高效且精确的解决方案。

Abstract: Despite multiple view consistency offered by 3D-aware GAN techniques, the
resulting images often lack the capacity for localized editing. In response,
generative radiance manifolds emerge as an efficient approach for constrained
point sampling within volumes, effectively reducing computational demands and
enabling the learning of fine details. This work introduces SemFaceEdit, a
novel method that streamlines the appearance and geometric editing process by
generating semantic fields on generative radiance manifolds. Utilizing latent
codes, our method effectively disentangles the geometry and appearance
associated with different facial semantics within the generated image. In
contrast to existing methods that can change the appearance of the entire
radiance field, our method enables the precise editing of particular facial
semantics while preserving the integrity of other regions. Our network
comprises two key modules: the Geometry module, which generates semantic
radiance and occupancy fields, and the Appearance module, which is responsible
for predicting RGB radiance. We jointly train both modules in adversarial
settings to learn semantic-aware geometry and appearance descriptors. The
appearance descriptors are then conditioned on their respective semantic latent
codes by the Appearance Module, facilitating disentanglement and enhanced
control. Our experiments highlight SemFaceEdit's superior performance in
semantic field-based editing, particularly in achieving improved radiance field
disentanglement.

</details>


### [55] [StyleDrive: Towards Driving-Style Aware Benchmarking of End-To-End Autonomous Driving](https://arxiv.org/abs/2506.23982)
*Ruiyang Hao,Bowen Jing,Haibao Yu,Zaiqing Nie*

Main category: cs.CV

TL;DR: 该论文提出了首个大规模真实世界数据集，用于个性化端到端自动驾驶（E2EAD），并通过视觉语言模型（VLM）和行为分析生成高质量偏好标注，为个性化E2EAD研究奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 个性化在传统自动驾驶系统中已有研究，但在端到端自动驾驶（E2EAD）中被忽视，而用户对齐行为对自动驾驶的信任和普及至关重要。缺乏大规模标注数据集阻碍了相关研究。

Method: 从真实道路拓扑中提取静态环境特征，使用VLM推断动态上下文，通过行为分布分析和规则启发式生成客观偏好标注，并结合VLM生成主观标注，最终通过人工验证融合两种标注。

Result: 提出了首个个性化E2EAD评估基准，实验表明结合个性化偏好的模型更符合人类驾驶行为。

Conclusion: 该研究为个性化E2EAD提供了标准化平台，推动了以人为中心的自动驾驶研究。

Abstract: While personalization has been explored in traditional autonomous driving
systems, it remains largely overlooked in end-to-end autonomous driving
(E2EAD), despite its growing prominence. This gap is critical, as user-aligned
behavior is essential for trust, comfort, and widespread adoption of autonomous
vehicles. A core challenge is the lack of large-scale real-world datasets
annotated with diverse and fine-grained driving preferences, hindering the
development and evaluation of personalized E2EAD models. In this work, we
present the first large-scale real-world dataset enriched with annotations
capturing diverse driving preferences, establishing a foundation for
personalization in E2EAD. We extract static environmental features from
real-world road topology and infer dynamic contextual cues using a fine-tuned
visual language model (VLM), enabling consistent and fine-grained scenario
construction. Based on these scenarios, we derive objective preference
annotations through behavioral distribution analysis and rule-based heuristics.
To address the inherent subjectivity of driving style, we further employ the
VLM to generate subjective annotations by jointly modeling scene semantics and
driver behavior. Final high-quality labels are obtained through a
human-in-the-loop verification process that fuses both perspectives. Building
on this dataset, we propose the first benchmark for evaluating personalized
E2EAD models. We assess several state-of-the-art models with and without
preference conditioning, demonstrating that incorporating personalized
preferences results in behavior more aligned with human driving. Our work lays
the foundation for personalized E2EAD by providing a standardized platform to
systematically integrate human preferences into data-driven E2EAD systems,
catalyzing future research in human-centric autonomy.

</details>


### [56] [FOCUS: Fine-grained Optimization with Semantic Guided Understanding for Pedestrian Attributes Recognition](https://arxiv.org/abs/2506.22836)
*Hongyan An,Kuan Zhu,Xin He,Haiyun Guo,Chaoyang Zhao,Ming Tang,Jinqiao Wang*

Main category: cs.CV

TL;DR: 论文提出FOCUS方法，通过多粒度混合令牌和属性引导视觉特征提取模块，自适应地为每个属性提取细粒度特征，解决了现有方法在行人属性识别中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常提取区域特征来预测预定义的固定属性集，这限制了性能和实践性，因为区域特征可能牺牲某些属性的细粒度模式，且无法泛化到未见过的属性。

Method: 提出FOCUS方法，包括多粒度混合令牌（MGMT）捕获不同视觉粒度的潜在特征，属性引导视觉特征提取（AVFE）模块利用文本属性查询视觉特征，以及区域感知对比学习（RACL）确保属性关注正确的令牌。

Result: 在PA100K、PETA和RAPv1数据集上的实验证明了方法的有效性和强泛化能力。

Conclusion: FOCUS方法通过自适应提取细粒度属性级特征，显著提升了行人属性识别的性能和泛化能力。

Abstract: Pedestrian attribute recognition (PAR) is a fundamental perception task in
intelligent transportation and security. To tackle this fine-grained task, most
existing methods focus on extracting regional features to enrich attribute
information. However, a regional feature is typically used to predict a fixed
set of pre-defined attributes in these methods, which limits the performance
and practicality in two aspects: 1) Regional features may compromise
fine-grained patterns unique to certain attributes in favor of capturing common
characteristics shared across attributes. 2) Regional features cannot
generalize to predict unseen attributes in the test time. In this paper, we
propose the \textbf{F}ine-grained \textbf{O}ptimization with semanti\textbf{C}
g\textbf{U}ided under\textbf{S}tanding (FOCUS) approach for PAR, which
adaptively extracts fine-grained attribute-level features for each attribute
individually, regardless of whether the attributes are seen or not during
training. Specifically, we propose the Multi-Granularity Mix Tokens (MGMT) to
capture latent features at varying levels of visual granularity, thereby
enriching the diversity of the extracted information. Next, we introduce the
Attribute-guided Visual Feature Extraction (AVFE) module, which leverages
textual attributes as queries to retrieve their corresponding visual attribute
features from the Mix Tokens using a cross-attention mechanism. To ensure that
textual attributes focus on the appropriate Mix Tokens, we further incorporate
a Region-Aware Contrastive Learning (RACL) method, encouraging attributes
within the same region to share consistent attention maps. Extensive
experiments on PA100K, PETA, and RAPv1 datasets demonstrate the effectiveness
and strong generalization ability of our method.

</details>


### [57] [A Survey on Vision-Language-Action Models for Autonomous Driving](https://arxiv.org/abs/2506.24044)
*Sicong Jiang,Zilin Huang,Kangan Qian,Ziang Luo,Tianze Zhu,Yang Zhong,Yihong Tang,Menglin Kong,Yunlong Wang,Siwen Jiao,Hao Ye,Zihao Sheng,Xin Zhao,Tuopu Wen,Zheng Fu,Sikai Chen,Kun Jiang,Diange Yang,Seongjin Choi,Lijun Sun*

Main category: cs.CV

TL;DR: 本文综述了视觉-语言-动作（VLA）在自动驾驶（VLA4AD）中的应用，总结了架构演变、模型比较、数据集和挑战。


<details>
  <summary>Details</summary>
Motivation: 整合视觉感知、自然语言理解和控制的VLA模型为自动驾驶提供了新范式，但相关研究分散且快速扩展，需要系统梳理。

Method: 通过分析20多个代表性模型，总结VLA4AD的架构演变，并整理数据集和评测协议。

Result: 提出了VLA4AD的共享架构模块，比较了模型性能，并指出了现有评测协议的不足。

Conclusion: VLA4AD面临鲁棒性、实时效率和形式化验证等挑战，未来需进一步研究以实现可解释且社会对齐的自动驾驶。

Abstract: The rapid progress of multimodal large language models (MLLM) has paved the
way for Vision-Language-Action (VLA) paradigms, which integrate visual
perception, natural language understanding, and control within a single policy.
Researchers in autonomous driving are actively adapting these methods to the
vehicle domain. Such models promise autonomous vehicles that can interpret
high-level instructions, reason about complex traffic scenes, and make their
own decisions. However, the literature remains fragmented and is rapidly
expanding. This survey offers the first comprehensive overview of VLA for
Autonomous Driving (VLA4AD). We (i) formalize the architectural building blocks
shared across recent work, (ii) trace the evolution from early explainer to
reasoning-centric VLA models, and (iii) compare over 20 representative models
according to VLA's progress in the autonomous driving domain. We also
consolidate existing datasets and benchmarks, highlighting protocols that
jointly measure driving safety, accuracy, and explanation quality. Finally, we
detail open challenges - robustness, real-time efficiency, and formal
verification - and outline future directions of VLA4AD. This survey provides a
concise yet complete reference for advancing interpretable socially aligned
autonomous vehicles. Github repo is available at
\href{https://github.com/JohnsonJiang1996/Awesome-VLA4AD}{SicongJiang/Awesome-VLA4AD}.

</details>


### [58] [AG-VPReID 2025: Aerial-Ground Video-based Person Re-identification Challenge Results](https://arxiv.org/abs/2506.22843)
*Kien Nguyen,Clinton Fookes,Sridha Sridharan,Huy Nguyen,Feng Liu,Xiaoming Liu,Arun Ross,Dana Michalski,Tamás Endrei,Ivan DeAndres-Tame,Ruben Tolosana,Ruben Vera-Rodriguez,Aythami Morales,Julian Fierrez,Javier Ortega-Garcia,Zijing Gong,Yuhao Wang,Xuehu Liu,Pingping Zhang,Md Rashidunnabi,Hugo Proença,Kailash A. Hambarde,Saeid Rezaei*

Main category: cs.CV

TL;DR: AG-VPReID 2025挑战赛首次聚焦高海拔（80-120米）空中-地面视频行人重识别（ReID），提出了新数据集和解决方案，领先方法X-TFCLIP取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决空中与地面视角间的行人重识别问题，弥补现有研究在跨视角场景中的不足。

Method: 基于AG-VPReID数据集，采用多流架构、基于Transformer的时间推理和物理信息建模等方法。

Result: X-TFCLIP方法在空对地和地对空ReID中分别达到72.28%和70.77%的Rank-1准确率。

Conclusion: AG-VPReID挑战赛展示了跨视角行人重识别的潜力，但数据集复杂性仍带来挑战。

Abstract: Person re-identification (ReID) across aerial and ground vantage points has
become crucial for large-scale surveillance and public safety applications.
Although significant progress has been made in ground-only scenarios, bridging
the aerial-ground domain gap remains a formidable challenge due to extreme
viewpoint differences, scale variations, and occlusions. Building upon the
achievements of the AG-ReID 2023 Challenge, this paper introduces the AG-VPReID
2025 Challenge - the first large-scale video-based competition focused on
high-altitude (80-120m) aerial-ground ReID. Constructed on the new AG-VPReID
dataset with 3,027 identities, over 13,500 tracklets, and approximately 3.7
million frames captured from UAVs, CCTV, and wearable cameras, the challenge
featured four international teams. These teams developed solutions ranging from
multi-stream architectures to transformer-based temporal reasoning and
physics-informed modeling. The leading approach, X-TFCLIP from UAM, attained
72.28% Rank-1 accuracy in the aerial-to-ground ReID setting and 70.77% in the
ground-to-aerial ReID setting, surpassing existing baselines while highlighting
the dataset's complexity. For additional details, please refer to the official
website at https://agvpreid25.github.io.

</details>


### [59] [DMD-Net: Deep Mesh Denoising Network](https://arxiv.org/abs/2506.22850)
*Aalok Gangopadhyay,Shashikant Verma,Shanmuganathan Raman*

Main category: cs.CV

TL;DR: DMD-Net是一种端到端深度学习框架，用于网格去噪，结合了图卷积神经网络和双流网络，通过特征引导变换器实现高效去噪。


<details>
  <summary>Details</summary>
Motivation: 解决网格去噪问题，提升在复杂和高噪声情况下的性能。

Method: 使用图卷积神经网络和双流网络，结合特征提取器、变换器和去噪器，通过大规模数据集训练。

Result: 在多种噪声条件下表现优异，优于现有先进算法。

Conclusion: DMD-Net是一种高效、鲁棒的网格去噪方法，适用于高噪声场景。

Abstract: We present Deep Mesh Denoising Network (DMD-Net), an end-to-end deep learning
framework, for solving the mesh denoising problem. DMD-Net consists of a Graph
Convolutional Neural Network in which aggregation is performed in both the
primal as well as the dual graph. This is realized in the form of an asymmetric
two-stream network, which contains a primal-dual fusion block that enables
communication between the primal-stream and the dual-stream. We develop a
Feature Guided Transformer (FGT) paradigm, which consists of a feature
extractor, a transformer, and a denoiser. The feature extractor estimates the
local features, that guide the transformer to compute a transformation, which
is applied to the noisy input mesh to obtain a useful intermediate
representation. This is further processed by the denoiser to obtain the
denoised mesh. Our network is trained on a large scale dataset of 3D objects.
We perform exhaustive ablation studies to demonstrate that each component in
our network is essential for obtaining the best performance. We show that our
method obtains competitive or better results when compared with the
state-of-the-art mesh denoising algorithms. We demonstrate that our method is
robust to various kinds of noise. We observe that even in the presence of
extremely high noise, our method achieves excellent performance.

</details>


### [60] [Mask-aware Text-to-Image Retrieval: Referring Expression Segmentation Meets Cross-modal Retrieval](https://arxiv.org/abs/2506.22864)
*Li-Cheng Shen,Jih-Kang Hsieh,Wei-Hua Li,Chu-Song Chen*

Main category: cs.CV

TL;DR: MaTIR任务统一了文本到图像检索（TIR）和参考表达式分割（RES），提出了一种两阶段框架，结合分割感知检索和多模态大语言模型（MLLM）优化结果。


<details>
  <summary>Details</summary>
Motivation: 现有TIR方法缺乏解释性，而RES在大规模图像集合中计算成本高，MaTIR旨在结合两者优势。

Method: 采用两阶段框架：第一阶段为分割感知检索，第二阶段用MLLM重新排序和对象定位。利用SAM 2生成对象掩码和Alpha-CLIP提取区域级嵌入。

Result: 在COCO和D$^3$数据集上，MaTIR在检索准确性和分割质量上显著优于现有方法。

Conclusion: MaTIR成功统一了TIR和RES，实现了高效检索和精确分割。

Abstract: Text-to-image retrieval (TIR) aims to find relevant images based on a textual
query, but existing approaches are primarily based on whole-image captions and
lack interpretability. Meanwhile, referring expression segmentation (RES)
enables precise object localization based on natural language descriptions but
is computationally expensive when applied across large image collections. To
bridge this gap, we introduce Mask-aware TIR (MaTIR), a new task that unifies
TIR and RES, requiring both efficient image search and accurate object
segmentation. To address this task, we propose a two-stage framework,
comprising a first stage for segmentation-aware image retrieval and a second
stage for reranking and object grounding with a multimodal large language model
(MLLM). We leverage SAM 2 to generate object masks and Alpha-CLIP to extract
region-level embeddings offline at first, enabling effective and scalable
online retrieval. Secondly, MLLM is used to refine retrieval rankings and
generate bounding boxes, which are matched to segmentation masks. We evaluate
our approach on COCO and D$^3$ datasets, demonstrating significant improvements
in both retrieval accuracy and segmentation quality over previous methods.

</details>


### [61] [Region-Aware CAM: High-Resolution Weakly-Supervised Defect Segmentation via Salient Region Perception](https://arxiv.org/abs/2506.22866)
*Hang-Cheng Dong,Lu Zou,Bingguo Liu,Dong Ye,Guodong Liu*

Main category: cs.CV

TL;DR: 提出了一种基于弱监督语义分割的表面缺陷检测框架，通过区域感知CAM和伪标签训练解决现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统语义分割和目标检测模型依赖大规模标注数据，与实际缺陷检测任务需求冲突，需弱监督方法提升实用性。

Method: 引入过滤引导反向传播（FGBP）优化CAM，结合区域感知加权模块提升空间精度，并通过伪标签迭代优化模型。

Result: 在工业缺陷数据集上验证了方法的优越性，实现了弱监督学习与高精度分割的有效结合。

Conclusion: 该框架为资源受限的工业场景提供了实用解决方案，填补了弱监督学习与高精度缺陷分割之间的鸿沟。

Abstract: Surface defect detection plays a critical role in industrial quality
inspection. Recent advances in artificial intelligence have significantly
enhanced the automation level of detection processes. However, conventional
semantic segmentation and object detection models heavily rely on large-scale
annotated datasets, which conflicts with the practical requirements of defect
detection tasks. This paper proposes a novel weakly supervised semantic
segmentation framework comprising two key components: a region-aware class
activation map (CAM) and pseudo-label training. To address the limitations of
existing CAM methods, especially low-resolution thermal maps, and insufficient
detail preservation, we introduce filtering-guided backpropagation (FGBP),
which refines target regions by filtering gradient magnitudes to identify areas
with higher relevance to defects. Building upon this, we further develop a
region-aware weighted module to enhance spatial precision. Finally,
pseudo-label segmentation is implemented to refine the model's performance
iteratively. Comprehensive experiments on industrial defect datasets
demonstrate the superiority of our method. The proposed framework effectively
bridges the gap between weakly supervised learning and high-precision defect
segmentation, offering a practical solution for resource-constrained industrial
scenarios.

</details>


### [62] [STR-Match: Matching SpatioTemporal Relevance Score for Training-Free Video Editing](https://arxiv.org/abs/2506.22868)
*Junsung Lee,Junoh Kang,Bohyung Han*

Main category: cs.CV

TL;DR: STR-Match是一种无需训练的视频编辑算法，通过新的STR评分优化潜在空间，解决了现有方法的时间不一致性和运动失真问题。


<details>
  <summary>Details</summary>
Motivation: 现有文本引导视频编辑方法存在时间不一致、运动失真和领域转换受限的问题，主要原因是时空像素相关性建模不足。

Method: 提出STR-Match算法，利用2D空间注意力和1D时间模块计算STR评分，结合潜在优化框架和潜在掩码生成视频。

Result: 实验表明，STR-Match在视觉质量和时空一致性上优于现有方法，尤其在显著领域转换下表现优异。

Conclusion: STR-Match通过高效建模时空相关性，实现了高质量且一致的视频编辑。

Abstract: Previous text-guided video editing methods often suffer from temporal
inconsistency, motion distortion, and-most notably-limited domain
transformation. We attribute these limitations to insufficient modeling of
spatiotemporal pixel relevance during the editing process. To address this, we
propose STR-Match, a training-free video editing algorithm that produces
visually appealing and spatiotemporally coherent videos through latent
optimization guided by our novel STR score. The score captures spatiotemporal
pixel relevance across adjacent frames by leveraging 2D spatial attention and
1D temporal modules in text-to-video (T2V) diffusion models, without the
overhead of computationally expensive 3D attention mechanisms. Integrated into
a latent optimization framework with a latent mask, STR-Match generates
temporally consistent and visually faithful videos, maintaining strong
performance even under significant domain transformations while preserving key
visual attributes of the source. Extensive experiments demonstrate that
STR-Match consistently outperforms existing methods in both visual quality and
spatiotemporal consistency.

</details>


### [63] [Decoupled Seg Tokens Make Stronger Reasoning Video Segmenter and Grounder](https://arxiv.org/abs/2506.22880)
*Dang Jisheng,Wu Xudong,Wang Bimei,Lv Ning,Chen Jiayu,Jingwen Zhao,Yichu liu,Jizhao Liu,Juncheng Li,Teng Wang*

Main category: cs.CV

TL;DR: DeSa2VA通过解耦增强提示方案，结合文本预训练和线性解耦模块，解决了现有视频分割和接地方法中动态视觉信息与静态语义纠缠的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如Sa2VA）在分割模型中直接融合特征，导致动态视觉信息与静态语义纠缠，降低分割准确性。

Method: 1. 设计预训练范式，将文本标签转换为点级提示并生成文本掩码；2. 使用线性投影将大语言模型的隐藏状态解耦为文本和视觉特征子空间；3. 动态掩码融合策略结合解耦特征。

Result: 在图像分割、图像问答、视频分割和视频问答等任务中实现最先进性能。

Conclusion: DeSa2VA通过解耦和动态融合显著提升了分割和接地任务的性能。

Abstract: Existing video segmenter and grounder approaches, exemplified by Sa2VA,
directly fuse features within segmentation models. This often results in an
undesirable entanglement of dynamic visual information and static semantics,
thereby degrading segmentation accuracy. To systematically mitigate this issue,
we propose DeSa2VA, a decoupling-enhanced prompting scheme integrating text
pre-training and a linear decoupling module to address the information
processing limitations inherent in SAM-2. Specifically, first, we devise a
pre-training paradigm that converts textual ground-truth labels into
point-level prompts while generating corresponding text masks. These masks are
refined through a hybrid loss function to strengthen the model's semantic
grounding capabilities. Next, we employ linear projection to disentangle hidden
states that generated by a large language model into distinct textual and
visual feature subspaces. Finally, a dynamic mask fusion strategy
synergistically combines these decoupled features through triple supervision
from predicted text/visual masks and ground-truth annotations. Extensive
experiments demonstrate state-of-the-art performance across diverse tasks,
including image segmentation, image question answering, video segmentation, and
video question answering. Our codes are available at
https://github.com/longmalongma/DeSa2VA.

</details>


### [64] [How Semantically Informative is an Image?: Measuring the Covariance-Weighted Norm of Contrastive Learning Embeddings](https://arxiv.org/abs/2506.22881)
*Fumiya Uchiyama,Rintaro Yanagi,Shohei Taniguchi,Shota Takashiro,Masahiro Suzuki,Hirokatsu Kataoka,Yusuke Iwasawa,Yutaka Matsuo*

Main category: cs.CV

TL;DR: 论文提出了一种基于对比学习的语义信息度量方法，用于量化图像和文本的绝对语义信息量，并扩展了信息增益的概念到视觉和语言领域。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索对比学习是否能表示绝对语义信息量，而不仅仅是关系语义相似性。

Method: 方法包括通过对比学习模型计算图像和文本的语义信息量，并提出一种基于嵌入的范数度量信息增益。

Result: 实验结果显示，信息增益分数低的图像通常对应占位符图标，且该方法与CLIP或SigLIP模型的结果高度相关。

Conclusion: 结论表明该方法计算成本低，适用于公开模型，能有效量化语义信息量。

Abstract: Contrastive learning has the capacity to model multimodal probability
distributions by embedding and aligning visual representations with semantics
from captions. This approach enables the estimation of relational semantic
similarity; however, it remains unclear whether it can also represent absolute
semantic informativeness. In this work, we introduce a semantic informativeness
metric for an image calculated from text samples via a contrastive learning
model; similarly, the informativeness of a text is calculated from image
samples. We propose a redefinition of the concept of Information Gain, a
concept previously explored in natural language processing, extending its
application to the domains of vision and language. Our metric quantifies how
conditioning on an image distorts the distribution of associated texts, and
vice versa for text conditioning on image distributions. In OpenCLIP's
empirical results, we observe that images with the lowest Information Gain
scores often correspond to placeholder icons such as "image not found."
Furthermore, we propose to measure a norm-based metric of the embedding to
estimate the Information Gain, following the theoretical results for Skip-Gram
with Negative Sampling (SGNS) word embedding. Information Gain can be measured
using either CLIP or SigLIP, and the results demonstrate a strong correlation
with a coefficient of determination ranging from 0.98 to 1.00. After obtaining
the mean and the covariance of the sample embedding, the computational cost of
this method is independent of the sample size, and it is compatible with
publicly available, open-weight models.

</details>


### [65] [CP-Guard: A Unified, Probability-Agnostic, and Adaptive Framework for Malicious Agent Detection and Defense in Multi-Agent Embodied Perception Systems](https://arxiv.org/abs/2506.22890)
*Senkang Hu,Yihang Tao,Guowen Xu,Xinyuan Qian,Yiqin Deng,Xianhao Chen,Sam Tak Wu Kwong,Yuguang Fang*

Main category: cs.CV

TL;DR: CP-Guard是一个针对协作感知（CP）的统一防御框架，通过概率无关的样本共识和动态阈值调整，有效检测并消除恶意代理。


<details>
  <summary>Details</summary>
Motivation: 协作感知在多代理系统中提升感知性能，但易受恶意代理攻击，需开发防御机制。

Method: 提出PASAC方法进行样本共识验证，定义CCLoss捕捉差异，并通过动态阈值调整确保可靠性。

Result: 实验证明CP-Guard能有效检测恶意代理并提升系统安全性。

Conclusion: CP-Guard为协作感知提供了可靠的防御机制，适用于动态环境。

Abstract: Collaborative Perception (CP) has been shown to be a promising technique for
multi-agent autonomous driving and multi-agent robotic systems, where multiple
agents share their perception information to enhance the overall perception
performance and expand the perception range. However, in CP, an ego agent needs
to receive messages from its collaborators, which makes it vulnerable to
attacks from malicious agents. To address this critical issue, we propose a
unified, probability-agnostic, and adaptive framework, namely, CP-Guard, which
is a tailored defense mechanism for CP deployed by each agent to accurately
detect and eliminate malicious agents in its collaboration network. Our key
idea is to enable CP to reach a consensus rather than a conflict against an ego
agent's perception results. Based on this idea, we first develop a
probability-agnostic sample consensus (PASAC) method to effectively sample a
subset of the collaborators and verify the consensus without prior
probabilities of malicious agents. Furthermore, we define collaborative
consistency loss (CCLoss) for object detection task and bird's eye view (BEV)
segmentation task to capture the discrepancy between an ego agent and its
collaborators, which is used as a verification criterion for consensus. In
addition, we propose online adaptive threshold via dual sliding windows to
dynamically adjust the threshold for consensus verification and ensure the
reliability of the systems in dynamic environments. Finally, we conduct
extensive experiments and demonstrate the effectiveness of our framework. Code
will be released at https://github.com/CP-Security/CP-Guard

</details>


### [66] [MOTOR: Multimodal Optimal Transport via Grounded Retrieval in Medical Visual Question Answering](https://arxiv.org/abs/2506.22900)
*Mai A. Shaaban,Tausifa Jan Saleem,Vijay Ram Papineni,Mohammad Yaqub*

Main category: cs.CV

TL;DR: MOTOR是一种新型的多模态检索和重排序方法，通过结合文本和视觉信息提升医学视觉问答（MedVQA）的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在医学视觉问答中常生成错误答案，且检索增强方法可能引入无关上下文，忽略多模态信息的重要性。

Method: MOTOR利用基于文本和视觉信息的检索重排序方法，结合优化传输技术，提升检索相关性。

Result: MOTOR在MedVQA数据集上平均准确率提升6.45%，优于现有方法。

Conclusion: MOTOR通过多模态检索和重排序显著提升了医学视觉问答的准确性和临床相关性。

Abstract: Medical visual question answering (MedVQA) plays a vital role in clinical
decision-making by providing contextually rich answers to image-based queries.
Although vision-language models (VLMs) are widely used for this task, they
often generate factually incorrect answers. Retrieval-augmented generation
addresses this challenge by providing information from external sources, but
risks retrieving irrelevant context, which can degrade the reasoning
capabilities of VLMs. Re-ranking retrievals, as introduced in existing
approaches, enhances retrieval relevance by focusing on query-text alignment.
However, these approaches neglect the visual or multimodal context, which is
particularly crucial for medical diagnosis. We propose MOTOR, a novel
multimodal retrieval and re-ranking approach that leverages grounded captions
and optimal transport. It captures the underlying relationships between the
query and the retrieved context based on textual and visual information.
Consequently, our approach identifies more clinically relevant contexts to
augment the VLM input. Empirical analysis and human expert evaluation
demonstrate that MOTOR achieves higher accuracy on MedVQA datasets,
outperforming state-of-the-art methods by an average of 6.45%. Code is
available at https://github.com/BioMedIA-MBZUAI/MOTOR.

</details>


### [67] [Point Cloud Compression and Objective Quality Assessment: A Survey](https://arxiv.org/abs/2506.22902)
*Yiling Xu,Yujie Zhang,Shuting Xia,Kaifa Yang,He Huang,Ziyu Shan,Wenjie Huang,Qi Yang,Le Yang*

Main category: cs.CV

TL;DR: 本文综述了3D点云数据压缩（PCC）和质量评估（PCQA）的最新进展，分析了手工和基于学习的算法，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 3D点云数据在自动驾驶、机器人和沉浸式环境中的快速增长，对高效压缩和质量评估技术提出了迫切需求。

Method: 通过分析手工和基于学习的PCC算法及PCQA指标，并在新兴数据集上对代表性方法进行基准测试。

Result: 提供了详细的比较和实际见解，指出了当前方法的优势和局限性。

Conclusion: 尽管取得显著进展，但仍需解决视觉保真度、延迟和多模态数据支持等挑战，未来方向包括混合压缩框架和高级特征提取策略。

Abstract: The rapid growth of 3D point cloud data, driven by applications in autonomous
driving, robotics, and immersive environments, has led to criticals demand for
efficient compression and quality assessment techniques. Unlike traditional 2D
media, point clouds present unique challenges due to their irregular structure,
high data volume, and complex attributes. This paper provides a comprehensive
survey of recent advances in point cloud compression (PCC) and point cloud
quality assessment (PCQA), emphasizing their significance for real-time and
perceptually relevant applications. We analyze a wide range of handcrafted and
learning-based PCC algorithms, along with objective PCQA metrics. By
benchmarking representative methods on emerging datasets, we offer detailed
comparisons and practical insights into their strengths and limitations.
Despite notable progress, challenges such as enhancing visual fidelity,
reducing latency, and supporting multimodal data remain. This survey outlines
future directions, including hybrid compression frameworks and advanced feature
extraction strategies, to enable more efficient, immersive, and intelligent 3D
applications.

</details>


### [68] [Attention to Burstiness: Low-Rank Bilinear Prompt Tuning](https://arxiv.org/abs/2506.22908)
*Yuzhu Wang,Manni Duan,Shu Kong*

Main category: cs.CV

TL;DR: 论文提出了一种名为Bilinear Prompt Tuning (BPT)的方法，通过数据白化和低秩分解优化视觉提示调优(VPT)，显著提升性能和效率。


<details>
  <summary>Details</summary>
Motivation: VPT中图像块嵌入与Transformer自注意力模块的交互导致数据分布非高斯性，影响提示学习效果。

Method: 提出数据白化方法，并引入低秩分解的双线性模型(BPT)来优化提示学习。

Result: BPT显著加速提示调优并提升准确性（如CUB数据集上提升>25个点），同时减少参数和计算开销。

Conclusion: BPT方法在多个基准数据集上优于现有VPT方法，展示了高效性和性能优势。

Abstract: Visual Prompt Tuning (VPT) is a parameter-efficient fune-tuning technique
that adapts a pre-trained vision Transformer (ViT) by learning a small set of
parameters in the input space, known as prompts. In VPT, we uncover
``burstiness'' in the values arising from the interaction of image patch
embeddings, and the key and query projectors within Transformer's
self-attention module. Furthermore, the values of patch embeddings and the key
and query projectors exhibit Laplacian and hyper-Laplacian distribution,
respectively. Intuitively, these non-Gaussian distributions pose challenges for
learning prompts. To address this, we propose whitening these data,
de-correlating them and equalizing their variance towards more Gaussian before
learning prompts. We derive the whitening matrix over random image patch
embeddings and ViT's key and query projectors, and multiply it with the prompt
to be learned in a bilinear manner. Surprisingly, this method significantly
accelerates prompt tuning and boosts accuracy, e.g., $>$25 accuracy points on
the CUB dataset; interestingly, it learns ``bursty prompts''. Extending the
bilinear model which is known to introduce burstiness, we present a compact,
low-rank version by learning two smaller matrices whose multiplication yields
the final prompts. We call the proposed methods Bilinear Prompt Tuning (BPT).
Extensive experiments across multiple benchmark datasets demonstrate that BPT
methods not only outperform various VPT methods but also reduce parameter count
and computation overhead.

</details>


### [69] [Towards Explainable Bilingual Multimodal Misinformation Detection and Localization](https://arxiv.org/abs/2506.22930)
*Yiwei He,Xiangtai Li,Zhenglin Huang,Yi Dong,Hao Fei,Jiangning Zhang,Baoyuan Wu,Guangliang Cheng*

Main category: cs.CV

TL;DR: BiMi是一个双语多模态框架，用于检测新闻媒体中的虚假信息，通过区域定位、跨模态和跨语言一致性检测，以及自然语言解释。BiMiBench是一个大规模基准测试集，包含10.4万个样本。BiMi在分类、定位和解释质量上均优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 多模态内容的真实性增加使得虚假信息更难以检测，尤其是在双语字幕新闻中。BiMi旨在解决这一问题。

Method: BiMi结合区域级定位、跨模态和跨语言一致性检测，并引入在线检索模块和GRPO优化解释质量。

Result: BiMi在分类准确率上提升8.9，定位准确率提升15.9，解释BERTScore提升2.5。

Conclusion: BiMi在多语言虚假信息检测中表现优异，推动了该领域的最新进展。

Abstract: The increasing realism of multimodal content has made misinformation more
subtle and harder to detect, especially in news media where images are
frequently paired with bilingual (e.g., Chinese-English) subtitles. Such
content often includes localized image edits and cross-lingual inconsistencies
that jointly distort meaning while remaining superficially plausible. We
introduce BiMi, a bilingual multimodal framework that jointly performs
region-level localization, cross-modal and cross-lingual consistency detection,
and natural language explanation for misinformation analysis. To support
generalization, BiMi integrates an online retrieval module that supplements
model reasoning with up-to-date external context. We further release BiMiBench,
a large-scale and comprehensive benchmark constructed by systematically editing
real news images and subtitles, comprising 104,000 samples with realistic
manipulations across visual and linguistic modalities. To enhance
interpretability, we apply Group Relative Policy Optimization (GRPO) to improve
explanation quality, marking the first use of GRPO in this domain. Extensive
experiments demonstrate that BiMi outperforms strong baselines by up to +8.9 in
classification accuracy, +15.9 in localization accuracy, and +2.5 in
explanation BERTScore, advancing state-of-the-art performance in realistic,
multilingual misinformation detection. Code, models, and datasets will be
released.

</details>


### [70] [Utilizing a Novel Deep Learning Method for Scene Categorization in Remote Sensing Data](https://arxiv.org/abs/2506.22939)
*Ghufran A. Omran,Wassan Saad Abduljabbar Hayale,Ahmad AbdulQadir AlRababah,Israa Ibraheem Al-Barazanchi,Ravi Sekhar,Pritesh Shah,Sushma Parihar,Harshavardhan Reddy Penubadi*

Main category: cs.CV

TL;DR: 论文提出了一种名为CO-BRNN的新方法，用于遥感数据的场景分类，其准确率高达97%，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 遥感图像场景分类在多个领域有广泛应用，但传统深度学习方法需要大量数据且难以处理噪声，因此需要更高效的方法。

Method: 提出Cuttlefish Optimized Bidirectional Recurrent Neural Network (CO-BRNN)，并与多种现有技术（如MLP-CNN、CNN-LSTM等）进行比较。

Result: CO-BRNN达到97%的最高准确率，显著优于其他方法（如LSTM-CRF的90%）。

Conclusion: CO-BRNN在遥感场景分类中表现优异，同时强调了物理验证对卫星数据效率的重要性。

Abstract: Scene categorization (SC) in remotely acquired images is an important subject
with broad consequences in different fields, including catastrophe control,
ecological observation, architecture for cities, and more. Nevertheless, its
several apps, reaching a high degree of accuracy in SC from distant observation
data has demonstrated to be difficult. This is because traditional conventional
deep learning models require large databases with high variety and high levels
of noise to capture important visual features. To address these problems, this
investigation file introduces an innovative technique referred to as the
Cuttlefish Optimized Bidirectional Recurrent Neural Network (CO- BRNN) for type
of scenes in remote sensing data. The investigation compares the execution of
CO-BRNN with current techniques, including Multilayer Perceptron- Convolutional
Neural Network (MLP-CNN), Convolutional Neural Network-Long Short Term Memory
(CNN-LSTM), and Long Short Term Memory-Conditional Random Field (LSTM-CRF),
Graph-Based (GB), Multilabel Image Retrieval Model (MIRM-CF), Convolutional
Neural Networks Data Augmentation (CNN-DA). The results demonstrate that
CO-BRNN attained the maximum accuracy of 97%, followed by LSTM-CRF with 90%,
MLP-CNN with 85%, and CNN-LSTM with 80%. The study highlights the significance
of physical confirmation to ensure the efficiency of satellite data.

</details>


### [71] [YM-WML: A new Yolo-based segmentation Model with Weighted Multi-class Loss for medical imaging](https://arxiv.org/abs/2506.22955)
*Haniyeh Nikkhah,Jafar Tanha,Mahdi Zarrin,SeyedEhsan Roshan,Amin Kazempour*

Main category: cs.CV

TL;DR: YM-WML模型通过集成鲁棒主干网络、YOLOv11颈部和注意力分割头，结合WME损失函数，在心脏图像分割中表现优异，Dice系数达91.02。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割面临类别不平衡和结构复杂的问题，需要更高效的解决方案。

Method: 提出YM-WML模型，结合鲁棒主干、YOLOv11颈部和注意力分割头，并引入WME损失函数。

Result: 在ACDC数据集上Dice系数达91.02，优于现有方法。

Conclusion: YM-WML在心脏分割任务中表现稳定、准确且泛化能力强，成为新标杆。

Abstract: Medical image segmentation poses significant challenges due to class
imbalance and the complex structure of medical images. To address these
challenges, this study proposes YM-WML, a novel model for cardiac image
segmentation. The model integrates a robust backbone for effective feature
extraction, a YOLOv11 neck for multi-scale feature aggregation, and an
attention-based segmentation head for precise and accurate segmentation. To
address class imbalance, we introduce the Weighted Multi-class Exponential
(WME) loss function. On the ACDC dataset, YM-WML achieves a Dice Similarity
Coefficient of 91.02, outperforming state-of-the-art methods. The model
demonstrates stable training, accurate segmentation, and strong generalization,
setting a new benchmark in cardiac segmentation tasks.

</details>


### [72] [Peccavi: Visual Paraphrase Attack Safe and Distortion Free Image Watermarking Technique for AI-Generated Images](https://arxiv.org/abs/2506.22960)
*Shreyas Dixit,Ashhar Aziz,Shashwat Bajpai,Vasu Sharma,Aman Chadha,Vinija Jain,Amitava Das*

Main category: cs.CV

TL;DR: PECCAVI是一种新型图像水印技术，能够抵抗视觉转述攻击，实现无失真水印嵌入。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI的普及，合成内容可能成为政治虚假信息的放大器，现有水印技术易被篡改或绕过，亟需更安全的解决方案。

Method: PECCAVI通过将水印嵌入非熔化点（NMPs）并结合多通道频域水印技术，同时采用噪声抛光防止逆向工程。

Result: PECCAVI能够有效抵抗视觉转述攻击，保持图像质量，且模型无关。

Conclusion: PECCAVI为生成式AI内容的安全水印提供了可行方案，相关资源将开源。

Abstract: A report by the European Union Law Enforcement Agency predicts that by 2026,
up to 90 percent of online content could be synthetically generated, raising
concerns among policymakers, who cautioned that "Generative AI could act as a
force multiplier for political disinformation. The combined effect of
generative text, images, videos, and audio may surpass the influence of any
single modality." In response, California's Bill AB 3211 mandates the
watermarking of AI-generated images, videos, and audio. However, concerns
remain regarding the vulnerability of invisible watermarking techniques to
tampering and the potential for malicious actors to bypass them entirely.
Generative AI-powered de-watermarking attacks, especially the newly introduced
visual paraphrase attack, have shown an ability to fully remove watermarks,
resulting in a paraphrase of the original image. This paper introduces PECCAVI,
the first visual paraphrase attack-safe and distortion-free image watermarking
technique. In visual paraphrase attacks, an image is altered while preserving
its core semantic regions, termed Non-Melting Points (NMPs). PECCAVI
strategically embeds watermarks within these NMPs and employs multi-channel
frequency domain watermarking. It also incorporates noisy burnishing to counter
reverse-engineering efforts aimed at locating NMPs to disrupt the embedded
watermark, thereby enhancing durability. PECCAVI is model-agnostic. All
relevant resources and codes will be open-sourced.

</details>


### [73] [ActAlign: Zero-Shot Fine-Grained Video Classification via Language-Guided Sequence Alignment](https://arxiv.org/abs/2506.22967)
*Amir Aghdam,Vincent Tao Hu*

Main category: cs.CV

TL;DR: ActAlign是一个零样本视频分类框架，通过序列对齐和动态时间规整（DTW）在共享嵌入空间中匹配视频帧与语言模型生成的子动作序列，无需视频文本监督或微调。


<details>
  <summary>Details</summary>
Motivation: 解决零样本细粒度视频分类任务中，现有对比视觉语言模型无法捕捉时间结构的问题。

Method: 利用大型语言模型生成有序子动作序列，并通过DTW在共享嵌入空间中对齐视频帧。

Result: 在ActionAtlas基准测试中达到30.5%的准确率，优于数十亿参数视频语言模型且参数更少。

Conclusion: 结构化语言先验与经典对齐技术结合，为细粒度视频理解提供了一种可扩展的通用方法。

Abstract: We address the task of zero-shot fine-grained video classification, where no
video examples or temporal annotations are available for unseen action classes.
While contrastive vision-language models such as SigLIP demonstrate strong
open-set recognition via mean-pooled image-text similarity, they fail to
capture the temporal structure critical for distinguishing fine-grained
activities. We introduce ActAlign, a zero-shot framework that formulates video
classification as sequence alignment. For each class, a large language model
generates an ordered sub-action sequence, which is aligned with video frames
using Dynamic Time Warping (DTW) in a shared embedding space. Without any
video-text supervision or fine-tuning, ActAlign achieves 30.5% accuracy on the
extremely challenging ActionAtlas benchmark, where human accuracy is only
61.6%. ActAlign outperforms billion-parameter video-language models while using
approximately 8x less parameters. These results demonstrate that structured
language priors, combined with classical alignment techniques, offer a scalable
and general approach to unlocking the open-set recognition potential of
vision-language models for fine-grained video understanding.

</details>


### [74] [Probabilistic Prototype Calibration of Vision-Language Models for Generalized Few-shot Semantic Segmentation](https://arxiv.org/abs/2506.22979)
*Jie Liu,Jiayi Shen,Pan Zhou,Jan-Jakob Sonke,Efstratios Gavves*

Main category: cs.CV

TL;DR: FewCLIP提出了一种概率原型校准框架，通过多模态原型学习提升广义少样本语义分割的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有确定性原型方法在少样本情况下适应性不足的问题。

Method: 引入原型校准机制和分布正则化，优化多模态原型学习。

Result: 在PASCAL-5$^i$和COCO-20$^i$数据集上显著优于现有方法。

Conclusion: FewCLIP通过概率原型校准提升了少样本分割的泛化能力。

Abstract: Generalized Few-Shot Semantic Segmentation (GFSS) aims to extend a
segmentation model to novel classes with only a few annotated examples while
maintaining performance on base classes. Recently, pretrained vision-language
models (VLMs) such as CLIP have been leveraged in GFSS to improve
generalization on novel classes through multi-modal prototypes learning.
However, existing prototype-based methods are inherently deterministic,
limiting the adaptability of learned prototypes to diverse samples,
particularly for novel classes with scarce annotations. To address this, we
propose FewCLIP, a probabilistic prototype calibration framework over
multi-modal prototypes from the pretrained CLIP, thus providing more adaptive
prototype learning for GFSS. Specifically, FewCLIP first introduces a prototype
calibration mechanism, which refines frozen textual prototypes with learnable
visual calibration prototypes, leading to a more discriminative and adaptive
representation. Furthermore, unlike deterministic prototype learning
techniques, FewCLIP introduces distribution regularization over these
calibration prototypes. This probabilistic formulation ensures structured and
uncertainty-aware prototype learning, effectively mitigating overfitting to
limited novel class data while enhancing generalization. Extensive experimental
results on PASCAL-5$^i$ and COCO-20$^i$ datasets demonstrate that our proposed
FewCLIP significantly outperforms state-of-the-art approaches across both GFSS
and class-incremental setting. The code is available at
https://github.com/jliu4ai/FewCLIP.

</details>


### [75] [Revisiting CroPA: A Reproducibility Study and Enhancements for Cross-Prompt Adversarial Transferability in Vision-Language Models](https://arxiv.org/abs/2506.22982)
*Atharv Mittal,Agam Pandey,Amritanshu Tiwari,Sukrit Jindal,Swadesh Swain*

Main category: cs.CV

TL;DR: 该论文研究了大型视觉语言模型（VLMs）对抗攻击的脆弱性，验证了CroPA方法的跨提示可转移性，并提出了改进策略以提高攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在计算机视觉任务中表现优异，但对对抗攻击高度脆弱，尤其是在多模态被操纵的场景下。研究旨在验证和改进CroPA方法，以增强对抗攻击的有效性。

Method: 论文复现了CroPA方法，并提出了三项改进：新颖的初始化策略、研究跨图像可转移性的通用扰动、针对视觉编码器注意力机制的新损失函数。

Result: 在多个主流VLM（如Flamingo、BLIP-2等）上的实验验证了CroPA的优越性，改进策略显著提升了攻击成功率。

Conclusion: 研究强调了研究VLM对抗漏洞的重要性，并为生成可转移对抗样本提供了更鲁棒的框架，对实际应用中的VLM安全性有重要意义。

Abstract: Large Vision-Language Models (VLMs) have revolutionized computer vision,
enabling tasks such as image classification, captioning, and visual question
answering. However, they remain highly vulnerable to adversarial attacks,
particularly in scenarios where both visual and textual modalities can be
manipulated. In this study, we conduct a comprehensive reproducibility study of
"An Image is Worth 1000 Lies: Adversarial Transferability Across Prompts on
Vision-Language Models" validating the Cross-Prompt Attack (CroPA) and
confirming its superior cross-prompt transferability compared to existing
baselines. Beyond replication we propose several key improvements: (1) A novel
initialization strategy that significantly improves Attack Success Rate (ASR).
(2) Investigate cross-image transferability by learning universal
perturbations. (3) A novel loss function targeting vision encoder attention
mechanisms to improve generalization. Our evaluation across prominent VLMs --
including Flamingo, BLIP-2, and InstructBLIP as well as extended experiments on
LLaVA validates the original results and demonstrates that our improvements
consistently boost adversarial effectiveness. Our work reinforces the
importance of studying adversarial vulnerabilities in VLMs and provides a more
robust framework for generating transferable adversarial examples, with
significant implications for understanding the security of VLMs in real-world
applications.

</details>


### [76] [A Novel Frame Identification and Synchronization Technique for Smartphone Visible Light Communication Systems Based on Convolutional Neural Networks](https://arxiv.org/abs/2506.23004)
*Vaigai Nayaki Yokar,Hoa Le-Minh,Xicong Li,Wai Lok Woo,Luis Nero Alves,Stanislav Zvanovec,Tran The Son,Zabih Ghassemlooy*

Main category: cs.CV

TL;DR: 提出了一种基于CNN的轻量级监督学习方法，用于屏幕到相机（S2C）可见光通信系统中的帧识别与同步，实验准确率达98.74%。


<details>
  <summary>Details</summary>
Motivation: 解决S2C可见光通信中因模糊、裁剪和旋转图像等实时挑战导致的帧识别与同步问题。

Method: 使用Python和TensorFlow Keras框架构建CNN模型，通过三次实时实验训练，数据集针对S2C通信的实时挑战设计。

Result: 模型在实验中达到98.74%的准确率，显著提升了帧识别与同步性能。

Conclusion: 该方法在S2C VLC系统中表现出高效性和鲁棒性，适用于实际应用。

Abstract: This paper proposes a novel, robust, and lightweight supervised Convolutional
Neural Network (CNN)-based technique for frame identification and
synchronization, designed to enhance short-link communication performance in a
screen-to-camera (S2C) based visible light communication (VLC) system.
Developed using Python and the TensorFlow Keras framework, the proposed CNN
model was trained through three real-time experimental investigations conducted
in Jupyter Notebook. These experiments incorporated a dataset created from
scratch to address various real-time challenges in S2C communication, including
blurring, cropping, and rotated images in mobility scenarios. Overhead frames
were introduced for synchronization, which leads to enhanced system
performance. The experimental results demonstrate that the proposed model
achieves an overall accuracy of approximately 98.74%, highlighting its
effectiveness in identifying and synchronizing frames in S2C VLC systems.

</details>


### [77] [MusiXQA: Advancing Visual Music Understanding in Multimodal Large Language Models](https://arxiv.org/abs/2506.23009)
*Jian Chen,Wenye Ma,Penghang Liu,Wei Wang,Tengwei Song,Ming Li,Chenguang Wang,Ruiyi Zhang,Changyou Chen*

Main category: cs.CV

TL;DR: 论文介绍了MusiXQA数据集，用于评估和改进多模态大语言模型（MLLMs）在乐谱理解方面的能力，并提出了Phi-3-MusiX模型，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 当前MLLMs在乐谱理解方面的能力尚未充分探索，需要填补这一空白。

Method: 通过MusiXTeX生成高质量合成乐谱，并构建包含多种注释的MusiXQA数据集，开发Phi-3-MusiX模型进行微调。

Result: 现有MLLMs在乐谱理解方面表现有限，Phi-3-MusiX模型显著优于GPT-based方法。

Conclusion: MusiXQA数据集和Phi-3-MusiX模型为未来MLLMs在乐谱理解领域的发展奠定了基础。

Abstract: Multimodal Large Language Models (MLLMs) have achieved remarkable visual
reasoning abilities in natural images, text-rich documents, and graphic
designs. However, their ability to interpret music sheets remains
underexplored. To bridge this gap, we introduce MusiXQA, the first
comprehensive dataset for evaluating and advancing MLLMs in music sheet
understanding. MusiXQA features high-quality synthetic music sheets generated
via MusiXTeX, with structured annotations covering note pitch and duration,
chords, clefs, key/time signatures, and text, enabling diverse visual QA tasks.
Through extensive evaluations, we reveal significant limitations of current
state-of-the-art MLLMs in this domain. Beyond benchmarking, we developed
Phi-3-MusiX, an MLLM fine-tuned on our dataset, achieving significant
performance gains over GPT-based methods. The proposed dataset and model
establish a foundation for future advances in MLLMs for music sheet
understanding. Code, data, and model will be released upon acceptance.

</details>


### [78] [Inpainting is All You Need: A Diffusion-based Augmentation Method for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2506.23038)
*Xinrong Hu,Yiyu Shi*

Main category: cs.CV

TL;DR: AugPaint是一种利用潜在扩散模型进行数据增强的框架，通过图像修复生成图像-标签对，显著提升医学图像分割性能。


<details>
  <summary>Details</summary>
Motivation: 医学数据集的像素级标注成本高且耗时，如何在标注数据稀缺的情况下提升分割性能是关键挑战。

Method: AugPaint利用潜在扩散模型，通过反向去噪过程修复图像背景区域，生成与标签掩码匹配的合成图像。

Result: 在四个公共医学图像分割数据集上，AugPaint显著优于现有方法，提升了分割性能。

Conclusion: AugPaint为标注稀缺的医学图像分割提供了高效的数据增强解决方案。

Abstract: Collecting pixel-level labels for medical datasets can be a laborious and
expensive process, and enhancing segmentation performance with a scarcity of
labeled data is a crucial challenge. This work introduces AugPaint, a data
augmentation framework that utilizes inpainting to generate image-label pairs
from limited labeled data. AugPaint leverages latent diffusion models, known
for their ability to generate high-quality in-domain images with low overhead,
and adapts the sampling process for the inpainting task without need for
retraining. Specifically, given a pair of image and label mask, we crop the
area labeled with the foreground and condition on it during reversed denoising
process for every noise level. Masked background area would gradually be filled
in, and all generated images are paired with the label mask. This approach
ensures the accuracy of match between synthetic images and label masks, setting
it apart from existing dataset generation methods. The generated images serve
as valuable supervision for training downstream segmentation models,
effectively addressing the challenge of limited annotations. We conducted
extensive evaluations of our data augmentation method on four public medical
image segmentation datasets, including CT, MRI, and skin imaging. Results
across all datasets demonstrate that AugPaint outperforms state-of-the-art
label-efficient methodologies, significantly improving segmentation
performance.

</details>


### [79] [From Coarse to Fine: Learnable Discrete Wavelet Transforms for Efficient 3D Gaussian Splatting](https://arxiv.org/abs/2506.23042)
*Hung Nguyen,An Le,Runfa Li,Truong Nguyen*

Main category: cs.CV

TL;DR: AutoOpti3DGS通过小波变换限制高斯增长，保持视觉质量的同时减少内存占用。


<details>
  <summary>Details</summary>
Motivation: 解决3D高斯溅射中高斯数量增长导致的内存和带宽问题。

Method: 使用可学习的离散小波变换，固定低通滤波器，学习高通滤波器，并通过正交性损失逐步激活细节。

Result: AutoOpti3DGS仅需一个超参数，生成更稀疏的场景表示，兼容内存受限硬件。

Conclusion: AutoOpti3DGS有效平衡了视觉质量与资源消耗。

Abstract: 3D Gaussian Splatting has emerged as a powerful approach in novel view
synthesis, delivering rapid training and rendering but at the cost of an
ever-growing set of Gaussian primitives that strains memory and bandwidth. We
introduce AutoOpti3DGS, a training-time framework that automatically restrains
Gaussian proliferation without sacrificing visual fidelity. The key idea is to
feed the input images to a sequence of learnable Forward and Inverse Discrete
Wavelet Transforms, where low-pass filters are kept fixed, high-pass filters
are learnable and initialized to zero, and an auxiliary orthogonality loss
gradually activates fine frequencies. This wavelet-driven, coarse-to-fine
process delays the formation of redundant fine Gaussians, allowing 3DGS to
capture global structure first and refine detail only when necessary. Through
extensive experiments, AutoOpti3DGS requires just a single filter learning-rate
hyper-parameter, integrates seamlessly with existing efficient 3DGS frameworks,
and consistently produces sparser scene representations more compatible with
memory or storage-constrained hardware.

</details>


### [80] [Ovis-U1 Technical Report](https://arxiv.org/abs/2506.23044)
*Guo-Hua Wang,Shanshan Zhao,Xinjie Zhang,Liangfu Cao,Pengxin Zhan,Lunhao Duan,Shiyin Lu,Minghao Fu,Xiaohao Chen,Jianshan Zhao,Yang Li,Qing-Guo Chen*

Main category: cs.CV

TL;DR: Ovis-U1是一个30亿参数的多模态统一模型，结合了理解、生成和编辑能力，性能优于现有先进模型。


<details>
  <summary>Details</summary>
Motivation: 旨在通过统一训练方法提升多模态任务（理解、生成、编辑）的性能，突破现有模型的局限。

Method: 采用基于扩散的视觉解码器和双向令牌细化器，从语言模型开始进行统一训练。

Result: 在多个基准测试中表现优异，如OpenCompass（69.6分）、DPG-Bench（83.72分）和ImgEdit-Bench（4.00分）。

Conclusion: Ovis-U1作为系列首款模型，在多模态任务中实现了显著突破。

Abstract: In this report, we introduce Ovis-U1, a 3-billion-parameter unified model
that integrates multimodal understanding, text-to-image generation, and image
editing capabilities. Building on the foundation of the Ovis series, Ovis-U1
incorporates a diffusion-based visual decoder paired with a bidirectional token
refiner, enabling image generation tasks comparable to leading models like
GPT-4o. Unlike some previous models that use a frozen MLLM for generation
tasks, Ovis-U1 utilizes a new unified training approach starting from a
language model. Compared to training solely on understanding or generation
tasks, unified training yields better performance, demonstrating the
enhancement achieved by integrating these two tasks. Ovis-U1 achieves a score
of 69.6 on the OpenCompass Multi-modal Academic Benchmark, surpassing recent
state-of-the-art models such as Ristretto-3B and SAIL-VL-1.5-2B. In
text-to-image generation, it excels with scores of 83.72 and 0.89 on the
DPG-Bench and GenEval benchmarks, respectively. For image editing, it achieves
4.00 and 6.42 on the ImgEdit-Bench and GEdit-Bench-EN, respectively. As the
initial version of the Ovis unified model series, Ovis-U1 pushes the boundaries
of multimodal understanding, generation, and editing.

</details>


### [81] [Empowering Small VLMs to Think with Dynamic Memorization and Exploration](https://arxiv.org/abs/2506.23061)
*Jiazhen Liu,Yuchuan Deng,Long Chen*

Main category: cs.CV

TL;DR: DyME是一种新的训练范式，通过动态选择记忆（SFT）和探索（RLVR）模式，解决了小规模视觉语言模型（SVLMs）在可靠思考能力上的挑战。


<details>
  <summary>Details</summary>
Motivation: 由于SVLMs参数容量有限且指令跟随能力弱，现有训练范式（如SFT和RLVR）对其要求过高，导致伪思考痕迹和优势崩溃问题。

Method: DyME动态选择记忆（SFT）和探索（RLVR）模式，确保每次优化更新都贡献于平衡。

Result: 实验表明，DyME在多个领域均能实现平衡，显著提升性能。

Conclusion: DyME是提升SVLMs可靠思考能力的实用有效解决方案。

Abstract: Empowering Small-scale Vision-Language Models (SVLMs) with reliable thinking
capabilities remains fundamentally challenging due to their limited parameter
capacity and weak instruction-following abilities. Existing training paradigms,
including Supervised Fine-Tuning (SFT) and Reinforcement Learning with
Verifiable Reward (RLVR), impose substantial demands on the base VLM, exceeding
the capabilities of SVLMs. Consequently, directly applying these paradigms to
SVLMs often suffers from severe pseudo thinking traces and advantage collapse,
ultimately undermining both thinking reliability and task performance. A
natural solution is to combine SFT and RLVR, leveraging their complementarity
to reduce the dependence on model capacity. However, the widely adopted
two-stage training paradigm still performs poorly on SVLMs, as their tendency
toward sub-optimal convergence hinders the trade-off and limits the benefits of
the combination. To address this, we propose DyME, a novel training paradigm
that Dynamically selects between Memorization (via SFT) and Exploration (via
RLVR) modes at each optimization step, ensuring that every update contributes
to the trade-off. Extensive experiments across diverse domains demonstrate that
DyME consistently achieves this balance, and thus delivers substantial
performance improvements. These results establish DyME as a practical and
effective solution for empowering SVLMs with reliable thinking capabilities.
GitHub: https://github.com/HKUST-LongGroup/DyME

</details>


### [82] [CoreMark: Toward Robust and Universal Text Watermarking Technique](https://arxiv.org/abs/2506.23066)
*Jiale Meng,Yiming Li,Zheming Lu,Zewei He,Hao Luo,Tianwei Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为CORE的新嵌入范式，并基于此构建了文本水印框架CoreMark，通过动态提取和调整CORE的厚度嵌入数据，实现了高鲁棒性、通用性和不可感知性。


<details>
  <summary>Details</summary>
Motivation: 解决现有文本水印方案在鲁棒性、通用性和不可感知性方面面临的挑战。

Method: 提出CORE嵌入范式，构建CoreMark框架，动态提取COREs并调整厚度嵌入数据，同时设计嵌入强度调节器以适应不同字体大小。

Result: CoreMark在多语言和字体中表现出色，显著提升了抗截图、打印扫描和打印相机攻击的能力，同时保持良好不可感知性。

Conclusion: CoreMark为文本水印提供了一种高效、通用的解决方案，具有广泛的应用潜力。

Abstract: Text watermarking schemes have gained considerable attention in recent years,
yet still face critical challenges in achieving simultaneous robustness,
generalizability, and imperceptibility. This paper introduces a new embedding
paradigm,termed CORE, which comprises several consecutively aligned black pixel
segments. Its key innovation lies in its inherent noise resistance during
transmission and broad applicability across languages and fonts. Based on the
CORE, we present a text watermarking framework named CoreMark. Specifically,
CoreMark first dynamically extracts COREs from characters. Then, the characters
with stronger robustness are selected according to the lengths of COREs. By
modifying the thickness of the CORE, the hidden data is embedded into the
selected characters without causing significant visual distortions. Moreover, a
general plug-and-play embedding strength modulator is proposed, which can
adaptively enhance the robustness for small font sizes by adjusting the
embedding strength according to the font size. Experimental evaluation
indicates that CoreMark demonstrates outstanding generalizability across
multiple languages and fonts. Compared to existing methods, CoreMark achieves
significant improvements in resisting screenshot, print-scan, and print camera
attacks, while maintaining satisfactory imperceptibility.

</details>


### [83] [Unsupervised 3D Braided Hair Reconstruction from a Single-View Image](https://arxiv.org/abs/2506.23072)
*Jing Gao*

Main category: cs.CV

TL;DR: 提出了一种无监督方法，从单视角RGB图像高效重建3D编织发型，解决了现有方法难以捕捉编织头发精细几何结构的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于发丝的重建方法主要针对松散发型，难以处理编织发型的复杂交织结构和拓扑。

Method: 利用受编织理论启发的合成编织模型，捕捉编织头发的复杂交织结构。

Result: 实验表明，该方法在准确性、真实性和效率上优于现有技术。

Conclusion: 该方法支持数字人类中更具表现力的发型建模。

Abstract: Reconstructing 3D braided hairstyles from single-view images remains a
challenging task due to the intricate interwoven structure and complex
topologies of braids. Existing strand-based hair reconstruction methods
typically focus on loose hairstyles and often struggle to capture the
fine-grained geometry of braided hair. In this paper, we propose a novel
unsupervised pipeline for efficiently reconstructing 3D braided hair from
single-view RGB images. Leveraging a synthetic braid model inspired by braid
theory, our approach effectively captures the complex intertwined structures of
braids. Extensive experiments demonstrate that our method outperforms
state-of-the-art approaches, providing superior accuracy, realism, and
efficiency in reconstructing 3D braided hairstyles, supporting expressive
hairstyle modeling in digital humans.

</details>


### [84] [Learning Counterfactually Decoupled Attention for Open-World Model Attribution](https://arxiv.org/abs/2506.23074)
*Yu Zheng,Boyang Gong,Fanye Kong,Yueqi Duan,Bingyao Yu,Wenzhao Zheng,Lei Chen,Jiwen Lu,Jie Zhou*

Main category: cs.CV

TL;DR: 提出了一种反事实解耦注意力学习（CDAL）方法，用于开放世界模型归属，通过建模因果关系和解耦混淆因素，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖手工设计的区域划分或特征空间，易受虚假统计相关性影响，难以应对开放世界中的新型攻击。

Method: CDAL显式建模注意力视觉痕迹与源模型归属的因果关系，反事实解耦模型特异性伪影与混淆源偏差。

Result: 在开放世界模型归属基准测试中，CDAL以最小计算开销大幅提升现有最优模型性能，尤其对未见新型攻击效果显著。

Conclusion: CDAL通过最大化因果效应，鼓励网络捕捉泛化能力强的生成模式，为开放世界模型归属提供了有效解决方案。

Abstract: In this paper, we propose a Counterfactually Decoupled Attention Learning
(CDAL) method for open-world model attribution. Existing methods rely on
handcrafted design of region partitioning or feature space, which could be
confounded by the spurious statistical correlations and struggle with novel
attacks in open-world scenarios. To address this, CDAL explicitly models the
causal relationships between the attentional visual traces and source model
attribution, and counterfactually decouples the discriminative model-specific
artifacts from confounding source biases for comparison. In this way, the
resulting causal effect provides a quantification on the quality of learned
attention maps, thus encouraging the network to capture essential generation
patterns that generalize to unseen source models by maximizing the effect.
Extensive experiments on existing open-world model attribution benchmarks show
that with minimal computational overhead, our method consistently improves
state-of-the-art models by large margins, particularly for unseen novel
attacks. Source code: https://github.com/yzheng97/CDAL.

</details>


### [85] [Dynamic Contrastive Learning for Hierarchical Retrieval: A Case Study of Distance-Aware Cross-View Geo-Localization](https://arxiv.org/abs/2506.23077)
*Suofei Zhang,Xinxin Wang,Xiaofu Wu,Quan Zhou,Haifeng Hu*

Main category: cs.CV

TL;DR: 论文提出了一种动态对比学习框架（DyCL），用于解决距离感知的跨视角地理定位问题，并通过构建DA-Campus基准数据集验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注跨域图像匹配的准确性，而忽略了目标周围上下文信息的全面捕捉和定位误差的最小化。

Method: 提出动态对比学习（DyCL），通过分层空间边界的渐进对齐特征表示。

Result: DyCL显著提升了分层检索性能和跨视角地理定位的整体准确性。

Conclusion: DyCL为解决复杂空间关系的地理定位问题提供了有效方法，并公开了代码和基准数据集。

Abstract: Existing deep learning-based cross-view geo-localization methods primarily
focus on improving the accuracy of cross-domain image matching, rather than
enabling models to comprehensively capture contextual information around the
target and minimize the cost of localization errors. To support systematic
research into this Distance-Aware Cross-View Geo-Localization (DACVGL) problem,
we construct Distance-Aware Campus (DA-Campus), the first benchmark that pairs
multi-view imagery with precise distance annotations across three spatial
resolutions. Based on DA-Campus, we formulate DACVGL as a hierarchical
retrieval problem across different domains. Our study further reveals that, due
to the inherent complexity of spatial relationships among buildings, this
problem can only be addressed via a contrastive learning paradigm, rather than
conventional metric learning. To tackle this challenge, we propose Dynamic
Contrastive Learning (DyCL), a novel framework that progressively aligns
feature representations according to hierarchical spatial margins. Extensive
experiments demonstrate that DyCL is highly complementary to existing
multi-scale metric learning methods and yields substantial improvements in both
hierarchical retrieval performance and overall cross-view geo-localization
accuracy. Our code and benchmark are publicly available at
https://github.com/anocodetest1/DyCL.

</details>


### [86] [Frequency-enhanced Multi-granularity Context Network for Efficient Vertebrae Segmentation](https://arxiv.org/abs/2506.23086)
*Jian Shi,Tianqi You,Pingping Zhang,Hongli Zhang,Rui Xu,Haojie Li*

Main category: cs.CV

TL;DR: 提出了一种频率增强的多粒度上下文网络（FMC-Net），用于提高3D CT和MRI图像中脊椎分割的准确性，解决了图像模糊和相似脊椎区分的问题。


<details>
  <summary>Details</summary>
Motivation: 当前成像技术的局限性和脊柱结构的复杂性导致现有方法难以减少图像模糊的影响并区分相似脊椎。

Method: 使用小波变换进行无损下采样，分别处理高频和低频成分。高频成分通过高频特征细化（HFR）增强关键特征并过滤噪声；低频成分通过多粒度状态空间模型（MG-SSM）提取不同感受野的特征，捕获长程依赖关系。

Result: 实验表明，该方法在CT和MRI脊椎分割数据集上优于现有技术。

Conclusion: FMC-Net通过频率增强和多粒度上下文处理，显著提高了脊椎分割的准确性，代码已开源。

Abstract: Automated and accurate segmentation of individual vertebra in 3D CT and MRI
images is essential for various clinical applications. Due to the limitations
of current imaging techniques and the complexity of spinal structures, existing
methods still struggle with reducing the impact of image blurring and
distinguishing similar vertebrae. To alleviate these issues, we introduce a
Frequency-enhanced Multi-granularity Context Network (FMC-Net) to improve the
accuracy of vertebrae segmentation. Specifically, we first apply wavelet
transform for lossless downsampling to reduce the feature distortion in blurred
images. The decomposed high and low-frequency components are then processed
separately. For the high-frequency components, we apply a High-frequency
Feature Refinement (HFR) to amplify the prominence of key features and filter
out noises, restoring fine-grained details in blurred images. For the
low-frequency components, we use a Multi-granularity State Space Model (MG-SSM)
to aggregate feature representations with different receptive fields,
extracting spatially-varying contexts while capturing long-range dependencies
with linear complexity. The utilization of multi-granularity contexts is
essential for distinguishing similar vertebrae and improving segmentation
accuracy. Extensive experiments demonstrate that our method outperforms
state-of-the-art approaches on both CT and MRI vertebrae segmentation datasets.
The source code is publicly available at https://github.com/anaanaa/FMCNet.

</details>


### [87] [Where, What, Why: Towards Explainable Driver Attention Prediction](https://arxiv.org/abs/2506.23088)
*Yuchen Zhou,Jiayu Tang,Xiaoyan Xiao,Yueyao Lin,Linkai Liu,Zipeng Guo,Hao Fei,Xiaobo Xia,Chao Gou*

Main category: cs.CV

TL;DR: 论文提出了一种可解释的驾驶员注意力预测任务范式（W3DA数据集和LLada框架），联合预测注意力区域、解析语义并提供认知推理，填补了现有方法在认知动机理解上的空白。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅通过生成空间热图预测驾驶员注视点，但未能捕捉特定情境下注意力分配的认知动机，限制了注意力机制的深入理解。

Method: 提出W3DA数据集（包含详细语义和因果标注）和LLada框架（结合像素建模、语义解析和认知推理的端到端架构）。

Result: LLada在实验中表现出色，具有跨数据集和驾驶条件的鲁棒泛化能力。

Conclusion: 该研究为深入理解驾驶员注意力机制迈出关键一步，对自动驾驶、智能驾驶员培训和人机交互有重要意义。

Abstract: Modeling task-driven attention in driving is a fundamental challenge for both
autonomous vehicles and cognitive science. Existing methods primarily predict
where drivers look by generating spatial heatmaps, but fail to capture the
cognitive motivations behind attention allocation in specific contexts, which
limits deeper understanding of attention mechanisms. To bridge this gap, we
introduce Explainable Driver Attention Prediction, a novel task paradigm that
jointly predicts spatial attention regions (where), parses attended semantics
(what), and provides cognitive reasoning for attention allocation (why). To
support this, we present W3DA, the first large-scale explainable driver
attention dataset. It enriches existing benchmarks with detailed semantic and
causal annotations across diverse driving scenarios, including normal
conditions, safety-critical situations, and traffic accidents. We further
propose LLada, a Large Language model-driven framework for driver attention
prediction, which unifies pixel modeling, semantic parsing, and cognitive
reasoning within an end-to-end architecture. Extensive experiments demonstrate
the effectiveness of LLada, exhibiting robust generalization across datasets
and driving conditions. This work serves as a key step toward a deeper
understanding of driver attention mechanisms, with significant implications for
autonomous driving, intelligent driver training, and human-computer
interaction.

</details>


### [88] [DC-TTA: Divide-and-Conquer Framework for Test-Time Adaptation of Interactive Segmentation](https://arxiv.org/abs/2506.23104)
*Jihun Kim,Hoyong Kwon,Hyeokjun Kweon,Wooseong Jeong,Kuk-Jin Yoon*

Main category: cs.CV

TL;DR: DC-TTA是一种测试时适应框架，通过用户交互监督改进SAM在复杂场景中的表现，显著优于零样本SAM和传统TTA方法。


<details>
  <summary>Details</summary>
Motivation: 解决SAM在专业领域或复杂场景（如伪装或多部分对象）中的表现不足问题。

Method: 提出DC-TTA框架，将用户点击划分为更一致的子集，独立进行测试时适应，最后合并模型。

Result: 在多个基准测试中，DC-TTA显著优于SAM的零样本结果和传统TTA方法，提高了准确性和交互效率。

Conclusion: DC-TTA通过分而治之策略有效解决了SAM在复杂任务中的局限性，提升了交互式分割的性能。

Abstract: Interactive segmentation (IS) allows users to iteratively refine object
boundaries with minimal cues, such as positive and negative clicks. While the
Segment Anything Model (SAM) has garnered attention in the IS community for its
promptable segmentation capabilities, it often struggles in specialized domains
or when handling complex scenarios (e.g., camouflaged or multi-part objects).
To overcome these challenges, we propose DC-TTA, a novel test-time adaptation
(TTA) framework that adapts SAM on a per-sample basis by leveraging user
interactions as supervision. Instead of forcing a single model to incorporate
all user clicks at once, DC-TTA partitions the clicks into more coherent
subsets, each processed independently via TTA with a separated model. This
Divide-and-Conquer strategy reduces conflicts among diverse cues and enables
more localized updates. Finally, we merge the adapted models to form a unified
predictor that integrates the specialized knowledge from each subset.
Experimental results across various benchmarks demonstrate that DC-TTA
significantly outperforms SAM's zero-shot results and conventional TTA methods,
effectively handling complex tasks such as camouflaged object segmentation with
fewer interactions and improved accuracy.

</details>


### [89] [Computer-Aided Multi-Stroke Character Simplification by Stroke Removal](https://arxiv.org/abs/2506.23106)
*Ryo Ishiyama,Shinnosuke Matsuo,Seiichi Uchida*

Main category: cs.CV

TL;DR: 提出了一种通过选择性去除笔画来简化多笔画汉字和日文字符的框架，旨在降低学习难度并提高字体设计的效率。


<details>
  <summary>Details</summary>
Motivation: 多笔画字符复杂度高，对非母语学习者尤其困难，简化字符可降低学习门槛、优化字体设计并提升字符通信系统效率。

Method: 使用高精度字符识别模型评估可读性，选择性去除对可读性影响最小的笔画。

Result: 实验表明，即使去除多个笔画，许多字符仍可区分，为更正式的简化策略提供了依据。

Conclusion: 该框架展示了简化多笔画字符的潜力，为未来简化策略的标准化提供了可能。

Abstract: Multi-stroke characters in scripts such as Chinese and Japanese can be highly
complex, posing significant challenges for both native speakers and,
especially, non-native learners. If these characters can be simplified without
degrading their legibility, it could reduce learning barriers for non-native
speakers, facilitate simpler and legible font designs, and contribute to
efficient character-based communication systems. In this paper, we propose a
framework to systematically simplify multi-stroke characters by selectively
removing strokes while preserving their overall legibility. More specifically,
we use a highly accurate character recognition model to assess legibility and
remove those strokes that minimally impact it. Experimental results on 1,256
character classes with 5, 10, 15, and 20 strokes reveal several key findings,
including the observation that even after removing multiple strokes, many
characters remain distinguishable. These findings suggest the potential for
more formalized simplification strategies.

</details>


### [90] [Hierarchical Corpus-View-Category Refinement for Carotid Plaque Risk Grading in Ultrasound](https://arxiv.org/abs/2506.23108)
*Zhiyuan Zhu,Jian Wang,Yong Jiang,Tong Han,Yuhao Huang,Ang Zhang,Kaiwen Yang,Mingyuan Luo,Zhe Liu,Yaofei Duan,Dong Ni,Tianhong Tang,Xin Yang*

Main category: cs.CV

TL;DR: 提出了一种新的多级细化框架CVC-RF，用于颈动脉斑块分级（CPG），通过全局建模和多尺度特征融合，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在多视图分类中忽略了表示学习和类特征差异，导致CPG任务表现不佳。

Method: 提出CVC-RF框架，包含语料库级中心记忆对比损失、视图级级联下采样注意力模块和类别级无参数专家混合加权策略。

Result: 实验表明CVC-RF在CPG任务中达到最先进性能。

Conclusion: CVC-RF通过多级细化有效建模全局特征，为CPG提供了高效解决方案。

Abstract: Accurate carotid plaque grading (CPG) is vital to assess the risk of
cardiovascular and cerebrovascular diseases. Due to the small size and high
intra-class variability of plaque, CPG is commonly evaluated using a
combination of transverse and longitudinal ultrasound views in clinical
practice. However, most existing deep learning-based multi-view classification
methods focus on feature fusion across different views, neglecting the
importance of representation learning and the difference in class features. To
address these issues, we propose a novel Corpus-View-Category Refinement
Framework (CVC-RF) that processes information from Corpus-, View-, and
Category-levels, enhancing model performance. Our contribution is four-fold.
First, to the best of our knowledge, we are the foremost deep learning-based
method for CPG according to the latest Carotid Plaque-RADS guidelines. Second,
we propose a novel center-memory contrastive loss, which enhances the network's
global modeling capability by comparing with representative cluster centers and
diverse negative samples at the Corpus level. Third, we design a cascaded
down-sampling attention module to fuse multi-scale information and achieve
implicit feature interaction at the View level. Finally, a parameter-free
mixture-of-experts weighting strategy is introduced to leverage class
clustering knowledge to weight different experts, enabling feature decoupling
at the Category level. Experimental results indicate that CVC-RF effectively
models global features via multi-level refinement, achieving state-of-the-art
performance in the challenging CPG task.

</details>


### [91] [MoCa: Modality-aware Continual Pre-training Makes Better Bidirectional Multimodal Embeddings](https://arxiv.org/abs/2506.23115)
*Haonan Chen,Hong Liu,Yuping Luo,Liang Wang,Nan Yang,Furu Wei,Zhicheng Dou*

Main category: cs.CV

TL;DR: MoCa是一个两阶段框架，将预训练的因果视觉语言模型转化为高效的双向多模态嵌入模型，解决了当前方法的局限性，并在多个基准测试中取得最佳性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态嵌入模型存在因果注意力不适用于嵌入任务、依赖高质量标注数据导致扩展性差以及训练目标和数据多样性不足的问题。

Method: MoCa分为两阶段：1）模态感知持续预训练，通过联合重构目标增强双向上下文推理；2）异构对比微调，利用多样化多模态数据提升泛化和对齐能力。

Result: MoCa在MMEB和ViDoRe-v2基准测试中表现优异，达到新的最佳性能，并在模型规模和训练数据上展现出强扩展性。

Conclusion: MoCa通过双向注意力、大规模无标注数据和多样化训练目标，显著提升了多模态嵌入模型的性能和扩展性。

Abstract: Multimodal embedding models, built upon causal Vision Language Models (VLMs),
have shown promise in various tasks. However, current approaches face three key
limitations: the use of causal attention in VLM backbones is suboptimal for
embedding tasks; scalability issues due to reliance on high-quality labeled
paired data for contrastive learning; and limited diversity in training
objectives and data. To address these issues, we propose MoCa, a two-stage
framework for transforming pre-trained VLMs into effective bidirectional
multimodal embedding models. The first stage, Modality-aware Continual
Pre-training, introduces a joint reconstruction objective that simultaneously
denoises interleaved text and image inputs, enhancing bidirectional
context-aware reasoning. The second stage, Heterogeneous Contrastive
Fine-tuning, leverages diverse, semantically rich multimodal data beyond simple
image-caption pairs to enhance generalization and alignment. Our method
addresses the stated limitations by introducing bidirectional attention through
continual pre-training, scaling effectively with massive unlabeled datasets via
joint reconstruction objectives, and utilizing diverse multimodal data for
enhanced representation robustness. Experiments demonstrate that MoCa
consistently improves performance across MMEB and ViDoRe-v2 benchmarks,
achieving new state-of-the-art results, and exhibits strong scalability with
both model size and training data on MMEB.

</details>


### [92] [Enhancing Spatial Reasoning in Multimodal Large Language Models through Reasoning-based Segmentation](https://arxiv.org/abs/2506.23120)
*Zhenhua Ning,Zhuotao Tian,Shaoshuai Shi,Guangming Lu,Daojing He,Wenjie Pei,Li Jiang*

Main category: cs.CV

TL;DR: 论文提出了一种基于推理的分割框架R²S和数据集3D ReasonSeg，以增强3D点云感知的空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理需要精确空间推理的复杂指令时存在挑战，尽管3D点云数据提供了详细的空间线索。

Method: R²S框架模仿人类认知过程，将空间推理分解为两个阶段：先识别相关元素，再基于视觉先验处理指令。

Result: 实验表明R²S和3D ReasonSeg显著提升了3D点云感知的空间推理能力。

Conclusion: R²S和3D ReasonSeg为未来研究提供了新的基准和数据集。

Abstract: Recent advances in point cloud perception have demonstrated remarkable
progress in scene understanding through vision-language alignment leveraging
large language models (LLMs). However, existing methods may still encounter
challenges in handling complex instructions that require accurate spatial
reasoning, even if the 3D point cloud data provides detailed spatial cues such
as size and position for identifying the targets. To tackle this issue, we
propose Relevant Reasoning Segmentation (R$^2$S), a reasoning-based
segmentation framework. The framework emulates human cognitive processes by
decomposing spatial reasoning into two sequential stages: first identifying
relevant elements, then processing instructions guided by their associated
visual priors. Furthermore, acknowledging the inadequacy of existing datasets
in complex reasoning tasks, we introduce 3D ReasonSeg, a reasoning-based
segmentation dataset comprising 25,185 training samples and 3,966 validation
samples with precise annotations. Both quantitative and qualitative experiments
demonstrate that the R$^2$S and 3D ReasonSeg effectively endow 3D point cloud
perception with stronger spatial reasoning capabilities, and we hope that they
can serve as a new baseline and benchmark for future work.

</details>


### [93] [Dare to Plagiarize? Plagiarized Painting Recognition and Retrieval](https://arxiv.org/abs/2506.23132)
*Sophie Zhou,Shu Kong*

Main category: cs.CV

TL;DR: 论文提出了一种基于视觉基础模型DINOv2的艺术抄袭检测方法，通过检索相似艺术品并优化检索性能，尽管识别精度略有下降。


<details>
  <summary>Details</summary>
Motivation: 艺术抄袭检测对保护艺术家版权至关重要，但现有方法在检索精度和识别准确性上存在不足。

Method: 构建数据集并使用DINOv2提取特征，通过相似度阈值分类抄袭；进一步用度量学习微调模型以提升检索性能。

Result: 基线方法识别准确率达97.2%，但检索精度仅29.0%；微调后检索性能提升12%，但识别精度降至92.7%。

Conclusion: 研究揭示了检索性能与识别精度的权衡，为未来优化方向提供了参考。

Abstract: Art plagiarism detection plays a crucial role in protecting artists'
copyrights and intellectual property, yet it remains a challenging problem in
forensic analysis. In this paper, we address the task of recognizing
plagiarized paintings and explaining the detected plagarisms by retrieving
visually similar authentic artworks. To support this study, we construct a
dataset by collecting painting photos and synthesizing plagiarized versions
using generative AI, tailored to specific artists' styles. We first establish a
baseline approach using off-the-shelf features from the visual foundation model
DINOv2 to retrieve the most similar images in the database and classify
plagiarism based on a similarity threshold. Surprisingly, this non-learned
method achieves a high recognition accuracy of 97.2\% but suffers from low
retrieval precision 29.0\% average precision (AP). To improve retrieval
quality, we finetune DINOv2 with a metric learning loss using positive and
negative sample pairs sampled in the database. The finetuned model greatly
improves retrieval performance by 12\% AP over the baseline, though it
unexpectedly results in a lower recognition accuracy (92.7\%). We conclude with
insightful discussions and outline directions for future research.

</details>


### [94] [VisualPrompter: Prompt Optimization with Visual Feedback for Text-to-Image Synthesis](https://arxiv.org/abs/2506.23138)
*Shiyu Wu,Mingzhen Sun,Weining Wang,Yequan Wang,Jing Liu*

Main category: cs.CV

TL;DR: VisualPrompter是一个无需训练的提示工程框架，通过自动自反思模块和细粒度提示优化机制，提升生成图像与用户描述的语义对齐。


<details>
  <summary>Details</summary>
Motivation: 现有提示工程方法虽能提升图像风格和美学，但常忽视语义对齐，导致生成图像内容不符合用户描述。

Method: 提出VisualPrompter框架，包含自动自反思模块识别缺失概念，以及目标特定提示优化机制细粒度修订提示。

Result: 在多个文本-图像对齐评估基准上达到新最优性能，且框架具有即插即用设计。

Conclusion: VisualPrompter有效解决了语义对齐问题，适用于多种生成模型。

Abstract: Since there exists a notable gap between user-provided and model-preferred
prompts, generating high-quality and satisfactory images using diffusion models
often requires prompt engineering to optimize user inputs. Current studies on
text-to-image prompt engineering can effectively enhance the style and
aesthetics of generated images. However, they often neglect the semantic
alignment between generated images and user descriptions, resulting in visually
appealing but content-wise unsatisfying outputs. In this work, we propose
VisualPrompter, a novel training-free prompt engineering framework that refines
user inputs to model-preferred sentences. In particular, VisualPrompter
utilizes an automatic self-reflection module to identify the missing concepts
in generated images and a target-specific prompt optimization mechanism to
revise the prompts in a fine-grained manner. Extensive experiments demonstrate
the effectiveness of our VisualPrompter, which achieves new state-of-the-art
performance on multiple benchmarks for text-image alignment evaluation.
Additionally, our framework features a plug-and-play design, making it highly
adaptable to various generative models.

</details>


### [95] [AlignCVC: Aligning Cross-View Consistency for Single-Image-to-3D Generation](https://arxiv.org/abs/2506.23150)
*Xinyue Liang,Zhiyuan Ma,Lingchen Sun,Yanjun Guo,Lei Zhang*

Main category: cs.CV

TL;DR: AlignCVC提出了一种通过分布对齐而非严格回归损失的单图像到3D生成框架，显著提升了跨视图一致性（CVC）和生成效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过预训练生成模型合成的中间多视图图像缺乏跨视图一致性，导致3D重建性能下降。

Method: AlignCVC采用软硬对齐策略，分别优化生成和重建模型，将生成和重建的多视图分布对齐到真实多视图分布。

Result: 实验表明，AlignCVC不仅提升了生成质量，还将推理加速至仅需4步。

Conclusion: AlignCVC是一种即插即用的方法，可无缝集成多种多视图生成和3D重建模型，显著提升单图像到3D生成的性能。

Abstract: Single-image-to-3D models typically follow a sequential generation and
reconstruction workflow. However, intermediate multi-view images synthesized by
pre-trained generation models often lack cross-view consistency (CVC),
significantly degrading 3D reconstruction performance. While recent methods
attempt to refine CVC by feeding reconstruction results back into the
multi-view generator, these approaches struggle with noisy and unstable
reconstruction outputs that limit effective CVC improvement. We introduce
AlignCVC, a novel framework that fundamentally re-frames single-image-to-3D
generation through distribution alignment rather than relying on strict
regression losses. Our key insight is to align both generated and reconstructed
multi-view distributions toward the ground-truth multi-view distribution,
establishing a principled foundation for improved CVC. Observing that generated
images exhibit weak CVC while reconstructed images display strong CVC due to
explicit rendering, we propose a soft-hard alignment strategy with distinct
objectives for generation and reconstruction models. This approach not only
enhances generation quality but also dramatically accelerates inference to as
few as 4 steps. As a plug-and-play paradigm, our method, namely AlignCVC,
seamlessly integrates various multi-view generation models with 3D
reconstruction models. Extensive experiments demonstrate the effectiveness and
efficiency of AlignCVC for single-image-to-3D generation.

</details>


### [96] [MEMFOF: High-Resolution Training for Memory-Efficient Multi-Frame Optical Flow Estimation](https://arxiv.org/abs/2506.23151)
*Vladislav Bargatin,Egor Chistov,Alexander Yakovenko,Dmitriy Vatolin*

Main category: cs.CV

TL;DR: MEMFOF是一种高效的多帧光流估计方法，显著降低GPU内存消耗，同时在高分辨率输入下保持高精度。


<details>
  <summary>Details</summary>
Motivation: 当前光流估计方法在高分辨率（如FullHD）输入下GPU内存消耗过大，限制了训练和推理的效率。

Method: 通过优化RAFT-like架构，减少相关体积并采用高分辨率训练协议，结合多帧估计，实现内存高效的光流估计。

Result: MEMFOF在多个基准测试中表现优异，内存消耗显著降低（运行时2.09 GB，训练时28.5 GB），并在Spring、Sintel和KITTI-2015上取得最佳成绩。

Conclusion: MEMFOF在高分辨率光流估计中实现了内存与性能的平衡，为实际应用提供了高效解决方案。

Abstract: Recent advances in optical flow estimation have prioritized accuracy at the
cost of growing GPU memory consumption, particularly for high-resolution
(FullHD) inputs. We introduce MEMFOF, a memory-efficient multi-frame optical
flow method that identifies a favorable trade-off between multi-frame
estimation and GPU memory usage. Notably, MEMFOF requires only 2.09 GB of GPU
memory at runtime for 1080p inputs, and 28.5 GB during training, which uniquely
positions our method to be trained at native 1080p without the need for
cropping or downsampling. We systematically revisit design choices from
RAFT-like architectures, integrating reduced correlation volumes and
high-resolution training protocols alongside multi-frame estimation, to achieve
state-of-the-art performance across multiple benchmarks while substantially
reducing memory overhead. Our method outperforms more resource-intensive
alternatives in both accuracy and runtime efficiency, validating its robustness
for flow estimation at high resolutions. At the time of submission, our method
ranks first on the Spring benchmark with a 1-pixel (1px) outlier rate of 3.289,
leads Sintel (clean) with an endpoint error (EPE) of 0.963, and achieves the
best Fl-all error on KITTI-2015 at 2.94%. The code is available at
https://github.com/msu-video-group/memfof.

</details>


### [97] [Dynamic View Synthesis from Small Camera Motion Videos](https://arxiv.org/abs/2506.23153)
*Huiqiang Sun,Xingyi Li,Juewen Peng,Liao Shen,Zhiguo Cao,Ke Xian,Guosheng Lin*

Main category: cs.CV

TL;DR: 论文提出了一种基于分布深度正则化（DDR）的方法，解决了动态3D场景中相机运动范围有限时几何表示和相机参数估计的挑战。


<details>
  <summary>Details</summary>
Motivation: 动态3D场景的新视角合成在相机运动范围有限时，现有方法难以准确表示场景几何和估计相机参数。

Method: 提出DDR方法，通过Gumbel-softmax采样点并约束体积密度，同时引入相机参数学习。

Result: 实验表明，该方法在小相机运动输入下表现优于现有方法。

Conclusion: DDR方法有效解决了小相机运动场景中的几何表示和相机参数估计问题。

Abstract: Novel view synthesis for dynamic $3$D scenes poses a significant challenge.
Many notable efforts use NeRF-based approaches to address this task and yield
impressive results. However, these methods rely heavily on sufficient motion
parallax in the input images or videos. When the camera motion range becomes
limited or even stationary (i.e., small camera motion), existing methods
encounter two primary challenges: incorrect representation of scene geometry
and inaccurate estimation of camera parameters. These challenges make prior
methods struggle to produce satisfactory results or even become invalid. To
address the first challenge, we propose a novel Distribution-based Depth
Regularization (DDR) that ensures the rendering weight distribution to align
with the true distribution. Specifically, unlike previous methods that use
depth loss to calculate the error of the expectation, we calculate the
expectation of the error by using Gumbel-softmax to differentiably sample
points from discrete rendering weight distribution. Additionally, we introduce
constraints that enforce the volume density of spatial points before the object
boundary along the ray to be near zero, ensuring that our model learns the
correct geometry of the scene. To demystify the DDR, we further propose a
visualization tool that enables observing the scene geometry representation at
the rendering weight level. For the second challenge, we incorporate camera
parameter learning during training to enhance the robustness of our model to
camera parameters. We conduct extensive experiments to demonstrate the
effectiveness of our approach in representing scenes with small camera motion
input, and our results compare favorably to state-of-the-art methods.

</details>


### [98] [Self-Supervised Contrastive Learning for Multi-Label Images](https://arxiv.org/abs/2506.23156)
*Jiale Chen*

Main category: cs.CV

TL;DR: 该论文提出了一种针对多标签图像的自监督学习方法，通过块级增强和图像感知对比损失，减少了预训练开销并提升了语义表示能力。


<details>
  <summary>Details</summary>
Motivation: 主流自监督学习方法依赖单标签高质数据集（如ImageNet），忽视了多标签图像的丰富语义信息，且预训练开销大。

Method: 提出块级增强模块提取多标签图像中的潜在正视图对，并设计图像感知对比损失连接这些视图，提取语义一致的表示。

Result: 通过线性微调和迁移学习验证了方法的竞争力，尽管样本质量和数量有限。

Conclusion: 该方法在多标签图像上实现了高效的自监督学习，具有广泛的下游应用潜力。

Abstract: Self-supervised learning (SSL) has demonstrated its effectiveness in learning
representations through comparison methods that align with human intuition.
However, mainstream SSL methods heavily rely on high body datasets with single
label, such as ImageNet, resulting in intolerable pre-training overhead.
Besides, more general multi-label images are frequently overlooked in SSL,
despite their potential for richer semantic information and broader
applicability in downstream scenarios. Therefore, we tailor the mainstream SSL
approach to guarantee excellent representation learning capabilities using
fewer multi-label images. Firstly, we propose a block-wise augmentation module
aimed at extracting additional potential positive view pairs from multi-label
images. Subsequently, an image-aware contrastive loss is devised to establish
connections between these views, thereby facilitating the extraction of
semantically consistent representations. Comprehensive linear fine-tuning and
transfer learning validate the competitiveness of our approach despite
challenging sample quality and quantity.

</details>


### [99] [STD-GS: Exploring Frame-Event Interaction for SpatioTemporal-Disentangled Gaussian Splatting to Reconstruct High-Dynamic Scene](https://arxiv.org/abs/2506.23157)
*Hanyu Zhou,Haonan Wang,Haoyue Liu,Yuxing Duan,Luxin Yan,Gim Hee Lee*

Main category: cs.CV

TL;DR: 提出了一种时空解耦的高斯泼溅框架，用于高动态场景重建，通过事件相机补偿帧相机，解决了背景与物体时空特征不匹配的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法采用统一表示模型（如高斯）直接匹配动态场景的时空特征，但无法处理物体潜在的不连续时间特征及背景与物体的异质空间特征。

Method: 引入事件相机补偿帧相机，提出时空解耦的高斯泼溅框架，通过聚类区分背景与物体的时空特征，并利用高斯表示与事件数据的一致性指导物体高斯的时空解耦。

Result: 实验验证了该方法的优越性，能够提高背景与物体的时空区分度，渲染时间连续的动态场景。

Conclusion: 该方法通过时空解耦和事件相机的引入，有效解决了高动态场景重建中的时空特征不匹配问题。

Abstract: High-dynamic scene reconstruction aims to represent static background with
rigid spatial features and dynamic objects with deformed continuous
spatiotemporal features. Typically, existing methods adopt unified
representation model (e.g., Gaussian) to directly match the spatiotemporal
features of dynamic scene from frame camera. However, this unified paradigm
fails in the potential discontinuous temporal features of objects due to frame
imaging and the heterogeneous spatial features between background and objects.
To address this issue, we disentangle the spatiotemporal features into various
latent representations to alleviate the spatiotemporal mismatching between
background and objects. In this work, we introduce event camera to compensate
for frame camera, and propose a spatiotemporal-disentangled Gaussian splatting
framework for high-dynamic scene reconstruction. As for dynamic scene, we
figure out that background and objects have appearance discrepancy in
frame-based spatial features and motion discrepancy in event-based temporal
features, which motivates us to distinguish the spatiotemporal features between
background and objects via clustering. As for dynamic object, we discover that
Gaussian representations and event data share the consistent spatiotemporal
characteristic, which could serve as a prior to guide the spatiotemporal
disentanglement of object Gaussians. Within Gaussian splatting framework, the
cumulative scene-object disentanglement can improve the spatiotemporal
discrimination between background and objects to render the time-continuous
dynamic scene. Extensive experiments have been performed to verify the
superiority of the proposed method.

</details>


### [100] [Trident: Detecting Face Forgeries with Adversarial Triplet Learning](https://arxiv.org/abs/2506.23189)
*Mustafa Hakan Kara,Aysegul Dundar,Uğur Güdükbay*

Main category: cs.CV

TL;DR: 论文提出了一种名为Trident的人脸伪造检测框架，通过三元组学习和Siamese网络架构提升对不同伪造方法的适应性，并结合对抗训练增强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 随着深度神经网络生成的人脸伪造技术日益复杂，检测数字媒体中的人脸篡改变得更具挑战性，维护数字媒体完整性和打击视觉虚假信息的重要性凸显。现有检测模型在遇到未见过的伪造技术时表现不佳。

Method: Trident框架采用三元组学习和Siamese网络架构，通过精心设计的训练三元组捕捉伪造样本的细微差异。同时引入领域对抗训练和伪造鉴别器，生成伪造无关的特征表示，避免过拟合。

Result: 在多个基准测试和消融研究中，Trident表现出色，证明了其有效性。

Conclusion: Trident通过三元组学习和对抗训练，显著提升了人脸伪造检测的泛化能力和鲁棒性，为数字媒体完整性提供了有力支持。

Abstract: As face forgeries generated by deep neural networks become increasingly
sophisticated, detecting face manipulations in digital media has posed a
significant challenge, underscoring the importance of maintaining digital media
integrity and combating visual disinformation. Current detection models,
predominantly based on supervised training with domain-specific data, often
falter against forgeries generated by unencountered techniques. In response to
this challenge, we introduce \textit{Trident}, a face forgery detection
framework that employs triplet learning with a Siamese network architecture for
enhanced adaptability across diverse forgery methods. \textit{Trident} is
trained on curated triplets to isolate nuanced differences of forgeries,
capturing fine-grained features that distinguish pristine samples from
manipulated ones while controlling for other variables. To further enhance
generalizability, we incorporate domain-adversarial training with a forgery
discriminator. This adversarial component guides our embedding model towards
forgery-agnostic representations, improving its robustness to unseen
manipulations. In addition, we prevent gradient flow from the classifier head
to the embedding model, avoiding overfitting induced by artifacts peculiar to
certain forgeries. Comprehensive evaluations across multiple benchmarks and
ablation studies demonstrate the effectiveness of our framework. We will
release our code in a GitHub repository.

</details>


### [101] [DEL: Dense Event Localization for Multi-modal Audio-Visual Understanding](https://arxiv.org/abs/2506.23196)
*Mona Ahmadian,Amir Shirian,Frank Guerin,Andrew Gilbert*

Main category: cs.CV

TL;DR: DEL框架通过多模态交互建模，在长未剪辑视频中实现密集语义动作定位，显著提升了动作检测和分类的准确性。


<details>
  <summary>Details</summary>
Motivation: 现实世界视频中的重叠事件和复杂时间依赖关系使得多模态交互建模具有挑战性。

Method: DEL包含两个关键模块：利用掩码自注意力增强模态内一致性的视听特征对齐，以及建模多尺度跨模态依赖的多模态交互细化模块。

Result: 在多个TAL数据集上取得最先进性能，平均mAP提升显著：UnAV-100（+3.3%）、THUMOS14（+2.6%）、ActivityNet 1.3（+1.2%）、EPIC-Kitchens-100（动词+1.7%，名词+1.4%）。

Conclusion: DEL框架在多模态动作定位任务中表现出色，显著优于现有方法。

Abstract: Real-world videos often contain overlapping events and complex temporal
dependencies, making multimodal interaction modeling particularly challenging.
We introduce DEL, a framework for dense semantic action localization, aiming to
accurately detect and classify multiple actions at fine-grained temporal
resolutions in long untrimmed videos. DEL consists of two key modules: the
alignment of audio and visual features that leverage masked self-attention to
enhance intra-mode consistency and a multimodal interaction refinement module
that models cross-modal dependencies across multiple scales, enabling
high-level semantics and fine-grained details. Our method achieves
state-of-the-art performance on multiple real-world Temporal Action
Localization (TAL) datasets, UnAV-100, THUMOS14, ActivityNet 1.3, and
EPIC-Kitchens-100, surpassing previous approaches with notable average mAP
gains of +3.3%, +2.6%, +1.2%, +1.7% (verb), and +1.4% (noun), respectively.

</details>


### [102] [Transformer-Based Person Search with High-Frequency Augmentation and Multi-Wave Mixing](https://arxiv.org/abs/2506.23202)
*Qilin Shu,Qixian Zhang,Qi Zhang,Hongyun Zhang,Duoqian Miao,Cairong Zhao*

Main category: cs.CV

TL;DR: 论文提出了一种名为HAMW的新方法，通过高频增强和多波混合技术改进基于Transformer的人员搜索模型，解决了自注意力机制抑制高频特征和计算成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于Transformer的人员搜索模型存在自注意力机制抑制高频特征和计算成本高的问题，影响了性能。

Method: 提出HAMW方法，包括高频增强输入和多级Haar小波融合策略，分三阶段优化检测和重识别性能。

Result: 在CUHK-SYSU和PRW数据集上取得了最先进的性能。

Conclusion: HAMW方法有效提升了Transformer模型在人员搜索任务中的性能，同时降低了计算成本。

Abstract: The person search task aims to locate a target person within a set of scene
images. In recent years, transformer-based models in this field have made some
progress. However, they still face three primary challenges: 1) the
self-attention mechanism tends to suppress high-frequency components in the
features, which severely impacts model performance; 2) the computational cost
of transformers is relatively high. To address these issues, we propose a novel
High-frequency Augmentation and Multi-Wave mixing (HAMW) method for person
search. HAMW is designed to enhance the discriminative feature extraction
capabilities of transformers while reducing computational overhead and
improving efficiency. Specifically, we develop a three-stage framework that
progressively optimizes both detection and re-identification performance. Our
model enhances the perception of high-frequency features by learning from
augmented inputs containing additional high-frequency components. Furthermore,
we replace the self-attention layers in the transformer with a strategy based
on multi-level Haar wavelet fusion to capture multi-scale features. This not
only lowers the computational complexity but also alleviates the suppression of
high-frequency features and enhances the ability to exploit multi-scale
information. Extensive experiments demonstrate that HAMW achieves
state-of-the-art performance on both the CUHK-SYSU and PRW datasets.

</details>


### [103] [BridgeShape: Latent Diffusion Schrödinger Bridge for 3D Shape Completion](https://arxiv.org/abs/2506.23205)
*Dequan Kong,Zhe Zhu,Honghua Chen,Mingqiang Wei*

Main category: cs.CV

TL;DR: BridgeShape提出了一种基于潜在扩散Schrödinger桥的3D形状补全框架，通过最优传输路径和深度增强的VQ-VAE编码，解决了现有方法在全局一致性和分辨率限制上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的3D形状补全方法未能明确建模最优全局传输路径，且受限于体素空间的分辨率约束，导致补全效果不佳。

Method: BridgeShape将形状补全建模为最优传输问题，并引入深度增强的VQ-VAE编码3D形状到潜在空间，结合多视角深度信息和DINOv2特征增强几何感知。

Result: BridgeShape在大规模3D形状补全基准测试中达到最先进性能，支持更高分辨率和未见物体类别的补全。

Conclusion: BridgeShape通过潜在扩散和最优传输路径，显著提升了3D形状补全的全局一致性和细节生成能力。

Abstract: Existing diffusion-based 3D shape completion methods typically use a
conditional paradigm, injecting incomplete shape information into the denoising
network via deep feature interactions (e.g., concatenation, cross-attention) to
guide sampling toward complete shapes, often represented by voxel-based
distance functions. However, these approaches fail to explicitly model the
optimal global transport path, leading to suboptimal completions. Moreover,
performing diffusion directly in voxel space imposes resolution constraints,
limiting the generation of fine-grained geometric details. To address these
challenges, we propose BridgeShape, a novel framework for 3D shape completion
via latent diffusion Schr\"odinger bridge. The key innovations lie in two
aspects: (i) BridgeShape formulates shape completion as an optimal transport
problem, explicitly modeling the transition between incomplete and complete
shapes to ensure a globally coherent transformation. (ii) We introduce a
Depth-Enhanced Vector Quantized Variational Autoencoder (VQ-VAE) to encode 3D
shapes into a compact latent space, leveraging self-projected multi-view depth
information enriched with strong DINOv2 features to enhance geometric
structural perception. By operating in a compact yet structurally informative
latent space, BridgeShape effectively mitigates resolution constraints and
enables more efficient and high-fidelity 3D shape completion. BridgeShape
achieves state-of-the-art performance on large-scale 3D shape completion
benchmarks, demonstrating superior fidelity at higher resolutions and for
unseen object classes.

</details>


### [104] [TVG-SLAM: Robust Gaussian Splatting SLAM with Tri-view Geometric Constraints](https://arxiv.org/abs/2506.23207)
*Zhen Tan,Xieyuanli Chen,Lei Feng,Yangbing Ge,Shuaifeng Zhi,Jiaxiong Liu,Dewen Hu*

Main category: cs.CV

TL;DR: TVG-SLAM是一种基于3D高斯泼溅的RGB-only SLAM系统，通过三视图几何和混合几何约束提升跟踪和建图的鲁棒性，尤其在户外环境中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-only SLAM系统过度依赖光度渲染损失，导致在户外环境中因视角和光照变化而鲁棒性不足。

Method: 提出三视图匹配模块和混合几何约束，结合光度损失进行相机跟踪；采用概率初始化策略和动态衰减机制优化建图。

Result: 在多个户外数据集上表现优于现有方法，显著降低轨迹误差（ATE减少69.0%），并实现高质量渲染。

Conclusion: TVG-SLAM通过几何约束和动态机制显著提升了RGB-only SLAM的鲁棒性和性能。

Abstract: Recent advances in 3D Gaussian Splatting (3DGS) have enabled RGB-only SLAM
systems to achieve high-fidelity scene representation. However, the heavy
reliance of existing systems on photometric rendering loss for camera tracking
undermines their robustness, especially in unbounded outdoor environments with
severe viewpoint and illumination changes. To address these challenges, we
propose TVG-SLAM, a robust RGB-only 3DGS SLAM system that leverages a novel
tri-view geometry paradigm to ensure consistent tracking and high-quality
mapping. We introduce a dense tri-view matching module that aggregates reliable
pairwise correspondences into consistent tri-view matches, forming robust
geometric constraints across frames. For tracking, we propose Hybrid Geometric
Constraints, which leverage tri-view matches to construct complementary
geometric cues alongside photometric loss, ensuring accurate and stable pose
estimation even under drastic viewpoint shifts and lighting variations. For
mapping, we propose a new probabilistic initialization strategy that encodes
geometric uncertainty from tri-view correspondences into newly initialized
Gaussians. Additionally, we design a Dynamic Attenuation of Rendering Trust
mechanism to mitigate tracking drift caused by mapping latency. Experiments on
multiple public outdoor datasets show that our TVG-SLAM outperforms prior
RGB-only 3DGS-based SLAM systems. Notably, in the most challenging dataset, our
method improves tracking robustness, reducing the average Absolute Trajectory
Error (ATE) by 69.0\% while achieving state-of-the-art rendering quality. The
implementation of our method will be released as open-source.

</details>


### [105] [A Hierarchical Slice Attention Network for Appendicitis Classification in 3D CT Scans](https://arxiv.org/abs/2506.23209)
*Chia-Wen Huang,Haw Hwai,Chien-Chang Lee,Pei-Yuan Wu*

Main category: cs.CV

TL;DR: 提出了一种基于3D CT扫描的深度学习模型，结合切片注意力机制和预训练2D模型，用于阑尾炎的准确分类和复杂程度区分，显著提升了诊断性能。


<details>
  <summary>Details</summary>
Motivation: 阑尾炎的及时准确诊断至关重要，但CT扫描数量增加可能导致放射科医生负担过重，引发延误。

Method: 利用3D CT扫描和切片注意力机制，结合外部2D数据集增强小病变检测；采用预训练2D模型的层次分类框架区分简单和复杂阑尾炎。

Result: 阑尾炎分类的AUC提升3%，复杂阑尾炎分类的AUC提升5.9%。

Conclusion: 该方法比现有工作更高效可靠，为阑尾炎诊断提供了更好的解决方案。

Abstract: Timely and accurate diagnosis of appendicitis is critical in clinical
settings to prevent serious complications. While CT imaging remains the
standard diagnostic tool, the growing number of cases can overwhelm
radiologists, potentially causing delays. In this paper, we propose a deep
learning model that leverages 3D CT scans for appendicitis classification,
incorporating Slice Attention mechanisms guided by external 2D datasets to
enhance small lesion detection. Additionally, we introduce a hierarchical
classification framework using pre-trained 2D models to differentiate between
simple and complicated appendicitis. Our approach improves AUC by 3% for
appendicitis and 5.9% for complicated appendicitis, offering a more efficient
and reliable diagnostic solution compared to previous work.

</details>


### [106] [UrbanLLaVA: A Multi-modal Large Language Model for Urban Intelligence with Spatial Reasoning and Understanding](https://arxiv.org/abs/2506.23219)
*Jie Feng,Shengyuan Wang,Tianhui Liu,Yanxin Xi,Yong Li*

Main category: cs.CV

TL;DR: 论文提出了一种多模态大语言模型UrbanLLaVA，用于处理城市研究中的多模态数据，并在多种任务中表现优于通用MLLMs。


<details>
  <summary>Details</summary>
Motivation: 当前城市研究方法通常局限于特定数据类型，缺乏统一框架，而多模态大语言模型（MLLMs）的成功为解决这一问题提供了机会。

Method: 通过构建多样化的城市指令数据集，并提出多阶段训练框架，分离空间推理增强与领域知识学习，提升模型性能。

Result: 实验结果表明，UrbanLLaVA在单模态和跨模态任务中均优于开源和专有MLLMs，并展现出跨城市的强泛化能力。

Conclusion: UrbanLLaVA为城市研究提供了一个高效的多模态数据处理框架，并展示了其在复杂任务中的潜力。

Abstract: Urban research involves a wide range of scenarios and tasks that require the
understanding of multi-modal data. Current methods often focus on specific data
types and lack a unified framework in urban field for processing them
comprehensively. The recent success of multi-modal large language models
(MLLMs) presents a promising opportunity to overcome this limitation. In this
paper, we introduce $\textit{UrbanLLaVA}$, a multi-modal large language model
designed to process these four types of data simultaneously and achieve strong
performance across diverse urban tasks compared with general MLLMs. In
$\textit{UrbanLLaVA}$, we first curate a diverse urban instruction dataset
encompassing both single-modal and cross-modal urban data, spanning from
location view to global view of urban environment. Additionally, we propose a
multi-stage training framework that decouples spatial reasoning enhancement
from domain knowledge learning, thereby improving the compatibility and
downstream performance of $\textit{UrbanLLaVA}$ across diverse urban tasks.
Finally, we also extend existing benchmark for urban research to assess the
performance of MLLMs across a wide range of urban tasks. Experimental results
from three cities demonstrate that $\textit{UrbanLLaVA}$ outperforms
open-source and proprietary MLLMs in both single-modal tasks and complex
cross-modal tasks and shows robust generalization abilities across cities.
Source codes and data are openly accessible to the research community via
https://github.com/tsinghua-fib-lab/UrbanLLaVA.

</details>


### [107] [High-quality Pseudo-labeling for Point Cloud Segmentation with Scene-level Annotation](https://arxiv.org/abs/2506.23227)
*Lunhao Duan,Shanshan Zhao,Xingxing Weng,Jing Zhang,Gui-Song Xia*

Main category: cs.CV

TL;DR: 本文提出了一种基于场景级标注的室内点云语义分割方法，通过多模态信息和区域-点语义一致性生成高质量伪标签，显著提升了分割性能。


<details>
  <summary>Details</summary>
Motivation: 当前方法在缺乏精确点级标注时，依赖伪标签训练分割模型，但伪标签生成准确性不足影响性能。本文旨在解决这一问题。

Method: 提出跨模态特征引导模块和区域-点语义一致性模块，利用2D-3D对应关系和区域投票策略优化伪标签生成。

Result: 在ScanNet v2和S3DIS数据集上显著优于先前方法，消融实验验证了各模块的有效性。

Conclusion: 通过多模态和一致性模块，本文方法能生成高质量伪标签，提升场景级标注下的点云语义分割性能。

Abstract: This paper investigates indoor point cloud semantic segmentation under
scene-level annotation, which is less explored compared to methods relying on
sparse point-level labels. In the absence of precise point-level labels,
current methods first generate point-level pseudo-labels, which are then used
to train segmentation models. However, generating accurate pseudo-labels for
each point solely based on scene-level annotations poses a considerable
challenge, substantially affecting segmentation performance. Consequently, to
enhance accuracy, this paper proposes a high-quality pseudo-label generation
framework by exploring contemporary multi-modal information and region-point
semantic consistency. Specifically, with a cross-modal feature guidance module,
our method utilizes 2D-3D correspondences to align point cloud features with
corresponding 2D image pixels, thereby assisting point cloud feature learning.
To further alleviate the challenge presented by the scene-level annotation, we
introduce a region-point semantic consistency module. It produces regional
semantics through a region-voting strategy derived from point-level semantics,
which are subsequently employed to guide the point-level semantic predictions.
Leveraging the aforementioned modules, our method can rectify inaccurate
point-level semantic predictions during training and obtain high-quality
pseudo-labels. Significant improvements over previous works on ScanNet v2 and
S3DIS datasets under scene-level annotation can demonstrate the effectiveness.
Additionally, comprehensive ablation studies validate the contributions of our
approach's individual components. The code is available at
https://github.com/LHDuan/WSegPC .

</details>


### [108] [VolumetricSMPL: A Neural Volumetric Body Model for Efficient Interactions, Contacts, and Collisions](https://arxiv.org/abs/2506.23236)
*Marko Mihajlovic,Siwei Zhang,Gen Li,Kaifeng Zhao,Lea Müller,Siyu Tang*

Main category: cs.CV

TL;DR: VolumetricSMPL是一种基于神经混合权重（NBW）的神经体积人体模型，显著提升了计算效率和表达能力，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的人体模型在处理与其他几何实体的交互时效率低下，现有体积神经隐式模型在复杂人体关节表达或计算成本上存在不足。

Method: 利用NBW动态混合少量学习权重矩阵，生成紧凑高效的MLP解码器，支持SDF用于接触建模。

Result: VolumetricSMPL在推理速度、GPU内存使用、准确性上显著优于COAP，并在四项任务中表现优异。

Conclusion: VolumetricSMPL在广泛应用中展现出卓越的性能和效率提升。

Abstract: Parametric human body models play a crucial role in computer graphics and
vision, enabling applications ranging from human motion analysis to
understanding human-environment interactions. Traditionally, these models use
surface meshes, which pose challenges in efficiently handling interactions with
other geometric entities, such as objects and scenes, typically represented as
meshes or point clouds. To address this limitation, recent research has
explored volumetric neural implicit body models. However, existing works are
either insufficiently robust for complex human articulations or impose high
computational and memory costs, limiting their widespread use. To this end, we
introduce VolumetricSMPL, a neural volumetric body model that leverages Neural
Blend Weights (NBW) to generate compact, yet efficient MLP decoders. Unlike
prior approaches that rely on large MLPs, NBW dynamically blends a small set of
learned weight matrices using predicted shape- and pose-dependent coefficients,
significantly improving computational efficiency while preserving
expressiveness. VolumetricSMPL outperforms prior volumetric occupancy model
COAP with 10x faster inference, 6x lower GPU memory usage, enhanced accuracy,
and a Signed Distance Function (SDF) for efficient and differentiable contact
modeling. We demonstrate VolumetricSMPL's strengths across four challenging
tasks: (1) reconstructing human-object interactions from in-the-wild images,
(2) recovering human meshes in 3D scenes from egocentric views, (3)
scene-constrained motion synthesis, and (4) resolving self-intersections. Our
results highlight its broad applicability and significant performance and
efficiency gains.

</details>


### [109] [Aggregating Local Saliency Maps for Semi-Global Explainable Image Classification](https://arxiv.org/abs/2506.23247)
*James Hinns,David Martens*

Main category: cs.CV

TL;DR: 提出Segment Attribution Tables (SATs)方法，将局部显著性解释汇总为半全局见解，填补全局与局部解释之间的空白。


<details>
  <summary>Details</summary>
Motivation: 深度学习在图像分类中表现优异，但模型预测的解释仍具挑战性。现有方法或过于局部化，或过于简化全局，难以平衡。

Method: SATs利用图像片段（如“眼睛”）和显著性图量化其影响，揭示模型依赖的概念及虚假相关性。

Result: SATs能解释任何可生成显著性图的分类器，提供介于全局与局部之间的实用分析工具。

Conclusion: SATs为图像分类器的分析和调试提供了实用方法，填补了现有解释方法的不足。

Abstract: Deep learning dominates image classification tasks, yet understanding how
models arrive at predictions remains a challenge. Much research focuses on
local explanations of individual predictions, such as saliency maps, which
visualise the influence of specific pixels on a model's prediction. However,
reviewing many of these explanations to identify recurring patterns is
infeasible, while global methods often oversimplify and miss important local
behaviours. To address this, we propose Segment Attribution Tables (SATs), a
method for summarising local saliency explanations into (semi-)global insights.
SATs take image segments (such as "eyes" in Chihuahuas) and leverage saliency
maps to quantify their influence. These segments highlight concepts the model
relies on across instances and reveal spurious correlations, such as reliance
on backgrounds or watermarks, even when out-of-distribution test performance
sees little change. SATs can explain any classifier for which a form of
saliency map can be produced, using segmentation maps that provide named
segments. SATs bridge the gap between oversimplified global summaries and
overly detailed local explanations, offering a practical tool for analysing and
debugging image classifiers.

</details>


### [110] [DGE-YOLO: Dual-Branch Gathering and Attention for Accurate UAV Object Detection](https://arxiv.org/abs/2506.23252)
*Kunwei Lv,Ping Lan*

Main category: cs.CV

TL;DR: DGE-YOLO是一种改进的YOLO框架，用于多模态无人机目标检测，通过双分支架构和EMA机制提升性能。


<details>
  <summary>Details</summary>
Motivation: 无人机目标检测在复杂条件下对小物体的检测效果不佳，现有方法多模态输入处理能力有限。

Method: 提出双分支架构处理红外和可见光图像，引入EMA机制增强多尺度特征学习，改进特征聚合模块。

Result: 在Drone Vehicle数据集上表现优于现有方法。

Conclusion: DGE-YOLO在多模态无人机目标检测任务中效果显著。

Abstract: The rapid proliferation of unmanned aerial vehicles (UAVs) has highlighted
the importance of robust and efficient object detection in diverse aerial
scenarios. Detecting small objects under complex conditions, however, remains a
significant challenge. Existing approaches often prioritize inference speed,
leading to degraded performance when handling multi-modal inputs. To address
this, we present DGE-YOLO, an enhanced YOLO-based detection framework designed
to effectively fuse multi-modal information. Specifically, we introduce a
dual-branch architecture for modality-specific feature extraction, enabling the
model to process both infrared and visible images. To further enrich semantic
representation, we propose an Efficient Multi-scale Attention (EMA) mechanism
that enhances feature learning across spatial scales. Additionally, we replace
the conventional neck with a Gather-and-Distribute module to mitigate
information loss during feature aggregation. Extensive experiments on the Drone
Vehicle dataset demonstrate that DGE-YOLO achieves superior performance over
state-of-the-art methods, validating its effectiveness in multi-modal UAV
object detection tasks.

</details>


### [111] [PixelBoost: Leveraging Brownian Motion for Realistic-Image Super-Resolution](https://arxiv.org/abs/2506.23254)
*Aradhana Mishra,Bumshik Lee*

Main category: cs.CV

TL;DR: PixelBoost是一种新型扩散模型，通过利用布朗运动的随机性提升图像超分辨率，在纹理和边缘定义上实现高度真实感，同时优化计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的图像超分辨率技术常面临生成真实感与计算效率的权衡问题，减少采样步骤会导致图像模糊和不真实。

Method: 提出PixelBoost模型，将受控随机性融入训练过程，避免局部最优，并通过Sigmoid噪声序列方法简化训练。

Result: 在LPIPS、LOE、PSNR、SSIM等指标上表现优异，边缘重建能力更强，且具有自适应学习能力。

Conclusion: PixelBoost在图像超分辨率中实现了高真实感和计算效率的平衡，尤其在纹理和边缘处理上表现突出。

Abstract: Diffusion-model-based image super-resolution techniques often face a
trade-off between realistic image generation and computational efficiency. This
issue is exacerbated when inference times by decreasing sampling steps,
resulting in less realistic and hazy images. To overcome this challenge, we
introduce a novel diffusion model named PixelBoost that underscores the
significance of embracing the stochastic nature of Brownian motion in advancing
image super-resolution, resulting in a high degree of realism, particularly
focusing on texture and edge definitions. By integrating controlled
stochasticity into the training regimen, our proposed model avoids convergence
to local optima, effectively capturing and reproducing the inherent uncertainty
of image textures and patterns. Our proposed model demonstrates superior
objective results in terms of learned perceptual image patch similarity
(LPIPS), lightness order error (LOE), peak signal-to-noise ratio(PSNR),
structural similarity index measure (SSIM), as well as visual quality. To
determine the edge enhancement, we evaluated the gradient magnitude and pixel
value, and our proposed model exhibited a better edge reconstruction
capability. Additionally, our model demonstrates adaptive learning capabilities
by effectively adjusting to Brownian noise patterns and introduces a sigmoidal
noise sequencing method that simplifies training, resulting in faster inference
speeds.

</details>


### [112] [PCLVis: Visual Analytics of Process Communication Latency in Large-Scale Simulation](https://arxiv.org/abs/2506.23257)
*Chongke Bi,Xin Gao,Baofeng Fu,Yuheng Zhao,Siming Chen,Ying Zhao,Yunhai Wang*

Main category: cs.CV

TL;DR: PCLVis框架通过分析MPI进程通信数据，帮助用户定位和优化大规模模拟中的通信延迟问题，提升模拟效率。


<details>
  <summary>Details</summary>
Motivation: 大规模模拟在超级计算机上的通信延迟问题严重，现有方法依赖管理员才能获取的物理链路层信息，限制了普通用户的分析能力。

Method: 1. 使用空间PCL事件定位方法，构建进程相关性树聚类高相关进程；2. 构建基于通信依赖的有向无环图（DAG），分析PCL事件传播路径；3. 设计通信状态符号（CS-Glyph）展示进程通信状态；4. 提出PCL事件归因策略帮助优化模拟。

Result: 在TH-1A超级计算机上的多个模拟中验证了PCLVis框架的有效性，显著提升了模拟效率。

Conclusion: PCLVis框架为普通用户提供了无需物理链路层信息的通信延迟分析工具，能够有效优化大规模模拟的性能。

Abstract: Large-scale simulations on supercomputers have become important tools for
users. However, their scalability remains a problem due to the huge
communication cost among parallel processes. Most of the existing communication
latency analysis methods rely on the physical link layer information, which is
only available to administrators. In this paper, a framework called PCLVis is
proposed to help general users analyze process communication latency (PCL)
events. Instead of the physical link layer information, the PCLVis uses the MPI
process communication data for the analysis. First, a spatial PCL event
locating method is developed. All processes with high correlation are
classified into a single cluster by constructing a process-correlation tree.
Second, the propagation path of PCL events is analyzed by constructing a
communication-dependency-based directed acyclic graph (DAG), which can help
users interactively explore a PCL event from the temporal evolution of a
located PCL event cluster. In this graph, a sliding window algorithm is
designed to generate the PCL events abstraction. Meanwhile, a new glyph called
the communication state glyph (CS-Glyph) is designed for each process to show
its communication states, including its in/out messages and load balance. Each
leaf node can be further unfolded to view additional information. Third, a PCL
event attribution strategy is formulated to help users optimize their
simulations. The effectiveness of the PCLVis framework is demonstrated by
analyzing the PCL events of several simulations running on the TH-1A
supercomputer. By using the proposed framework, users can greatly improve the
efficiency of their simulations.

</details>


### [113] [Causal-Entity Reflected Egocentric Traffic Accident Video Synthesis](https://arxiv.org/abs/2506.23263)
*Lei-lei Li,Jianwu Fang,Junbin Xiao,Shanmin Pang,Hongkai Yu,Chen Lv,Jianru Xue,Tat-Seng Chua*

Main category: cs.CV

TL;DR: 提出了一种名为Causal-VidSyn的扩散模型，用于合成以自我为中心的交通事故视频，通过结合原因描述和驾驶员注视点来识别事故参与者和行为。


<details>
  <summary>Details</summary>
Motivation: 理解交通事故的因果关系对自动驾驶汽车的安全至关重要，而合成具有因果关系的视频可以测试对现实中难以承受的事故的响应能力。

Method: 利用原因描述和驾驶员注视点，通过事故原因回答和注视条件选择模块，实现视频扩散中的因果实体定位。

Result: Causal-VidSyn在帧质量和因果敏感性方面优于现有视频扩散模型，支持事故视频编辑、正常到事故视频扩散和文本到视频生成等任务。

Conclusion: Causal-VidSyn通过结合因果关系和驾驶员注视点，显著提升了合成交通事故视频的质量和实用性。

Abstract: Egocentricly comprehending the causes and effects of car accidents is crucial
for the safety of self-driving cars, and synthesizing causal-entity reflected
accident videos can facilitate the capability test to respond to unaffordable
accidents in reality. However, incorporating causal relations as seen in
real-world videos into synthetic videos remains challenging. This work argues
that precisely identifying the accident participants and capturing their
related behaviors are of critical importance. In this regard, we propose a
novel diffusion model, Causal-VidSyn, for synthesizing egocentric traffic
accident videos. To enable causal entity grounding in video diffusion,
Causal-VidSyn leverages the cause descriptions and driver fixations to identify
the accident participants and behaviors, facilitated by accident reason
answering and gaze-conditioned selection modules. To support Causal-VidSyn, we
further construct Drive-Gaze, the largest driver gaze dataset (with 1.54M
frames of fixations) in driving accident scenarios. Extensive experiments show
that Causal-VidSyn surpasses state-of-the-art video diffusion models in terms
of frame quality and causal sensitivity in various tasks, including accident
video editing, normal-to-accident video diffusion, and text-to-video
generation.

</details>


### [114] [Token Activation Map to Visually Explain Multimodal LLMs](https://arxiv.org/abs/2506.23270)
*Yi Li,Hualiang Wang,Xinpeng Ding,Haonan Wang,Xiaomeng Li*

Main category: cs.CV

TL;DR: 提出了一种名为Token Activation Map (TAM)的方法，通过估计因果推理和秩高斯滤波，解决了多模态大语言模型(MLLMs)解释性中上下文冗余激活的问题，显著提升了解释质量。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型(MLLMs)的解释性研究不足，影响了模型的可信度和可视化效果。现有方法忽视了上下文冗余激活对解释可靠性的负面影响。

Method: 提出TAM方法，通过估计因果推理减少上下文干扰，并引入秩高斯滤波降低激活噪声。

Result: TAM在多种任务（如目标定位、失败案例分析等）中显著优于现有方法，提供了高质量的可视化结果。

Conclusion: TAM为MLLMs的解释性提供了有效解决方案，适用于多种应用场景，提升了模型的可理解性和可信度。

Abstract: Multimodal large language models (MLLMs) are broadly empowering various
fields. Despite their advancements, the explainability of MLLMs remains less
explored, hindering deeper understanding, model credibility, and effective
visualization. Unlike conventional vision models (e.g., CNNs, ViTs, CLIP) that
produce a single output, MLLMs generate sequences of tokens progressively,
where each generated token depends on the previous context. Therefore, earlier
context tokens can introduce redundant activations that interfere with the
explanation of later tokens beyond their original information. Existing studies
often overlook this issue, but our observations reveal that these redundant
correlations can significantly hurt the reliability of explanations. To address
this, we propose an estimated causal inference method to mitigate the
interference of context to achieve high-quality MLLM explanation, with a novel
rank Gaussian filter to further reduce activation noises. We term this method
Token Activation Map (TAM) to highlight the consideration of interactions
between tokens. TAM also indicates that it excels at explaining multiple tokens
of MLLM, which is different from the Class Activation Map (CAM) for a single
prediction. Our TAM method significantly outperforms existing SoTA methods,
showcasing high-quality visualization results that can be utilized for various
scenarios, such as object localization, failure case analysis, video
visualization, MLLMs visual comparison, and model understanding (e.g., color,
shape, action, location, visual reasoning, multi-turn conversation, etc). The
code is available atgithub.com/xmed-lab/TAM.

</details>


### [115] [Mettle: Meta-Token Learning for Memory-Efficient Audio-Visual Adaptation](https://arxiv.org/abs/2506.23271)
*Jinxing Zhou,Zhihui Li,Yongqiang Yu,Yanghao Zhou,Ruohao Guo,Guangyao Li,Yuxin Mao,Mingfei Han,Xiaojun Chang,Meng Wang*

Main category: cs.CV

TL;DR: Mettle是一种高效的内存方法，通过并行蒸馏音频或视觉特征为元令牌，适应大规模预训练Transformer模型到下游视听任务。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法在适应大规模预训练Transformer模型时内存和训练时间效率低下的问题。

Method: 使用轻量级Layer-Centric Distillation (LCD)模块并行蒸馏特征为元令牌，并引入Meta-Token Injection (MTI)模块支持细粒度分割任务。

Result: 在多个视听基准测试中显著减少内存使用和训练时间，同时保持参数效率和竞争性准确率。

Conclusion: Mettle提供了一种高效且内存友好的方法，适用于多种视听任务。

Abstract: We present \textbf{Met}a-\textbf{T}oken \textbf{Le}arning (Mettle), a simple
and memory-efficient method for adapting large-scale pretrained transformer
models to downstream audio-visual tasks. Instead of sequentially modifying the
output feature distribution of the transformer backbone, Mettle utilizes a
lightweight \textit{Layer-Centric Distillation (LCD)} module to distill in
parallel the intact audio or visual features embedded by each transformer layer
into compact meta-tokens. This distillation process considers both pretrained
knowledge preservation and task-specific adaptation. The obtained meta-tokens
can be directly applied to classification tasks, such as audio-visual event
localization and audio-visual video parsing. To further support fine-grained
segmentation tasks, such as audio-visual segmentation, we introduce a
\textit{Meta-Token Injection (MTI)} module, which utilizes the audio and visual
meta-tokens distilled from the top transformer layer to guide feature
adaptation in earlier layers. Extensive experiments on multiple audiovisual
benchmarks demonstrate that our method significantly reduces memory usage and
training time while maintaining parameter efficiency and competitive accuracy.

</details>


### [116] [Why Settle for One? Text-to-ImageSet Generation and Evaluation](https://arxiv.org/abs/2506.23275)
*Chengyou Jia,Xin Shen,Zhuohang Dang,Zhuohang Dang,Changliang Xia,Weijia Wu,Xinyu Zhang,Hangwei Qian,Ivor W. Tsang,Minnan Luo*

Main category: cs.CV

TL;DR: 本文提出了一种更具挑战性的问题——文本到图像集（T2IS）生成，旨在根据用户指令生成满足多种一致性要求的图像集。作者引入了T2IS-Bench数据集和T2IS-Eval评估框架，并提出了训练无关的AutoT2IS方法，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的一致性方法通常局限于特定领域，限制了其泛化能力。本文旨在解决更广泛的文本到图像集生成问题，满足多样的一致性需求。

Method: 作者首先构建了T2IS-Bench数据集和T2IS-Eval评估框架，随后提出了AutoT2IS方法，利用预训练的Diffusion Transformers的上下文能力来满足图像级提示对齐和集级视觉一致性。

Result: 实验表明，AutoT2IS显著优于现有方法，并能支持多种未充分探索的实际应用。

Conclusion: 本文提出的T2IS生成框架在多样一致性需求下表现出色，具有重要的实用价值。

Abstract: Despite remarkable progress in Text-to-Image models, many real-world
applications require generating coherent image sets with diverse consistency
requirements. Existing consistent methods often focus on a specific domain with
specific aspects of consistency, which significantly constrains their
generalizability to broader applications. In this paper, we propose a more
challenging problem, Text-to-ImageSet (T2IS) generation, which aims to generate
sets of images that meet various consistency requirements based on user
instructions. To systematically study this problem, we first introduce
$\textbf{T2IS-Bench}$ with 596 diverse instructions across 26 subcategories,
providing comprehensive coverage for T2IS generation. Building on this, we
propose $\textbf{T2IS-Eval}$, an evaluation framework that transforms user
instructions into multifaceted assessment criteria and employs effective
evaluators to adaptively assess consistency fulfillment between criteria and
generated sets. Subsequently, we propose $\textbf{AutoT2IS}$, a training-free
framework that maximally leverages pretrained Diffusion Transformers'
in-context capabilities to harmonize visual elements to satisfy both
image-level prompt alignment and set-level visual consistency. Extensive
experiments on T2IS-Bench reveal that diverse consistency challenges all
existing methods, while our AutoT2IS significantly outperforms current
generalized and even specialized approaches. Our method also demonstrates the
ability to enable numerous underexplored real-world applications, confirming
its substantial practical value. Visit our project in
https://chengyou-jia.github.io/T2IS-Home.

</details>


### [117] [Autoregressive Denoising Score Matching is a Good Video Anomaly Detector](https://arxiv.org/abs/2506.23282)
*Hanwen Zhang,Congqi Cao,Qinyi Lv,Lingtong Min,Yanning Zhang*

Main category: cs.CV

TL;DR: 该论文提出了一种基于生成模型的视频异常检测方法，通过噪声条件评分变换器和场景依赖的运动感知评分函数，解决了局部模式异常的检测问题。


<details>
  <summary>Details</summary>
Motivation: 视频异常检测（VAD）是计算机视觉中的重要问题，但现有基于似然的方法对局部模式异常不敏感。论文旨在解决这一问题。

Method: 使用噪声条件评分变换器进行去噪评分匹配，引入场景依赖和运动感知评分函数，并通过自回归去噪评分匹配机制增强异常检测。

Result: 在三个流行的VAD基准测试中，该方法表现出最先进的性能。

Conclusion: 综合考虑场景、运动和外观三个方面的差距，能够更全面地检测视频异常。

Abstract: Video anomaly detection (VAD) is an important computer vision problem. Thanks
to the mode coverage capabilities of generative models, the likelihood-based
paradigm is catching growing interest, as it can model normal distribution and
detect out-of-distribution anomalies. However, these likelihood-based methods
are blind to the anomalies located in local modes near the learned
distribution. To handle these ``unseen" anomalies, we dive into three gaps
uniquely existing in VAD regarding scene, motion and appearance. Specifically,
we first build a noise-conditioned score transformer for denoising score
matching. Then, we introduce a scene-dependent and motion-aware score function
by embedding the scene condition of input sequences into our model and
assigning motion weights based on the difference between key frames of input
sequences. Next, to solve the problem of blindness in principle, we integrate
unaffected visual information via a novel autoregressive denoising score
matching mechanism for inference. Through autoregressively injecting
intensifying Gaussian noise into the denoised data and estimating the
corresponding score function, we compare the denoised data with the original
data to get a difference and aggregate it with the score function for an
enhanced appearance perception and accumulate the abnormal context. With all
three gaps considered, we can compute a more comprehensive anomaly indicator.
Experiments on three popular VAD benchmarks demonstrate the state-of-the-art
performance of our method.

</details>


### [118] [MoMa: Modulating Mamba for Adapting Image Foundation Models to Video Recognition](https://arxiv.org/abs/2506.23283)
*Yuhuan Yang,Chaofan Ma,Zhenjie Mao,Jiangchao Yao,Ya Zhang,Yanfeng Wang*

Main category: cs.CV

TL;DR: MoMa是一个高效的适配器框架，通过将Mamba的选择性状态空间建模集成到图像基础模型（IFMs）中，实现全时空建模。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理视频时空信息时往往分离处理，未能充分捕捉视频动态的复杂性，因此需要一种更高效的建模方法。

Method: 提出SeqMod操作，将时空信息注入预训练的IFMs中，同时保持其原始特征；采用Divide-and-Modulate架构。

Result: 在多个视频基准测试中表现优异，计算成本降低。

Conclusion: MoMa通过高效的时空建模，显著提升了视频理解能力，同时保持计算效率。

Abstract: Video understanding is a complex challenge that requires effective modeling
of spatial-temporal dynamics. With the success of image foundation models
(IFMs) in image understanding, recent approaches have explored
parameter-efficient fine-tuning (PEFT) to adapt IFMs for video. However, most
of these methods tend to process spatial and temporal information separately,
which may fail to capture the full intricacy of video dynamics. In this paper,
we propose MoMa, an efficient adapter framework that achieves full
spatial-temporal modeling by integrating Mamba's selective state space modeling
into IFMs. We propose a novel SeqMod operation to inject spatial-temporal
information into pre-trained IFMs, without disrupting their original features.
By incorporating SeqMod into a Divide-and-Modulate architecture, MoMa enhances
video understanding while maintaining computational efficiency. Extensive
experiments on multiple video benchmarks demonstrate the effectiveness of MoMa,
achieving superior performance with reduced computational cost.

</details>


### [119] [Competitive Distillation: A Simple Learning Strategy for Improving Visual Classification](https://arxiv.org/abs/2506.23285)
*Daqian Shi,Xiaolei Diao,Xu Chen,Cédric M. John*

Main category: cs.CV

TL;DR: 提出了一种新颖的竞争蒸馏策略，通过动态选择教师网络和引入竞争优化，提升多网络协同训练的效果。


<details>
  <summary>Details</summary>
Motivation: 现有蒸馏方法因对学习方向影响理解不足，性能提升有限。

Method: 提出竞争蒸馏策略，动态选择教师网络，引入竞争优化和随机扰动。

Result: 实验表明，该方法在多种任务和数据集上表现优异。

Conclusion: 竞争蒸馏通过动态竞争和扰动，显著提升了训练性能和泛化能力。

Abstract: Deep Neural Networks (DNNs) have significantly advanced the field of computer
vision. To improve DNN training process, knowledge distillation methods
demonstrate their effectiveness in accelerating network training by introducing
a fixed learning direction from the teacher network to student networks. In
this context, several distillation-based optimization strategies are proposed,
e.g., deep mutual learning and self-distillation, as an attempt to achieve
generic training performance enhancement through the cooperative training of
multiple networks. However, such strategies achieve limited improvements due to
the poor understanding of the impact of learning directions among networks
across different iterations. In this paper, we propose a novel competitive
distillation strategy that allows each network in a group to potentially act as
a teacher based on its performance, enhancing the overall learning performance.
Competitive distillation organizes a group of networks to perform a shared task
and engage in competition, where competitive optimization is proposed to
improve the parameter updating process. We further introduce stochastic
perturbation in competitive distillation, aiming to motivate networks to induce
mutations to achieve better visual representations and global optimum. The
experimental results show that competitive distillation achieves promising
performance in diverse tasks and datasets.

</details>


### [120] [DDL: A Dataset for Interpretable Deepfake Detection and Localization in Real-World Scenarios](https://arxiv.org/abs/2506.23292)
*Changtao Miao,Yi Zhang,Weize Gao,Man Luo,Weiwei Feng,Zhiya Tan,Jianshu Li,Ajian Liu,Yunfeng Diao,Qi Chu,Tao Gong,Zhe Li,Weibin Yao,Joey Tianyi Zhou*

Main category: cs.CV

TL;DR: 论文提出了一种新的大规模深度伪造检测与定位数据集（DDL），包含180万伪造样本和75种深度伪造方法，旨在解决现有数据集在多样性和规模上的不足，提升检测和解释性。


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术的滥用日益严重，现有检测方法缺乏解释性，且数据集在多样性和规模上不足，无法满足复杂现实场景的需求。

Method: 构建了DDL数据集，包含多样伪造场景、全面深度伪造方法、多种操纵模式和细粒度伪造标注。

Result: DDL数据集为复杂现实伪造提供了更具挑战性的基准，并支持下一代深度伪造检测、定位和解释性方法的发展。

Conclusion: DDL数据集通过多样性和规模上的改进，为深度伪造检测和解释性研究提供了重要支持。

Abstract: Recent advances in AIGC have exacerbated the misuse of malicious deepfake
content, making the development of reliable deepfake detection methods an
essential means to address this challenge. Although existing deepfake detection
models demonstrate outstanding performance in detection metrics, most methods
only provide simple binary classification results, lacking interpretability. In
critical domains such as law, interpretability is crucial for enhancing the
credibility and authority of decisions. Recent studies attempt to improve the
interpretability of classification results by providing spatial manipulation
masks or temporal forgery segments. However, the practical effectiveness of
these methods remains suboptimal due to limitations of the forgery data. Most
current deepfake datasets predominantly offer binary labels, only a few
datasets with localization annotations. However, they suffer from restricted
forgery scenarios, limited diversity in deepfake types, and insufficient data
scale, making them inadequate for complex real-world scenarios. To address this
predicament, we construct a novel large-scale deepfake detection and
localization ($\textbf{DDL}$) dataset containing over $\textbf{1.8M}$ forged
samples and encompassing up to $\textbf{75}$ distinct deepfake methods. The DDL
design incorporates four key innovations: (1) $\textbf{Diverse Forgery
Scenarios}$, (2) $\textbf{Comprehensive Deepfake Methods}$, (3) $\textbf{Varied
Manipulation Modes}$, and (4) $\textbf{Fine-grained Forgery Annotations}$.
Through these improvements, our DDL not only provides a more challenging
benchmark for complex real-world forgeries, but also offers crucial support for
building next-generation deepfake detection, localization, and interpretability
methods. The DDL dataset project page is on
https://deepfake-workshop-ijcai2025.github.io/main/index.html.

</details>


### [121] [DiffFit: Disentangled Garment Warping and Texture Refinement for Virtual Try-On](https://arxiv.org/abs/2506.23295)
*Xiang Xu*

Main category: cs.CV

TL;DR: DiffFit是一种新型的两阶段潜在扩散框架，用于高保真虚拟试穿，通过几何感知的服装变形和纹理细化解决现有方法的不足。


<details>
  <summary>Details</summary>
Motivation: 虚拟试穿（VTON）在电子商务和数字时尚中有广泛应用，但现有方法在保留服装细节、精确对齐、推理效率和多样化姿势与风格泛化方面仍有挑战。

Method: DiffFit采用两阶段策略：第一阶段通过几何感知的服装变形对齐目标身体；第二阶段通过跨模态条件扩散模型细化纹理。

Result: DiffFit在定量指标和感知评估中均优于现有最先进方法，能够保留服装细节并确保与人体准确对齐。

Conclusion: DiffFit通过解耦几何对齐和外观细化，显著提升了虚拟试穿的生成稳定性和视觉真实感。

Abstract: Virtual try-on (VTON) aims to synthesize realistic images of a person wearing
a target garment, with broad applications in e-commerce and digital fashion.
While recent advances in latent diffusion models have substantially improved
visual quality, existing approaches still struggle with preserving fine-grained
garment details, achieving precise garment-body alignment, maintaining
inference efficiency, and generalizing to diverse poses and clothing styles. To
address these challenges, we propose DiffFit, a novel two-stage latent
diffusion framework for high-fidelity virtual try-on. DiffFit adopts a
progressive generation strategy: the first stage performs geometry-aware
garment warping, aligning the garment with the target body through fine-grained
deformation and pose adaptation. The second stage refines texture fidelity via
a cross-modal conditional diffusion model that integrates the warped garment,
the original garment appearance, and the target person image for high-quality
rendering. By decoupling geometric alignment and appearance refinement, DiffFit
effectively reduces task complexity and enhances both generation stability and
visual realism. It excels in preserving garment-specific attributes such as
textures, wrinkles, and lighting, while ensuring accurate alignment with the
human body. Extensive experiments on large-scale VTON benchmarks demonstrate
that DiffFit achieves superior performance over existing state-of-the-art
methods in both quantitative metrics and perceptual evaluations.

</details>


### [122] [Endo-4DGX: Robust Endoscopic Scene Reconstruction and Illumination Correction with Gaussian Splatting](https://arxiv.org/abs/2506.23308)
*Yiming Huang,Long Bai,Beilei Cui,Yanheng Li,Tong Chen,Jie Wang,Jinlin Wu,Zhen Lei,Hongbin Liu,Hongliang Ren*

Main category: cs.CV

TL;DR: Endo-4DGX是一种新型的内窥镜场景重建方法，通过光照自适应的高斯泼溅技术解决了3D-GS在极端光照条件下的渲染问题。


<details>
  <summary>Details</summary>
Motivation: 在图像引导机器人手术中，软组织的精确重建对自动化至关重要。3D-GS及其变体在动态手术场景中实现了高质量的实时渲染，但在极端光照条件下表现不佳。

Method: Endo-4DGX结合了光照嵌入、区域感知增强模块和空间感知调整模块，实现了光照自适应优化。

Result: 实验表明，Endo-4DGX在低光和过曝光条件下均优于现有方法，同时保持几何精度。

Conclusion: Endo-4DGX在挑战性光照环境中表现出色，有望推动机器人辅助手术的发展。

Abstract: Accurate reconstruction of soft tissue is crucial for advancing automation in
image-guided robotic surgery. The recent 3D Gaussian Splatting (3DGS)
techniques and their variants, 4DGS, achieve high-quality renderings of dynamic
surgical scenes in real-time. However, 3D-GS-based methods still struggle in
scenarios with varying illumination, such as low light and over-exposure.
Training 3D-GS in such extreme light conditions leads to severe optimization
problems and devastating rendering quality. To address these challenges, we
present Endo-4DGX, a novel reconstruction method with illumination-adaptive
Gaussian Splatting designed specifically for endoscopic scenes with uneven
lighting. By incorporating illumination embeddings, our method effectively
models view-dependent brightness variations. We introduce a region-aware
enhancement module to model the sub-area lightness at the Gaussian level and a
spatial-aware adjustment module to learn the view-consistent brightness
adjustment. With the illumination adaptive design, Endo-4DGX achieves superior
rendering performance under both low-light and over-exposure conditions while
maintaining geometric accuracy. Additionally, we employ an exposure control
loss to restore the appearance from adverse exposure to the normal level for
illumination-adaptive optimization. Experimental results demonstrate that
Endo-4DGX significantly outperforms combinations of state-of-the-art
reconstruction and restoration methods in challenging lighting environments,
underscoring its potential to advance robot-assisted surgical applications. Our
code is available at https://github.com/lastbasket/Endo-4DGX.

</details>


### [123] [FastSeg: Efficient Training-Free Open-Vocabulary Segmentation via Hierarchical Attention Refinement Method](https://arxiv.org/abs/2506.23323)
*Quang-Huy Che,Vinh-Tiep Nguyen*

Main category: cs.CV

TL;DR: FastSeg提出了一种高效的训练无关框架，通过预训练扩散模型（如Stable Diffusion）的（1+1）步反向过程实现开放词汇语义分割（OVSS），并在多类别分割中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有对比学习模型在像素级空间精度上表现不足，而扩散模型虽能捕捉细粒度特征，但迭代次数与分割质量难以平衡。FastSeg旨在解决这些问题。

Method: FastSeg采用双提示机制、分层注意力细化方法（HARD）和测试时间翻转（TTF）方案，提升分割质量与效率。

Result: FastSeg在PASCAL VOC、PASCAL Context和COCO Object基准测试中达到43.8%的平均mIoU，表现优异且高效。

Conclusion: FastSeg为开放词汇语义分割提供了高质量与高效推理的平衡方案，具有扩展潜力。

Abstract: Open-vocabulary semantic segmentation (OVSS) aims to segment objects from
arbitrary text categories without requiring densely annotated datasets.
Although contrastive learning based models enable zero-shot segmentation, they
often lose fine spatial precision at pixel level, due to global representation
bias. In contrast, diffusion-based models naturally encode fine-grained spatial
features via attention mechanisms that capture both global context and local
details. However, they often face challenges in balancing the number of
iterations with the quality of the segmentation. In this work, we propose
FastSeg, a novel and efficient training-free framework with only (1+1)-step of
reverse process of a pretrained diffusion model (e.g., Stable Diffusion).
Moreover, instead of running multiple times for different classes, FastSeg
performs segmentation for all classes at once. To further enhance the
segmentation quality, FastSeg introduces three key components: (i) a
dual-prompt mechanism for discriminative, class-aware attention extraction,
(ii) a Hierarchical Attention Refinement Method (HARD) that enhances fused
cross-attention using scale-aligned selfattention maps, and (iii) a Test-Time
Flipping (TTF) scheme designed to improve spatial consistency. Extensive
experiments show that FastSeg achieves state-of-the-art training-free
performance, obtaining 43.8% average mIoU across PASCAL VOC, PASCAL Context,
and COCO Object benchmarks while maintaining superior inference efficiency. Our
results demonstrate that FastSeg provides a strong foundation for
extendability, bridging the gap between segmentation quality and inference
efficiency.

</details>


### [124] [IR3D-Bench: Evaluating Vision-Language Model Scene Understanding as Agentic Inverse Rendering](https://arxiv.org/abs/2506.23329)
*Parker Liu,Chenxin Li,Zhengxin Li,Yipeng Wu,Wuyang Li,Zhiqin Yang,Zhenyuan Zhang,Yunlong Lin,Sirui Han,Brandon Y. Feng*

Main category: cs.CV

TL;DR: IR3D-Bench是一个新的基准测试，通过要求视觉语言模型（VLMs）主动使用工具重建输入图像的3D结构，评估其场景理解能力。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在描述性任务上表现优异，但其是否真正理解场景仍不确定。IR3D-Bench旨在通过“通过创造来理解”的方法，探索模型的工具使用生成能力。

Method: 基于分析-合成范式，IR3D-Bench要求视觉语言代理（VLAs）使用编程和渲染工具重建输入图像的3D结构，实现逆向渲染。

Result: 初步实验表明，现有VLMs在视觉精度上存在局限，而非基本工具使用。

Conclusion: IR3D-Bench为系统研究和开发工具使用型VLAs提供了数据与评估协议，推动真正的场景理解。

Abstract: Vision-language models (VLMs) excel at descriptive tasks, but whether they
truly understand scenes from visual observations remains uncertain. We
introduce IR3D-Bench, a benchmark challenging VLMs to demonstrate understanding
through active creation rather than passive recognition. Grounded in the
analysis-by-synthesis paradigm, IR3D-Bench tasks Vision-Language Agents (VLAs)
with actively using programming and rendering tools to recreate the underlying
3D structure of an input image, achieving agentic inverse rendering through
tool use. This "understanding-by-creating" approach probes the tool-using
generative capacity of VLAs, moving beyond the descriptive or conversational
capacity measured by traditional scene understanding benchmarks. We provide a
comprehensive suite of metrics to evaluate geometric accuracy, spatial
relations, appearance attributes, and overall plausibility. Initial experiments
on agentic inverse rendering powered by various state-of-the-art VLMs highlight
current limitations, particularly in visual precision rather than basic tool
usage. IR3D-Bench, including data and evaluation protocols, is released to
facilitate systematic study and development of tool-using VLAs towards genuine
scene understanding by creating.

</details>


### [125] [CycleVAR: Repurposing Autoregressive Model for Unsupervised One-Step Image Translation](https://arxiv.org/abs/2506.23347)
*Yi Liu,Shengqian Li,Zuzeng Lin,Feng Wang,Si Liu*

Main category: cs.CV

TL;DR: 论文提出CycleVAR方法，通过Softmax Relaxed Quantization解决传统量化方法梯度中断问题，实现无监督图像翻译的端到端优化。


<details>
  <summary>Details</summary>
Motivation: 现有条件自回归图像生成方法在无监督图像翻译领域潜力未充分挖掘，传统量化方法导致梯度中断，阻碍优化。

Method: 提出Softmax Relaxed Quantization保持梯度传播，并基于此设计CycleVAR，将图像翻译转化为条件自回归生成任务，支持串行和并行生成模式。

Result: 并行单步生成模式在无监督场景下表现优于串行多步模式，CycleVAR超越现有最优模型如CycleGAN-Turbo。

Conclusion: CycleVAR通过连续概率混合和条件自回归生成，显著提升无监督图像翻译性能。

Abstract: The current conditional autoregressive image generation methods have shown
promising results, yet their potential remains largely unexplored in the
practical unsupervised image translation domain, which operates without
explicit cross-domain correspondences. A critical limitation stems from the
discrete quantization inherent in traditional Vector Quantization-based
frameworks, which disrupts gradient flow between the Variational Autoencoder
decoder and causal Transformer, impeding end-to-end optimization during
adversarial training in image space. To tackle this issue, we propose using
Softmax Relaxed Quantization, a novel approach that reformulates codebook
selection as a continuous probability mixing process via Softmax, thereby
preserving gradient propagation. Building upon this differentiable foundation,
we introduce CycleVAR, which reformulates image-to-image translation as
image-conditional visual autoregressive generation by injecting multi-scale
source image tokens as contextual prompts, analogous to prefix-based
conditioning in language models. CycleVAR exploits two modes to generate the
target image tokens, including (1) serial multi-step generation, enabling
iterative refinement across scales, and (2) parallel one-step generation
synthesizing all resolution outputs in a single forward pass. Experimental
findings indicate that the parallel one-step generation mode attains superior
translation quality with quicker inference speed than the serial multi-step
mode in unsupervised scenarios. Furthermore, both quantitative and qualitative
results indicate that CycleVAR surpasses previous state-of-the-art unsupervised
image translation models, \textit{e}.\textit{g}., CycleGAN-Turbo.

</details>


### [126] [GeoProg3D: Compositional Visual Reasoning for City-Scale 3D Language Fields](https://arxiv.org/abs/2506.23352)
*Shunsuke Yasuki,Taiki Miyanishi,Nakamasa Inoue,Shuhei Kurita,Koya Sakamoto,Daichi Azuma,Masato Taki,Yutaka Matsuo*

Main category: cs.CV

TL;DR: GeoProg3D是一个基于自然语言的视觉编程框架，用于城市规模的高保真3D场景交互，通过地理感知和视觉API实现高效推理。


<details>
  <summary>Details</summary>
Motivation: 现有3D语言方法局限于小规模环境，缺乏城市规模的可扩展性和组合推理能力。

Method: 结合地理感知的3D语言场（GCLF）和地理视觉API（GV-APIs），利用大语言模型（LLMs）动态组合工具。

Result: 在GeoEval3D基准测试中显著优于现有方法，支持多种地理视觉任务。

Conclusion: GeoProg3D是首个支持城市规模3D环境中组合地理推理的框架。

Abstract: The advancement of 3D language fields has enabled intuitive interactions with
3D scenes via natural language. However, existing approaches are typically
limited to small-scale environments, lacking the scalability and compositional
reasoning capabilities necessary for large, complex urban settings. To overcome
these limitations, we propose GeoProg3D, a visual programming framework that
enables natural language-driven interactions with city-scale high-fidelity 3D
scenes. GeoProg3D consists of two key components: (i) a Geography-aware
City-scale 3D Language Field (GCLF) that leverages a memory-efficient
hierarchical 3D model to handle large-scale data, integrated with geographic
information for efficiently filtering vast urban spaces using directional cues,
distance measurements, elevation data, and landmark references; and (ii)
Geographical Vision APIs (GV-APIs), specialized geographic vision tools such as
area segmentation and object detection. Our framework employs large language
models (LLMs) as reasoning engines to dynamically combine GV-APIs and operate
GCLF, effectively supporting diverse geographic vision tasks. To assess
performance in city-scale reasoning, we introduce GeoEval3D, a comprehensive
benchmark dataset containing 952 query-answer pairs across five challenging
tasks: grounding, spatial reasoning, comparison, counting, and measurement.
Experiments demonstrate that GeoProg3D significantly outperforms existing 3D
language fields and vision-language models across multiple tasks. To our
knowledge, GeoProg3D is the first framework enabling compositional geographic
reasoning in high-fidelity city-scale 3D environments via natural language. The
code is available at https://snskysk.github.io/GeoProg3D/.

</details>


### [127] [Layer Decomposition and Morphological Reconstruction for Task-Oriented Infrared Image Enhancement](https://arxiv.org/abs/2506.23353)
*Siyuan Chai,Xiaodong Guo,Tong Liu*

Main category: cs.CV

TL;DR: 提出了一种面向任务的红外图像增强方法，通过层分解和显著性信息提取，提升复杂天气下自动驾驶的感知能力。


<details>
  <summary>Details</summary>
Motivation: 红外图像在复杂天气条件下（如雾、雨、低光）能提升自动驾驶的感知能力，但其低对比度问题（尤其是非发热目标）影响下游视觉任务性能。如何在增强对比度的同时避免噪声放大和信息丢失是挑战。

Method: 方法包括层分解和显著性信息提取。层分解增强细节并保留暗区特征；显著性提取基于形态学重建，有效增强目标信息且不放大噪声。

Result: 实验表明，该方法在目标检测和语义分割任务中优于现有方法。

Conclusion: 该方法显著提升了红外图像质量，为自动驾驶感知任务提供了更优的输入。

Abstract: Infrared image helps improve the perception capabilities of autonomous
driving in complex weather conditions such as fog, rain, and low light.
However, infrared image often suffers from low contrast, especially in
non-heat-emitting targets like bicycles, which significantly affects the
performance of downstream high-level vision tasks. Furthermore, achieving
contrast enhancement without amplifying noise and losing important information
remains a challenge. To address these challenges, we propose a task-oriented
infrared image enhancement method. Our approach consists of two key components:
layer decomposition and saliency information extraction. First, we design an
layer decomposition method for infrared images, which enhances scene details
while preserving dark region features, providing more features for subsequent
saliency information extraction. Then, we propose a morphological
reconstruction-based saliency extraction method that effectively extracts and
enhances target information without amplifying noise. Our method improves the
image quality for object detection and semantic segmentation tasks. Extensive
experiments demonstrate that our approach outperforms state-of-the-art methods.

</details>


### [128] [OmniVCus: Feedforward Subject-driven Video Customization with Multimodal Control Conditions](https://arxiv.org/abs/2506.23361)
*Yuanhao Cai,He Zhang,Xi Chen,Jinbo Xing,Yiwei Hu,Yuqian Zhou,Kai Zhang,Zhifei Zhang,Soo Ye Kim,Tianyu Wang,Yulun Zhang,Xiaokang Yang,Zhe Lin,Alan Yuille*

Main category: cs.CV

TL;DR: 提出了一种多主体视频定制方法，通过数据构造管道和混合训练实现高效编辑，并采用扩散Transformer框架提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要针对单主体场景，且缺乏对多主体训练数据和控制信号的研究。

Method: 提出VideoCus-Factory数据构造管道和IVTM混合训练，开发了OmniVCus框架，包含Lottery Embedding和Temporally Aligned Embedding机制。

Result: 实验表明，该方法在定量和定性评估中显著优于现有技术。

Conclusion: 该方法在多主体视频定制和控制信号利用方面取得了显著进展。

Abstract: Existing feedforward subject-driven video customization methods mainly study
single-subject scenarios due to the difficulty of constructing multi-subject
training data pairs. Another challenging problem that how to use the signals
such as depth, mask, camera, and text prompts to control and edit the subject
in the customized video is still less explored. In this paper, we first propose
a data construction pipeline, VideoCus-Factory, to produce training data pairs
for multi-subject customization from raw videos without labels and control
signals such as depth-to-video and mask-to-video pairs. Based on our
constructed data, we develop an Image-Video Transfer Mixed (IVTM) training with
image editing data to enable instructive editing for the subject in the
customized video. Then we propose a diffusion Transformer framework, OmniVCus,
with two embedding mechanisms, Lottery Embedding (LE) and Temporally Aligned
Embedding (TAE). LE enables inference with more subjects by using the training
subjects to activate more frame embeddings. TAE encourages the generation
process to extract guidance from temporally aligned control signals by
assigning the same frame embeddings to the control and noise tokens.
Experiments demonstrate that our method significantly surpasses
state-of-the-art methods in both quantitative and qualitative evaluations.
Video demos are at our project page:
https://caiyuanhao1998.github.io/project/OmniVCus/. Our code will be released
at https://github.com/caiyuanhao1998/Open-OmniVCus

</details>


### [129] [SIEDD: Shared-Implicit Encoder with Discrete Decoders](https://arxiv.org/abs/2506.23382)
*Vikram Rangarajan,Shishira Maiya,Max Ehrlich,Abhinav Shrivastava*

Main category: cs.CV

TL;DR: SIEDD是一种新型架构，通过共享编码器和离散解码器显著加速隐式神经表示（INR）的视频编码，同时保持高质量和坐标级控制。


<details>
  <summary>Details</summary>
Motivation: 解决INR编码速度慢的问题，同时避免牺牲重建质量或坐标级控制。

Method: SIEDD采用共享编码器捕获全局低频特征，再并行训练轻量级离散解码器，结合坐标空间采样加速。

Result: 在HD和4K基准测试中，编码速度提升20-30倍，同时保持竞争性重建质量和压缩比。

Conclusion: SIEDD显著提升了高保真神经视频压缩的实用性，为实际部署提供了高效路径。

Abstract: Implicit Neural Representations (INRs) offer exceptional fidelity for video
compression by learning per-video optimized functions, but their adoption is
crippled by impractically slow encoding times. Existing attempts to accelerate
INR encoding often sacrifice reconstruction quality or crucial coordinate-level
control essential for adaptive streaming and transcoding. We introduce SIEDD
(Shared-Implicit Encoder with Discrete Decoders), a novel architecture that
fundamentally accelerates INR encoding without these compromises. SIEDD first
rapidly trains a shared, coordinate-based encoder on sparse anchor frames to
efficiently capture global, low-frequency video features. This encoder is then
frozen, enabling massively parallel training of lightweight, discrete decoders
for individual frame groups, further expedited by aggressive coordinate-space
sampling. This synergistic design delivers a remarkable 20-30X encoding
speed-up over state-of-the-art INR codecs on HD and 4K benchmarks, while
maintaining competitive reconstruction quality and compression ratios.
Critically, SIEDD retains full coordinate-based control, enabling continuous
resolution decoding and eliminating costly transcoding. Our approach
significantly advances the practicality of high-fidelity neural video
compression, demonstrating a scalable and efficient path towards real-world
deployment. Our codebase is available at
https://github.com/VikramRangarajan/SIEDD .

</details>


### [130] [A High-Throughput Platform to Bench Test Smartphone-Based Heart Rate Measurements Derived From Video](https://arxiv.org/abs/2506.23414)
*Ming-Zher Poh,Jonathan Wang,Jonathan Hsu,Lawrence Cai,Eric Teasley,James A. Taylor,Jameson K. Rogers,Anupam Pathak,Shwetak Patel*

Main category: cs.CV

TL;DR: 本文提出了一种新型高通量测试平台，用于评估智能手机心率监测应用的性能与设备兼容性。


<details>
  <summary>Details</summary>
Motivation: 智能手机心率监测应用因设备多样性和碎片化面临性能评估和设备兼容性挑战，缺乏标准化测试方法。

Method: 设计了一个包含12部智能手机并行测试的系统，生成可控心率和信号质量的合成PPG测试视频，并通过主机协调视频播放和数据记录。

Result: 系统在输入与测量心率间的平均绝对百分比误差为0.11%，PPG信号相关性为0.92，20款智能手机均符合ANSI/CTA标准。

Conclusion: 该平台为智能手机心率应用提供了可扩展的预部署测试解决方案，提升性能、确保兼容性，推动移动健康领域发展。

Abstract: Smartphone-based heart rate (HR) monitoring apps using finger-over-camera
photoplethysmography (PPG) face significant challenges in performance
evaluation and device compatibility due to device variability and
fragmentation. Manual testing is impractical, and standardized methods are
lacking. This paper presents a novel, high-throughput bench-testing platform to
address this critical need. We designed a system comprising a test rig capable
of holding 12 smartphones for parallel testing, a method for generating
synthetic PPG test videos with controllable HR and signal quality, and a host
machine for coordinating video playback and data logging. The system achieved a
mean absolute percentage error (MAPE) of 0.11% +/- 0.001% between input and
measured HR, and a correlation coefficient of 0.92 +/- 0.008 between input and
measured PPG signals using a clinically-validated smartphone-based HR app.
Bench-testing results of 20 different smartphone models correctly classified
all the devices as meeting the ANSI/CTA accuracy standards for HR monitors
(MAPE <10%) when compared to a prospective clinical study with 80 participants,
demonstrating high positive predictive value. This platform offers a scalable
solution for pre-deployment testing of smartphone HR apps to improve app
performance, ensure device compatibility, and advance the field of mobile
health.

</details>


### [131] [Why Settle for Mid: A Probabilistic Viewpoint to Spatial Relationship Alignment in Text-to-image Models](https://arxiv.org/abs/2506.23418)
*Parham Rezaei,Arash Marioriyad,Mahdieh Soleymani Baghshah,Mohammad Hossein Rohban*

Main category: cs.CV

TL;DR: 提出了一种基于概率优势（PoS）的框架，用于改进文本到图像模型在空间关系生成上的准确性，包括新的评估指标PSE和生成方法PSG。


<details>
  <summary>Details</summary>
Motivation: 文本到图像模型在生成复杂空间关系时存在困难，尤其是空间配置的准确性不足。

Method: 提出PoS框架，包括PSE评估指标和PSG生成方法，后者通过梯度引导或噪声向量搜索改进空间关系生成。

Result: PSE指标与人类判断更一致，PSG方法在多个评测中优于现有方法。

Conclusion: PoS框架显著提升了文本到图像模型在空间关系生成上的表现。

Abstract: Despite the ability of text-to-image models to generate high-quality,
realistic, and diverse images, they face challenges in compositional
generation, often struggling to accurately represent details specified in the
input prompt. A prevalent issue in compositional generation is the misalignment
of spatial relationships, as models often fail to faithfully generate images
that reflect the spatial configurations specified between objects in the input
prompts. To address this challenge, we propose a novel probabilistic framework
for modeling the relative spatial positioning of objects in a scene, leveraging
the concept of Probability of Superiority (PoS). Building on this insight, we
make two key contributions. First, we introduce a novel evaluation metric,
PoS-based Evaluation (PSE), designed to assess the alignment of 2D and 3D
spatial relationships between text and image, with improved adherence to human
judgment. Second, we propose PoS-based Generation (PSG), an inference-time
method that improves the alignment of 2D and 3D spatial relationships in T2I
models without requiring fine-tuning. PSG employs a Part-of-Speech PoS-based
reward function that can be utilized in two distinct ways: (1) as a
gradient-based guidance mechanism applied to the cross-attention maps during
the denoising steps, or (2) as a search-based strategy that evaluates a set of
initial noise vectors to select the best one. Extensive experiments demonstrate
that the PSE metric exhibits stronger alignment with human judgment compared to
traditional center-based metrics, providing a more nuanced and reliable measure
of complex spatial relationship accuracy in text-image alignment. Furthermore,
PSG significantly enhances the ability of text-to-image models to generate
images with specified spatial configurations, outperforming state-of-the-art
methods across multiple evaluation metrics and benchmarks.

</details>


### [132] [Detecting What Matters: A Novel Approach for Out-of-Distribution 3D Object Detection in Autonomous Vehicles](https://arxiv.org/abs/2506.23426)
*Menna Taha,Aya Ahmed,Mohammed Karmoose,Yasser Gadallah*

Main category: cs.CV

TL;DR: 论文提出了一种新的目标检测方法，将重点从传统的基于类别的分类转向基于对象危害性的判定，以提升自动驾驶车辆的安全性。


<details>
  <summary>Details</summary>
Motivation: 传统目标检测方法无法有效识别分布外（OOD）对象，可能导致自动驾驶车辆（AV）误判危险情况，引发安全隐患。

Method: 通过对象相对于AV的位置和轨迹，将其分类为‘有害’或‘无害’，而非具体类别。

Result: 模型能有效检测OOD对象并评估其危害性，提升AV在动态环境中的决策能力。

Conclusion: 该方法显著增强了AV对未知对象的识别和响应能力，提高了安全性。

Abstract: Autonomous vehicles (AVs) use object detection models to recognize their
surroundings and make driving decisions accordingly. Conventional object
detection approaches classify objects into known classes, which limits the AV's
ability to detect and appropriately respond to Out-of-Distribution (OOD)
objects. This problem is a significant safety concern since the AV may fail to
detect objects or misclassify them, which can potentially lead to hazardous
situations such as accidents. Consequently, we propose a novel object detection
approach that shifts the emphasis from conventional class-based classification
to object harmfulness determination. Instead of object detection by their
specific class, our method identifies them as either 'harmful' or 'harmless'
based on whether they pose a danger to the AV. This is done based on the object
position relative to the AV and its trajectory. With this metric, our model can
effectively detect previously unseen objects to enable the AV to make safer
real-time decisions. Our results demonstrate that the proposed model
effectively detects OOD objects, evaluates their harmfulness, and classifies
them accordingly, thus enhancing the AV decision-making effectiveness in
dynamic environments.

</details>


### [133] [PathDiff: Histopathology Image Synthesis with Unpaired Text and Mask Conditions](https://arxiv.org/abs/2506.23440)
*Mahesh Bhosale,Abdul Wasi,Yuanhao Zhai,Yunjie Tian,Samuel Border,Nan Xi,Pinaki Sarder,Junsong Yuan,David Doermann,Xuan Gong*

Main category: cs.CV

TL;DR: PathDiff是一种扩散框架，利用未配对的文本和掩码数据生成高质量的病理图像，提升语义和空间细节的控制。


<details>
  <summary>Details</summary>
Motivation: 解决因隐私限制导致的数据稀缺问题，并充分利用文本和掩码数据的联合优势。

Method: 提出PathDiff框架，将未配对的文本和掩码数据整合到统一的条件空间中。

Result: 生成的图像质量高，语义准确，提升了图像保真度、文本对齐和下游任务性能。

Conclusion: PathDiff在生成病理图像方面优于现有方法，为数据增强提供了有效工具。

Abstract: Diffusion-based generative models have shown promise in synthesizing
histopathology images to address data scarcity caused by privacy constraints.
Diagnostic text reports provide high-level semantic descriptions, and masks
offer fine-grained spatial structures essential for representing distinct
morphological regions. However, public datasets lack paired text and mask data
for the same histopathological images, limiting their joint use in image
generation. This constraint restricts the ability to fully exploit the benefits
of combining both modalities for enhanced control over semantics and spatial
details. To overcome this, we propose PathDiff, a diffusion framework that
effectively learns from unpaired mask-text data by integrating both modalities
into a unified conditioning space. PathDiff allows precise control over
structural and contextual features, generating high-quality, semantically
accurate images. PathDiff also improves image fidelity, text-image alignment,
and faithfulness, enhancing data augmentation for downstream tasks like nuclei
segmentation and classification. Extensive experiments demonstrate its
superiority over existing methods.

</details>


### [134] [Contrastive Learning with Diffusion Features for Weakly Supervised Medical Image Segmentation](https://arxiv.org/abs/2506.23460)
*Dewen Zeng,Xinrong Hu,Yu-Jen Chen,Yawen Wu,Xiaowei Xu,Yiyu Shi*

Main category: cs.CV

TL;DR: 论文提出了一种基于对比学习和扩散特征的新方法（CLDF），用于弱监督语义分割，通过结合梯度图和CAMs减少噪声，显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 传统CAM方法在弱监督语义分割中存在部分激活和边界模糊问题，而基于条件扩散模型的方法虽能生成分割掩码，但易受背景噪声干扰。

Method: 提出CLDF方法，利用对比学习将冻结CDM的扩散特征映射到低维嵌入空间，结合梯度图和CAMs优化像素嵌入学习。

Result: 在两个公共医学数据集的四个分割任务中，CLDF显著优于现有基线。

Conclusion: CLDF通过对比学习和扩散特征结合，有效解决了弱监督语义分割中的噪声和边界问题，性能优越。

Abstract: Weakly supervised semantic segmentation (WSSS) methods using class labels
often rely on class activation maps (CAMs) to localize objects. However,
traditional CAM-based methods struggle with partial activations and imprecise
object boundaries due to optimization discrepancies between classification and
segmentation. Recently, the conditional diffusion model (CDM) has been used as
an alternative for generating segmentation masks in WSSS, leveraging its strong
image generation capabilities tailored to specific class distributions. By
modifying or perturbing the condition during diffusion sampling, the related
objects can be highlighted in the generated images. Yet, the saliency maps
generated by CDMs are prone to noise from background alterations during reverse
diffusion. To alleviate the problem, we introduce Contrastive Learning with
Diffusion Features (CLDF), a novel method that uses contrastive learning to
train a pixel decoder to map the diffusion features from a frozen CDM to a
low-dimensional embedding space for segmentation. Specifically, we integrate
gradient maps generated from CDM external classifier with CAMs to identify
foreground and background pixels with fewer false positives/negatives for
contrastive learning, enabling robust pixel embedding learning. Experimental
results on four segmentation tasks from two public medical datasets demonstrate
that our method significantly outperforms existing baselines.

</details>


### [135] [Time-variant Image Inpainting via Interactive Distribution Transition Estimation](https://arxiv.org/abs/2506.23461)
*Yun Xing,Qing Guo,Xiaoguang Li,Yihao Huang,Xiaofeng Cao,Di Lin,Ivor Tsang,Lei Ma*

Main category: cs.CV

TL;DR: 论文提出了一种新颖的时间变异图像修复任务（TAMP），通过交互式分布转移估计（InDiTE）模块和扩散模型（InDiTE-Diff）解决传统方法在时间变异图像修复中的不足，并构建了TAMP-Street数据集验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统参考引导的图像修复方法在处理时间变异图像时效果不佳，因为参考图像与目标图像内容差异大且可能受损。TAMP任务旨在解决这一问题。

Method: 提出InDiTE模块交互补充时间变异图像的语义信息，并结合扩散模型（InDiTE-Diff）进行潜在交叉参考。

Result: 在TAMP-Street数据集上的实验表明，该方法显著优于现有参考引导的图像修复方法。

Conclusion: InDiTE-Diff方法有效解决了时间变异图像修复问题，为实际应用提供了新思路。

Abstract: In this work, we focus on a novel and practical task, i.e., Time-vAriant
iMage inPainting (TAMP). The aim of TAMP is to restore a damaged target image
by leveraging the complementary information from a reference image, where both
images captured the same scene but with a significant time gap in between,
i.e., time-variant images. Different from conventional reference-guided image
inpainting, the reference image under TAMP setup presents significant content
distinction to the target image and potentially also suffers from damages. Such
an application frequently happens in our daily lives to restore a damaged image
by referring to another reference image, where there is no guarantee of the
reference image's source and quality. In particular, our study finds that even
state-of-the-art (SOTA) reference-guided image inpainting methods fail to
achieve plausible results due to the chaotic image complementation. To address
such an ill-posed problem, we propose a novel Interactive Distribution
Transition Estimation (InDiTE) module which interactively complements the
time-variant images with adaptive semantics thus facilitate the restoration of
damaged regions. To further boost the performance, we propose our TAMP
solution, namely Interactive Distribution Transition Estimation-driven
Diffusion (InDiTE-Diff), which integrates InDiTE with SOTA diffusion model and
conducts latent cross-reference during sampling. Moreover, considering the lack
of benchmarks for TAMP task, we newly assembled a dataset, i.e., TAMP-Street,
based on existing image and mask datasets. We conduct experiments on the
TAMP-Street datasets under two different time-variant image inpainting
settings, which show our method consistently outperform SOTA reference-guided
image inpainting methods for solving TAMP.

</details>


### [136] [Sanitizing Manufacturing Dataset Labels Using Vision-Language Models](https://arxiv.org/abs/2506.23465)
*Nazanin Mahjourian,Vinh Nguyen*

Main category: cs.CV

TL;DR: VLSR框架通过视觉-语言模型CLIP嵌入图像和文本标签到共享语义空间，利用余弦相似度进行标签净化和聚类，显著提升制造业多标签数据集的质量。


<details>
  <summary>Details</summary>
Motivation: 制造业领域的大规模数据集常因标签噪声和不一致性导致模型训练效果不佳，而高质量标签获取成本高。

Method: 使用CLIP模型嵌入图像和标签到共享语义空间，通过余弦相似度进行标签净化和密度聚类合并相似标签。

Result: 在Factorynet数据集上验证，VLSR成功识别问题标签并提升一致性，减少标签词汇量。

Conclusion: VLSR以最小人工干预显著提升工业应用数据集质量，支持鲁棒模型训练。

Abstract: The success of machine learning models in industrial applications is heavily
dependent on the quality of the datasets used to train the models. However,
large-scale datasets, specially those constructed from crowd-sourcing and
web-scraping, often suffer from label noise, inconsistencies, and errors. This
problem is particularly pronounced in manufacturing domains, where obtaining
high-quality labels is costly and time-consuming. This paper introduces
Vision-Language Sanitization and Refinement (VLSR), which is a
vision-language-based framework for label sanitization and refinement in
multi-label manufacturing image datasets. This method embeds both images and
their associated textual labels into a shared semantic space leveraging the
CLIP vision-language model. Then two key tasks are addressed in this process by
computing the cosine similarity between embeddings. First, label sanitization
is performed to identify irrelevant, misspelled, or semantically weak labels,
and surface the most semantically aligned label for each image by comparing
image-label pairs using cosine similarity between image and label embeddings.
Second, the method applies density-based clustering on text embeddings,
followed by iterative cluster merging, to group semantically similar labels
into unified label groups. The Factorynet dataset, which includes noisy labels
from both human annotations and web-scraped sources, is employed to evaluate
the effectiveness of the proposed framework. Experimental results demonstrate
that the VLSR framework successfully identifies problematic labels and improves
label consistency. This method enables a significant reduction in label
vocabulary through clustering, which ultimately enhances the dataset's quality
for training robust machine learning models in industrial applications with
minimal human intervention.

</details>


### [137] [AdFair-CLIP: Adversarial Fair Contrastive Language-Image Pre-training for Chest X-rays](https://arxiv.org/abs/2506.23467)
*Chenlang Yi,Zizhan Xiong,Qi Qi,Xiyuan Wei,Girish Bathla,Ching-Long Lin,Bobak Jack Mortazavi,Tianbao Yang*

Main category: cs.CV

TL;DR: AdFair-CLIP通过对抗性特征干预减少CLIP模型中的敏感属性偏差，提升公平性和诊断准确性。


<details>
  <summary>Details</summary>
Motivation: CLIP模型在医学图像分类中表现优异，但存在公平性问题，如种族和性别偏差，影响诊断结果。

Method: 提出AdFair-CLIP框架，利用对抗性特征干预抑制敏感属性，减少虚假相关性。

Result: 在胸部X光数据集上，AdFair-CLIP显著提升公平性和诊断准确性，且在零样本和少样本场景中表现稳健。

Conclusion: AdFair-CLIP为基于CLIP的医学诊断模型（尤其是胸部X光分析）设定了公平性学习的新基准。

Abstract: Contrastive Language-Image Pre-training (CLIP) models have demonstrated
superior performance across various visual tasks including medical image
classification. However, fairness concerns, including demographic biases, have
received limited attention for CLIP models. This oversight leads to critical
issues, particularly those related to race and gender, resulting in disparities
in diagnostic outcomes and reduced reliability for underrepresented groups. To
address these challenges, we introduce AdFair-CLIP, a novel framework employing
adversarial feature intervention to suppress sensitive attributes, thereby
mitigating spurious correlations and improving prediction fairness. We conduct
comprehensive experiments on chest X-ray (CXR) datasets, and show that
AdFair-CLIP significantly enhances both fairness and diagnostic accuracy, while
maintaining robust generalization in zero-shot and few-shot scenarios. These
results establish new benchmarks for fairness-aware learning in CLIP-based
medical diagnostic models, particularly for CXR analysis.

</details>


### [138] [NavMorph: A Self-Evolving World Model for Vision-and-Language Navigation in Continuous Environments](https://arxiv.org/abs/2506.23468)
*Xuan Yao,Junyu Gao,Changsheng Xu*

Main category: cs.CV

TL;DR: NavMorph是一个自演化的世界模型框架，用于提升视觉与语言导航任务中的环境理解和决策能力。


<details>
  <summary>Details</summary>
Motivation: 解决当前方法在新环境中泛化能力不足和导航过程中适应变化的问题。

Method: 采用紧凑的潜在表示建模环境动态，结合上下文演化记忆以支持自适应规划和策略优化。

Result: 在主流VLN-CE基准测试中表现显著提升。

Conclusion: NavMorph通过自演化和上下文记忆机制，有效提升了导航任务的性能。

Abstract: Vision-and-Language Navigation in Continuous Environments (VLN-CE) requires
agents to execute sequential navigation actions in complex environments guided
by natural language instructions. Current approaches often struggle with
generalizing to novel environments and adapting to ongoing changes during
navigation. Inspired by human cognition, we present NavMorph, a self-evolving
world model framework that enhances environmental understanding and
decision-making in VLN-CE tasks. NavMorph employs compact latent
representations to model environmental dynamics, equipping agents with
foresight for adaptive planning and policy refinement. By integrating a novel
Contextual Evolution Memory, NavMorph leverages scene-contextual information to
support effective navigation while maintaining online adaptability. Extensive
experiments demonstrate that our method achieves notable performance
improvements on popular VLN-CE benchmarks. Code is available at
\href{https://github.com/Feliciaxyao/NavMorph}{this https URL}.

</details>


### [139] [Interactive Interface For Semantic Segmentation Dataset Synthesis](https://arxiv.org/abs/2506.23470)
*Ngoc-Do Tran,Minh-Tuan Huynh,Tam V. Nguyen,Minh-Triet Tran,Trung-Nghia Le*

Main category: cs.CV

TL;DR: SynthLab是一个模块化平台，用于高效合成视觉数据，解决语义分割数据标注的资源密集和隐私问题。


<details>
  <summary>Details</summary>
Motivation: 解决高质量标注数据集创建的资源密集和隐私问题。

Method: 开发模块化平台SynthLab，支持视觉数据合成和用户友好界面，便于维护和扩展。

Result: 用户研究表明SynthLab灵活易用，适合不同技术水平的用户。

Conclusion: SynthLab为AI应用提供了高效、可扩展的数据合成解决方案。

Abstract: The rapid advancement of AI and computer vision has significantly increased
the demand for high-quality annotated datasets, particularly for semantic
segmentation. However, creating such datasets is resource-intensive, requiring
substantial time, labor, and financial investment, and often raises privacy
concerns due to the use of real-world data. To mitigate these challenges, we
present SynthLab, consisting of a modular platform for visual data synthesis
and a user-friendly interface. The modular architecture of SynthLab enables
easy maintenance, scalability with centralized updates, and seamless
integration of new features. Each module handles distinct aspects of computer
vision tasks, enhancing flexibility and adaptability. Meanwhile, its
interactive, user-friendly interface allows users to quickly customize their
data pipelines through drag-and-drop actions. Extensive user studies involving
a diverse range of users across different ages, professions, and expertise
levels, have demonstrated flexible usage, and high accessibility of SynthLab,
enabling users without deep technical expertise to harness AI for real-world
applications.

</details>


### [140] [GeoCD: A Differential Local Approximation for Geodesic Chamfer Distance](https://arxiv.org/abs/2506.23478)
*Pedro Alonso,Tianrui Li,Chongshou Li*

Main category: cs.CV

TL;DR: GeoCD是一种基于拓扑感知和完全可微分的地测距离近似方法，用于改进3D点云学习中的Chamfer Distance（CD）度量。


<details>
  <summary>Details</summary>
Motivation: Chamfer Distance（CD）因其简单高效被广泛使用，但仅依赖欧几里得距离，无法捕捉3D形状的内在几何结构。

Method: 提出GeoCD，一种拓扑感知且完全可微分的地测距离近似方法，用于替代CD。

Result: 实验表明，GeoCD在各种架构和数据集上均能显著提升重建质量，仅需单轮微调即可在多指标上取得显著改进。

Conclusion: GeoCD是一种有效的改进CD的方法，能够更好地捕捉3D形状的几何特征。

Abstract: Chamfer Distance (CD) is a widely adopted metric in 3D point cloud learning
due to its simplicity and efficiency. However, it suffers from a fundamental
limitation: it relies solely on Euclidean distances, which often fail to
capture the intrinsic geometry of 3D shapes. To address this limitation, we
propose GeoCD, a topology-aware and fully differentiable approximation of
geodesic distance designed to serve as a metric for 3D point cloud learning.
Our experiments show that GeoCD consistently improves reconstruction quality
over standard CD across various architectures and datasets. We demonstrate this
by fine-tuning several models, initially trained with standard CD, using GeoCD.
Remarkably, fine-tuning for a single epoch with GeoCD yields significant gains
across multiple evaluation metrics.

</details>


### [141] [Instant GaussianImage: A Generalizable and Self-Adaptive Image Representation via 2D Gaussian Splatting](https://arxiv.org/abs/2506.23479)
*Zhaojie Zeng,Yuesong Wang,Chao Yang,Tao Guan,Lili Ju*

Main category: cs.CV

TL;DR: 提出了一种基于2D高斯泼溅的自适应图像表示框架，显著减少训练时间并动态调整高斯点数量。


<details>
  <summary>Details</summary>
Motivation: 解决Implicit Neural Representation (INR)的高GPU资源需求和GaussianImage训练慢、适应性差的问题。

Method: 使用网络快速生成粗略高斯表示，再通过少量微调步骤，动态调整高斯点数量以适应图像复杂度。

Result: 在DIV2K和Kodak数据集上，训练时间减少一个数量级，渲染性能优于或匹配GaussianImage。

Conclusion: 该方法在减少训练时间的同时，提升了灵活性和效率，适用于实际应用。

Abstract: Implicit Neural Representation (INR) has demonstrated remarkable advances in
the field of image representation but demands substantial GPU resources.
GaussianImage recently pioneered the use of Gaussian Splatting to mitigate this
cost, however, the slow training process limits its practicality, and the fixed
number of Gaussians per image limits its adaptability to varying information
entropy. To address these issues, we propose in this paper a generalizable and
self-adaptive image representation framework based on 2D Gaussian Splatting.
Our method employs a network to quickly generate a coarse Gaussian
representation, followed by minimal fine-tuning steps, achieving comparable
rendering quality of GaussianImage while significantly reducing training time.
Moreover, our approach dynamically adjusts the number of Gaussian points based
on image complexity to further enhance flexibility and efficiency in practice.
Experiments on DIV2K and Kodak datasets show that our method matches or exceeds
GaussianImage's rendering performance with far fewer iterations and shorter
training times. Specifically, our method reduces the training time by up to one
order of magnitude while achieving superior rendering performance with the same
number of Gaussians.

</details>


### [142] [Evaluation of Geolocation Capabilities of Multimodal Large Language Models and Analysis of Associated Privacy Risks](https://arxiv.org/abs/2506.23481)
*Xian Zhang,Xiang Cheng*

Main category: cs.CV

TL;DR: 多模态大语言模型（MLLMs）在图像地理定位方面表现出色，但引发隐私和伦理问题。研究分析现有技术，发现模型在1公里半径内定位准确率达49%，并提出应对措施。


<details>
  <summary>Details</summary>
Motivation: 探讨MLLMs在图像地理定位中的能力及其对隐私的潜在威胁。

Method: 系统回顾文献并评估最先进视觉推理模型在地理定位任务中的表现。

Result: 高级视觉大模型在1公里半径内定位准确率达49%。

Conclusion: 研究识别了成功定位的关键视觉元素，并讨论了隐私风险及应对措施。

Abstract: Objectives: The rapid advancement of Multimodal Large Language Models (MLLMs)
has significantly enhanced their reasoning capabilities, enabling a wide range
of intelligent applications. However, these advancements also raise critical
concerns regarding privacy and ethics. MLLMs are now capable of inferring the
geographic location of images -- such as those shared on social media or
captured from street views -- based solely on visual content, thereby posing
serious risks of privacy invasion, including doxxing, surveillance, and other
security threats.
  Methods: This study provides a comprehensive analysis of existing geolocation
techniques based on MLLMs. It systematically reviews relevant litera-ture and
evaluates the performance of state-of-the-art visual reasoning models on
geolocation tasks, particularly in identifying the origins of street view
imagery.
  Results: Empirical evaluation reveals that the most advanced visual large
models can successfully localize the origin of street-level imagery with up to
$49\%$ accuracy within a 1-kilometer radius. This performance underscores the
models' powerful capacity to extract and utilize fine-grained geographic cues
from visual data.
  Conclusions: Building on these findings, the study identifies key visual
elements that contribute to suc-cessful geolocation, such as text,
architectural styles, and environmental features. Furthermore, it discusses the
potential privacy implications associated with MLLM-enabled geolocation and
discuss several technical and policy-based coun-termeasures to mitigate
associated risks. Our code and dataset are available at
https://github.com/zxyl1003/MLLM-Geolocation-Evaluation.

</details>


### [143] [MTADiffusion: Mask Text Alignment Diffusion Model for Object Inpainting](https://arxiv.org/abs/2506.23482)
*Jun Huang,Ting Liu,Yihang Wu,Xiaochao Qu,Luoqi Liu,Xiaolin Hu*

Main category: cs.CV

TL;DR: MTADiffusion是一种用于对象修复的Mask-Text Alignment扩散模型，通过MTAPipeline自动标注掩码和详细描述，构建了包含500万图像和2500万掩码-文本对的新数据集，并采用多任务训练策略和风格一致性损失提升修复效果。


<details>
  <summary>Details</summary>
Motivation: 现有修复方法存在语义不对齐、结构扭曲和风格不一致等问题，需要一种更高效的解决方案。

Method: 提出MTADiffusion模型，结合MTAPipeline自动标注掩码和描述，构建MTADataset，并采用多任务训练策略和风格一致性损失。

Result: 在BrushBench和EditBench上评估，MTADiffusion取得了最先进的性能。

Conclusion: MTADiffusion通过改进语义对齐、结构稳定性和风格一致性，显著提升了对象修复的效果。

Abstract: Advancements in generative models have enabled image inpainting models to
generate content within specific regions of an image based on provided prompts
and masks. However, existing inpainting methods often suffer from problems such
as semantic misalignment, structural distortion, and style inconsistency. In
this work, we present MTADiffusion, a Mask-Text Alignment diffusion model
designed for object inpainting. To enhance the semantic capabilities of the
inpainting model, we introduce MTAPipeline, an automatic solution for
annotating masks with detailed descriptions. Based on the MTAPipeline, we
construct a new MTADataset comprising 5 million images and 25 million mask-text
pairs. Furthermore, we propose a multi-task training strategy that integrates
both inpainting and edge prediction tasks to improve structural stability. To
promote style consistency, we present a novel inpainting style-consistency loss
using a pre-trained VGG network and the Gram matrix. Comprehensive evaluations
on BrushBench and EditBench demonstrate that MTADiffusion achieves
state-of-the-art performance compared to other methods.

</details>


### [144] [When Test-Time Adaptation Meets Self-Supervised Models](https://arxiv.org/abs/2506.23529)
*Jisu Han,Jihee Park,Dongyoon Han,Wonjun Hwang*

Main category: cs.CV

TL;DR: 论文提出了一种自监督测试时适应（TTA）协议，通过协作学习框架结合自监督学习（SSL）和TTA模型，提升模型在无源预训练情况下的性能。


<details>
  <summary>Details</summary>
Motivation: 研究测试时适应方法是否能持续改进自监督学习模型，而不依赖源预训练模型。

Method: 提出协作学习框架，结合对比学习和知识蒸馏，逐步优化表示。

Result: 在多种自监督模型（如DINO、MoCo、iBOT）上验证了方法的有效性，即使无源预训练也能取得竞争性性能。

Conclusion: 自监督TTA协议和协作学习框架为动态环境中的模型适应提供了新思路。

Abstract: Training on test-time data enables deep learning models to adapt to dynamic
environmental changes, enhancing their practical applicability. Online
adaptation from source to target domains is promising but it remains highly
reliant on the performance of source pretrained model. In this paper, we
investigate whether test-time adaptation (TTA) methods can continuously improve
models trained via self-supervised learning (SSL) without relying on source
pretraining. We introduce a self-supervised TTA protocol after observing that
existing TTA approaches struggle when directly applied to self-supervised
models with low accuracy on the source domain. Furthermore, we propose a
collaborative learning framework that integrates SSL and TTA models, leveraging
contrastive learning and knowledge distillation for stepwise representation
refinement. We validate our method on diverse self-supervised models, including
DINO, MoCo, and iBOT, across TTA benchmarks. Extensive experiments validate the
effectiveness of our approach in SSL, showing that it achieves competitive
performance even without source pretraining.

</details>


### [145] [Qwen-GUI-3B: A Lightweight Vision-Language Model for Cross-Resolution GUI Grounding](https://arxiv.org/abs/2506.23491)
*ZongHan Hsieh,Tzer-Jen Wei*

Main category: cs.CV

TL;DR: Qwen-GUI-3B是一个轻量级视觉语言模型，专注于图形用户界面（GUI）任务，性能接近更大模型，但可在单GPU上训练。


<details>
  <summary>Details</summary>
Motivation: 解决大规模视觉语言模型计算资源需求高、不适用于消费级硬件的问题。

Method: 结合跨平台多分辨率数据集、两阶段微调策略及数据去冗余方法。

Result: 在标准GUI基准测试中表现优异，如ScreenSpot（84.9%）和ScreenSpot-v2（86.4%）。

Conclusion: Qwen-GUI-3B通过高效训练策略和数据优化，在轻量级模型中实现了高性能。

Abstract: This paper introduces Qwen-GUI-3B, a lightweight Vision-Language Model (VLM)
specifically designed for Graphical User Interface grounding tasks, achieving
performance competitive with significantly larger models. Unlike large-scale
VLMs (>7B parameters) that are computationally intensive and impractical for
consumer-grade hardware, Qwen-GUI-3B delivers strong grounding accuracy while
being fully trainable on a single GPU (RTX 4090). The model incorporates
several key innovations: (i) combine cross-platform, multi-resolution dataset
of 24K examples from diverse sources including mobile, desktop, and web GUI
screenshots to effectively address data scarcity in high-resolution desktop
environments; (ii) a two-stage fine-tuning strategy, where initial
cross-platform training establishes robust GUI understanding, followed by
specialized fine-tuning on high-resolution data to significantly enhance model
adaptability; and (iii) data curation and redundancy reduction strategies,
demonstrating that randomly sampling a smaller subset with reduced redundancy
achieves performance comparable to larger datasets, emphasizing data diversity
over sheer volume. Empirical evaluation on standard GUI grounding
benchmarks-including ScreenSpot, ScreenSpot-v2, and the challenging
ScreenSpot-Pro, highlights Qwen-GUI-3B's exceptional accuracy, achieving 84.9%
on ScreenSpot and 86.4% on ScreenSpot-v2, surpassing prior models under 4B
parameters. Ablation studies validate the critical role of balanced sampling
and two-stage fine-tuning in enhancing robustness, particularly in
high-resolution desktop scenarios. The Qwen-GUI-3B is available at:
https://github.com/Han1018/Qwen-GUI-3B

</details>


### [146] [GViT: Representing Images as Gaussians for Visual Recognition](https://arxiv.org/abs/2506.23532)
*Jefferson Hernandez,Ruozhen He,Guha Balakrishnan,Alexander C. Berg,Vicente Ordonez*

Main category: cs.CV

TL;DR: GVIT是一种分类框架，用可学习的2D高斯分布替代传统像素或补丁网格输入表示，结合ViT分类器，性能接近传统ViT。


<details>
  <summary>Details</summary>
Motivation: 传统像素或补丁网格输入表示可能效率不高，GVIT旨在通过更紧凑的高斯表示提升分类性能。

Method: 将图像编码为几百个高斯分布，优化其位置、尺度、方向等参数，并结合ViT分类器训练。利用分类器梯度指导高斯分布聚焦于类别显著区域。

Result: GVIT在Imagenet-1k上达到76.9%的top-1准确率，性能接近传统ViT。

Conclusion: GVIT通过高斯输入表示和梯度指导，实现了高效且性能接近传统方法的分类框架。

Abstract: We introduce GVIT, a classification framework that abandons conventional
pixel or patch grid input representations in favor of a compact set of
learnable 2D Gaussians. Each image is encoded as a few hundred Gaussians whose
positions, scales, orientations, colors, and opacities are optimized jointly
with a ViT classifier trained on top of these representations. We reuse the
classifier gradients as constructive guidance, steering the Gaussians toward
class-salient regions while a differentiable renderer optimizes an image
reconstruction loss. We demonstrate that by 2D Gaussian input representations
coupled with our GVIT guidance, using a relatively standard ViT architecture,
closely matches the performance of a traditional patch-based ViT, reaching a
76.9% top-1 accuracy on Imagenet-1k using a ViT-B architecture.

</details>


### [147] [LLM-enhanced Action-aware Multi-modal Prompt Tuning for Image-Text Matching](https://arxiv.org/abs/2506.23502)
*Mengxiao Tian,Xinxiao Wu,Shuo Yang*

Main category: cs.CV

TL;DR: 本文提出了一种基于LLM增强的动作感知多模态提示调优方法，以提升CLIP模型对细粒度动作的理解能力。


<details>
  <summary>Details</summary>
Motivation: CLIP模型在图像-文本匹配任务中表现出色，但在细粒度细节（如对象属性和空间关系）和动作感知方面存在不足。

Method: 设计了动作三元组提示和动作状态提示，利用LLM生成的外部知识，并通过自适应交互模块聚合视觉特征。

Result: 在两个基准数据集上的实验验证了方法的有效性。

Conclusion: 该方法显著提升了CLIP模型对动作的理解能力，为细粒度视觉-语言对齐提供了新思路。

Abstract: Driven by large-scale contrastive vision-language pre-trained models such as
CLIP, recent advancements in the image-text matching task have achieved
remarkable success in representation learning. Due to image-level
visual-language alignment, CLIP falls short in understanding fine-grained
details such as object attributes and spatial relationships between objects.
Recent efforts have attempted to compel CLIP to acquire structured visual
representations by introducing prompt learning to achieve object-level
alignment. While achieving promising results, they still lack the capability to
perceive actions, which are crucial for describing the states or relationships
between objects. Therefore, we propose to endow CLIP with fine-grained
action-level understanding by introducing an LLM-enhanced action-aware
multi-modal prompt-tuning method, incorporating the action-related external
knowledge generated by large language models (LLMs). Specifically, we design an
action triplet prompt and an action state prompt to exploit compositional
semantic knowledge and state-related causal knowledge implicitly stored in
LLMs. Subsequently, we propose an adaptive interaction module to aggregate
attentive visual features conditioned on action-aware prompted knowledge for
establishing discriminative and action-aware visual representations, which
further improves the performance. Comprehensive experimental results on two
benchmark datasets demonstrate the effectiveness of our method.

</details>


### [148] [Uncertainty-aware Diffusion and Reinforcement Learning for Joint Plane Localization and Anomaly Diagnosis in 3D Ultrasound](https://arxiv.org/abs/2506.23538)
*Yuhao Huang,Yueyue Xu,Haoran Dou,Jiaxiao Deng,Xin Yang,Hongyu Zheng,Dong Ni*

Main category: cs.CV

TL;DR: 提出了一种智能系统，用于同时实现自动平面定位和先天性子宫异常（CUA）诊断，结合去噪扩散模型和强化学习框架，显著提升了诊断效果。


<details>
  <summary>Details</summary>
Motivation: 先天性子宫异常（CUAs）可能导致不孕、流产和妊娠并发症，传统2D超声难以准确评估，3D超声提供了更清晰的子宫形态可视化。

Method: 1）开发了结合局部（平面）和全局（体积/文本）指导的去噪扩散模型；2）引入基于强化学习的框架，从冗余序列中提取关键切片；3）提供文本驱动的不确定性建模以优化分类。

Result: 在大规模3D子宫超声数据集上的实验表明，该方法在平面定位和CUA诊断方面效果显著。

Conclusion: 该方法通过智能系统显著提升了CUA的诊断准确性，代码已开源。

Abstract: Congenital uterine anomalies (CUAs) can lead to infertility, miscarriage,
preterm birth, and an increased risk of pregnancy complications. Compared to
traditional 2D ultrasound (US), 3D US can reconstruct the coronal plane,
providing a clear visualization of the uterine morphology for assessing CUAs
accurately. In this paper, we propose an intelligent system for simultaneous
automated plane localization and CUA diagnosis. Our highlights are: 1) we
develop a denoising diffusion model with local (plane) and global (volume/text)
guidance, using an adaptive weighting strategy to optimize attention allocation
to different conditions; 2) we introduce a reinforcement learning-based
framework with unsupervised rewards to extract the key slice summary from
redundant sequences, fully integrating information across multiple planes to
reduce learning difficulty; 3) we provide text-driven uncertainty modeling for
coarse prediction, and leverage it to adjust the classification probability for
overall performance improvement. Extensive experiments on a large 3D uterine US
dataset show the efficacy of our method, in terms of plane localization and CUA
diagnosis. Code is available at https://github.com/yuhoo0302/CUA-US.

</details>


### [149] [Improve Underwater Object Detection through YOLOv12 Architecture and Physics-informed Augmentation](https://arxiv.org/abs/2506.23505)
*Tinh Nguyen*

Main category: cs.CV

TL;DR: 该研究通过结合物理增强技术和YOLOv12架构，提升了水下目标检测的精度和效率，尤其在低能见度条件下表现优异。


<details>
  <summary>Details</summary>
Motivation: 水下目标检测在自主导航和环境监测中至关重要，但受限于光线衰减、浑浊和遮挡等问题，现有方法难以在实时条件下高效运行。

Method: 采用YOLOv12架构，结合Residual ELAN块和区域注意力机制，并引入领域特定的增强技术（如湍流自适应模糊和光谱HSV变换）。

Result: 在四个数据集上取得领先性能，Brackish数据达到98.30% mAP和142 FPS，遮挡鲁棒性提升18.9%，小目标召回率提高22.4%。

Conclusion: 该研究为水下机器人和保护应用提供了高效精准的解决方案，并通过消融实验验证了增强策略的关键作用。

Abstract: Underwater object detection is crucial for autonomous navigation,
environmental monitoring, and marine exploration, but it is severely hampered
by light attenuation, turbidity, and occlusion. Current methods balance
accuracy and computational efficiency, but they have trouble deploying in
real-time under low visibility conditions. Through the integration of
physics-informed augmentation techniques with the YOLOv12 architecture, this
study advances underwater detection. With Residual ELAN blocks to preserve
structural features in turbid waters and Area Attention to maintain large
receptive fields for occluded objects while reducing computational complexity.
Underwater optical properties are addressed by domain-specific augmentations
such as turbulence adaptive blurring, biologically grounded occlusion
simulation, and spectral HSV transformations for color distortion. Extensive
tests on four difficult datasets show state-of-the-art performance, with
Brackish data registering 98.30% mAP at 142 FPS. YOLOv12 improves occlusion
robustness by 18.9%, small-object recall by 22.4%, and detection precision by
up to 7.94% compared to previous models. The crucial role of augmentation
strategy is validated by ablation studies. This work offers a precise and
effective solution for conservation and underwater robotics applications.

</details>


### [150] [Metadata, Wavelet, and Time Aware Diffusion Models for Satellite Image Super Resolution](https://arxiv.org/abs/2506.23566)
*Luigi Sigillo,Renato Giamba,Danilo Comminiello*

Main category: cs.CV

TL;DR: MWT-Diff是一种结合潜在扩散模型和小波变换的卫星图像超分辨率框架，通过MWT-Encoder生成嵌入特征，逐步重建高分辨率图像。


<details>
  <summary>Details</summary>
Motivation: 高分辨率卫星图像获取受限于传感器时空限制和高成本，影响环境监测、灾害响应等应用。

Method: 提出MWT-Diff框架，结合潜在扩散模型和小波变换，利用MWT-Encoder生成嵌入特征，指导分层扩散动态重建高分辨率图像。

Result: 在多个数据集上表现优于现有方法，感知质量指标（FID和LPIPS）验证了其优越性。

Conclusion: MWT-Diff能有效解决卫星图像超分辨率问题，保留关键空间特征，适用于详细遥感分析。

Abstract: The acquisition of high-resolution satellite imagery is often constrained by
the spatial and temporal limitations of satellite sensors, as well as the high
costs associated with frequent observations. These challenges hinder
applications such as environmental monitoring, disaster response, and
agricultural management, which require fine-grained and high-resolution data.
In this paper, we propose MWT-Diff, an innovative framework for satellite image
super-resolution (SR) that combines latent diffusion models with wavelet
transforms to address these challenges. At the core of the framework is a novel
metadata-, wavelet-, and time-aware encoder (MWT-Encoder), which generates
embeddings that capture metadata attributes, multi-scale frequency information,
and temporal relationships. The embedded feature representations steer the
hierarchical diffusion dynamics, through which the model progressively
reconstructs high-resolution satellite imagery from low-resolution inputs. This
process preserves critical spatial characteristics including textural patterns,
boundary discontinuities, and high-frequency spectral components essential for
detailed remote sensing analysis. The comparative analysis of MWT-Diff across
multiple datasets demonstrated favorable performance compared to recent
approaches, as measured by standard perceptual quality metrics including FID
and LPIPS.

</details>


### [151] [ViewPoint: Panoramic Video Generation with Pretrained Diffusion Models](https://arxiv.org/abs/2506.23513)
*Zixun Fang,Kai Zhu,Zhiheng Liu,Yu Liu,Wei Zhai,Yang Cao,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: 提出了一种利用预训练视角视频模型生成全景视频的新框架，通过设计的ViewPoint map和Pano-Perspective注意力机制，解决了现有方法因模态差异导致的全景视频质量低的问题。


<details>
  <summary>Details</summary>
Motivation: 全景视频生成在VR、世界模型和空间智能领域具有重要意义，但现有方法因全景数据与视角数据的模态差异无法生成高质量视频。

Method: 设计了具有全局空间连续性和细粒度视觉细节的ViewPoint map，并提出了Pano-Perspective注意力机制，利用预训练视角先验捕获全景空间相关性。

Result: 实验表明，该方法能生成动态性强且空间一致的全景视频，性能达到最先进水平。

Conclusion: 该方法有效解决了模态差异问题，显著提升了全景视频生成的质量和一致性。

Abstract: Panoramic video generation aims to synthesize 360-degree immersive videos,
holding significant importance in the fields of VR, world models, and spatial
intelligence. Existing works fail to synthesize high-quality panoramic videos
due to the inherent modality gap between panoramic data and perspective data,
which constitutes the majority of the training data for modern diffusion
models. In this paper, we propose a novel framework utilizing pretrained
perspective video models for generating panoramic videos. Specifically, we
design a novel panorama representation named ViewPoint map, which possesses
global spatial continuity and fine-grained visual details simultaneously. With
our proposed Pano-Perspective attention mechanism, the model benefits from
pretrained perspective priors and captures the panoramic spatial correlations
of the ViewPoint map effectively. Extensive experiments demonstrate that our
method can synthesize highly dynamic and spatially consistent panoramic videos,
achieving state-of-the-art performance and surpassing previous methods.

</details>


### [152] [WAVE: Warp-Based View Guidance for Consistent Novel View Synthesis Using a Single Image](https://arxiv.org/abs/2506.23518)
*Jiwoo Park,Tae Eun Choi,Youngjun Jun,Seong Jae Hwang*

Main category: cs.CV

TL;DR: 提出了一种无需额外模块的扩散模型方法，通过自适应注意力操纵和噪声重新初始化来提升视图一致性。


<details>
  <summary>Details</summary>
Motivation: 解决现有扩散模型在多视图生成中难以保持空间连续性的问题，同时避免复杂多步流程的低效性。

Method: 利用视图引导的变形技术，结合训练自由的自适应注意力操纵和噪声重新初始化。

Result: 在多种扩散模型中显著提升了视图一致性，并通过专门设计的指标框架验证了其有效性。

Conclusion: 该方法在保持高效的同时，显著提升了多视图生成的视图一致性，具有广泛适用性。

Abstract: Generating high-quality novel views of a scene from a single image requires
maintaining structural coherence across different views, referred to as view
consistency. While diffusion models have driven advancements in novel view
synthesis, they still struggle to preserve spatial continuity across views.
Diffusion models have been combined with 3D models to address the issue, but
such approaches lack efficiency due to their complex multi-step pipelines. This
paper proposes a novel view-consistent image generation method which utilizes
diffusion models without additional modules. Our key idea is to enhance
diffusion models with a training-free method that enables adaptive attention
manipulation and noise reinitialization by leveraging view-guided warping to
ensure view consistency. Through our comprehensive metric framework suitable
for novel-view datasets, we show that our method improves view consistency
across various diffusion models, demonstrating its broader applicability.

</details>


### [153] [PBCAT: Patch-based composite adversarial training against physically realizable attacks on object detection](https://arxiv.org/abs/2506.23581)
*Xiao Li,Yiming Zhu,Yifan Huang,Wei Zhang,Yingzhe He,Jie Shi,Xiaolin Hu*

Main category: cs.CV

TL;DR: 提出了一种名为PBCAT的对抗训练方法，用于防御多种物理可实现攻击，显著提升了目标检测器的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 物理可实现攻击（如对抗性补丁和纹理）对目标检测器构成现实威胁，现有对抗训练方法主要针对分类模型，对目标检测器的防御研究不足。

Method: 提出PBCAT策略，结合小区域梯度引导对抗补丁和全局不可察觉扰动进行对抗训练。

Result: 实验表明，PBCAT显著提升对抗多种物理可实现攻击的鲁棒性，检测准确率提升29.7%。

Conclusion: PBCAT为防御物理可实现攻击提供了统一且有效的解决方案。

Abstract: Object detection plays a crucial role in many security-sensitive
applications. However, several recent studies have shown that object detectors
can be easily fooled by physically realizable attacks, \eg, adversarial patches
and recent adversarial textures, which pose realistic and urgent threats.
Adversarial Training (AT) has been recognized as the most effective defense
against adversarial attacks. While AT has been extensively studied in the
$l_\infty$ attack settings on classification models, AT against physically
realizable attacks on object detectors has received limited exploration. Early
attempts are only performed to defend against adversarial patches, leaving AT
against a wider range of physically realizable attacks under-explored. In this
work, we consider defending against various physically realizable attacks with
a unified AT method. We propose PBCAT, a novel Patch-Based Composite
Adversarial Training strategy. PBCAT optimizes the model by incorporating the
combination of small-area gradient-guided adversarial patches and imperceptible
global adversarial perturbations covering the entire image. With these designs,
PBCAT has the potential to defend against not only adversarial patches but also
unseen physically realizable attacks such as adversarial textures. Extensive
experiments in multiple settings demonstrated that PBCAT significantly improved
robustness against various physically realizable attacks over state-of-the-art
defense methods. Notably, it improved the detection accuracy by 29.7\% over
previous defense methods under one recent adversarial texture attack.

</details>


### [154] [From Sight to Insight: Unleashing Eye-Tracking in Weakly Supervised Video Salient Object Detection](https://arxiv.org/abs/2506.23519)
*Qi Qin,Runmin Cong,Gen Zhan,Yiting Liao,Sam Kwong*

Main category: cs.CV

TL;DR: 论文提出了一种利用眼动追踪信息辅助视频显著物体检测的方法，通过位置和语义嵌入模块（PSE）以及语义和局部查询（SLQ）竞争器，结合对比学习范式（IIMC），在弱监督下提升了性能。


<details>
  <summary>Details</summary>
Motivation: 眼动追踪注释更易获取且更符合人类视觉模式，因此论文旨在利用这些信息辅助视频显著物体检测。

Method: 提出PSE模块提供位置和语义指导，设计SLQ竞争器进行特征选择，并引入IIMC模型进行对比学习。

Result: 在五个流行的VSOD基准测试中，模型在多种评估指标上优于其他方法。

Conclusion: 通过结合眼动追踪信息和弱监督学习，论文提出的方法显著提升了视频显著物体检测的性能。

Abstract: The eye-tracking video saliency prediction (VSP) task and video salient
object detection (VSOD) task both focus on the most attractive objects in video
and show the result in the form of predictive heatmaps and pixel-level saliency
masks, respectively. In practical applications, eye tracker annotations are
more readily obtainable and align closely with the authentic visual patterns of
human eyes. Therefore, this paper aims to introduce fixation information to
assist the detection of video salient objects under weak supervision. On the
one hand, we ponder how to better explore and utilize the information provided
by fixation, and then propose a Position and Semantic Embedding (PSE) module to
provide location and semantic guidance during the feature learning process. On
the other hand, we achieve spatiotemporal feature modeling under weak
supervision from the aspects of feature selection and feature contrast. A
Semantics and Locality Query (SLQ) Competitor with semantic and locality
constraints is designed to effectively select the most matching and accurate
object query for spatiotemporal modeling. In addition, an Intra-Inter Mixed
Contrastive (IIMC) model improves the spatiotemporal modeling capabilities
under weak supervision by forming an intra-video and inter-video contrastive
learning paradigm. Experimental results on five popular VSOD benchmarks
indicate that our model outperforms other competitors on various evaluation
metrics.

</details>


### [155] [Brain Tumor Detection through Thermal Imaging and MobileNET](https://arxiv.org/abs/2506.23627)
*Roham Maiti,Debasmita Bhoumik*

Main category: cs.CV

TL;DR: 论文提出了一种基于MobileNET的高效脑肿瘤检测方法，解决了传统机器学习模型的高计算需求和长训练时间问题，准确率达98.5%。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤对人类健康构成重大威胁，传统检测方法成本高且依赖专业医疗知识，机器学习方法虽有效但存在计算资源需求大等问题。

Method: 使用MobileNET模型结合图像处理技术，构建低计算资源需求、快速运行的脑肿瘤检测模型。

Result: 模型平均准确率达到98.5%。

Conclusion: 该方法在脑肿瘤检测中表现出高效性和准确性，为临床诊断提供了可行方案。

Abstract: Brain plays a crucial role in regulating body functions and cognitive
processes, with brain tumors posing significant risks to human health. Precise
and prompt detection is a key factor in proper treatment and better patient
outcomes. Traditional methods for detecting brain tumors, that include
biopsies, MRI, and CT scans often face challenges due to their high costs and
the need for specialized medical expertise. Recent developments in machine
learning (ML) and deep learning (DL) has exhibited strong capabilities in
automating the identification and categorization of brain tumors from medical
images, especially MRI scans. However, these classical ML models have
limitations, such as high computational demands, the need for large datasets,
and long training times, which hinder their accessibility and efficiency. Our
research uses MobileNET model for efficient detection of these tumors. The
novelty of this project lies in building an accurate tumor detection model
which use less computing re-sources and runs in less time followed by efficient
decision making through the use of image processing technique for accurate
results. The suggested method attained an average accuracy of 98.5%.

</details>


### [156] [Lightweight Temporal Transformer Decomposition for Federated Autonomous Driving](https://arxiv.org/abs/2506.23523)
*Tuong Do,Binh X. Nguyen,Quang D. Tran,Erman Tjiputra,Te-Chuan Chiu,Anh Nguyen*

Main category: cs.CV

TL;DR: 提出轻量级时间变换器分解方法，通过分解注意力图提升自动驾驶性能，实现实时预测。


<details>
  <summary>Details</summary>
Motivation: 传统基于视觉的自动驾驶系统在复杂环境中表现不佳，需引入时间数据提升鲁棒性。

Method: 轻量级时间变换器分解，将大注意力图分解为小矩阵，降低模型复杂度。

Result: 在三个数据集上表现优于现有方法，并实现实时性能。

Conclusion: 方法有效提升自动驾驶性能，适用于实时和联邦学习场景。

Abstract: Traditional vision-based autonomous driving systems often face difficulties
in navigating complex environments when relying solely on single-image inputs.
To overcome this limitation, incorporating temporal data such as past image
frames or steering sequences, has proven effective in enhancing robustness and
adaptability in challenging scenarios. While previous high-performance methods
exist, they often rely on resource-intensive fusion networks, making them
impractical for training and unsuitable for federated learning. To address
these challenges, we propose lightweight temporal transformer decomposition, a
method that processes sequential image frames and temporal steering data by
breaking down large attention maps into smaller matrices. This approach reduces
model complexity, enabling efficient weight updates for convergence and
real-time predictions while leveraging temporal information to enhance
autonomous driving performance. Intensive experiments on three datasets
demonstrate that our method outperforms recent approaches by a clear margin
while achieving real-time performance. Additionally, real robot experiments
further confirm the effectiveness of our method.

</details>


### [157] [On the Domain Robustness of Contrastive Vision-Language Models](https://arxiv.org/abs/2506.23663)
*Mario Koddenbrock,Rudolf Hoffmann,David Brodmann,Erik Rodner*

Main category: cs.CV

TL;DR: Deepbench是一个评估视觉语言模型（VLM）领域特定鲁棒性的框架，利用大语言模型（LLM）生成特定领域的图像损坏，无需标注数据。


<details>
  <summary>Details</summary>
Motivation: 大型预训练基础模型在领域变化下性能下降，需要针对性评估其鲁棒性。

Method: 使用LLM生成特定领域的图像损坏，评估多种VLM架构在六个真实领域的表现。

Result: 不同架构的鲁棒性差异显著，凸显领域感知评估的必要性。

Conclusion: Deepbench作为开源工具，支持领域感知鲁棒性评估的进一步研究。

Abstract: In real-world vision-language applications, practitioners increasingly rely
on large, pretrained foundation models rather than custom-built solutions,
despite limited transparency regarding their training data and processes. While
these models achieve impressive performance on general benchmarks, their
effectiveness can decline notably under specialized domain shifts, such as
unique imaging conditions or environmental variations. In this work, we
introduce Deepbench, a framework designed to assess domain-specific robustness
of vision-language models (VLMs). Deepbench leverages a large language model
(LLM) to generate realistic, context-aware image corruptions tailored to
specific deployment domains without requiring labeled data. We evaluate a range
of contrastive vision-language architectures and architectural variants across
six real-world domains and observe substantial variability in robustness,
highlighting the need for targeted, domain-aware evaluation. Deepbench is
released as open-source software to support further research into domain-aware
robustness assessment.

</details>


### [158] [Mamba-FETrack V2: Revisiting State Space Model for Frame-Event based Visual Object Tracking](https://arxiv.org/abs/2506.23783)
*Shiao Wang,Ju Huang,Qingchuan Ma,Jinfeng Gao,Chunyi Xu,Xiao Wang,Lan Chen,Bo Jiang*

Main category: cs.CV

TL;DR: 提出了一种基于线性复杂度Vision Mamba网络的高效RGB-Event目标跟踪框架Mamba-FETrack V2，通过轻量级Prompt Generator和FEMamba主干网络实现跨模态特征提取与融合。


<details>
  <summary>Details</summary>
Motivation: 现有跨模态跟踪算法依赖高复杂度Vision Transformer，导致计算开销大且跨模态交互效果受限。

Method: 设计轻量级Prompt Generator生成模态特定提示向量，结合Vision Mamba网络实现特征提取与融合。

Result: 在多个RGB-Event跟踪基准测试中表现优异，包括短期的COESOT和长期的FE108、FELT V2数据集。

Conclusion: Mamba-FETrack V2在性能和效率上均优于现有方法，代码和模型将开源。

Abstract: Combining traditional RGB cameras with bio-inspired event cameras for robust
object tracking has garnered increasing attention in recent years. However,
most existing multimodal tracking algorithms depend heavily on high-complexity
Vision Transformer architectures for feature extraction and fusion across
modalities. This not only leads to substantial computational overhead but also
limits the effectiveness of cross-modal interactions. In this paper, we propose
an efficient RGB-Event object tracking framework based on the linear-complexity
Vision Mamba network, termed Mamba-FETrack V2. Specifically, we first design a
lightweight Prompt Generator that utilizes embedded features from each
modality, together with a shared prompt pool, to dynamically generate
modality-specific learnable prompt vectors. These prompts, along with the
modality-specific embedded features, are then fed into a Vision Mamba-based
FEMamba backbone, which facilitates prompt-guided feature extraction,
cross-modal interaction, and fusion in a unified manner. Finally, the fused
representations are passed to the tracking head for accurate target
localization. Extensive experimental evaluations on multiple RGB-Event tracking
benchmarks, including short-term COESOT dataset and long-term datasets, i.e.,
FE108 and FELT V2, demonstrate the superior performance and efficiency of the
proposed tracking framework. The source code and pre-trained models will be
released on https://github.com/Event-AHU/Mamba_FETrack

</details>


### [159] [Consistent Time-of-Flight Depth Denoising via Graph-Informed Geometric Attention](https://arxiv.org/abs/2506.23542)
*Weida Wang,Changyong He,Jin Zeng,Di Qiu*

Main category: cs.CV

TL;DR: 提出了一种基于运动不变图融合的ToF深度去噪网络，通过跨帧几何注意力增强时间稳定性和空间清晰度。


<details>
  <summary>Details</summary>
Motivation: ToF传感器捕获的深度图像易受噪声影响，现有方法存在时间不一致性和空间模糊问题。

Method: 利用图结构的时序自相似性进行图融合，结合图像平滑先验和ToF噪声分布，构建最大后验问题，并通过迭代滤波器实现。

Result: 在合成DVToF数据集上达到最先进性能，并在真实Kinectv2数据集上表现出鲁棒泛化能力。

Conclusion: 该方法在ToF深度去噪中实现了高精度和一致性，具有可解释性和泛化性。

Abstract: Depth images captured by Time-of-Flight (ToF) sensors are prone to noise,
requiring denoising for reliable downstream applications. Previous works either
focus on single-frame processing, or perform multi-frame processing without
considering depth variations at corresponding pixels across frames, leading to
undesirable temporal inconsistency and spatial ambiguity. In this paper, we
propose a novel ToF depth denoising network leveraging motion-invariant graph
fusion to simultaneously enhance temporal stability and spatial sharpness.
Specifically, despite depth shifts across frames, graph structures exhibit
temporal self-similarity, enabling cross-frame geometric attention for graph
fusion. Then, by incorporating an image smoothness prior on the fused graph and
data fidelity term derived from ToF noise distribution, we formulate a maximum
a posterior problem for ToF denoising. Finally, the solution is unrolled into
iterative filters whose weights are adaptively learned from the graph-informed
geometric attention, producing a high-performance yet interpretable network.
Experimental results demonstrate that the proposed scheme achieves
state-of-the-art performance in terms of accuracy and consistency on synthetic
DVToF dataset and exhibits robust generalization on the real Kinectv2 dataset.
Source code will be released at
\href{https://github.com/davidweidawang/GIGA-ToF}{https://github.com/davidweidawang/GIGA-ToF}.

</details>


### [160] [Pyramidal Patchification Flow for Visual Generation](https://arxiv.org/abs/2506.23543)
*Hui Li,Baoyou Chen,Liwei Zhang,Jiaye Li,Jingdong Wang,Siyu Zhu*

Main category: cs.CV

TL;DR: PPFlow通过动态调整patch大小优化DiTs的计算成本，高噪声时用大patch，低噪声时用小patch，并修改线性投影和Unpatchify。训练结果显示速度提升且性能相近。


<details>
  <summary>Details</summary>
Motivation: 传统DiTs对所有时间步使用固定patch大小，计算成本高。PPFlow旨在动态调整patch大小以优化计算效率。

Method: PPFlow采用金字塔式patch划分，不同噪声水平对应不同patch大小，并学习各自的线性投影。

Result: 训练结果显示，PPFlow在推理速度上提升1.6-2.0倍，训练FLOPs略低且生成性能相近。

Conclusion: PPFlow通过动态patch划分显著提升效率，且支持从预训练模型微调，性能更优。

Abstract: Diffusion transformers (DiTs) adopt Patchify, mapping patch representations
to token representations through linear projections, to adjust the number of
tokens input to DiT blocks and thus the computation cost. Instead of a single
patch size for all the timesteps, we introduce a Pyramidal Patchification Flow
(PPFlow) approach: Large patch sizes are used for high noise timesteps and
small patch sizes for low noise timesteps; Linear projections are learned for
each patch size; and Unpatchify is accordingly modified. Unlike Pyramidal Flow,
our approach operates over full latent representations other than pyramid
representations, and adopts the normal denoising process without requiring the
renoising trick. We demonstrate the effectiveness of our approach through two
training manners. Training from scratch achieves a $1.6\times$ ($2.0\times$)
inference speed over SiT-B/2 for 2-level (3-level) pyramid patchification with
slightly lower training FLOPs and similar image generation performance.
Training from pretrained normal DiTs achieves even better performance with
small training time. The code and checkpoint are at
https://github.com/fudan-generative-vision/PPFlow.

</details>


### [161] [Spurious-Aware Prototype Refinement for Reliable Out-of-Distribution Detection](https://arxiv.org/abs/2506.23881)
*Reihaneh Zohrabi,Hosein Hasani,Mahdieh Soleymani Baghshah,Anna Rohrbach,Marcus Rohrbach,Mohammad Hossein Rohban*

Main category: cs.CV

TL;DR: SPROD是一种新型的原型OOD检测方法，通过优化类别原型减少虚假相关性的干扰，无需额外数据或调参，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现实应用中，机器学习模型常遇到训练时未见的数据分布，现有OOD检测方法易受虚假相关性影响，导致鲁棒性不足。

Method: 提出SPROD，一种后处理方法，通过优化类别原型减少虚假特征的偏差，适用于多种主干网络和OOD检测场景。

Result: 在多个挑战性OOD数据集上，SPROD平均AUROC提升4.7%，FPR@95降低9.3%，优于现有方法。

Conclusion: SPROD有效解决了虚假相关性对OOD检测的干扰，具有广泛适用性和显著性能提升。

Abstract: Out-of-distribution (OOD) detection is crucial for ensuring the reliability
and safety of machine learning models in real-world applications, where they
frequently face data distributions unseen during training. Despite progress,
existing methods are often vulnerable to spurious correlations that mislead
models and compromise robustness. To address this, we propose SPROD, a novel
prototype-based OOD detection approach that explicitly addresses the challenge
posed by unknown spurious correlations. Our post-hoc method refines class
prototypes to mitigate bias from spurious features without additional data or
hyperparameter tuning, and is broadly applicable across diverse backbones and
OOD detection settings. We conduct a comprehensive spurious correlation OOD
detection benchmarking, comparing our method against existing approaches and
demonstrating its superior performance across challenging OOD datasets, such as
CelebA, Waterbirds, UrbanCars, Spurious Imagenet, and the newly introduced
Animals MetaCoCo. On average, SPROD improves AUROC by 4.7% and FPR@95 by 9.3%
over the second best.

</details>


### [162] [Oneta: Multi-Style Image Enhancement Using Eigentransformation Functions](https://arxiv.org/abs/2506.23547)
*Jiwon Kim,Soohyun Hwang,Dong-O Kim,Changsu Han,Min Kyu Park,Chang-Su Kim*

Main category: cs.CV

TL;DR: 提出了Oneta算法，用于多风格图像增强任务，通过两步操作（强度增强和色彩校正）实现高性能，支持多种风格和任务。


<details>
  <summary>Details</summary>
Motivation: 解决多风格图像增强的需求，通过简单但高效的两步模型实现广泛适用性。

Method: Oneta采用Y-Net和C-Net分别预测eigenTF和CCM参数，使用K个可学习令牌支持多风格。

Result: 实验表明，Oneta能有效处理六种增强任务，覆盖30个数据集。

Conclusion: Oneta是一种高效且通用的多风格图像增强方法。

Abstract: The first algorithm, called Oneta, for a novel task of multi-style image
enhancement is proposed in this work. Oneta uses two point operators
sequentially: intensity enhancement with a transformation function (TF) and
color correction with a color correction matrix (CCM). This two-step
enhancement model, though simple, achieves a high performance upper bound.
Also, we introduce eigentransformation function (eigenTF) to represent TF
compactly. The Oneta network comprises Y-Net and C-Net to predict eigenTF and
CCM parameters, respectively. To support $K$ styles, Oneta employs $K$
learnable tokens. During training, each style token is learned using image
pairs from the corresponding dataset. In testing, Oneta selects one of the $K$
style tokens to enhance an image accordingly. Extensive experiments show that
the single Oneta network can effectively undertake six enhancement tasks --
retouching, image signal processing, low-light image enhancement, dehazing,
underwater image enhancement, and white balancing -- across 30 datasets.

</details>


### [163] [LH2Face: Loss function for Hard High-quality Face](https://arxiv.org/abs/2506.23555)
*Fan Xie,Pan Cao*

Main category: cs.CV

TL;DR: 提出了一种名为LH2Face的新型损失函数，通过自适应边缘和代理约束优化人脸识别性能，特别是在高质量硬样本上表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前基于余弦相似度和softmax分类的人脸识别方法在处理硬样本时表现不佳，且未考虑人脸质量或识别难度。

Method: 结合vMF分布的相似性度量，提出自适应边缘的多分类方法，并使用代理损失函数优化表示空间分布。

Result: 在IJB-B数据集上达到49.39%的准确率，优于第二名2.37%。

Conclusion: LH2Face通过自适应策略和代理约束显著提升了硬高质量人脸识别的性能。

Abstract: In current practical face authentication systems, most face recognition (FR)
algorithms are based on cosine similarity with softmax classification. Despite
its reliable classification performance, this method struggles with hard
samples. A popular strategy to improve FR performance is incorporating angular
or cosine margins. However, it does not take face quality or recognition
hardness into account, simply increasing the margin value and thus causing an
overly uniform training strategy. To address this problem, a novel loss
function is proposed, named Loss function for Hard High-quality Face (LH2Face).
Firstly, a similarity measure based on the von Mises-Fisher (vMF) distribution
is stated, specifically focusing on the logarithm of the Probability Density
Function (PDF), which represents the distance between a probability
distribution and a vector. Then, an adaptive margin-based multi-classification
method using softmax, called the Uncertainty-Aware Margin Function, is
implemented in the article. Furthermore, proxy-based loss functions are used to
apply extra constraints between the proxy and sample to optimize their
representation space distribution. Finally, a renderer is constructed that
optimizes FR through face reconstruction and vice versa. Our LH2Face is
superior to similiar schemes on hard high-quality face datasets, achieving
49.39% accuracy on the IJB-B dataset, which surpasses the second-place method
by 2.37%.

</details>


### [164] [OcRFDet: Object-Centric Radiance Fields for Multi-View 3D Object Detection in Autonomous Driving](https://arxiv.org/abs/2506.23565)
*Mingqian Ji,Jian Yang,Shanshan Zhang*

Main category: cs.CV

TL;DR: 提出了一种基于物体中心辐射场（OcRF）的多视图3D物体检测方法，通过渲染前景物体增强3D特征，并结合高度感知不透明度注意力（HOA）提升2D特征，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 当前多视图3D物体检测方法通常通过深度估计或3D位置编码将2D特征隐式转换为3D空间，限制了检测性能。受辐射场在3D重建中的成功启发，尝试将其用于增强3D几何估计能力，但直接应用会导致背景干扰。

Method: 提出物体中心辐射场（OcRF），专注于建模前景物体并忽略背景噪声；通过高度感知不透明度注意力（HOA）增强2D特征。

Result: 在nuScenes测试基准上达到57.2% mAP和64.8% NDS，优于现有方法。

Conclusion: OcRFDet通过结合OcRF和HOA，显著提升了多视图3D物体检测的性能。

Abstract: Current multi-view 3D object detection methods typically transfer 2D features
into 3D space using depth estimation or 3D position encoder, but in a fully
data-driven and implicit manner, which limits the detection performance.
Inspired by the success of radiance fields on 3D reconstruction, we assume they
can be used to enhance the detector's ability of 3D geometry estimation.
However, we observe a decline in detection performance, when we directly use
them for 3D rendering as an auxiliary task. From our analysis, we find the
performance drop is caused by the strong responses on the background when
rendering the whole scene. To address this problem, we propose object-centric
radiance fields, focusing on modeling foreground objects while discarding
background noises. Specifically, we employ Object-centric Radiance Fields
(OcRF) to enhance 3D voxel features via an auxiliary task of rendering
foreground objects. We further use opacity - the side-product of rendering- to
enhance the 2D foreground BEV features via Height-aware Opacity-based Attention
(HOA), where attention maps at different height levels are generated separately
via multiple networks in parallel. Extensive experiments on the nuScenes
validation and test datasets demonstrate that our OcRFDet achieves superior
performance, outperforming previous state-of-the-art methods with 57.2$\%$ mAP
and 64.8$\%$ NDS on the nuScenes test benchmark. Code will be available at
https://github.com/Mingqj/OcRFDet.

</details>


### [165] [Event-based Tiny Object Detection: A Benchmark Dataset and Baseline](https://arxiv.org/abs/2506.23575)
*Nuo Chen,Chao Xiao,Yimian Dai,Shiman He,Miao Li,Wei An*

Main category: cs.CV

TL;DR: 论文提出了首个针对反无人机任务的大规模事件相机小目标检测数据集EV-UAV，并提出了一种基于事件点云分割的新方法EV-SpSegNet。


<details>
  <summary>Details</summary>
Motivation: 传统帧相机在复杂背景下检测小目标（如无人机）存在困难，而现有事件相机数据集规模小且目标尺寸大，无法满足需求。

Method: 提出EV-UAV数据集，包含147个序列和230万事件级标注；设计EV-SpSegNet网络及STC损失函数，利用运动连续性分割目标。

Result: 实验证明EV-SpSegNet在EV-UAV数据集上表现优越，为小目标检测提供了新基准。

Conclusion: EV-UAV数据集和方法为事件相机小目标检测研究提供了重要资源和方向。

Abstract: Small object detection (SOD) in anti-UAV task is a challenging problem due to
the small size of UAVs and complex backgrounds. Traditional frame-based cameras
struggle to detect small objects in complex environments due to their low frame
rates, limited dynamic range, and data redundancy. Event cameras, with
microsecond temporal resolution and high dynamic range, provide a more
effective solution for SOD. However, existing event-based object detection
datasets are limited in scale, feature large targets size, and lack diverse
backgrounds, making them unsuitable for SOD benchmarks. In this paper, we
introduce a Event-based Small object detection (EVSOD) dataset (namely EV-UAV),
the first large-scale, highly diverse benchmark for anti-UAV tasks. It includes
147 sequences with over 2.3 million event-level annotations, featuring
extremely small targets (averaging 6.8 $\times$ 5.4 pixels) and diverse
scenarios such as urban clutter and extreme lighting conditions. Furthermore,
based on the observation that small moving targets form continuous curves in
spatiotemporal event point clouds, we propose Event based Sparse Segmentation
Network (EV-SpSegNet), a novel baseline for event segmentation in point cloud
space, along with a Spatiotemporal Correlation (STC) loss that leverages motion
continuity to guide the network in retaining target events. Extensive
experiments on the EV-UAV dataset demonstrate the superiority of our method and
provide a benchmark for future research in EVSOD. The dataset and code are at
https://github.com/ChenYichen9527/Ev-UAV.

</details>


### [166] [StackCLIP: Clustering-Driven Stacked Prompt in Zero-Shot Industrial Anomaly Detection](https://arxiv.org/abs/2506.23577)
*Yanning Hou,Yanran Ruan,Junfa Li,Shanshan Wang,Jianfeng Qiu,Ke Xu*

Main category: cs.CV

TL;DR: 论文提出StackCLIP模型，通过多类别名称堆叠生成堆叠提示，结合CSP和EFA模块提升零样本工业异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在预训练中使用特定类别提示，容易过拟合训练类别，限制模型泛化能力。

Method: 提出堆叠提示方法，包括CSP模块（构建通用提示）和EFA模块（训练知识特定线性层）。

Result: 在七个工业异常检测数据集上实现最先进的零样本检测和分割性能。

Conclusion: StackCLIP模型显著提升训练速度、稳定性和收敛性，并具有强大的分类任务泛化能力。

Abstract: Enhancing the alignment between text and image features in the CLIP model is
a critical challenge in zero-shot industrial anomaly detection tasks. Recent
studies predominantly utilize specific category prompts during pretraining,
which can cause overfitting to the training categories and limit model
generalization. To address this, we propose a method that transforms category
names through multicategory name stacking to create stacked prompts, forming
the basis of our StackCLIP model. Our approach introduces two key components.
The Clustering-Driven Stacked Prompts (CSP) module constructs generic prompts
by stacking semantically analogous categories, while utilizing multi-object
textual feature fusion to amplify discriminative anomalies among similar
objects. The Ensemble Feature Alignment (EFA) module trains knowledge-specific
linear layers tailored for each stack cluster and adaptively integrates them
based on the attributes of test categories. These modules work together to
deliver superior training speed, stability, and convergence, significantly
boosting anomaly segmentation performance. Additionally, our stacked prompt
framework offers robust generalization across classification tasks. To further
improve performance, we introduce the Regulating Prompt Learning (RPL) module,
which leverages the generalization power of stacked prompts to refine prompt
learning, elevating results in anomaly detection classification tasks.
Extensive testing on seven industrial anomaly detection datasets demonstrates
that our method achieves state-of-the-art performance in both zero-shot anomaly
detection and segmentation tasks.

</details>


### [167] [Dataset Distillation via Vision-Language Category Prototype](https://arxiv.org/abs/2506.23580)
*Yawen Zou,Guang Li,Duo Su,Zi Wang,Jun Yu,Chao Zhang*

Main category: cs.CV

TL;DR: 该论文提出了一种结合视觉-语言方法的数据集蒸馏技术，通过引入文本原型来增强语义信息，提升蒸馏性能。


<details>
  <summary>Details</summary>
Motivation: 传统数据集蒸馏方法主要关注图像信息，忽略了语义信息，导致模型泛化能力不足。

Method: 结合视觉-语言方法，利用开源大语言模型生成的描述性文本信息作为文本原型，与图像原型协同合成数据。

Result: 生成的图像逻辑连贯且包含目标对象，验证性能达到最优，并展现出强大的泛化能力。

Conclusion: 该方法扩展了数据集蒸馏的应用范围，超越了传统的基于图像的方法。

Abstract: Dataset distillation (DD) condenses large datasets into compact yet
informative substitutes, preserving performance comparable to the original
dataset while reducing storage, transmission costs, and computational
consumption. However, previous DD methods mainly focus on distilling
information from images, often overlooking the semantic information inherent in
the data. The disregard for context hinders the model's generalization ability,
particularly in tasks involving complex datasets, which may result in illogical
outputs or the omission of critical objects. In this study, we integrate
vision-language methods into DD by introducing text prototypes to distill
language information and collaboratively synthesize data with image prototypes,
thereby enhancing dataset distillation performance. Notably, the text
prototypes utilized in this study are derived from descriptive text information
generated by an open-source large language model. This framework demonstrates
broad applicability across datasets without pre-existing text descriptions,
expanding the potential of dataset distillation beyond traditional image-based
approaches. Compared to other methods, the proposed approach generates
logically coherent images containing target objects, achieving state-of-the-art
validation performance and demonstrating robust generalization. Source code and
generated data are available in
https://github.com/zou-yawen/Dataset-Distillation-via-Vision-Language-Category-Prototype/

</details>


### [168] [CAI: Caption-Sensitive Attention Intervention for Mitigating Object Hallucination in Large Vision-Language Models](https://arxiv.org/abs/2506.23590)
*Qiming Li,Zekai Ye,Xiaocheng Feng,Weihong Zhong,Libo Qin,Ruihan Chen,Baohang Li,Kui Jiang,Yaowei Wang,Ting Liu,Bing Qin*

Main category: cs.CV

TL;DR: 提出了一种无需训练、即插即用的方法（CAI），通过利用LVLMs在回答标题查询时的注意力模式，减少视觉信息偏差（幻觉现象），并在多个基准测试中取得最佳效果。


<details>
  <summary>Details</summary>
Motivation: LVLMs在解释视觉信息时经常产生与视觉信息不符的内容（对象幻觉），现有方法依赖昂贵的手动标注或增加推理时间。

Method: 提出Caption-sensitive Attention Intervention (CAI)，利用LVLMs在回答标题查询时的注意力激活模式，增强视觉感知能力。

Result: 在四个基准测试中（涵盖判别和生成任务），CAI以最小的额外推理成本实现了最先进的幻觉缓解性能。

Conclusion: CAI是一种高效且低成本的方法，有效减少了LVLMs的视觉信息幻觉问题。

Abstract: Although Large Vision-Language Models (LVLMs) have demonstrated powerful
capabilities in interpreting visual information, they frequently produce
content that deviates from visual information, leading to object hallucination.
To tackle this, recent works mostly depend on expensive manual annotations and
training cost, or significantly increase inference time. In this work, we
observe that LVLMs' attention to visual information is significantly stronger
when answering caption queries compared to non-caption queries. Inspired by
this phenomenon, we propose Caption-sensitive Attention Intervention (CAI), a
training-free, plug-and-play hallucination mitigation method that leverages the
attention activation pattern in response to caption queries to enhance LVLMs'
visual perception capability. Extensive experimental results across four
benchmarks covering both discriminative and generative tasks, demonstrate that
CAI achieves state-of-the-art (SOTA) hallucination mitigating performance only
with minimal additional inference cost.

</details>


### [169] [AI-Generated Lecture Slides for Improving Slide Element Detection and Retrieval](https://arxiv.org/abs/2506.23605)
*Suyash Maniyar,Vishvesh Trivedi,Ajoy Mondal,Anand Mishra,C. V. Jawahar*

Main category: cs.CV

TL;DR: 提出了一种基于大语言模型（LLM）的合成幻灯片生成方法SynLecSlideGen，并通过实验验证其能有效提升少样本迁移学习性能。


<details>
  <summary>Details</summary>
Motivation: 手动标注大量幻灯片数据耗时且需要专业知识，因此需要一种替代方法生成高质量合成数据。

Method: 使用LLM引导的合成幻灯片生成管道SynLecSlideGen，并创建了真实幻灯片标注数据集RealSlide进行评估。

Result: 实验表明，在合成数据上预训练的模型通过少样本迁移学习显著优于仅使用真实数据训练的模型。

Conclusion: 合成数据可以有效弥补真实标注数据的不足，提升模型性能。

Abstract: Lecture slide element detection and retrieval are key problems in slide
understanding. Training effective models for these tasks often depends on
extensive manual annotation. However, annotating large volumes of lecture
slides for supervised training is labor intensive and requires domain
expertise. To address this, we propose a large language model (LLM)-guided
synthetic lecture slide generation pipeline, SynLecSlideGen, which produces
high-quality, coherent and realistic slides. We also create an evaluation
benchmark, namely RealSlide by manually annotating 1,050 real lecture slides.
To assess the utility of our synthetic slides, we perform few-shot transfer
learning on real data using models pre-trained on them. Experimental results
show that few-shot transfer learning with pretraining on synthetic slides
significantly improves performance compared to training only on real data. This
demonstrates that synthetic data can effectively compensate for limited labeled
lecture slides. The code and resources of our work are publicly available on
our project website: https://synslidegen.github.io/.

</details>


### [170] [SG-LDM: Semantic-Guided LiDAR Generation via Latent-Aligned Diffusion](https://arxiv.org/abs/2506.23606)
*Zhengkang Xiang,Zizhao Li,Amir Khodabandeh,Kourosh Khoshelham*

Main category: cs.CV

TL;DR: SG-LDM是一种基于语义引导的激光雷达扩散模型，通过潜在对齐实现高保真激光雷达点云生成，并首次提出基于扩散的激光雷达翻译框架，显著提升下游感知性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有激光雷达点云生成方法忽视实际应用潜力的问题，通过语义引导生成更丰富的数据以增强深度学习模型。

Method: 提出SG-LDM模型，利用潜在对齐和显式语义条件在原生激光雷达空间生成点云，并开发扩散式激光雷达翻译框架。

Result: SG-LDM在生成高保真点云方面表现最优，翻译框架进一步提升了数据增强在下游分割任务中的效果。

Conclusion: SG-LDM及其翻译框架为激光雷达数据合成和跨域适应提供了高效解决方案，显著提升了感知性能。

Abstract: Lidar point cloud synthesis based on generative models offers a promising
solution to augment deep learning pipelines, particularly when real-world data
is scarce or lacks diversity. By enabling flexible object manipulation, this
synthesis approach can significantly enrich training datasets and enhance
discriminative models. However, existing methods focus on unconditional lidar
point cloud generation, overlooking their potential for real-world
applications. In this paper, we propose SG-LDM, a Semantic-Guided Lidar
Diffusion Model that employs latent alignment to enable robust
semantic-to-lidar synthesis. By directly operating in the native lidar space
and leveraging explicit semantic conditioning, SG-LDM achieves state-of-the-art
performance in generating high-fidelity lidar point clouds guided by semantic
labels. Moreover, we propose the first diffusion-based lidar translation
framework based on SG-LDM, which enables cross-domain translation as a domain
adaptation strategy to enhance downstream perception performance. Systematic
experiments demonstrate that SG-LDM significantly outperforms existing lidar
diffusion models and the proposed lidar translation framework further improves
data augmentation performance in the downstream lidar segmentation task.

</details>


### [171] [PGOV3D: Open-Vocabulary 3D Semantic Segmentation with Partial-to-Global Curriculum](https://arxiv.org/abs/2506.23607)
*Shiqi Zhang,Sha Zhang,Jiajun Deng,Yedong Shen,Mingxiao MA,Yanyong Zhang*

Main category: cs.CV

TL;DR: PGOV3D提出了一种基于Partial-to-Global课程的两阶段训练框架，通过多视角图像和语言模型生成开放词汇标签，提升了3D语义分割的效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅将多视角图像作为开放词汇信息传递的中介，忽略了其丰富的语义内容和跨视角对应关系，限制了模型效果。

Method: 采用两阶段训练：第一阶段在部分场景预训练，利用多模态语言模型和2D分割模型生成开放词汇标签；第二阶段在完整场景微调，通过伪标签桥接语义差距。

Result: 在ScanNet、ScanNet200和S3DIS基准测试中表现优异。

Conclusion: PGOV3D通过Partial-to-Global课程和跨视角一致性模块，显著提升了开放词汇3D语义分割的性能。

Abstract: Existing open-vocabulary 3D semantic segmentation methods typically supervise
3D segmentation models by merging text-aligned features (e.g., CLIP) extracted
from multi-view images onto 3D points. However, such approaches treat
multi-view images merely as intermediaries for transferring open-vocabulary
information, overlooking their rich semantic content and cross-view
correspondences, which limits model effectiveness. To address this, we propose
PGOV3D, a novel framework that introduces a Partial-to-Global curriculum for
improving open-vocabulary 3D semantic segmentation. The key innovation lies in
a two-stage training strategy. In the first stage, we pre-train the model on
partial scenes that provide dense semantic information but relatively simple
geometry. These partial point clouds are derived from multi-view RGB-D inputs
via pixel-wise depth projection. To enable open-vocabulary learning, we
leverage a multi-modal large language model (MLLM) and a 2D segmentation
foundation model to generate open-vocabulary labels for each viewpoint,
offering rich and aligned supervision. An auxiliary inter-frame consistency
module is introduced to enforce feature consistency across varying viewpoints
and enhance spatial understanding. In the second stage, we fine-tune the model
on complete scene-level point clouds, which are sparser and structurally more
complex. We aggregate the partial vocabularies associated with each scene and
generate pseudo labels using the pre-trained model, effectively bridging the
semantic gap between dense partial observations and large-scale 3D
environments. Extensive experiments on ScanNet, ScanNet200, and S3DIS
benchmarks demonstrate that PGOV3D achieves competitive performance in
open-vocabulary 3D semantic segmentation.

</details>


### [172] [AttentionGS: Towards Initialization-Free 3D Gaussian Splatting via Structural Attention](https://arxiv.org/abs/2506.23611)
*Ziao Liu,Zhenjia Li,Yifeng Shi,Xiangang Li*

Main category: cs.CV

TL;DR: AttentionGS 是一种新框架，通过结构注意力直接从随机初始化进行3D重建，解决了3D高斯泼溅对高质量点云的依赖问题。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅（3DGS）依赖高质量点云，限制了其在纹理缺失或视角受限场景中的应用。

Method: 提出AttentionGS，结合几何注意力快速恢复全局结构，纹理注意力优化细节，并使用不透明度加权梯度指导高斯密度化。

Result: 在多个基准数据集上显著优于现有方法，尤其在点云初始化不可靠的场景中。

Conclusion: AttentionGS为3D高斯泼溅在现实应用中提供了更鲁棒和灵活的解决方案。

Abstract: 3D Gaussian Splatting (3DGS) is a powerful alternative to Neural Radiance
Fields (NeRF), excelling in complex scene reconstruction and efficient
rendering. However, it relies on high-quality point clouds from
Structure-from-Motion (SfM), limiting its applicability. SfM also fails in
texture-deficient or constrained-view scenarios, causing severe degradation in
3DGS reconstruction. To address this limitation, we propose AttentionGS, a
novel framework that eliminates the dependency on high-quality initial point
clouds by leveraging structural attention for direct 3D reconstruction from
randomly initialization. In the early training stage, we introduce geometric
attention to rapidly recover the global scene structure. As training
progresses, we incorporate texture attention to refine fine-grained details and
enhance rendering quality. Furthermore, we employ opacity-weighted gradients to
guide Gaussian densification, leading to improved surface reconstruction.
Extensive experiments on multiple benchmark datasets demonstrate that
AttentionGS significantly outperforms state-of-the-art methods, particularly in
scenarios where point cloud initialization is unreliable. Our approach paves
the way for more robust and flexible 3D Gaussian Splatting in real-world
applications.

</details>


### [173] [TurboVSR: Fantastic Video Upscalers and Where to Find Them](https://arxiv.org/abs/2506.23618)
*Zhongdao Wang,Guodongfang Zhao,Jingjing Ren,Bailan Feng,Shifeng Zhang,Wenbo Li*

Main category: cs.CV

TL;DR: TurboVSR是一种基于扩散模型的超高效视频超分辨率方法，通过高压缩比自动编码器、因子化条件和快捷模型设计，实现100倍加速，同时保持与现有方法相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的视频超分辨率方法在细节生成方面表现优异，但计算效率低下，处理短视频耗时过长。

Method: 采用高压缩比自动编码器减少token数量；引入因子化条件降低训练复杂度；将预训练扩散模型转换为快捷模型以减少采样步骤。

Result: TurboVSR在性能上与现有最优方法相当，但速度快100倍以上，处理2秒1080p视频仅需7秒，并支持4K图像超分辨率。

Conclusion: TurboVSR通过高效设计解决了扩散模型的计算效率问题，为更高分辨率的超分辨率任务提供了可能。

Abstract: Diffusion-based generative models have demonstrated exceptional promise in
the video super-resolution (VSR) task, achieving a substantial advancement in
detail generation relative to prior methods. However, these approaches face
significant computational efficiency challenges. For instance, current
techniques may require tens of minutes to super-resolve a mere 2-second, 1080p
video. In this paper, we present TurboVSR, an ultra-efficient diffusion-based
video super-resolution model. Our core design comprises three key aspects: (1)
We employ an autoencoder with a high compression ratio of 32$\times$32$\times$8
to reduce the number of tokens. (2) Highly compressed latents pose substantial
challenges for training. We introduce factorized conditioning to mitigate the
learning complexity: we first learn to super-resolve the initial frame;
subsequently, we condition the super-resolution of the remaining frames on the
high-resolution initial frame and the low-resolution subsequent frames. (3) We
convert the pre-trained diffusion model to a shortcut model to enable fewer
sampling steps, further accelerating inference. As a result, TurboVSR performs
on par with state-of-the-art VSR methods, while being 100+ times faster, taking
only 7 seconds to process a 2-second long 1080p video. TurboVSR also supports
image resolution by considering image as a one-frame video. Our efficient
design makes SR beyond 1080p possible, results on 4K (3648$\times$2048) image
SR show surprising fine details.

</details>


### [174] [Revisiting Audio-Visual Segmentation with Vision-Centric Transformer](https://arxiv.org/abs/2506.23623)
*Shaofei Huang,Rui Ling,Tianrui Hui,Hongyu Li,Xu Zhou,Shifeng Zhang,Si Liu,Richang Hong,Meng Wang*

Main category: cs.CV

TL;DR: 论文提出了一种视觉为中心的Transformer（VCT）框架，通过视觉驱动的查询解决音频-视觉分割（AVS）中的感知模糊和视觉细节丢失问题。


<details>
  <summary>Details</summary>
Motivation: 现有音频为中心的Transformer方法存在感知模糊和视觉细节丢失的局限性，影响了分割效果。

Method: 采用视觉驱动的查询迭代获取音频和视觉信息，并引入原型提示查询生成（PPQG）模块增强语义和视觉丰富性。

Result: 在AVSBench数据集的三个子集上实现了新的最佳性能。

Conclusion: VCT框架有效提升了音频-视觉分割的准确性和轮廓描绘能力。

Abstract: Audio-Visual Segmentation (AVS) aims to segment sound-producing objects in
video frames based on the associated audio signal. Prevailing AVS methods
typically adopt an audio-centric Transformer architecture, where object queries
are derived from audio features. However, audio-centric Transformers suffer
from two limitations: perception ambiguity caused by the mixed nature of audio,
and weakened dense prediction ability due to visual detail loss. To address
these limitations, we propose a new Vision-Centric Transformer (VCT) framework
that leverages vision-derived queries to iteratively fetch corresponding audio
and visual information, enabling queries to better distinguish between
different sounding objects from mixed audio and accurately delineate their
contours. Additionally, we also introduce a Prototype Prompted Query Generation
(PPQG) module within our VCT framework to generate vision-derived queries that
are both semantically aware and visually rich through audio prototype prompting
and pixel context grouping, facilitating audio-visual information aggregation.
Extensive experiments demonstrate that our VCT framework achieves new
state-of-the-art performances on three subsets of the AVSBench dataset. The
code is available at https://github.com/spyflying/VCT_AVS.

</details>


### [175] [Blending Concepts with Text-to-Image Diffusion Models](https://arxiv.org/abs/2506.23630)
*Lorenzo Olearo,Giorgio Longari,Alessandro Raganato,Rafael Peñaloza,Simone Melzi*

Main category: cs.CV

TL;DR: 扩散模型在零样本框架下能够将不同概念（从具体对象到抽象想法）融合成连贯的新视觉实体，展示了其创造性混合能力。


<details>
  <summary>Details</summary>
Motivation: 研究扩散模型是否能够在不进行额外训练或微调的情况下，将多个概念的属性融合成单一新颖的图像。

Method: 研究了四种混合方法，包括提示调度、嵌入插值和分层条件等，通过系统实验验证其效果。

Result: 实验表明扩散模型具有创造性混合能力，但不同方法在不同场景下表现各异，受提示顺序、概念距离和随机种子等因素影响。

Conclusion: 扩散模型展示了显著的组合潜力，但对输入变化的敏感性也暴露无遗。

Abstract: Diffusion models have dramatically advanced text-to-image generation in
recent years, translating abstract concepts into high-fidelity images with
remarkable ease. In this work, we examine whether they can also blend distinct
concepts, ranging from concrete objects to intangible ideas, into coherent new
visual entities under a zero-shot framework. Specifically, concept blending
merges the key attributes of multiple concepts (expressed as textual prompts)
into a single, novel image that captures the essence of each concept. We
investigate four blending methods, each exploiting different aspects of the
diffusion pipeline (e.g., prompt scheduling, embedding interpolation, or
layer-wise conditioning). Through systematic experimentation across diverse
concept categories, such as merging concrete concepts, synthesizing compound
words, transferring artistic styles, and blending architectural landmarks, we
show that modern diffusion models indeed exhibit creative blending capabilities
without further training or fine-tuning. Our extensive user study, involving
100 participants, reveals that no single approach dominates in all scenarios:
each blending technique excels under certain conditions, with factors like
prompt ordering, conceptual distance, and random seed affecting the outcome.
These findings highlight the remarkable compositional potential of diffusion
models while exposing their sensitivity to seemingly minor input variations.

</details>


### [176] [Unified Multimodal Understanding via Byte-Pair Visual Encoding](https://arxiv.org/abs/2506.23639)
*Wanpeng Zhang,Yicheng Feng,Hao Luo,Yijiang Li,Zihao Yue,Sipeng Zheng,Zongqing Lu*

Main category: cs.CV

TL;DR: 提出了一种基于字节对编码的统一多模态理解框架，通过优先级引导的编码方案和多阶段训练，提升了跨模态关系建模能力。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在视觉-语言理解方面取得进展，但不同模态的有效对齐仍是挑战。

Method: 采用字节对编码将结构信息直接融入视觉标记，引入优先级引导的编码方案和多阶段训练。

Result: 实验表明，该方法在多种视觉-语言任务中性能提升。

Conclusion: 通过弥合视觉与文本表示之间的差距，推动了更高效的多模态基础模型发展。

Abstract: Multimodal large language models (MLLMs) have made significant progress in
vision-language understanding, yet effectively aligning different modalities
remains a fundamental challenge. We present a framework that unifies multimodal
understanding by applying byte-pair encoding to visual tokens. Unlike
conventional approaches that rely on modality-specific encoders, our method
directly incorporates structural information into visual tokens, mirroring
successful tokenization strategies in text-only language models. We introduce a
priority-guided encoding scheme that considers both frequency and spatial
consistency, coupled with a multi-stage training procedure based on
curriculum-driven data composition. These enhancements enable the transformer
model to better capture cross-modal relationships and reason with visual
information. Comprehensive experiments demonstrate improved performance across
diverse vision-language tasks. By bridging the gap between visual and textual
representations, our approach contributes to the advancement of more capable
and efficient multimodal foundation models.

</details>


### [177] [VAP-Diffusion: Enriching Descriptions with MLLMs for Enhanced Medical Image Generation](https://arxiv.org/abs/2506.23641)
*Peng Huang,Junhu Fu,Bowen Guo,Zeju Li,Yuanyuan Wang,Yi Guo*

Main category: cs.CV

TL;DR: VAP-Diffusion利用多模态大语言模型（MLLMs）的外部知识，通过视觉属性提示生成更真实多样的医学图像。


<details>
  <summary>Details</summary>
Motivation: 医学图像的生成需要丰富的属性信息，但详细描述通常难以获取。

Method: 设计基于Chain-of-Thoughts的提示从MLLMs获取描述，并提出原型条件机制增强生成器的鲁棒性。

Result: 在四种数据集上的实验验证了VAP-Diffusion的有效性。

Conclusion: VAP-Diffusion通过外部知识和创新机制提升了医学图像生成的质量和多样性。

Abstract: As the appearance of medical images is influenced by multiple underlying
factors, generative models require rich attribute information beyond labels to
produce realistic and diverse images. For instance, generating an image of skin
lesion with specific patterns demands descriptions that go beyond diagnosis,
such as shape, size, texture, and color. However, such detailed descriptions
are not always accessible. To address this, we explore a framework, termed
Visual Attribute Prompts (VAP)-Diffusion, to leverage external knowledge from
pre-trained Multi-modal Large Language Models (MLLMs) to improve the quality
and diversity of medical image generation. First, to derive descriptions from
MLLMs without hallucination, we design a series of prompts following
Chain-of-Thoughts for common medical imaging tasks, including dermatologic,
colorectal, and chest X-ray images. Generated descriptions are utilized during
training and stored across different categories. During testing, descriptions
are randomly retrieved from the corresponding category for inference. Moreover,
to make the generator robust to unseen combination of descriptions at the test
time, we propose a Prototype Condition Mechanism that restricts test embeddings
to be similar to those from training. Experiments on three common types of
medical imaging across four datasets verify the effectiveness of VAP-Diffusion.

</details>


### [178] [MReg: A Novel Regression Model with MoE-based Video Feature Mining for Mitral Regurgitation Diagnosis](https://arxiv.org/abs/2506.23648)
*Zhe Liu,Yuhao Huang,Lian Liu,Chengrui Zhang,Haotian Lin,Tong Han,Zhiyuan Zhu,Yanlin Chen,Yuerui Chen,Dong Ni,Zhongshan Gou,Xin Yang*

Main category: cs.CV

TL;DR: 提出了一种基于四腔心彩色多普勒超声视频的自动化二尖瓣反流诊断模型（MReg），通过回归任务和特征选择机制提高诊断准确性和临床适用性。


<details>
  <summary>Details</summary>
Motivation: 现有智能诊断方法常与临床工作流不符，导致准确性和可解释性不足，需开发更贴合临床现实的自动化模型。

Method: 将二尖瓣反流诊断建模为回归任务，设计特征选择与放大机制模拟超声医师逻辑，并引入特征总结模块增强分类能力。

Result: 在大规模内部数据集上验证，MReg在诊断性能上优于其他弱监督和监督学习方法。

Conclusion: MReg通过回归任务和特征优化机制，显著提升了二尖瓣反流诊断的准确性和临床适用性。

Abstract: Color Doppler echocardiography is a crucial tool for diagnosing mitral
regurgitation (MR). Recent studies have explored intelligent methods for MR
diagnosis to minimize user dependence and improve accuracy. However, these
approaches often fail to align with clinical workflow and may lead to
suboptimal accuracy and interpretability. In this study, we introduce an
automated MR diagnosis model (MReg) developed on the 4-chamber cardiac color
Doppler echocardiography video (A4C-CDV). It follows comprehensive feature
mining strategies to detect MR and assess its severity, considering clinical
realities. Our contribution is threefold. First, we formulate the MR diagnosis
as a regression task to capture the continuity and ordinal relationships
between categories. Second, we design a feature selection and amplification
mechanism to imitate the sonographer's diagnostic logic for accurate MR
grading. Third, inspired by the Mixture-of-Experts concept, we introduce a
feature summary module to extract the category-level features, enhancing the
representational capacity for more accurate grading. We trained and evaluated
our proposed MReg on a large in-house A4C-CDV dataset comprising 1868 cases
with three graded regurgitation labels. Compared to other weakly supervised
video anomaly detection and supervised classification methods, MReg
demonstrated superior performance in MR diagnosis. Our code is available at:
https://github.com/cskdstz/MReg.

</details>


### [179] [Towards Markerless Intraoperative Tracking of Deformable Spine Tissue](https://arxiv.org/abs/2506.23657)
*Connor Daly,Elettra Marconi,Marco Riva,Jinendra Ekanayake,Daniel S. Elson,Ferdinando Rodriguez y Baena*

Main category: cs.CV

TL;DR: 论文介绍了首个脊柱手术临床RGB-D数据集，开发了SpineAlign系统用于捕捉术前与术中脊柱状态变形，并提出了用于分割和配准的多任务框架CorrespondNet。


<details>
  <summary>Details</summary>
Motivation: 减少手术时间和复杂性，通过无标记跟踪替代骨安装设备，推动RGB-D成像在脊柱手术中的应用。

Method: 引入临床RGB-D数据集，开发SpineAlign系统，训练术中分割网络，提出多任务框架CorrespondNet。

Result: 成功开发了用于脊柱状态变形捕捉的系统及配准关键区域预测的多任务框架。

Conclusion: 该研究为脊柱手术中的无标记跟踪提供了实用工具，具有临床转化潜力。

Abstract: Consumer-grade RGB-D imaging for intraoperative orthopedic tissue tracking is
a promising method with high translational potential. Unlike bone-mounted
tracking devices, markerless tracking can reduce operating time and complexity.
However, its use has been limited to cadaveric studies. This paper introduces
the first real-world clinical RGB-D dataset for spine surgery and develops
SpineAlign, a system for capturing deformation between preoperative and
intraoperative spine states. We also present an intraoperative segmentation
network trained on this data and introduce CorrespondNet, a multi-task
framework for predicting key regions for registration in both intraoperative
and preoperative scenes.

</details>


### [180] [Partial Forward Blocking: A Novel Data Pruning Paradigm for Lossless Training Acceleration](https://arxiv.org/abs/2506.23674)
*Dongyue Wu,Zilin Guo,Jialong Zuo,Nong Sang,Changxin Gao*

Main category: cs.CV

TL;DR: PFB是一种无损训练加速框架，通过浅层特征评估样本重要性并动态剪枝，显著减少计算开销，无需代理模型或额外反向传播。


<details>
  <summary>Details</summary>
Motivation: 解决现有数据剪枝方法因依赖梯度或代理模型而带来的高计算成本问题。

Method: 提出Partial Forward Blocking (PFB)，基于浅层特征动态评估样本重要性并剪枝，结合概率密度指标和自适应分布估计模块。

Result: 在ImageNet上，PFB在剪枝40%数据时，准确率提升0.5%，训练时间减少33%。

Conclusion: PFB在性能和速度上显著优于现有方法，为高效训练提供了新思路。

Abstract: The ever-growing size of training datasets enhances the generalization
capability of modern machine learning models but also incurs exorbitant
computational costs. Existing data pruning approaches aim to accelerate
training by removing those less important samples. However, they often rely on
gradients or proxy models, leading to prohibitive additional costs of gradient
back-propagation and proxy model training. In this paper, we propose Partial
Forward Blocking (PFB), a novel framework for lossless training acceleration.
The efficiency of PFB stems from its unique adaptive pruning pipeline: sample
importance is assessed based on features extracted from the shallow layers of
the target model. Less important samples are then pruned, allowing only the
retained ones to proceed with the subsequent forward pass and loss
back-propagation. This mechanism significantly reduces the computational
overhead of deep-layer forward passes and back-propagation for pruned samples,
while also eliminating the need for auxiliary backward computations and proxy
model training. Moreover, PFB introduces probability density as an indicator of
sample importance. Combined with an adaptive distribution estimation module,
our method dynamically prioritizes relatively rare samples, aligning with the
constantly evolving training state. Extensive experiments demonstrate the
significant superiority of PFB in performance and speed. On ImageNet, PFB
achieves a 0.5% accuracy improvement and 33% training time reduction with 40%
data pruned.

</details>


### [181] [Pruning by Block Benefit: Exploring the Properties of Vision Transformer Blocks during Domain Adaptation](https://arxiv.org/abs/2506.23675)
*Patrick Glandorf,Bodo Rosenhahn*

Main category: cs.CV

TL;DR: 论文提出了一种名为P3B的剪枝方法，通过块级贡献全局分配参数资源，解决传统剪枝在未见数据域中的性能损失问题。


<details>
  <summary>Details</summary>
Motivation: Vision Transformer计算成本高，传统剪枝方法在未见数据域中性能不佳，导致资源分配不优。

Method: 提出P3B方法，基于块级贡献全局分配参数资源，保留关键组件并减少低影响组件的参数分配。

Result: P3B在高稀疏度（70%参数减少）下仅损失0.64%准确率，在迁移学习任务中表现突出。

Conclusion: P3B是一种先进的剪枝方法，尤其在资源受限硬件上表现优异。

Abstract: Vision Transformer have set new benchmarks in several tasks, but these models
come with the lack of high computational costs which makes them impractical for
resource limited hardware. Network pruning reduces the computational complexity
by removing less important operations while maintaining performance. However,
pruning a model on an unseen data domain, leads to a misevaluation of weight
significance, resulting in suboptimal resource assignment. In this work, we
find that task-sensitive layers initially fail to improve the feature
representation on downstream tasks, leading to performance loss for early
pruning decisions. To address this problem, we introduce Pruning by Block
Benefit (P3B), a pruning method that utilizes the relative contribution on
block level to globally assign parameter resources. P3B identifies low-impact
components to reduce parameter allocation while preserving critical ones.
Classical pruning mask optimization struggles to reactivate zero-mask-elements.
In contrast, P3B sets a layerwise keep ratio based on global performance
metrics, ensuring the reactivation of late-converging blocks. We show in
extensive experiments that P3B is a state of the art pruning method with most
noticeable gains in transfer learning tasks. Notably, P3B is able to conserve
high performance, even in high sparsity regimes of 70% parameter reduction
while only losing 0.64% in accuracy.

</details>


### [182] [A Unified Framework for Stealthy Adversarial Generation via Latent Optimization and Transferability Enhancement](https://arxiv.org/abs/2506.23676)
*Gaozheng Pei,Ke Ma,Dongpeng Zhang,Chengzhi Sun,Qianqian Xu,Qingming Huang*

Main category: cs.CV

TL;DR: 提出了一种统一框架，将传统对抗样本迁移增强策略融入基于扩散模型的图像编辑方法，以提升其在更广泛下游任务中的适用性。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像生成方面强大，但在对抗样本生成中难以泛化到传统图像分类以外的任务（如Deepfake检测），且传统迁移增强策略难以适配。

Method: 开发了一个统一框架，将传统迁移增强策略整合到基于扩散模型的对抗样本生成中。

Result: 方法在ACM MM25竞赛中获胜，验证了其有效性。

Conclusion: 该框架成功解决了扩散模型在对抗样本生成中的泛化和迁移性问题。

Abstract: Due to their powerful image generation capabilities, diffusion-based
adversarial example generation methods through image editing are rapidly
gaining popularity. However, due to reliance on the discriminative capability
of the diffusion model, these diffusion-based methods often struggle to
generalize beyond conventional image classification tasks, such as in Deepfake
detection. Moreover, traditional strategies for enhancing adversarial example
transferability are challenging to adapt to these methods. To address these
challenges, we propose a unified framework that seamlessly incorporates
traditional transferability enhancement strategies into diffusion model-based
adversarial example generation via image editing, enabling their application
across a wider range of downstream tasks. Our method won first place in the
"1st Adversarial Attacks on Deepfake Detectors: A Challenge in the Era of
AI-Generated Media" competition at ACM MM25, which validates the effectiveness
of our approach.

</details>


### [183] [SynMotion: Semantic-Visual Adaptation for Motion Customized Video Generation](https://arxiv.org/abs/2506.23690)
*Shuai Tan,Biao Gong,Yujie Wei,Shiwei Zhang,Zhuoxin Liu,Dandan Zheng,Jingdong Chen,Yan Wang,Hao Ouyang,Kecheng Zheng,Yujun Shen*

Main category: cs.CV

TL;DR: SynMotion提出了一种结合语义引导和视觉适应的运动定制视频生成模型，通过双嵌入语义理解机制和参数高效的运动适配器，提升了运动的保真度和时间一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅关注语义对齐或视觉表示，导致运动复杂性和语义混淆的问题。

Method: 引入双嵌入语义理解机制和运动适配器，交替优化主题和运动嵌入，并使用SPV数据集。

Result: 在T2V和I2V设置中，SynMotion优于现有基线。

Conclusion: SynMotion有效平衡了语义和视觉表示，提升了运动定制视频生成的质量。

Abstract: Diffusion-based video motion customization facilitates the acquisition of
human motion representations from a few video samples, while achieving
arbitrary subjects transfer through precise textual conditioning. Existing
approaches often rely on semantic-level alignment, expecting the model to learn
new motion concepts and combine them with other entities (e.g., ''cats'' or
''dogs'') to produce visually appealing results. However, video data involve
complex spatio-temporal patterns, and focusing solely on semantics cause the
model to overlook the visual complexity of motion. Conversely, tuning only the
visual representation leads to semantic confusion in representing the intended
action. To address these limitations, we propose SynMotion, a new
motion-customized video generation model that jointly leverages semantic
guidance and visual adaptation. At the semantic level, we introduce the
dual-embedding semantic comprehension mechanism which disentangles subject and
motion representations, allowing the model to learn customized motion features
while preserving its generative capabilities for diverse subjects. At the
visual level, we integrate parameter-efficient motion adapters into a
pre-trained video generation model to enhance motion fidelity and temporal
coherence. Furthermore, we introduce a new embedding-specific training strategy
which \textbf{alternately optimizes} subject and motion embeddings, supported
by the manually constructed Subject Prior Video (SPV) training dataset. This
strategy promotes motion specificity while preserving generalization across
diverse subjects. Lastly, we introduce MotionBench, a newly curated benchmark
with diverse motion patterns. Experimental results across both T2V and I2V
settings demonstrate that \method outperforms existing baselines. Project page:
https://lucaria-academy.github.io/SynMotion/

</details>


### [184] [Single Image Test-Time Adaptation via Multi-View Co-Training](https://arxiv.org/abs/2506.23705)
*Smriti Joshi,Richard Osuala,Lidia Garrucho,Kaisar Kushibar,Dimitri Kessler,Oliver Diaz,Karim Lekadir*

Main category: cs.CV

TL;DR: 提出了一种基于补丁的多视图协同训练方法，用于单图像测试时适应，解决了医疗场景中实时推理的需求。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖大数据集且难以处理医疗场景中的实时需求，同时未能充分利用医学影像的体数据特性。

Method: 通过不确定性引导的自训练实现特征和预测一致性，仅需单张测试图像即可完成目标域的体积分割。

Result: 在三个公开的乳腺MRI数据集上验证，性能接近监督基准，平均Dice系数提升3.75%。

Conclusion: 该方法在医疗影像分割中表现出色，代码公开且易于集成到nnUNet框架。

Abstract: Test-time adaptation enables a trained model to adjust to a new domain during
inference, making it particularly valuable in clinical settings where such
on-the-fly adaptation is required. However, existing techniques depend on large
target domain datasets, which are often impractical and unavailable in medical
scenarios that demand per-patient, real-time inference. Moreover, current
methods commonly focus on two-dimensional images, failing to leverage the
volumetric richness of medical imaging data. Bridging this gap, we propose a
Patch-Based Multi-View Co-Training method for Single Image Test-Time
adaptation. Our method enforces feature and prediction consistency through
uncertainty-guided self-training, enabling effective volumetric segmentation in
the target domain with only a single test-time image. Validated on three
publicly available breast magnetic resonance imaging datasets for tumor
segmentation, our method achieves performance close to the upper bound
supervised benchmark while also outperforming all existing state-of-the-art
methods, on average by a Dice Similarity Coefficient of 3.75%. We publicly
share our accessible codebase, readily integrable with the popular nnUNet
framework, at https://github.com/smriti-joshi/muvi.git.

</details>


### [185] [Subjective Camera: Bridging Human Cognition and Visual Reconstruction through Sequence-Aware Sketch-Guided Diffusion](https://arxiv.org/abs/2506.23711)
*Haoyang Chen,Dongfang Sun,Caoyuan Ma,Shiqin Wang,Kewei Zhang,Zheng Wang,Zhixiang Wang*

Main category: cs.CV

TL;DR: 提出Subjective Camera，通过结合语言描述和渐进草图，将主观感知转化为逼真图像，解决了语言模糊和草图抽象的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在用户主观输入偏差、草图与3D先验的模态差异及草图质量敏感性问题，需要资源密集型调整或高精度草图。

Method: 采用概念序列生成，通过文本奖励优化建立外观先验，并利用序列感知解耦生成和潜在优化，无需训练即可适应主观期望。

Result: 在多样数据集上评估，实现了语义和空间一致性的最先进性能。

Conclusion: 该框架有效解决了现有挑战，支持使用粗糙草图且无需艺术专业知识。

Abstract: We propose Subjective Camera, a human-as-imaging-device paradigm that
reconstructs real-world scenes from mental impressions through synergistic use
of verbal descriptions and progressive rough sketches. This approach overcomes
dual limitations of language ambiguity and sketch abstraction by treating the
user's drawing sequence as priors, effectively translating subjective
perceptual expectations into photorealistic images.
  Existing approaches face three fundamental barriers: (1) user-specific
subjective input biases, (2) huge modality gap between planar sketch and 3D
priors in diffusion, and (3) sketch quality-sensitive performance degradation.
Current solutions either demand resource-intensive model adaptation or impose
impractical requirements on sketch precision.
  Our framework addresses these challenges through concept-sequential
generation. (1) We establish robust appearance priors through text-reward
optimization, and then implement sequence-aware disentangled generation that
processes concepts in sketching order; these steps accommodate user-specific
subjective expectation in a train-free way. (2) We employ latent optimization
that effectively bridges the modality gap between planar sketches and 3D priors
in diffusion. (3) Our hierarchical reward-guided framework enables the use of
rough sketches without demanding artistic expertise. Comprehensive evaluation
across diverse datasets demonstrates that our approach achieves
state-of-the-art performance in maintaining both semantic and spatial
coherence.

</details>


### [186] [Towards an Automated Multimodal Approach for Video Summarization: Building a Bridge Between Text, Audio and Facial Cue-Based Summarization](https://arxiv.org/abs/2506.23714)
*Md Moinul Islam,Sofoklis Kakouros,Janne Heikkilä,Mourad Oussalah*

Main category: cs.CV

TL;DR: 本文提出了一种行为感知的多模态视频摘要框架，整合文本、音频和视觉线索生成时间戳对齐的摘要，显著提升了传统方法的性能。


<details>
  <summary>Details</summary>
Motivation: 随着视频内容在教育、职业和社交领域的增加，需要超越传统单模态方法的有效摘要技术。

Method: 通过提取韵律特征、文本线索和视觉指标，识别语义和情感重要时刻，并利用跨模态强调的“奖励词”提升摘要的语义相关性和表达清晰度。

Result: 实验结果显示，在文本和视频评估指标上均显著优于传统方法，如ROUGE-1从0.4769提升至0.7929，BERTScore从0.9152提升至0.9536，视频F1分数提升近23%。

Conclusion: 多模态整合在生成全面且行为感知的视频摘要方面具有巨大潜力。

Abstract: The increasing volume of video content in educational, professional, and
social domains necessitates effective summarization techniques that go beyond
traditional unimodal approaches. This paper proposes a behaviour-aware
multimodal video summarization framework that integrates textual, audio, and
visual cues to generate timestamp-aligned summaries. By extracting prosodic
features, textual cues and visual indicators, the framework identifies
semantically and emotionally important moments. A key contribution is the
identification of bonus words, which are terms emphasized across multiple
modalities and used to improve the semantic relevance and expressive clarity of
the summaries. The approach is evaluated against pseudo-ground truth (pGT)
summaries generated using LLM-based extractive method. Experimental results
demonstrate significant improvements over traditional extractive method, such
as the Edmundson method, in both text and video-based evaluation metrics.
Text-based metrics show ROUGE-1 increasing from 0.4769 to 0.7929 and BERTScore
from 0.9152 to 0.9536, while in video-based evaluation, our proposed framework
improves F1-Score by almost 23%. The findings underscore the potential of
multimodal integration in producing comprehensive and behaviourally informed
video summaries.

</details>


### [187] [When Small Guides Large: Cross-Model Co-Learning for Test-Time Adaptation](https://arxiv.org/abs/2506.23724)
*Chang'an Yi,Xiaohui Deng,Guohao Chen,Yan Zhou,Qinghua Lu,Shuaicheng Niu*

Main category: cs.CV

TL;DR: 本文提出了一种跨模型协同学习框架COCA，用于测试时适应（TTA），通过整合不同模型的互补知识，显著提升了模型的适应性能。


<details>
  <summary>Details</summary>
Motivation: 研究跨模型知识如何影响TTA过程，发现不同模型在无监督在线设置下可以提供互补的自信知识。

Method: 提出COCA框架，包括协同适应（整合互补知识）和自适应（增强模型独特优势）两种策略。

Result: 实验表明，COCA显著提升了现有方法的性能，例如将ViT-Base在ImageNet-C上的平均适应准确率从51.7%提高到64.5%。

Conclusion: COCA是一种有效的跨模型协同学习框架，可作为即插即用模块提升TTA性能。

Abstract: Test-time Adaptation (TTA) adapts a given model to testing domain data with
potential domain shifts through online unsupervised learning, yielding
impressive performance. However, to date, existing TTA methods primarily focus
on single-model adaptation. In this work, we investigate an intriguing
question: how does cross-model knowledge influence the TTA process? Our
findings reveal that, in TTA's unsupervised online setting, each model can
provide complementary, confident knowledge to the others, even when there are
substantial differences in model size. For instance, a smaller model like
MobileViT (10.6M parameters) can effectively guide a larger model like ViT-Base
(86.6M parameters). In light of this, we propose COCA, a Cross-Model
Co-Learning framework for TTA, which mainly consists of two main strategies. 1)
Co-adaptation adaptively integrates complementary knowledge from other models
throughout the TTA process, reducing individual model biases. 2)
Self-adaptation enhances each model's unique strengths via unsupervised
learning, enabling diverse adaptation to the target domain. Extensive
experiments show that COCA, which can also serve as a plug-and-play module,
significantly boosts existing SOTAs, on models with various sizes--including
ResNets, ViTs, and Mobile-ViTs--via cross-model co-learned TTA. For example,
with Mobile-ViT's guidance, COCA raises ViT-Base's average adaptation accuracy
on ImageNet-C from 51.7% to 64.5%. The code is publicly available at
https://github.com/ycarobot/COCA.

</details>


### [188] [Proteus-ID: ID-Consistent and Motion-Coherent Video Customization](https://arxiv.org/abs/2506.23729)
*Guiyu Zhang,Chen Shi,Zijian Jiang,Xunzhi Xiang,Jingjing Qian,Shaoshuai Shi,Li Jiang*

Main category: cs.CV

TL;DR: Proteus-ID是一个基于扩散的框架，用于身份一致和运动连贯的视频定制，通过多模态身份融合和时间感知身份注入解决身份一致性和运动自然性问题。


<details>
  <summary>Details</summary>
Motivation: 视频身份定制任务面临身份一致性和运动自然性的挑战，需要一种新方法来同时满足这两点。

Method: 提出MIF模块统一视觉和文本线索，TAII机制动态调节身份条件，AML策略通过光流增强运动真实性。

Result: Proteus-ID在身份保留、文本对齐和运动质量上优于现有方法。

Conclusion: Proteus-ID为视频身份定制设立了新基准，代码和数据已公开。

Abstract: Video identity customization seeks to synthesize realistic, temporally
coherent videos of a specific subject, given a single reference image and a
text prompt. This task presents two core challenges: (1) maintaining identity
consistency while aligning with the described appearance and actions, and (2)
generating natural, fluid motion without unrealistic stiffness. To address
these challenges, we introduce Proteus-ID, a novel diffusion-based framework
for identity-consistent and motion-coherent video customization. First, we
propose a Multimodal Identity Fusion (MIF) module that unifies visual and
textual cues into a joint identity representation using a Q-Former, providing
coherent guidance to the diffusion model and eliminating modality imbalance.
Second, we present a Time-Aware Identity Injection (TAII) mechanism that
dynamically modulates identity conditioning across denoising steps, improving
fine-detail reconstruction. Third, we propose Adaptive Motion Learning (AML), a
self-supervised strategy that reweights the training loss based on
optical-flow-derived motion heatmaps, enhancing motion realism without
requiring additional inputs. To support this task, we construct Proteus-Bench,
a high-quality dataset comprising 200K curated clips for training and 150
individuals from diverse professions and ethnicities for evaluation. Extensive
experiments demonstrate that Proteus-ID outperforms prior methods in identity
preservation, text alignment, and motion quality, establishing a new benchmark
for video identity customization. Codes and data are publicly available at
https://grenoble-zhang.github.io/Proteus-ID/.

</details>


### [189] [Can We Challenge Open-Vocabulary Object Detectors with Generated Content in Street Scenes?](https://arxiv.org/abs/2506.23751)
*Annika Mütze,Sadia Ilyas,Christian Dörpelkus,Matthias Rottmann*

Main category: cs.CV

TL;DR: 该论文探讨了通过合成数据挑战开放词汇目标检测器的局限性，发现其性能依赖于对象位置而非语义。


<details>
  <summary>Details</summary>
Motivation: 研究开放词汇目标检测器在安全关键应用中的局限性，缺乏对其泛化能力的严格评估。

Method: 设计两个自动化流程，使用稳定扩散技术生成多样化的合成数据，评估和比较多种检测器。

Result: 合成数据能挑战检测器，发现其性能依赖于对象位置而非语义。

Conclusion: 提供了一种系统性挑战开放词汇模型的方法，并为改进模型数据采集提供了见解。

Abstract: Open-vocabulary object detectors such as Grounding DINO are trained on vast
and diverse data, achieving remarkable performance on challenging datasets. Due
to that, it is unclear where to find their limitations, which is of major
concern when using in safety-critical applications. Real-world data does not
provide sufficient control, required for a rigorous evaluation of model
generalization. In contrast, synthetically generated data allows to
systematically explore the boundaries of model competence/generalization. In
this work, we address two research questions: 1) Can we challenge
open-vocabulary object detectors with generated image content? 2) Can we find
systematic failure modes of those models? To address these questions, we design
two automated pipelines using stable diffusion to inpaint unusual objects with
high diversity in semantics, by sampling multiple substantives from WordNet and
ChatGPT. On the synthetically generated data, we evaluate and compare multiple
open-vocabulary object detectors as well as a classical object detector. The
synthetic data is derived from two real-world datasets, namely LostAndFound, a
challenging out-of-distribution (OOD) detection benchmark, and the NuImages
dataset. Our results indicate that inpainting can challenge open-vocabulary
object detectors in terms of overlooking objects. Additionally, we find a
strong dependence of open-vocabulary models on object location, rather than on
object semantics. This provides a systematic approach to challenge
open-vocabulary models and gives valuable insights on how data could be
acquired to effectively improve these models.

</details>


### [190] [Visual Textualization for Image Prompted Object Detection](https://arxiv.org/abs/2506.23785)
*Yongjian Wu,Yang Zhou,Jiya Saiyin,Bingzheng Wei,Yan Xu*

Main category: cs.CV

TL;DR: VisTex-OVLM是一种通过视觉文本化增强对象级视觉语言模型（OVLM）检测罕见类别能力的新方法，同时保持其预训练的对象-文本对齐。


<details>
  <summary>Details</summary>
Motivation: 解决OVLM在检测难以用文本描述且预训练数据中罕见的类别时的局限性。

Method: 利用多尺度文本化块和多阶段融合策略，将视觉样本信息转化为文本特征空间中的视觉标记，指导OVLM。

Result: 在开放集数据集和少样本基准测试（PASCAL VOC和MSCOCO）上表现优异，达到SOTA。

Conclusion: VisTex-OVLM在不改变OVLM架构的情况下，显著提升了其在少样本场景中的性能。

Abstract: We propose VisTex-OVLM, a novel image prompted object detection method that
introduces visual textualization -- a process that projects a few visual
exemplars into the text feature space to enhance Object-level Vision-Language
Models' (OVLMs) capability in detecting rare categories that are difficult to
describe textually and nearly absent from their pre-training data, while
preserving their pre-trained object-text alignment. Specifically, VisTex-OVLM
leverages multi-scale textualizing blocks and a multi-stage fusion strategy to
integrate visual information from visual exemplars, generating textualized
visual tokens that effectively guide OVLMs alongside text prompts. Unlike
previous methods, our method maintains the original architecture of OVLM,
maintaining its generalization capabilities while enhancing performance in
few-shot settings. VisTex-OVLM demonstrates superior performance across
open-set datasets which have minimal overlap with OVLM's pre-training data and
achieves state-of-the-art results on few-shot benchmarks PASCAL VOC and MSCOCO.
The code will be released at https://github.com/WitGotFlg/VisTex-OVLM.

</details>


### [191] [Controllable Reference-Based Real-World Remote Sensing Image Super-Resolution with Generative Diffusion Priors](https://arxiv.org/abs/2506.23801)
*Ce Wang,Wanjie Sun*

Main category: cs.CV

TL;DR: 论文提出了一种名为CRefDiff的新型可控参考扩散模型，用于解决遥感图像超分辨率中的实际挑战，如分辨率差距和地表覆盖变化。


<details>
  <summary>Details</summary>
Motivation: 现有参考超分辨率方法在真实场景中表现不佳，存在生成不足或过度依赖参考图像的问题。

Method: 基于预训练的Stable Diffusion模型，引入双分支融合机制自适应整合参考图像的局部和全局信息，并提出Better Start策略加速推理。

Result: 在Real-RefRSSRD数据集上，CRefDiff在多项指标上达到最优，并提升了下游任务性能。

Conclusion: CRefDiff通过可控参考和高效推理，显著提升了遥感图像超分辨率的实用性和灵活性。

Abstract: Super-resolution (SR) techniques can enhance the spatial resolution of remote
sensing images by utilizing low-resolution (LR) images to reconstruct
high-resolution (HR) images, enabling more efficient large-scale earth
observation applications. While single-image super-resolution (SISR) methods
have shown progress, reference-based super-resolution (RefSR) offers superior
performance by incorporating historical HR images alongside current LR
observations. However, existing RefSR methods struggle with real-world
complexities, such as cross-sensor resolution gap and significant land cover
changes, often leading to under-generation or over-reliance on reference image.
To address these challenges, we propose CRefDiff, a novel controllable
reference-based diffusion model for real-world remote sensing image SR. To
address the under-generation problem, CRefDiff is built upon the pretrained
Stable Diffusion model, leveraging its powerful generative prior to produce
accurate structures and textures. To mitigate over-reliance on the reference,
we introduce a dual-branch fusion mechanism that adaptively integrates both
local and global information from the reference image. Moreover, this novel
dual-branch design enables reference strength control during inference,
enhancing interactivity and flexibility of the model. Finally, a strategy named
Better Start is proposed to significantly reduce the number of denoising steps,
thereby accelerating the inference process. To support further research, we
introduce Real-RefRSSRD, a new real-world RefSR dataset for remote sensing
images, consisting of HR NAIP and LR Sentinel-2 image pairs with diverse land
cover changes and significant temporal gaps. Extensive experiments on
Real-RefRSSRD show that CRefDiff achieves state-of-the-art performance across
various metrics and improves downstream tasks such as scene classification and
semantic segmentation.

</details>


### [192] [Towards Initialization-free Calibrated Bundle Adjustment](https://arxiv.org/abs/2506.23808)
*Carl Olsson,Amanda Nilsson*

Main category: cs.CV

TL;DR: 提出一种利用已知相机标定的方法，通过引入相对旋转估计，实现无初始化校准SfM，生成接近度量精度的重建。


<details>
  <summary>Details</summary>
Motivation: 传统无初始化BA方法因缺乏相机标定信息，仅能生成射影变换解，且需要更多数据。本文旨在利用标定信息，实现更精确的度量重建。

Method: 引入成对相对旋转估计，结合pOSE框架，将旋转平均集成到优化过程中，确保解保持场景的度量特征。

Result: 实验表明，该方法能可靠优化目标，从随机初始解高概率收敛到全局最优，生成接近度量精度的重建。

Conclusion: 通过结合相机标定和旋转平均，本文方法实现了无初始化且高精度的SfM重建。

Abstract: A recent series of works has shown that initialization-free BA can be
achieved using pseudo Object Space Error (pOSE) as a surrogate objective. The
initial reconstruction-step optimizes an objective where all terms are
projectively invariant and it cannot incorporate knowledge of the camera
calibration. As a result, the solution is only determined up to a projective
transformation of the scene and the process requires more data for successful
reconstruction.
  In contrast, we present a method that is able to use the known camera
calibration thereby producing near metric solutions, that is, reconstructions
that are accurate up to a similarity transformation. To achieve this we
introduce pairwise relative rotation estimates that carry information about
camera calibration. These are only invariant to similarity transformations,
thus encouraging solutions that preserve metric features of the real scene. Our
method can be seen as integrating rotation averaging into the pOSE framework
striving towards initialization-free calibrated SfM.
  Our experimental evaluation shows that we are able to reliably optimize our
objective, achieving convergence to the global minimum with high probability
from random starting solutions, resulting in accurate near metric
reconstructions.

</details>


### [193] [MadCLIP: Few-shot Medical Anomaly Detection with CLIP](https://arxiv.org/abs/2506.23810)
*Mahshid Shiri,Cigdem Beyan,Vittorio Murino*

Main category: cs.CV

TL;DR: 提出了一种基于预训练CLIP模型的少样本异常检测方法，适用于医学数据的图像级和像素级异常检测，通过双分支设计和可学习文本提示提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像中少样本异常检测的挑战，避免依赖合成数据或内存库。

Method: 采用双分支设计和可学习适配器，结合SigLIP损失处理图像与文本提示的多对一关系。

Result: 在多种模态上验证了方法，性能优于现有方法，且无需合成数据或内存库。

Conclusion: 该方法在医学异常检测中表现出色，各组件均对性能有贡献，代码已开源。

Abstract: An innovative few-shot anomaly detection approach is presented, leveraging
the pre-trained CLIP model for medical data, and adapting it for both
image-level anomaly classification (AC) and pixel-level anomaly segmentation
(AS). A dual-branch design is proposed to separately capture normal and
abnormal features through learnable adapters in the CLIP vision encoder. To
improve semantic alignment, learnable text prompts are employed to link visual
features. Furthermore, SigLIP loss is applied to effectively handle the
many-to-one relationship between images and unpaired text prompts, showcasing
its adaptation in the medical field for the first time. Our approach is
validated on multiple modalities, demonstrating superior performance over
existing methods for AC and AS, in both same-dataset and cross-dataset
evaluations. Unlike prior work, it does not rely on synthetic data or memory
banks, and an ablation study confirms the contribution of each component. The
code is available at https://github.com/mahshid1998/MadCLIP.

</details>


### [194] [Interpretable Zero-Shot Learning with Locally-Aligned Vision-Language Model](https://arxiv.org/abs/2506.23822)
*Shiming Chen,Bowen Duan,Salman Khan,Fahad Shahbaz Khan*

Main category: cs.CV

TL;DR: LaZSL提出了一种基于局部视觉-语义对齐的可解释零样本学习方法，通过最优传输实现视觉区域与属性的交互，提升模型的可解释性和准确性。


<details>
  <summary>Details</summary>
Motivation: 大规模视觉语言模型（如CLIP）在零样本学习中表现出色，但缺乏可解释性。为解决这一问题，需要开发基于离散属性的可解释模型。

Method: LaZSL利用最优传输实现局部视觉特征与属性的对齐，无需额外训练即可提供可解释的相似性。

Result: 实验表明，LaZSL在可解释性、准确性和领域泛化性方面均有显著提升。

Conclusion: LaZSL为可解释零样本学习提供了一种有效解决方案，同时保持了模型的性能优势。

Abstract: Large-scale vision-language models (VLMs), such as CLIP, have achieved
remarkable success in zero-shot learning (ZSL) by leveraging large-scale
visual-text pair datasets. However, these methods often lack interpretability,
as they compute the similarity between an entire query image and the embedded
category words, making it difficult to explain their predictions. One approach
to address this issue is to develop interpretable models by integrating
language, where classifiers are built using discrete attributes, similar to
human perception. This introduces a new challenge: how to effectively align
local visual features with corresponding attributes based on pre-trained VLMs.
To tackle this, we propose LaZSL, a locally-aligned vision-language model for
interpretable ZSL. LaZSL employs local visual-semantic alignment via optimal
transport to perform interaction between visual regions and their associated
attributes, facilitating effective alignment and providing interpretable
similarity without the need for additional training. Extensive experiments
demonstrate that our method offers several advantages, including enhanced
interpretability, improved accuracy, and strong domain generalization. Codes
available at: https://github.com/shiming-chen/LaZSL.

</details>


### [195] [Flash-VStream: Efficient Real-Time Understanding for Long Video Streams](https://arxiv.org/abs/2506.23825)
*Haoji Zhang,Yiqin Wang,Yansong Tang,Yong Liu,Jiashi Feng,Xiaojie Jin*

Main category: cs.CV

TL;DR: Flash-VStream是一种高效的长视频语言模型，通过创新的Flash Memory模块显著降低推理延迟，并在多个基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有模型处理长视频效率低且难以泛化，Flash-VStream旨在解决这一问题。

Method: 设计了Flash Memory模块，包含低容量上下文记忆和高容量增强记忆，分别聚合长时信息和检索空间细节。

Result: 在EgoSchema等基准测试中表现优异，显著降低推理延迟。

Conclusion: Flash-VStream在长视频理解中实现了高效和实时响应，具有广泛应用潜力。

Abstract: Benefiting from the advances in large language models and cross-modal
alignment, existing multimodal large language models have achieved prominent
performance in image and short video understanding. However, the understanding
of long videos is still challenging, as their long-context nature results in
significant computational and memory overhead. Most existing work treats long
videos in the same way as short videos, which is inefficient for real-world
applications and hard to generalize to even longer videos. To address these
issues, we propose Flash-VStream, an efficient video language model capable of
processing extremely long videos and responding to user queries in real time.
Particularly, we design a Flash Memory module, containing a low-capacity
context memory to aggregate long-context temporal information and model the
distribution of information density, and a high-capacity augmentation memory to
retrieve detailed spatial information based on this distribution. Compared to
existing models, Flash-VStream achieves significant reductions in inference
latency. Extensive experiments on long video benchmarks and comprehensive video
benchmarks, i.e., EgoSchema, MLVU, LVBench, MVBench and Video-MME, demonstrate
the state-of-the-art performance and outstanding efficiency of our method. Code
is available at https://github.com/IVGSZ/Flash-VStream.

</details>


### [196] [Spatially Gene Expression Prediction using Dual-Scale Contrastive Learning](https://arxiv.org/abs/2506.23827)
*Mingcheng Qu,Yuncong Wu,Donglin Di,Yue Gao,Tonghua Su,Yang Song,Lei Fan*

Main category: cs.CV

TL;DR: NH2ST框架通过整合空间上下文和病理与基因模态，显著提升了基因表达预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略了复杂的空间和分子相互作用，导致无法捕捉相邻区域间的联系和跨模态关系。

Method: NH2ST采用查询分支和邻居分支处理目标区域及其邻近区域，结合交叉注意力和对比学习。

Result: 在六个数据集上表现优于现有方法，PCC指标提升超过20%。

Conclusion: NH2ST为基因表达预测提供了一种更有效的解决方案。

Abstract: Spatial transcriptomics (ST) provides crucial insights into tissue
micro-environments, but is limited to its high cost and complexity. As an
alternative, predicting gene expression from pathology whole slide images (WSI)
is gaining increasing attention. However, existing methods typically rely on
single patches or a single pathology modality, neglecting the complex spatial
and molecular interactions between target and neighboring information (e.g.,
gene co-expression). This leads to a failure in establishing connections among
adjacent regions and capturing intricate cross-modal relationships. To address
these issues, we propose NH2ST, a framework that integrates spatial context and
both pathology and gene modalities for gene expression prediction. Our model
comprises a query branch and a neighbor branch to process paired target patch
and gene data and their neighboring regions, where cross-attention and
contrastive learning are employed to capture intrinsic associations and ensure
alignments between pathology and gene expression. Extensive experiments on six
datasets demonstrate that our model consistently outperforms existing methods,
achieving over 20% in PCC metrics. Codes are available at
https://github.com/MCPathology/NH2ST

</details>


### [197] [Low-latency vision transformers via large-scale multi-head attention](https://arxiv.org/abs/2506.23832)
*Ronit D. Gross,Tal Halevi,Ella Koresh,Yarden Tzach,Ido Kanter*

Main category: cs.CV

TL;DR: 研究发现多头注意力机制（MHA）在分类任务中自发对称性破缺，通过单头性能（SHP）矩阵量化，提高了信号噪声比（SNR）和分类精度。


<details>
  <summary>Details</summary>
Motivation: 探索多头注意力机制在分类任务中的学习机制，并推广到大规模MHA（LS-MHA），以提高分类精度和减少延迟。

Method: 使用单头性能（SHP）矩阵量化多头注意力的性能，并设计不同的视觉Transformer（ViT）架构。

Result: 每个SHP矩阵包含多个单元簇，显著提高SNR和分类精度，同时通过卷积层替换减少延迟。

Conclusion: 该机制可推广至自然语言处理任务，为深度学习提供新见解。

Abstract: The emergence of spontaneous symmetry breaking among a few heads of
multi-head attention (MHA) across transformer blocks in classification tasks
was recently demonstrated through the quantification of single-nodal
performance (SNP). This finding indicates that each head focuses its attention
on a subset of labels through cooperation among its SNPs. This underlying
learning mechanism is generalized to large-scale MHA (LS-MHA) using a single
matrix value representing single-head performance (SHP), analogous to
single-filter performance in convolutional neural networks (CNNs). The results
indicate that each SHP matrix comprises multiple unit clusters such that each
label being explicitly recognized by a few heads with negligible noise. This
leads to an increased signal-to-noise ratio (SNR) along the transformer blocks,
thereby improving classification accuracy. These features give rise to several
distinct vision transformer (ViT) architectures that achieve the same accuracy
but differ in their LS-MHA structures. As a result, their soft committee yields
superior accuracy, an outcome not typically observed in CNNs which rely on
hundreds of filters. In addition, a significant reduction in latency is
achieved without affecting the accuracy by replacing the initial transformer
blocks with convolutional layers. This substitution accelerates early-stage
learning, which is then improved by subsequent transformer layers. The
extension of this learning mechanism to natural language processing tasks,
based on quantitative differences between CNNs and ViT architectures, has the
potential to yield new insights in deep learning. The findings are demonstrated
using compact convolutional transformer architectures trained on the CIFAR-100
dataset.

</details>


### [198] [PointSSIM: A novel low dimensional resolution invariant image-to-image comparison metric](https://arxiv.org/abs/2506.23833)
*Oscar Ovanger,Ragnar Hauge,Jacob Skauvold,Michael J. Pyrcz,Jo Eidsvik*

Main category: cs.CV

TL;DR: PointSSIM是一种低维度的图像比较方法，具有分辨率不变性，适用于不同分辨率的二值图像比较。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够跨分辨率比较二值图像的方法，解决现有方法在分辨率变化时的局限性。

Method: 通过标记点模式表示二值图像，提取关键特征（锚点），并使用总结向量比较图像的强度、连通性、复杂性和结构属性。

Result: PointSSIM提供了高效可靠的图像比较方法，特别适用于需要跨分辨率结构分析的应用。

Conclusion: PointSSIM是一种有效的跨分辨率二值图像比较工具，具有广泛的应用潜力。

Abstract: This paper presents PointSSIM, a novel low-dimensional image-to-image
comparison metric that is resolution invariant. Drawing inspiration from the
structural similarity index measure and mathematical morphology, PointSSIM
enables robust comparison across binary images of varying resolutions by
transforming them into marked point pattern representations. The key features
of the image, referred to as anchor points, are extracted from binary images by
identifying locally adaptive maxima from the minimal distance transform. Image
comparisons are then performed using a summary vector, capturing intensity,
connectivity, complexity, and structural attributes. Results show that this
approach provides an efficient and reliable method for image comparison,
particularly suited to applications requiring structural analysis across
different resolutions.

</details>


### [199] [Refine Any Object in Any Scene](https://arxiv.org/abs/2506.23835)
*Ziwei Chen,Ziling Liu,Zitong Huang,Mingqi Gao,Feng Zheng*

Main category: cs.CV

TL;DR: RAISE是一个3D增强框架，利用3D生成先验恢复缺失视角下的物体几何和外观，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决场景重建中物体视角缺失问题，提升对象级建模的保真度，同时保持场景级表示的准确性。

Method: 采用两阶段细化：先通过3D生成模型替换退化对象，再通过7-DOF姿态对齐和注册约束增强纠正不一致。

Result: 在挑战性基准测试中，RAISE在新视角合成和几何补全任务中显著优于现有方法。

Conclusion: RAISE成功实现了高保真度的对象级建模，同时保持场景一致性，为下游任务提供了强大支持。

Abstract: Viewpoint missing of objects is common in scene reconstruction, as camera
paths typically prioritize capturing the overall scene structure rather than
individual objects. This makes it highly challenging to achieve high-fidelity
object-level modeling while maintaining accurate scene-level representation.
Addressing this issue is critical for advancing downstream tasks requiring
detailed object understanding and appearance modeling. In this paper, we
introduce Refine Any object In any ScenE (RAISE), a novel 3D enhancement
framework that leverages 3D generative priors to recover fine-grained object
geometry and appearance under missing views. Starting from substituting
degraded objects with proxies, via a 3D generative model with strong 3D
understanding, RAISE progressively refines geometry and texture by aligning
each proxy to its degraded counterpart in 7-DOF pose, followed by correcting
spatial and appearance inconsistencies via registration-constrained
enhancement. This two-stage refinement ensures the high-fidelity geometry and
appearance of the original object in unseen views while maintaining consistency
in spatial positioning, observed geometry, and appearance. Extensive
experiments on challenging benchmarks show that RAISE significantly outperforms
state-of-the-art methods in both novel view synthesis and geometry completion
tasks. RAISE is made publicly available at https://github.com/PolySummit/RAISE.

</details>


### [200] [RGC-VQA: An Exploration Database for Robotic-Generated Video Quality Assessment](https://arxiv.org/abs/2506.23852)
*Jianing Jin,Jiangyong Ying,Huiyu Duan,Liu Yang,Sijing Wu,Yunhao Li,Yushuo Zheng,Xiongkuo Min,Guangtao Zhai*

Main category: cs.CV

TL;DR: 论文提出了机器人生成内容（RGC）的概念，并建立了首个RGC视频数据库（RGCD），用于评估现有视频质量评估（VQA）模型的性能，发现其局限性。


<details>
  <summary>Details</summary>
Motivation: 随着机器人视频在流媒体平台的普及，RGC视频的感知质量对人类-机器人交互至关重要，但目前缺乏专门的研究。

Method: 建立了包含2,100个视频的RGCD数据库，并进行了主观VQA实验，评估了11种现有VQA模型的表现。

Result: 实验结果表明，现有VQA模型在处理复杂的RGC视频时存在显著局限性。

Conclusion: 研究强调了开发RGC专用VQA模型的必要性，并公开了RGCD数据库以支持未来研究。

Abstract: As camera-equipped robotic platforms become increasingly integrated into
daily life, robotic-generated videos have begun to appear on streaming media
platforms, enabling us to envision a future where humans and robots coexist. We
innovatively propose the concept of Robotic-Generated Content (RGC) to term
these videos generated from egocentric perspective of robots. The perceptual
quality of RGC videos is critical in human-robot interaction scenarios, and RGC
videos exhibit unique distortions and visual requirements that differ markedly
from those of professionally-generated content (PGC) videos and user-generated
content (UGC) videos. However, dedicated research on quality assessment of RGC
videos is still lacking. To address this gap and to support broader robotic
applications, we establish the first Robotic-Generated Content Database (RGCD),
which contains a total of 2,100 videos drawn from three robot categories and
sourced from diverse platforms. A subjective VQA experiment is conducted
subsequently to assess human visual perception of robotic-generated videos.
Finally, we conduct a benchmark experiment to evaluate the performance of 11
state-of-the-art VQA models on our database. Experimental results reveal
significant limitations in existing VQA models when applied to complex,
robotic-generated content, highlighting a critical need for RGC-specific VQA
models. Our RGCD is publicly available at:
https://github.com/IntMeGroup/RGC-VQA.

</details>


### [201] [A Closer Look at Conditional Prompt Tuning for Vision-Language Models](https://arxiv.org/abs/2506.23856)
*Ji Zhang,Shihan Wu,Lianli Gao,Jingkuan Song,Nicu Sebe,Heng Tao Shen*

Main category: cs.CV

TL;DR: 论文提出Class-adaptive Prompt Tuning (CaPT)，通过基于文本类别信息（TCI）的动态提示解决Vision-Language Pretrained Models (VLPMs)中的Base-New Tradeoff (BNT)问题，显著提升模型在新任务上的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉图像信息（VII）的条件提示调优方法性能不佳，甚至不如随机噪声条件提示。研究发现，基于文本类别信息（TCI）的动态提示是解决BNT问题的关键。

Method: 提出CaPT方法，通过学习基于TCI的动态提示，快速适应新类别。CaPT可作为插件提升现有无条件提示调优方案的性能。

Result: 在11个数据集上的实验表明，CaPT显著提升了五种无条件提示调优基线的性能，且计算成本几乎不增加。结合DePT框架的DeCaPT方法在性能上优于现有最佳条件提示调优方案3.49%。

Conclusion: CaPT通过TCI条件提示有效解决了BNT问题，显著提升了VLPMs的泛化能力，且计算成本低。DeCaPT进一步提升了性能。

Abstract: Despite the great promise of Prompt Tuning (PT) in adapting large
Vision-Language Pretrained Models (VLPMs) to downstream tasks, they often
struggle to overcome the Base-New Tradeoff (BNT) dilemma: as VLPMs are better
tuned to a base task, their ability to generalize to new tasks diminishes.
Recent work on conditional PT addresses this problem by replacing static
prompts with dynamic Visual Image Information (VII)-conditioned prompts,
improving the model's generalization to new tasks to some extent. In this work,
we first identify a critical issue with existing conditional PT methods: using
VII as the "condition" of prompts yields suboptimal performance, and even
random noise-conditioned prompts can outperform the VII-conditioned
counterparts. On further analysis, we find that learning dynamic prompts
conditioned on Textual Class Information (TCI) is the key to solving the BNT
problem. Motivated by this, we then propose Class-adaptive Prompt Tuning
(CaPT), which enables fast adaptation of tuned models to new classes by
learning TCI-conditioned prompts from base classes. Remarkably, CaPT can be
used as a plugin to mitigate the BNT problem for existing unconditional PT
schemes. Extensive experiments on 11 datasets show that CaPT consistently
improves the performance of five strong unconditional PT baselines with
negligible additional computational cost. Additionally, by integrating CaPT
with our recently proposed DePT framework, we devise a new conditional PT
approach, termed DeCaPT, which outperforms the H ACC of the state-of-the-art
conditional PT scheme by 3.49%, averaged over the 11 datasets. Code:
https://github.com/Koorye/CaPT.

</details>


### [202] [VMoBA: Mixture-of-Block Attention for Video Diffusion Models](https://arxiv.org/abs/2506.23858)
*Jianzong Wu,Liang Hou,Haotian Yang,Xin Tao,Ye Tian,Pengfei Wan,Di Zhang,Yunhai Tong*

Main category: cs.CV

TL;DR: 论文提出了一种名为VMoBA的新型稀疏注意力机制，专门用于视频扩散模型（VDMs），通过动态适应时空注意力模式显著提升了训练和推理效率。


<details>
  <summary>Details</summary>
Motivation: 全注意力机制的二次复杂度限制了视频扩散模型生成长时长、高分辨率视频的能力，而现有的稀疏注意力方法未能充分捕捉视频数据的时空特性。

Method: VMoBA基于对预训练视频变换器中注意力模式的分析，引入了层循环块分区方案、全局块选择和基于阈值的块选择三种改进。

Result: VMoBA显著提升了VDMs的训练效率（2.92x FLOPs和1.48x延迟加速），并在推理中表现出色（2.40x FLOPs和1.35x延迟加速），同时保持或超越全注意力的生成质量。

Conclusion: VMoBA是一种高效的稀疏注意力机制，适用于视频扩散模型，能够显著提升性能并保持生成质量。

Abstract: The quadratic complexity of full attention mechanisms poses a significant
bottleneck for Video Diffusion Models (VDMs) aiming to generate long-duration,
high-resolution videos. While various sparse attention methods have been
proposed, many are designed as training-free inference accelerators or do not
optimally capture the unique spatio-temporal characteristics inherent in video
data when trained natively. This paper introduces Video Mixture of Block
Attention (VMoBA), a novel sparse attention mechanism specifically adapted for
VDMs. Motivated by an in-depth analysis of attention patterns within
pre-trained video transformers, which revealed strong spatio-temporal locality,
varying query importance, and head-specific concentration levels, VMoBA
enhances the original MoBA framework with three key modifications: (1) a
layer-wise recurrent block partition scheme (1D-2D-3D) to dynamically adapt to
diverse spatio-temporal attention patterns and improve efficiency; (2) global
block selection to prioritize the most salient query-key block interactions
across an entire attention head; and (3) threshold-based block selection to
dynamically determine the number of attended blocks based on their cumulative
similarity. Extensive experiments demonstrate that VMoBA significantly
accelerates the training of VDMs on longer sequences, achieving 2.92x FLOPs and
1.48x latency speedup, while attaining comparable or even superior generation
quality to full attention. Furthermore, VMoBA exhibits competitive performance
in training-free inference, offering 2.40x FLOPs and 1.35x latency speedup for
high-res video generation.

</details>


### [203] [Puzzles: Unbounded Video-Depth Augmentation for Scalable End-to-End 3D Reconstruction](https://arxiv.org/abs/2506.23863)
*Jiahao Ma,Lei Wang,Miaomiao liu,David Ahmedt-Aristizabal,Chuong Nguyen*

Main category: cs.CV

TL;DR: 提出了一种名为Puzzles的数据增强策略，通过单张图像或视频片段生成大量高质量的姿态-深度数据，显著提升了3D重建模型的性能。


<details>
  <summary>Details</summary>
Motivation: 解决多视角3D重建中训练数据多样性和规模不足的问题。

Method: 通过模拟多样化的相机轨迹和场景几何变换，合成大量高质量训练数据。

Result: 实验表明，Puzzles显著提升了模型性能，仅需10%的原始数据即可达到与完整数据相当的精度。

Conclusion: Puzzles是一种高效的数据增强方法，能够在不改变网络架构的情况下提升3D重建性能。

Abstract: Multi-view 3D reconstruction remains a core challenge in computer vision.
Recent methods, such as DUST3R and its successors, directly regress pointmaps
from image pairs without relying on known scene geometry or camera parameters.
However, the performance of these models is constrained by the diversity and
scale of available training data. In this work, we introduce Puzzles, a data
augmentation strategy that synthesizes an unbounded volume of high-quality
posed video-depth data from a single image or video clip. By simulating diverse
camera trajectories and realistic scene geometry through targeted image
transformations, Puzzles significantly enhances data variety. Extensive
experiments show that integrating Puzzles into existing video-based 3D
reconstruction pipelines consistently boosts performance without modifying the
underlying network architecture. Notably, models trained on only ten percent of
the original data augmented with Puzzles still achieve accuracy comparable to
those trained on the full dataset. Code is available at
https://jiahao-ma.github.io/puzzles/.

</details>


### [204] [PriOr-Flow: Enhancing Primitive Panoramic Optical Flow with Orthogonal View](https://arxiv.org/abs/2506.23897)
*Longliang Liu,Miaojie Feng,Junda Cheng,Jijun Xiang,Xuan Zhu,Xin Yang*

Main category: cs.CV

TL;DR: PriOr-Flow是一种新颖的双分支框架，通过正交视图的低失真特性提升全景光流估计性能，特别是在极地区域。


<details>
  <summary>Details</summary>
Motivation: 传统基于透视的光流方法在全景投影（如ERP）中因严重失真而性能下降，尤其是在极地区域。

Method: 提出DCCL操作符联合检索原始和正交成本体积的相关信息，并设计ODDC模块迭代优化运动特征。

Result: PriOr-Flow在公开全景光流数据集上表现优异，兼容多种迭代光流方法。

Conclusion: PriOr-Flow通过双分支框架和失真补偿技术，显著提升了全景光流估计性能，为宽视场运动估计设定了新标准。

Abstract: Panoramic optical flow enables a comprehensive understanding of temporal
dynamics across wide fields of view. However, severe distortions caused by
sphere-to-plane projections, such as the equirectangular projection (ERP),
significantly degrade the performance of conventional perspective-based optical
flow methods, especially in polar regions. To address this challenge, we
propose PriOr-Flow, a novel dual-branch framework that leverages the
low-distortion nature of the orthogonal view to enhance optical flow estimation
in these regions. Specifically, we introduce the Dual-Cost Collaborative Lookup
(DCCL) operator, which jointly retrieves correlation information from both the
primitive and orthogonal cost volumes, effectively mitigating distortion noise
during cost volume construction. Furthermore, our Ortho-Driven Distortion
Compensation (ODDC) module iteratively refines motion features from both
branches, further suppressing polar distortions. Extensive experiments
demonstrate that PriOr-Flow is compatible with various perspective-based
iterative optical flow methods and consistently achieves state-of-the-art
performance on publicly available panoramic optical flow datasets, setting a
new benchmark for wide-field motion estimation. The code is publicly available
at: https://github.com/longliangLiu/PriOr-Flow.

</details>


### [205] [GroundingDINO-US-SAM: Text-Prompted Multi-Organ Segmentation in Ultrasound with LoRA-Tuned Vision-Language Models](https://arxiv.org/abs/2506.23903)
*Hamza Rasaee,Taha Koleilat,Hassan Rivaz*

Main category: cs.CV

TL;DR: 提出了一种基于提示驱动的视觉语言模型（VLM），结合Grounding DINO和SAM2，用于多器官超声图像分割，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 超声图像分割面临解剖变异性、成像协议多样性和标注数据不足的挑战，需要一种通用且准确的方法。

Method: 使用18个公共超声数据集，15个用于微调Grounding DINO（采用LoRA适应超声领域），3个用于测试未见分布的性能。

Result: 在多数已见数据集上优于UniverSeg、MedSAM等方法，在未见数据集上表现稳定，无需额外微调。

Conclusion: VLM在超声图像分析中具有潜力，减少了对大规模器官特定标注数据的依赖。

Abstract: Accurate and generalizable object segmentation in ultrasound imaging remains
a significant challenge due to anatomical variability, diverse imaging
protocols, and limited annotated data. In this study, we propose a
prompt-driven vision-language model (VLM) that integrates Grounding DINO with
SAM2 to enable object segmentation across multiple ultrasound organs. A total
of 18 public ultrasound datasets, encompassing the breast, thyroid, liver,
prostate, kidney, and paraspinal muscle, were utilized. These datasets were
divided into 15 for fine-tuning and validation of Grounding DINO using Low Rank
Adaptation (LoRA) to the ultrasound domain, and 3 were held out entirely for
testing to evaluate performance in unseen distributions. Comprehensive
experiments demonstrate that our approach outperforms state-of-the-art
segmentation methods, including UniverSeg, MedSAM, MedCLIP-SAM, BiomedParse,
and SAMUS on most seen datasets while maintaining strong performance on unseen
datasets without additional fine-tuning. These results underscore the promise
of VLMs in scalable and robust ultrasound image analysis, reducing dependence
on large, organ-specific annotated datasets. We will publish our code on
code.sonography.ai after acceptance.

</details>


### [206] [Three-dimensional end-to-end deep learning for brain MRI analysis](https://arxiv.org/abs/2506.23916)
*Radhika Juglan,Marta Ligero,Zunamys I. Carrero,Asier Rabasco,Tim Lenz,Leo Misera,Gregory Patrick Veldhuizen,Paul Kuntke,Hagen H. Kitzler,Sven Nebelung,Daniel Truhn,Jakob Nikolas Kather*

Main category: cs.CV

TL;DR: 研究发现，在脑影像分析中，简单的卷积网络（SFCN）比复杂的注意力架构（如Swin Transformer）表现更好，具有更强的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 评估深度学习模型在不同脑影像队列中的泛化能力，尤其是年龄和性别预测任务。

Method: 比较了三种3D架构（SFCN、DenseNet、Swin Transformer）在四个独立队列（UKB、DLBS、PPMI、IXI）中的表现。

Result: SFCN在性别分类和年龄预测任务中均优于其他模型，泛化能力更强。

Conclusion: 简单的卷积网络在脑影像分析中优于复杂架构，更适合跨数据集应用。

Abstract: Deep learning (DL) methods are increasingly outperforming classical
approaches in brain imaging, yet their generalizability across diverse imaging
cohorts remains inadequately assessed. As age and sex are key neurobiological
markers in clinical neuroscience, influencing brain structure and disease risk,
this study evaluates three of the existing three-dimensional architectures,
namely Simple Fully Connected Network (SFCN), DenseNet, and Shifted Window
(Swin) Transformers, for age and sex prediction using T1-weighted MRI from four
independent cohorts: UK Biobank (UKB, n=47,390), Dallas Lifespan Brain Study
(DLBS, n=132), Parkinson's Progression Markers Initiative (PPMI, n=108 healthy
controls), and Information eXtraction from Images (IXI, n=319). We found that
SFCN consistently outperformed more complex architectures with AUC of 1.00
[1.00-1.00] in UKB (internal test set) and 0.85-0.91 in external test sets for
sex classification. For the age prediction task, SFCN demonstrated a mean
absolute error (MAE) of 2.66 (r=0.89) in UKB and 4.98-5.81 (r=0.55-0.70) across
external datasets. Pairwise DeLong and Wilcoxon signed-rank tests with
Bonferroni corrections confirmed SFCN's superiority over Swin Transformer
across most cohorts (p<0.017, for three comparisons). Explainability analysis
further demonstrates the regional consistency of model attention across cohorts
and specific to each task. Our findings reveal that simpler convolutional
networks outperform the denser and more complex attention-based DL
architectures in brain image analysis by demonstrating better generalizability
across different datasets.

</details>


### [207] [Thinking with Images for Multimodal Reasoning: Foundations, Methods, and Future Frontiers](https://arxiv.org/abs/2506.23918)
*Zhaochen Su,Peng Xia,Hangyu Guo,Zhenhua Liu,Yan Ma,Xiaoye Qu,Jiaqi Liu,Yanshu Li,Kaide Zeng,Zhengyuan Yang,Linjie Li,Yu Cheng,Heng Ji,Junxian He,Yi R.,Fung*

Main category: cs.CV

TL;DR: 论文探讨了多模态推理中的视觉动态思维范式，提出了从静态视觉输入到动态视觉工作空间的转变，并总结了该领域的关键发展阶段、方法、评估和应用。


<details>
  <summary>Details</summary>
Motivation: 解决文本链式思维（CoT）在处理视觉信息时的语义鸿沟问题，推动AI从静态视觉输入转向动态视觉思维，以更接近人类认知方式。

Method: 提出三阶段框架（外部工具探索、程序化操作、内在想象），并总结了各阶段的核心方法、评估基准和应用。

Result: 建立了视觉动态思维范式的基础原则，提供了该领域的结构化综述，并指出了未来研究方向。

Conclusion: 该研究为多模态AI的未来发展提供了清晰的路线图，目标是实现更强大且与人类认知对齐的智能系统。

Abstract: Recent progress in multimodal reasoning has been significantly advanced by
textual Chain-of-Thought (CoT), a paradigm where models conduct reasoning
within language. This text-centric approach, however, treats vision as a
static, initial context, creating a fundamental "semantic gap" between rich
perceptual data and discrete symbolic thought. Human cognition often transcends
language, utilizing vision as a dynamic mental sketchpad. A similar evolution
is now unfolding in AI, marking a fundamental paradigm shift from models that
merely think about images to those that can truly think with images. This
emerging paradigm is characterized by models leveraging visual information as
intermediate steps in their thought process, transforming vision from a passive
input into a dynamic, manipulable cognitive workspace. In this survey, we chart
this evolution of intelligence along a trajectory of increasing cognitive
autonomy, which unfolds across three key stages: from external tool
exploration, through programmatic manipulation, to intrinsic imagination. To
structure this rapidly evolving field, our survey makes four key contributions.
(1) We establish the foundational principles of the think with image paradigm
and its three-stage framework. (2) We provide a comprehensive review of the
core methods that characterize each stage of this roadmap. (3) We analyze the
critical landscape of evaluation benchmarks and transformative applications.
(4) We identify significant challenges and outline promising future directions.
By providing this structured overview, we aim to offer a clear roadmap for
future research towards more powerful and human-aligned multimodal AI.

</details>


### [208] [Evaluating the Impact of Khmer Font Types on Text Recognition](https://arxiv.org/abs/2506.23963)
*Vannkinh Nom,Souhail Bakkali,Muhammad Muzzamil Luqman,Mickael Coustaty,Jean-Marc Ogier*

Main category: cs.CV

TL;DR: 研究评估了19种高棉字体对OCR准确性的影响，发现部分字体表现优异，部分较差，强调了字体选择对高棉文本识别的重要性。


<details>
  <summary>Details</summary>
Motivation: 高棉字体多样性对复杂脚本的OCR系统带来挑战，研究旨在评估不同字体对识别准确性的影响。

Method: 使用Pytesseract对19种随机选择的高棉字体进行文本识别准确性测试。

Result: Khmer、Odor MeanChey等字体表现优异，而iSeth First、Bayon等表现较差。

Conclusion: 字体选择对高棉文本识别至关重要，研究结果为开发更鲁棒的OCR系统提供了参考。

Abstract: Text recognition is significantly influenced by font types, especially for
complex scripts like Khmer. The variety of Khmer fonts, each with its unique
character structure, presents challenges for optical character recognition
(OCR) systems. In this study, we evaluate the impact of 19 randomly selected
Khmer font types on text recognition accuracy using Pytesseract. The fonts
include Angkor, Battambang, Bayon, Bokor, Chenla, Dangrek, Freehand, Kh Kompong
Chhnang, Kh SN Kampongsom, Khmer, Khmer CN Stueng Songke, Khmer Savuth Pen,
Metal, Moul, Odor MeanChey, Preah Vihear, Siemreap, Sithi Manuss, and iSeth
First. Our comparison of OCR performance across these fonts reveals that Khmer,
Odor MeanChey, Siemreap, Sithi Manuss, and Battambang achieve high accuracy,
while iSeth First, Bayon, and Dangrek perform poorly. This study underscores
the critical importance of font selection in optimizing Khmer text recognition
and provides valuable insights for developing more robust OCR systems.

</details>


### [209] [Visual and Memory Dual Adapter for Multi-Modal Object Tracking](https://arxiv.org/abs/2506.23972)
*Boyue Xu,Ruichao Hou,Tongwei Ren,Gangshan Wu*

Main category: cs.CV

TL;DR: 提出了一种新颖的视觉与记忆双重适配器（VMDA），通过联合建模频率、空间和通道特征，以及利用记忆机制存储全局时序线索，提升了多模态跟踪的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法因未能充分利用频率和时序领域的关键线索，导致提示学习不可靠。

Method: 设计了视觉适配器和记忆适配器，前者自适应转移辅助模态的判别线索，后者存储全局时序信息并动态更新。

Result: 在RGB-热成像、RGB-深度和RGB-事件等多模态跟踪任务中取得了最先进的性能。

Conclusion: VMDA通过结合视觉和记忆适配器，显著提升了多模态跟踪的鲁棒性和判别性。

Abstract: Prompt-learning-based multi-modal trackers have achieved promising progress
by employing lightweight visual adapters to incorporate auxiliary modality
features into frozen foundation models. However, existing approaches often
struggle to learn reliable prompts due to limited exploitation of critical cues
across frequency and temporal domains. In this paper, we propose a novel visual
and memory dual adapter (VMDA) to construct more robust and discriminative
representations for multi-modal tracking. Specifically, we develop a simple but
effective visual adapter that adaptively transfers discriminative cues from
auxiliary modality to dominant modality by jointly modeling the frequency,
spatial, and channel-wise features. Additionally, we design the memory adapter
inspired by the human memory mechanism, which stores global temporal cues and
performs dynamic update and retrieval operations to ensure the consistent
propagation of reliable temporal information across video sequences. Extensive
experiments demonstrate that our method achieves state-of-the-art performance
on the various multi-modal tracking tasks, including RGB-Thermal, RGB-Depth,
and RGB-Event tracking. Code and models are available at
https://github.com/xuboyue1999/mmtrack.git.

</details>


### [210] [Toward Simple and Robust Contrastive Explanations for Image Classification by Leveraging Instance Similarity and Concept Relevance](https://arxiv.org/abs/2506.23975)
*Yuliia Kaidashova,Bettina Finzel,Ute Schmid*

Main category: cs.CV

TL;DR: 论文提出了一种基于概念的对比解释方法，用于图像分类模型，通过分析实例嵌入的相似性和概念相关性，生成解释并评估其复杂性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决分类模型为何偏好某一类别的挑战，通过对比解释提升模型的可解释性和鲁棒性。

Method: 提取概念及其相关性分数，计算相似实例的对比，评估解释复杂性和鲁棒性。

Result: 高相关性概念生成更简洁的解释，低相关性则更复杂；解释在不同图像增强下表现不同鲁棒性。

Conclusion: 研究为构建更可解释和鲁棒的AI系统提供了潜在方向。

Abstract: Understanding why a classification model prefers one class over another for
an input instance is the challenge of contrastive explanation. This work
implements concept-based contrastive explanations for image classification by
leveraging the similarity of instance embeddings and relevance of
human-understandable concepts used by a fine-tuned deep learning model. Our
approach extracts concepts with their relevance score, computes contrasts for
similar instances, and evaluates the resulting contrastive explanations based
on explanation complexity. Robustness is tested for different image
augmentations. Two research questions are addressed: (1) whether explanation
complexity varies across different relevance ranges, and (2) whether
explanation complexity remains consistent under image augmentations such as
rotation and noise. The results confirm that for our experiments higher concept
relevance leads to shorter, less complex explanations, while lower relevance
results in longer, more diffuse explanations. Additionally, explanations show
varying degrees of robustness. The discussion of these findings offers insights
into the potential of building more interpretable and robust AI systems.

</details>


### [211] [Ella: Embodied Social Agents with Lifelong Memory](https://arxiv.org/abs/2506.24019)
*Hongxin Zhang,Zheyuan Zhang,Zeyuan Wang,Zunzhe Zhang,Lixing Fang,Qinhong Zhou,Chuang Gan*

Main category: cs.CV

TL;DR: Ella是一个能够在3D开放世界中通过视觉观察和社交互动进行终身学习的社交代理，其核心是多模态记忆系统与基础模型的结合。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索如何通过结构化记忆系统和基础模型的结合，提升具身智能体的学习和社交能力。

Method: Ella采用名称中心的语义记忆和时空情景记忆的多模态记忆系统，结合基础模型进行信息检索和决策。

Result: 实验表明，Ella能够有效影响、领导和合作其他代理，展示出通过观察和社交互动学习的能力。

Conclusion: 结合结构化记忆系统与基础模型，为具身智能的发展提供了变革性潜力。

Abstract: We introduce Ella, an embodied social agent capable of lifelong learning
within a community in a 3D open world, where agents accumulate experiences and
acquire knowledge through everyday visual observations and social interactions.
At the core of Ella's capabilities is a structured, long-term multimodal memory
system that stores, updates, and retrieves information effectively. It consists
of a name-centric semantic memory for organizing acquired knowledge and a
spatiotemporal episodic memory for capturing multimodal experiences. By
integrating this lifelong memory system with foundation models, Ella retrieves
relevant information for decision-making, plans daily activities, builds social
relationships, and evolves autonomously while coexisting with other intelligent
beings in the open world. We conduct capability-oriented evaluations in a
dynamic 3D open world where 15 agents engage in social activities for days and
are assessed with a suite of unseen controlled evaluations. Experimental
results show that Ella can influence, lead, and cooperate with other agents
well to achieve goals, showcasing its ability to learn effectively through
observation and social interaction. Our findings highlight the transformative
potential of combining structured memory systems with foundation models for
advancing embodied intelligence. More videos can be found at
https://umass-embodied-agi.github.io/Ella/.

</details>


### [212] [Continual Adaptation: Environment-Conditional Parameter Generation for Object Detection in Dynamic Scenarios](https://arxiv.org/abs/2506.24063)
*Deng Li,Aming Wu,Yang Li,Yaowei Wang,Yahong Han*

Main category: cs.CV

TL;DR: 论文提出了一种新的机制，将微调过程转化为特定参数生成，通过双路径LoRA域感知适配器和条件扩散参数生成机制，提升目标检测器在持续测试时适应环境变化的能力。


<details>
  <summary>Details</summary>
Motivation: 现实环境中，目标检测器因训练和测试数据分布不一致而面临挑战，传统微调方法可能导致性能下降。

Method: 设计了双路径LoRA域感知适配器分离特征，结合条件扩散参数生成机制动态生成适配器参数，并提出类中心最优传输对齐方法减轻灾难性遗忘。

Result: 在多种持续域自适应目标检测任务中表现优异，可视化结果显示生成的参数能更好地捕捉目标信息并增强泛化能力。

Conclusion: 该方法通过参数生成和特征解耦，有效提升了目标检测器在动态环境中的适应性和泛化性能。

Abstract: In practice, environments constantly change over time and space, posing
significant challenges for object detectors trained based on a closed-set
assumption, i.e., training and test data share the same distribution. To this
end, continual test-time adaptation has attracted much attention, aiming to
improve detectors' generalization by fine-tuning a few specific parameters,
e.g., BatchNorm layers. However, based on a small number of test images,
fine-tuning certain parameters may affect the representation ability of other
fixed parameters, leading to performance degradation. Instead, we explore a new
mechanism, i.e., converting the fine-tuning process to a specific-parameter
generation. Particularly, we first design a dual-path LoRA-based domain-aware
adapter that disentangles features into domain-invariant and domain-specific
components, enabling efficient adaptation. Additionally, a conditional
diffusion-based parameter generation mechanism is presented to synthesize the
adapter's parameters based on the current environment, preventing the
optimization from getting stuck in local optima. Finally, we propose a
class-centered optimal transport alignment method to mitigate catastrophic
forgetting. Extensive experiments conducted on various continuous domain
adaptive object detection tasks demonstrate the effectiveness. Meanwhile,
visualization results show that the representation extracted by the generated
parameters can capture more object-related information and strengthen the
generalization ability.

</details>


### [213] [Imagine for Me: Creative Conceptual Blending of Real Images and Text via Blended Attention](https://arxiv.org/abs/2506.24085)
*Wonwoong Cho,Yanxia Zhang,Yan-Ying Chen,David I. Inouye*

Main category: cs.CV

TL;DR: IT-Blender是一种基于T2I扩散适配器的方法，用于自动化视觉与文本概念的混合，以增强人类创造力。


<details>
  <summary>Details</summary>
Motivation: 人类在跨模态概念混合中存在认知偏差（如设计固定），导致设计空间局部最优。IT-Blender旨在解决这一问题。

Method: 利用预训练扩散模型（SD和FLUX）混合干净参考图像和生成噪声图像的潜在表示，并结合混合注意力机制。

Result: IT-Blender在视觉与文本概念混合上大幅优于基线方法。

Conclusion: IT-Blender展示了图像生成模型在增强人类创造力方面的新应用潜力。

Abstract: Blending visual and textual concepts into a new visual concept is a unique
and powerful trait of human beings that can fuel creativity. However, in
practice, cross-modal conceptual blending for humans is prone to cognitive
biases, like design fixation, which leads to local minima in the design space.
In this paper, we propose a T2I diffusion adapter "IT-Blender" that can
automate the blending process to enhance human creativity. Prior works related
to cross-modal conceptual blending are limited in encoding a real image without
loss of details or in disentangling the image and text inputs. To address these
gaps, IT-Blender leverages pretrained diffusion models (SD and FLUX) to blend
the latent representations of a clean reference image with those of the noisy
generated image. Combined with our novel blended attention, IT-Blender encodes
the real reference image without loss of details and blends the visual concept
with the object specified by the text in a disentangled way. Our experiment
results show that IT-Blender outperforms the baselines by a large margin in
blending visual and textual concepts, shedding light on the new application of
image generative models to augment human creativity.

</details>


### [214] [MotionGPT3: Human Motion as a Second Modality](https://arxiv.org/abs/2506.24086)
*Bingfan Zhu,Biao Jiang,Sunyi Wang,Shixiang Tang,Tao Chen,Linjie Luo,Youyi Zheng,Xin Chen*

Main category: cs.CV

TL;DR: MotionGPT3是一个双模态运动-语言模型，通过分离参数处理运动建模，解决了运动与语言统一训练中的挑战，同时保持了语言智能。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态模型在统一理解和生成方面取得了进展，但运动-语言统一模型的发展仍不足。需要解决运动模态与离散表示的重建差距以及语言智能退化问题。

Method: 提出MotionGPT3，通过共享注意力机制整合运动分支，使用变分自编码器（VAE）编码运动，并通过扩散头预测运动潜在表示。

Result: 实验表明，该方法在运动理解和生成任务中表现优异，同时保持了语言能力。

Conclusion: MotionGPT3建立了自回归框架下的统一双模态运动扩散模型。

Abstract: Though recent advances in multimodal models have demonstrated strong
capabilities and opportunities in unified understanding and generation, the
development of unified motion-language models remains underexplored. To enable
such models with high-fidelity human motion, two core challenges must be
addressed. The first is the reconstruction gap between the continuous motion
modality and discrete representation in an autoregressive manner, and the
second is the degradation of language intelligence during unified training.
Inspired by the mixture of experts, we propose MotionGPT3, a bimodal
motion-language model that treats human motion as a second modality, decoupling
motion modeling via separate model parameters and enabling both effective
cross-modal interaction and efficient multimodal scaling training. To preserve
language intelligence, the text branch retains the original structure and
parameters of the pretrained language model, while a new motion branch is
integrated via a shared attention mechanism, enabling bidirectional information
flow between two modalities. We first employ a motion Variational Autoencoder
(VAE) to encode raw human motion into latent representations. Based on this
continuous latent space, the motion branch predicts motion latents directly
from intermediate hidden states using a diffusion head, bypassing discrete
tokenization. Extensive experiments show that our approach achieves competitive
performance on both motion understanding and generation tasks while preserving
strong language capabilities, establishing a unified bimodal motion diffusion
framework within an autoregressive manner.

</details>


### [215] [WaRA: Wavelet Low Rank Adaptation](https://arxiv.org/abs/2506.24092)
*Moein Heidari,Yasamin Medghalchi,Mahdi Khoursha,Reza Rezaeian,Ilker Hacihaliloglu*

Main category: cs.CV

TL;DR: WaRA是一种新型参数高效微调方法，利用小波变换分解权重更新矩阵，实现多分辨率分析，优于传统LoRA方法。


<details>
  <summary>Details</summary>
Motivation: 现有PEFT方法（如LoRA）依赖全局低秩分解，忽略了局部或多尺度结构，无法捕捉权重更新中的复杂模式。

Method: WaRA通过小波变换将权重更新矩阵分解为多分辨率表示，在频域进行低秩分解并通过逆变换重建更新。

Result: 在多种视觉任务（如图像生成、分类和语义分割）中表现优异，同时降低计算复杂度。

Conclusion: WaRA不仅适用于视觉任务，在语言任务中也表现出广泛适用性和泛化能力。

Abstract: Parameter-efficient fine-tuning (PEFT) has gained widespread adoption across
various applications. Among PEFT techniques, Low-Rank Adaptation (LoRA) and its
extensions have emerged as particularly effective, allowing efficient model
adaptation while significantly reducing computational overhead. However,
existing approaches typically rely on global low-rank factorizations, which
overlook local or multi-scale structure, failing to capture complex patterns in
the weight updates. To address this, we propose WaRA, a novel PEFT method that
leverages wavelet transforms to decompose the weight update matrix into a
multi-resolution representation. By performing low-rank factorization in the
wavelet domain and reconstructing updates through an inverse transform, WaRA
obtains compressed adaptation parameters that harness multi-resolution
analysis, enabling it to capture both coarse and fine-grained features while
providing greater flexibility and sparser representations than standard LoRA.
Through comprehensive experiments and analysis, we demonstrate that WaRA
performs superior on diverse vision tasks, including image generation,
classification, and semantic segmentation, significantly enhancing generated
image quality while reducing computational complexity. Although WaRA was
primarily designed for vision tasks, we further showcase its effectiveness in
language tasks, highlighting its broader applicability and generalizability.
The code is publicly available at
\href{GitHub}{https://github.com/moeinheidari7829/WaRA}.

</details>


### [216] [MILo: Mesh-In-the-Loop Gaussian Splatting for Detailed and Efficient Surface Reconstruction](https://arxiv.org/abs/2506.24096)
*Antoine Guédon,Diego Gomez,Nissim Maruani,Bingchen Gong,George Drettakis,Maks Ovsjanikov*

Main category: cs.CV

TL;DR: MILo是一种新型高斯泼溅框架，通过可微分地从3D高斯提取网格，解决了从体积表示到表面表示的转换问题，减少了顶点数量并保留了几何细节。


<details>
  <summary>Details</summary>
Motivation: 当前方法在从高斯泼溅中提取表面网格时存在成本高、几何细节丢失或网格过于密集的问题，限制了其在训练中捕获的几何结构的保留能力。

Method: MILo通过双向一致性框架、自适应网格提取过程和基于3D高斯的符号距离计算方法，实现了可微分的网格提取。

Result: 该方法能够以最先进的质重建完整场景，且所需的网格顶点数量比之前方法少一个数量级。

Conclusion: MILo生成的网格轻量且内部为空，适用于物理模拟或动画等下游应用。

Abstract: While recent advances in Gaussian Splatting have enabled fast reconstruction
of high-quality 3D scenes from images, extracting accurate surface meshes
remains a challenge. Current approaches extract the surface through costly
post-processing steps, resulting in the loss of fine geometric details or
requiring significant time and leading to very dense meshes with millions of
vertices. More fundamentally, the a posteriori conversion from a volumetric to
a surface representation limits the ability of the final mesh to preserve all
geometric structures captured during training. We present MILo, a novel
Gaussian Splatting framework that bridges the gap between volumetric and
surface representations by differentiably extracting a mesh from the 3D
Gaussians. We design a fully differentiable procedure that constructs the
mesh-including both vertex locations and connectivity-at every iteration
directly from the parameters of the Gaussians, which are the only quantities
optimized during training. Our method introduces three key technical
contributions: a bidirectional consistency framework ensuring both
representations-Gaussians and the extracted mesh-capture the same underlying
geometry during training; an adaptive mesh extraction process performed at each
training iteration, which uses Gaussians as differentiable pivots for Delaunay
triangulation; a novel method for computing signed distance values from the 3D
Gaussians that enables precise surface extraction while avoiding geometric
erosion. Our approach can reconstruct complete scenes, including backgrounds,
with state-of-the-art quality while requiring an order of magnitude fewer mesh
vertices than previous methods. Due to their light weight and empty interior,
our meshes are well suited for downstream applications such as physics
simulations or animation.

</details>


### [217] [DenseWorld-1M: Towards Detailed Dense Grounded Caption in the Real World](https://arxiv.org/abs/2506.24102)
*Xiangtai Li,Tao Zhang,Yanwei Li,Haobo Yuan,Shihao Chen,Yikang Zhou,Jiahao Meng,Yueyi Sun,Shilin Xu,Lu Qi,Tianheng Cheng,Yi Lin,Zilong Huang,Wenhao Huang,Jiashi Feng,Guang Shi*

Main category: cs.CV

TL;DR: 论文提出了DenseWorld-1M数据集，填补了现有标注数据集中缺乏详细描述和实体关系的空白，并通过三阶段标注流程和两个VLM模型提升了标注效率和质量。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数标注数据集缺乏视觉实体的位置和关系信息，且现有数据集在详细描述、关系和对象描述方面存在不足。

Method: 设计了三阶段标注流程（开放世界感知、详细对象描述生成、密集描述合并）和两个VLM模型（Detailed Region Caption模型和Spatial Caption Merging模型）。

Result: 实验证明DenseWorld-1M数据集在视觉语言理解、视觉定位和区域描述生成等任务中表现有效。

Conclusion: DenseWorld-1M为社区提供了首个大规模、详细且密集的标注数据集，并通过高效标注方法提升了数据质量。

Abstract: Multimodal Large Language Models (MLLMs) demonstrate a complex understanding
of scenes, benefiting from large-scale and high-quality datasets. Most existing
caption datasets lack the ground locations and relations for visual entities.
Several grounded caption datasets face the problems of missing detailed
descriptions, relations, and massive object descriptions on high-resolution
images. To fill this gap for the community, we present DenseWorld-1M, the first
massive, detailed, dense grounded caption dataset in the real world. We design
a three-stage labeling pipeline, containing open-world perception, detailed
object caption generation, and dense caption merging. The first stage obtains
entity-level masks and labels. The second stage generates the object-level,
detailed captions with the guidance of masks and labels from the first stage.
The final stage merges object captions and masks into spatial and relational
dense captions. To accelerate the labeling process and improve caption quality,
we present two VLM models: the Detailed Region Caption model and the Spatial
Caption Merging model. Extensive experiments on various settings, including
vision-language understanding, visual grounding, and region caption generation,
demonstrate the effectiveness of our DenseWorld-1M dataset and labeling models.

</details>


### [218] [Epona: Autoregressive Diffusion World Model for Autonomous Driving](https://arxiv.org/abs/2506.24113)
*Kaiwen Zhang,Zhenyu Tang,Xiaotao Hu,Xingang Pan,Xiaoyang Guo,Yuan Liu,Jingwei Huang,Li Yuan,Qian Zhang,Xiao-Xiao Long,Xun Cao,Wei Yin*

Main category: cs.CV

TL;DR: 论文提出Epona，一种自回归扩散世界模型，通过解耦时空因子化和模块化轨迹与视频预测，实现长时程高分辨率视频生成，并在自动驾驶世界建模中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于视频扩散的世界模型在灵活长度、长时程预测和轨迹规划集成方面存在不足，主要因其依赖固定长度帧序列的全局联合分布建模。

Method: 提出两种创新：1) 解耦时空因子化，分离时间动态建模与细粒度未来世界生成；2) 模块化轨迹与视频预测，将运动规划与视觉建模无缝集成。

Result: 实验结果显示，Epona在FVD指标上提升7.4%，预测时长显著延长，并在NAVSIM基准测试中优于现有端到端规划器。

Conclusion: Epona不仅实现了高质量长时程视频生成，还可作为实时运动规划器，为自动驾驶世界建模提供了新思路。

Abstract: Diffusion models have demonstrated exceptional visual quality in video
generation, making them promising for autonomous driving world modeling.
However, existing video diffusion-based world models struggle with
flexible-length, long-horizon predictions and integrating trajectory planning.
This is because conventional video diffusion models rely on global joint
distribution modeling of fixed-length frame sequences rather than sequentially
constructing localized distributions at each timestep. In this work, we propose
Epona, an autoregressive diffusion world model that enables localized
spatiotemporal distribution modeling through two key innovations: 1) Decoupled
spatiotemporal factorization that separates temporal dynamics modeling from
fine-grained future world generation, and 2) Modular trajectory and video
prediction that seamlessly integrate motion planning with visual modeling in an
end-to-end framework. Our architecture enables high-resolution, long-duration
generation while introducing a novel chain-of-forward training strategy to
address error accumulation in autoregressive loops. Experimental results
demonstrate state-of-the-art performance with 7.4\% FVD improvement and minutes
longer prediction duration compared to prior works. The learned world model
further serves as a real-time motion planner, outperforming strong end-to-end
planners on NAVSIM benchmarks. Code will be publicly available at
\href{https://github.com/Kevin-thu/Epona/}{https://github.com/Kevin-thu/Epona/}.

</details>


### [219] [TextMesh4D: High-Quality Text-to-4D Mesh Generation](https://arxiv.org/abs/2506.24121)
*Sisi Dai,Xinxin Su,Boyan Wan,Ruizhen Hu,Kai Xu*

Main category: cs.CV

TL;DR: TextMesh4D是一个新颖的框架，用于高质量文本到4D生成，通过两阶段分解和正则化优化实现高效动态内容生成。


<details>
  <summary>Details</summary>
Motivation: 当前扩散生成模型在图像、视频和3D内容生成上取得进展，但动态3D内容生成（文本到4D）仍未被充分探索。

Method: 采用基于面的Jacobians作为可微分网格表示，将4D生成分为静态对象创建和动态运动合成两阶段，并引入灵活性-刚性正则化项优化。

Result: 实验表明，TextMesh4D在时间一致性、结构保真度和视觉真实感上达到最优，且仅需单24GB GPU。

Conclusion: TextMesh4D为文本驱动的4D网格生成提供了高效且高质量的解决方案，代码将开源以推动未来研究。

Abstract: Recent advancements in diffusion generative models significantly advanced
image, video, and 3D content creation from user-provided text prompts. However,
the challenging problem of dynamic 3D content generation (text-to-4D) with
diffusion guidance remains largely unexplored. In this paper, we introduce
TextMesh4D, a novel framework for high-quality text-to-4D generation. Our
approach leverages per-face Jacobians as a differentiable mesh representation
and decomposes 4D generation into two stages: static object creation and
dynamic motion synthesis. We further propose a flexibility-rigidity
regularization term to stabilize Jacobian optimization under video diffusion
priors, ensuring robust geometric performance. Experiments demonstrate that
TextMesh4D achieves state-of-the-art results in terms of temporal consistency,
structural fidelity, and visual realism. Moreover, TextMesh4D operates with a
low GPU memory overhead-requiring only a single 24GB GPU-offering a
cost-effective yet high-quality solution for text-driven 4D mesh generation.
The code will be released to facilitate future research in text-to-4D
generation.

</details>


### [220] [Calligrapher: Freestyle Text Image Customization](https://arxiv.org/abs/2506.24123)
*Yue Ma,Qingyan Bai,Hao Ouyang,Ka Leong Cheng,Qiuyu Wang,Hongyu Liu,Zichen Liu,Haofan Wang,Jingye Chen,Yujun Shen,Qifeng Chen*

Main category: cs.CV

TL;DR: Calligrapher是一个基于扩散模型的框架，结合文本定制与艺术字体，解决了风格控制和数据依赖问题。


<details>
  <summary>Details</summary>
Motivation: 解决数字书法和设计中精确风格控制和数据依赖的挑战。

Method: 1. 自蒸馏机制构建风格基准；2. 可训练风格编码器提取特征；3. 上下文生成机制嵌入参考图像。

Result: 在多种字体和设计场景中准确复现风格细节和字形定位，超越传统模型。

Conclusion: Calligrapher为数字艺术和品牌设计提供了高质量的自动化解决方案。

Abstract: We introduce Calligrapher, a novel diffusion-based framework that
innovatively integrates advanced text customization with artistic typography
for digital calligraphy and design applications. Addressing the challenges of
precise style control and data dependency in typographic customization, our
framework incorporates three key technical contributions. First, we develop a
self-distillation mechanism that leverages the pre-trained text-to-image
generative model itself alongside the large language model to automatically
construct a style-centric typography benchmark. Second, we introduce a
localized style injection framework via a trainable style encoder, which
comprises both Qformer and linear layers, to extract robust style features from
reference images. An in-context generation mechanism is also employed to
directly embed reference images into the denoising process, further enhancing
the refined alignment of target styles. Extensive quantitative and qualitative
evaluations across diverse fonts and design contexts confirm Calligrapher's
accurate reproduction of intricate stylistic details and precise glyph
positioning. By automating high-quality, visually consistent typography,
Calligrapher surpasses traditional models, empowering creative practitioners in
digital art, branding, and contextual typographic design.

</details>


### [221] [FADRM: Fast and Accurate Data Residual Matching for Dataset Distillation](https://arxiv.org/abs/2506.24125)
*Jiacheng Cui,Xinyue Bi,Yaxin Luo,Xiaohan Zhao,Jiacheng Liu,Zhiqiang Shen*

Main category: cs.CV

TL;DR: 论文提出了一种名为FADRM的新方法，首次引入数据级残差连接（Data Residual Matching），用于数据集蒸馏任务，显著提升了效率和性能。


<details>
  <summary>Details</summary>
Motivation: 探索数据级残差连接的潜力，解决数据信息消失问题，平衡新知识与原始数据信息。

Method: 通过数据级跳跃连接和优化级改进，提升计算效率，减少训练时间和GPU内存使用。

Result: 在多个数据集基准测试中表现优异，例如在ImageNet-1K上，单模型和多模型蒸馏分别达到47.7%和50.0%的测试准确率。

Conclusion: FADRM方法在数据集蒸馏任务中实现了新的最优性能，显著优于现有方法。

Abstract: Residual connection has been extensively studied and widely applied at the
model architecture level. However, its potential in the more challenging
data-centric approaches remains unexplored. In this work, we introduce the
concept of Data Residual Matching for the first time, leveraging data-level
skip connections to facilitate data generation and mitigate data information
vanishing. This approach maintains a balance between newly acquired knowledge
through pixel space optimization and existing core local information
identification within raw data modalities, specifically for the dataset
distillation task. Furthermore, by incorporating optimization-level
refinements, our method significantly improves computational efficiency,
achieving superior performance while reducing training time and peak GPU memory
usage by 50%. Consequently, the proposed method Fast and Accurate Data Residual
Matching for Dataset Distillation (FADRM) establishes a new state-of-the-art,
demonstrating substantial improvements over existing methods across multiple
dataset benchmarks in both efficiency and effectiveness. For instance, with
ResNet-18 as the student model and a 0.8% compression ratio on ImageNet-1K, the
method achieves 47.7% test accuracy in single-model dataset distillation and
50.0% in multi-model dataset distillation, surpassing RDED by +5.7% and
outperforming state-of-the-art multi-model approaches, EDC and CV-DD, by +1.4%
and +4.0%. Code is available at: https://github.com/Jiacheng8/FADRM.

</details>


### [222] [How to Design and Train Your Implicit Neural Representation for Video Compression](https://arxiv.org/abs/2506.24127)
*Matthew Gwilliam,Roy Zhang,Namitha Padmanabhan,Hongyang Du,Abhinav Shrivastava*

Main category: cs.CV

TL;DR: 论文提出了一种名为RNeRV的改进视频压缩方法，通过优化隐式神经表示（INR）设计，提升了压缩质量和训练效率，并探索了超网络技术以实现实时编码。


<details>
  <summary>Details</summary>
Motivation: 传统INR方法因需要逐样本训练网络，编码速度过慢，难以实际应用。本文旨在解决这一问题，同时提升压缩性能。

Method: 开发了一个库来分析NeRV家族方法的组件，提出RNeRV配置，并探索超网络技术以预测INR权重，实现实时编码。

Result: RNeRV在相同训练时间下，平均PSNR提升1.27%；超网络技术在UCF-101数据集上PSNR和MS-SSIM分别提升1.7%。

Conclusion: RNeRV和超网络技术显著提升了视频压缩的性能和编码速度，为实际应用提供了可能。

Abstract: Implicit neural representation (INR) methods for video compression have
recently achieved visual quality and compression ratios that are competitive
with traditional pipelines. However, due to the need for per-sample network
training, the encoding speeds of these methods are too slow for practical
adoption. We develop a library to allow us to disentangle and review the
components of methods from the NeRV family, reframing their performance in
terms of not only size-quality trade-offs, but also impacts on training time.
We uncover principles for effective video INR design and propose a
state-of-the-art configuration of these components, Rabbit NeRV (RNeRV). When
all methods are given equal training time (equivalent to 300 NeRV epochs) for 7
different UVG videos at 1080p, RNeRV achieves +1.27% PSNR on average compared
to the best-performing alternative for each video in our NeRV library. We then
tackle the encoding speed issue head-on by investigating the viability of
hyper-networks, which predict INR weights from video inputs, to disentangle
training from encoding to allow for real-time encoding. We propose masking the
weights of the predicted INR during training to allow for variable, higher
quality compression, resulting in 1.7% improvements to both PSNR and MS-SSIM at
0.037 bpp on the UCF-101 dataset, and we increase hyper-network parameters by
0.4% for 2.5%/2.7% improvements to PSNR/MS-SSIM with equal bpp and similar
speeds. Our project website is available at https://mgwillia.github.io/vinrb/
and our code is available at https://github.com/mgwillia/vinrb.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [223] [Hierarchical Adversarially-Resilient Multi-Agent Reinforcement Learning for Cyber-Physical Systems Security](https://arxiv.org/abs/2506.22445)
*Saad Alqithami*

Main category: cs.LG

TL;DR: 论文提出了一种名为HAMARL的分层对抗弹性多智能体强化学习框架，旨在提升关键基础设施中信息物理系统的安全性。


<details>
  <summary>Details</summary>
Motivation: 信息物理系统（CPS）在多个关键领域扮演重要角色，但其日益增长的互联性使其易受复杂网络攻击，传统安全方法难以应对。

Method: HAMARL采用分层结构，包括专注于子系统安全的本地智能体和全局协调器，并结合对抗训练循环以模拟和预测威胁。

Result: 实验表明，HAMARL显著优于传统多智能体强化学习方法，提高了攻击检测准确性，缩短了响应时间。

Conclusion: 结合分层多智能体协调和对抗感知训练，HAMARL有效增强了下一代CPS的弹性和安全性。

Abstract: Cyber-Physical Systems play a critical role in the infrastructure of various
sectors, including manufacturing, energy distribution, and autonomous
transportation systems. However, their increasing connectivity renders them
highly vulnerable to sophisticated cyber threats, such as adaptive and zero-day
attacks, against which traditional security methods like rule-based intrusion
detection and single-agent reinforcement learning prove insufficient. To
overcome these challenges, this paper introduces a novel Hierarchical
Adversarially-Resilient Multi-Agent Reinforcement Learning (HAMARL) framework.
HAMARL employs a hierarchical structure consisting of local agents dedicated to
subsystem security and a global coordinator that oversees and optimizes
comprehensive, system-wide defense strategies. Furthermore, the framework
incorporates an adversarial training loop designed to simulate and anticipate
evolving cyber threats, enabling proactive defense adaptation. Extensive
experimental evaluations conducted on a simulated industrial IoT testbed
indicate that HAMARL substantially outperforms traditional multi-agent
reinforcement learning approaches, significantly improving attack detection
accuracy, reducing response times, and ensuring operational continuity. The
results underscore the effectiveness of combining hierarchical multi-agent
coordination with adversarially-aware training to enhance the resilience and
security of next-generation CPS.

</details>


### [224] [Latent Factorization of Tensors with Threshold Distance Weighted Loss for Traffic Data Estimation](https://arxiv.org/abs/2506.22441)
*Lei Yang*

Main category: cs.LG

TL;DR: 提出了一种基于阈值距离加权损失函数的张量潜在分解模型（TDWLFT），用于处理交通数据中的缺失值和异常值，提高了预测精度和计算效率。


<details>
  <summary>Details</summary>
Motivation: 智能交通系统（ITS）依赖高质量的时空交通数据，但实际数据常因通信故障或传感器故障而缺失或损坏。现有张量潜在分解（LFT）模型对异常值敏感，限制了其性能。

Method: 提出了一种阈值距离加权（TDW）损失函数，结合到LFT模型中（TDWLFT），通过为样本分配不同权重降低对异常值的敏感性。

Result: 在两个不同城市环境的交通速度数据集上实验表明，TDWLFT模型在预测精度和计算效率上均优于现有方法。

Conclusion: TDWLFT模型通过改进损失函数，有效提升了交通数据缺失值填充的性能，为ITS提供了更可靠的数据支持。

Abstract: Intelligent transportation systems (ITS) rely heavily on complete and
high-quality spatiotemporal traffic data to achieve optimal performance.
Nevertheless, in real-word traffic data collection processes, issues such as
communication failures and sensor malfunctions often lead to incomplete or
corrupted datasets, thereby posing significant challenges to the advancement of
ITS. Among various methods for imputing missing spatiotemporal traffic data,
the latent factorization of tensors (LFT) model has emerged as a widely adopted
and effective solution. However, conventional LFT models typically employ the
standard L2-norm in their learning objective, which makes them vulnerable to
the influence of outliers. To overcome this limitation, this paper proposes a
threshold distance weighted (TDW) loss-incorporated Latent Factorization of
Tensors (TDWLFT) model. The proposed loss function effectively reduces the
model's sensitivity to outliers by assigning differentiated weights to
individual samples. Extensive experiments conducted on two traffic speed
datasets sourced from diverse urban environments confirm that the proposed
TDWLFT model consistently outperforms state-of-the-art approaches in terms of
both in both prediction accuracy and computational efficiency.

</details>


### [225] [Features-based embedding or Feature-grounding](https://arxiv.org/abs/2506.22442)
*Piotr Makarevich*

Main category: cs.LG

TL;DR: 论文探讨如何通过特征嵌入在深度学习模型中复现基于知识的结构化思维，提出了一种构建特征基础嵌入的方法。


<details>
  <summary>Details</summary>
Motivation: 研究如何将人类基于先验知识和概念类别的结构化思维融入深度学习模型，以提升模型的解释性和共享表示能力。

Method: 提出了一种特征基础嵌入方法，通过可操作字典与领域特定概念特征的对齐，构建共享表示。

Result: 实现了基于特征嵌入的深度学习模型，能够更好地模拟人类的结构化思维。

Conclusion: 特征基础嵌入方法为深度学习模型提供了更接近人类思维的表示能力，增强了模型的解释性和实用性。

Abstract: In everyday reasoning, when we think about a particular object, we associate
it with a unique set of expected properties such as weight, size, or more
abstract attributes like density or horsepower. These expectations are shaped
by our prior knowledge and the conceptual categories we have formed through
experience. This paper investigates how such knowledge-based structured
thinking can be reproduced in deep learning models using features based
embeddings. Specially, it introduces an specific approach to build
feature-grounded embedding, aiming to align shareable representations of
operable dictionary with interpretable domain-specific conceptual features.

</details>


### [226] [Learning Interpretable Rules from Neural Networks: Neurosymbolic AI for Radar Hand Gesture Recognition](https://arxiv.org/abs/2506.22443)
*Sarah Seifi,Tobias Sukianto,Cecilia Carbonelli,Lorenzo Servadei,Robert Wille*

Main category: cs.LG

TL;DR: RL-Net是一种神经符号规则学习网络，首次应用于雷达手势识别，在性能和可解释性之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 解决规则模型在复杂数据上的性能不足和深度学习模型缺乏透明性的问题。

Method: 通过神经优化学习可解释的规则列表，并与透明规则系统（MIRA）和可解释黑盒模型（XentricAI）进行对比。

Result: RL-Net在保持高性能（93.03% F1）的同时显著降低规则复杂性，优于MIRA和XentricAI。

Conclusion: RL-Net为透明性和性能提供了实用折中方案，展示了神经符号模型在手势识别中的可行性。

Abstract: Rule-based models offer interpretability but struggle with complex data,
while deep neural networks excel in performance yet lack transparency. This
work investigates a neuro-symbolic rule learning neural network named RL-Net
that learns interpretable rule lists through neural optimization, applied for
the first time to radar-based hand gesture recognition (HGR). We benchmark
RL-Net against a fully transparent rule-based system (MIRA) and an explainable
black-box model (XentricAI), evaluating accuracy, interpretability, and user
adaptability via transfer learning. Our results show that RL-Net achieves a
favorable trade-off, maintaining strong performance (93.03% F1) while
significantly reducing rule complexity. We identify optimization challenges
specific to rule pruning and hierarchy bias and propose stability-enhancing
modifications. Compared to MIRA and XentricAI, RL-Net emerges as a practical
middle ground between transparency and performance. This study highlights the
real-world feasibility of neuro-symbolic models for interpretable HGR and
offers insights for extending explainable AI to edge-deployable sensing
systems.

</details>


### [227] [Active Learning for Forecasting Severity among Patients with Post Acute Sequelae of SARS-CoV-2](https://arxiv.org/abs/2506.22444)
*Jing Wang,Amar Sra,Jeremy C. Weiss*

Main category: cs.LG

TL;DR: 研究提出了一种基于大型语言模型和主动注意力网络的PASC临床风险预测方法，旨在提高预测准确性并减少标注需求。


<details>
  <summary>Details</summary>
Motivation: PASC对全球医疗系统构成挑战，传统模型难以捕捉其复杂进展，需更精准的方法。

Method: 使用Llama-3.1-70B-Instruct生成文本时间序列特征，结合临床专家标注，提出主动注意力网络预测风险。

Result: 方法旨在提高临床风险预测准确性，并识别进展事件，减少标注需求。

Conclusion: 研究目标是通过结合人类专业知识和主动学习，改善SARS-CoV-2患者的护理和决策。

Abstract: The long-term effects of Postacute Sequelae of SARS-CoV-2, known as PASC,
pose a significant challenge to healthcare systems worldwide. Accurate
identification of progression events, such as hospitalization and reinfection,
is essential for effective patient management and resource allocation. However,
traditional models trained on structured data struggle to capture the nuanced
progression of PASC. In this study, we introduce the first publicly available
cohort of 18 PASC patients, with text time series features based on Large
Language Model Llama-3.1-70B-Instruct and clinical risk annotated by clinical
expert. We propose an Active Attention Network to predict the clinical risk and
identify progression events related to the risk. By integrating human expertise
with active learning, we aim to enhance clinical risk prediction accuracy and
enable progression events identification with fewer number of annotation. The
ultimate goal is to improves patient care and decision-making for SARS-CoV-2
patient.

</details>


### [228] [FF-INT8: Efficient Forward-Forward DNN Training on Edge Devices with INT8 Precision](https://arxiv.org/abs/2506.22771)
*Jingxiao Ma,Priyadarshini Panda,Sherief Reda*

Main category: cs.LG

TL;DR: 论文提出了一种基于INT8量化的Forward-Forward算法训练方法，通过层间策略稳定梯度量化，并引入“look-ahead”方案提升模型精度，实验显示在训练速度、能耗和内存占用上均有显著优化。


<details>
  <summary>Details</summary>
Motivation: 传统反向传播算法在时间和能耗上的低效限制了其在资源受限的边缘设备上的适用性，而低精度量化在训练中的应用尚未充分探索。

Method: 采用Forward-Forward算法替代反向传播，结合INT8量化训练和“look-ahead”方案，以稳定梯度并提升精度。

Result: 在NVIDIA Jetson Orin Nano上实验，训练速度提升4.6%，能耗降低8.3%，内存占用减少27.0%，同时保持模型精度。

Conclusion: 该方法为资源受限设备提供了一种高效、低能耗的神经网络训练解决方案。

Abstract: Backpropagation has been the cornerstone of neural network training for
decades, yet its inefficiencies in time and energy consumption limit its
suitability for resource-constrained edge devices. While low-precision neural
network quantization has been extensively researched to speed up model
inference, its application in training has been less explored. Recently, the
Forward-Forward (FF) algorithm has emerged as a promising alternative to
backpropagation, replacing the backward pass with an additional forward pass.
By avoiding the need to store intermediate activations for backpropagation, FF
can reduce memory footprint, making it well-suited for embedded devices. This
paper presents an INT8 quantized training approach that leverages FF's
layer-by-layer strategy to stabilize gradient quantization. Furthermore, we
propose a novel "look-ahead" scheme to address limitations of FF and improve
model accuracy. Experiments conducted on NVIDIA Jetson Orin Nano board
demonstrate 4.6% faster training, 8.3% energy savings, and 27.0% reduction in
memory usage, while maintaining competitive accuracy compared to the
state-of-the-art.

</details>


### [229] [Mirror Descent Policy Optimisation for Robust Constrained Markov Decision Processes](https://arxiv.org/abs/2506.23165)
*David Bossens,Atsushi Nitanda*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Safety is an essential requirement for reinforcement learning systems. The
newly emerging framework of robust constrained Markov decision processes allows
learning policies that satisfy long-term constraints while providing guarantees
under epistemic uncertainty. This paper presents mirror descent policy
optimisation for robust constrained Markov decision processes (RCMDPs), making
use of policy gradient techniques to optimise both the policy (as a maximiser)
and the transition kernel (as an adversarial minimiser) on the Lagrangian
representing a constrained MDP. In the oracle-based RCMDP setting, we obtain an
$\mathcal{O}\left(\frac{1}{T}\right)$ convergence rate for the squared distance
as a Bregman divergence, and an $\mathcal{O}\left(e^{-T}\right)$ convergence
rate for entropy-regularised objectives. In the sample-based RCMDP setting, we
obtain an $\tilde{\mathcal{O}}\left(\frac{1}{T^{1/3}}\right)$ convergence rate.
Experiments confirm the benefits of mirror descent policy optimisation in
constrained and unconstrained optimisation, and significant improvements are
observed in robustness tests when compared to baseline policy optimisation
algorithms.

</details>


### [230] [EAGLE: Efficient Alignment of Generalized Latent Embeddings for Multimodal Survival Prediction with Interpretable Attribution Analysis](https://arxiv.org/abs/2506.22446)
*Aakash Tripathi,Asim Waqas,Matthew B. Schabath,Yasin Yilmaz,Ghulam Rasool*

Main category: cs.LG

TL;DR: EAGLE是一种新型深度学习框架，通过注意力机制和多模态融合解决癌症生存预测中的计算和可解释性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多模态融合、计算需求和可解释性方面存在不足，限制了临床应用的潜力。

Method: EAGLE采用动态跨模态注意力机制、维度大幅减少、三种互补归因方法和统一管道。

Result: 在911名患者中验证，EAGLE能识别高风险患者依赖影像特征，风险分层显示生存率差异显著。

Conclusion: EAGLE结合高性能和临床可解释性，为多模态生存预测提供了实用解决方案。

Abstract: Accurate cancer survival prediction requires integration of diverse data
modalities that reflect the complex interplay between imaging, clinical
parameters, and textual reports. However, existing multimodal approaches suffer
from simplistic fusion strategies, massive computational requirements, and lack
of interpretability-critical barriers to clinical adoption. We present EAGLE
(Efficient Alignment of Generalized Latent Embeddings), a novel deep learning
framework that addresses these limitations through attention-based multimodal
fusion with comprehensive attribution analysis. EAGLE introduces four key
innovations: (1) dynamic cross-modal attention mechanisms that learn
hierarchical relationships between modalities, (2) massive dimensionality
reduction (99.96%) while maintaining predictive performance, (3) three
complementary attribution methods providing patient-level interpretability, and
(4) a unified pipeline enabling seamless adaptation across cancer types. We
evaluated EAGLE on 911 patients across three distinct malignancies:
glioblastoma (GBM, n=160), intraductal papillary mucinous neoplasms (IPMN,
n=171), and non-small cell lung cancer (NSCLC, n=580). Patient-level analysis
showed high-risk individuals relied more heavily on adverse imaging features,
while low-risk patients demonstrated balanced modality contributions. Risk
stratification identified clinically meaningful groups with 4-fold (GBM) to
5-fold (NSCLC) differences in median survival, directly informing treatment
intensity decisions. By combining state-of-the-art performance with clinical
interpretability, EAGLE bridges the gap between advanced AI capabilities and
practical healthcare deployment, offering a scalable solution for multimodal
survival prediction that enhances both prognostic accuracy and physician trust
in automated predictions.

</details>


### [231] [Vision Transformers for Multi-Variable Climate Downscaling: Emulating Regional Climate Models with a Shared Encoder and Multi-Decoder Architecture](https://arxiv.org/abs/2506.22447)
*Fabio Merizzi,Harilaos Loukos*

Main category: cs.LG

TL;DR: 提出了一种多任务、多变量的Vision Transformer架构（1EMD），用于从GCM分辨率输入中联合预测三个关键气候变量，优于单变量模型。


<details>
  <summary>Details</summary>
Motivation: GCMs的空间分辨率较低，RCMs计算成本高且灵活性有限，现有深度学习方法多为单变量模型，存在上下文意识不足和计算冗余问题。

Method: 采用共享编码器和变量特定解码器的ViT架构（1EMD），联合预测温度、风速和500 hPa位势高度。

Result: 多变量方法实现了跨变量知识转移，性能优于单变量基线，同时提高了计算效率。

Conclusion: 多变量建模在高分辨率气候降尺度中具有显著优势。

Abstract: Global Climate Models (GCMs) are critical for simulating large-scale climate
dynamics, but their coarse spatial resolution limits their applicability in
regional studies. Regional Climate Models (RCMs) refine this through dynamic
downscaling, albeit at considerable computational cost and with limited
flexibility. While deep learning has emerged as an efficient data-driven
alternative, most existing studies have focused on single-variable models that
downscale one variable at a time. This approach can lead to limited contextual
awareness, redundant computation, and lack of cross-variable interaction. Our
study addresses these limitations by proposing a multi-task, multi-variable
Vision Transformer (ViT) architecture with a shared encoder and
variable-specific decoders (1EMD). The proposed architecture jointly predicts
three key climate variables: surface temperature (tas), wind speed (sfcWind),
and 500 hPa geopotential height (zg500), directly from GCM-resolution inputs,
emulating RCM-scale downscaling over Europe. We show that our multi-variable
approach achieves positive cross-variable knowledge transfer and consistently
outperforms single-variable baselines trained under identical conditions, while
also improving computational efficiency. These results demonstrate the
effectiveness of multi-variable modeling for high-resolution climate
downscaling.

</details>


### [232] [Stabilization of industrial processes with time series machine learning](https://arxiv.org/abs/2506.22502)
*Matvei Anoshin,Olga Tsurkan,Vadim Lopatkin,Leonid Fedichkin*

Main category: cs.LG

TL;DR: 论文提出了一种基于两个神经网络的简单流程，用于时间序列稳定化，显著提升了温度控制的稳定性。


<details>
  <summary>Details</summary>
Motivation: 时间序列稳定化在工业领域至关重要，机器学习可以提升稳定化质量并减少计算资源需求。

Method: 使用两个神经网络（预言预测器和优化器），将点值优化问题转化为神经网络训练问题。

Result: 温度控制的稳定性比普通求解器提高了约3倍。

Conclusion: 该方法在时间序列稳定化中表现出显著优势。

Abstract: The stabilization of time series processes is a crucial problem that is
ubiquitous in various industrial fields. The application of machine learning to
its solution can have a decisive impact, improving both the quality of the
resulting stabilization with less computational resources required. In this
work, we present a simple pipeline consisting of two neural networks: the
oracle predictor and the optimizer, proposing a substitution of the point-wise
values optimization to the problem of the neural network training, which
successfully improves stability in terms of the temperature control by about 3
times compared to ordinary solvers.

</details>


### [233] [Task-Agnostic Contrastive Pretraining for Relational Deep Learning](https://arxiv.org/abs/2506.22530)
*Jakub Peleška,Gustav Šír*

Main category: cs.LG

TL;DR: 提出了一种任务无关的对比预训练方法，用于关系深度学习（RDL），通过三个对比目标（行级、链接级和上下文级）学习数据库范围的表示。


<details>
  <summary>Details</summary>
Motivation: 现有RDL模型通常依赖任务特定的监督学习，需要为每个预测任务训练单独模型，限制了可扩展性和重用性。

Method: 引入任务无关的对比预训练方法，设计三个对比目标，并通过模块化RDL架构和高效采样策略实现。

Result: 初步结果表明，微调预训练模型明显优于从头训练，验证了该方法在学习可迁移表示方面的潜力。

Conclusion: 提出的方法为关系数据学习提供了可扩展且可重用的表示学习框架。

Abstract: Relational Deep Learning (RDL) is an emerging paradigm that leverages Graph
Neural Network principles to learn directly from relational databases by
representing them as heterogeneous graphs. However, existing RDL models
typically rely on task-specific supervised learning, requiring training
separate models for each predictive task, which may hamper scalability and
reuse.
  In this work, we propose a novel task-agnostic contrastive pretraining
approach for RDL that enables database-wide representation learning. For that
aim, we introduce three levels of contrastive objectives$-$row-level,
link-level, and context-level$-$designed to capture the structural and semantic
heterogeneity inherent to relational data. We implement the respective
pretraining approach through a modular RDL architecture and an efficient
sampling strategy tailored to the heterogeneous database setting. Our
preliminary results on standard RDL benchmarks demonstrate that fine-tuning the
pretrained models measurably outperforms training from scratch, validating the
promise of the proposed methodology in learning transferable representations
for relational data.

</details>


### [234] [Exploration Behavior of Untrained Policies](https://arxiv.org/abs/2506.22566)
*Jacob Adamczyk*

Main category: cs.LG

TL;DR: 论文研究了深度神经策略架构在训练前如何隐式影响探索行为，通过理论和实验展示了未训练策略在玩具模型中产生弹道或扩散轨迹的策略。


<details>
  <summary>Details</summary>
Motivation: 探索是强化学习中的核心挑战，尤其是在稀疏或对抗性奖励结构的环境中。研究未训练策略的探索行为有助于理解其初始化的影响。

Method: 利用无限宽度网络理论和连续时间极限，分析未训练策略产生的相关动作和非平凡状态访问分布。

Result: 研究表明，未训练策略会产生相关动作，并形成特定的状态访问分布，揭示了架构对探索的归纳偏差。

Conclusion: 研究为利用策略初始化作为设计工具提供了理论和实验框架，以理解早期训练中的探索行为。

Abstract: Exploration remains a fundamental challenge in reinforcement learning (RL),
particularly in environments with sparse or adversarial reward structures. In
this work, we study how the architecture of deep neural policies implicitly
shapes exploration before training. We theoretically and empirically
demonstrate strategies for generating ballistic or diffusive trajectories from
untrained policies in a toy model. Using the theory of infinite-width networks
and a continuous-time limit, we show that untrained policies return correlated
actions and result in non-trivial state-visitation distributions. We discuss
the distributions of the corresponding trajectories for a standard
architecture, revealing insights into inductive biases for tackling
exploration. Our results establish a theoretical and experimental framework for
using policy initialization as a design tool to understand exploration behavior
in early training.

</details>


### [235] [The Hidden Link Between RLHF and Contrastive Learning](https://arxiv.org/abs/2506.22578)
*Xufei Lv,Haoyuan Sun,Xuefeng Bai,Min Zhang,Houde Liu,Kehai Chen*

Main category: cs.LG

TL;DR: 论文通过互信息最大化视角重新解读RLHF和DPO，提出MIO方法，解决了DPO后期性能下降问题，并在推理和数学任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型（LLM）与人类价值观对齐的方法，揭示RLHF和DPO的互信息最大化本质，并提出改进方案。

Method: 从互信息最大化角度分析RLHF和DPO，提出基于Jensen-Shannon互信息估计器的MIO方法。

Result: MIO解决了DPO后期性能下降问题，在推理和数学任务上表现优于或与现有方法相当。

Conclusion: MIO通过改进互信息估计器，为LLM对齐提供了更优方法，具有理论和实践意义。

Abstract: Alignment of large language models (LLMs) with human values has recently
garnered significant attention, with prominent examples including the canonical
yet costly Reinforcement Learning from Human Feedback (RLHF) and the simple
Direct Preference Optimization (DPO). In this work, we demonstrate that both
RLHF and DPO can be interpreted from the perspective of mutual information (MI)
maximization, uncovering a profound connection to contrastive learning. Within
this framework, both RLHF and DPO can be viewed as methods that perform
contrastive learning based on the positive and negative samples derived from
the base model, leveraging the Donsker-Varadhan (DV) lower bound on MI
(equivalently, the MINE estimator). This paradigm further explains why RLHF may
not intrinsically incentivize reasoning capacities in LLMs beyond what is
already present in the base model. Building on this perspective, we replace the
DV/MINE bound with the Jensen-Shannon MI estimator and propose Mutual
Information Optimization (MIO). Comprehensive theoretical analysis and
extensive empirical evaluations demonstrate that MIO mitigates the late-stage
decline in chosen-likelihood observed in DPO, achieving competitive or superior
performance across various challenging reasoning and mathematical benchmarks.
We will release the model and code upon acceptance.

</details>


### [236] [Are Fast Methods Stable in Adversarially Robust Transfer Learning?](https://arxiv.org/abs/2506.22602)
*Joshua C. Zhao,Saurabh Bagchi*

Main category: cs.LG

TL;DR: 研究发现，在对抗性微调中使用FGSM比从头训练更稳定，且计算成本更低，性能接近PGD。


<details>
  <summary>Details</summary>
Motivation: 降低对抗性微调的计算成本，同时保持高鲁棒性。

Method: 在对抗性微调中使用FGSM，并与PGD进行比较。

Result: FGSM在ε=4和ε=8时仅损失少量鲁棒性，但训练时间减少4倍。

Conclusion: FGSM是PGD的高效替代方案，适用于对抗性鲁棒迁移学习。

Abstract: Transfer learning is often used to decrease the computational cost of model
training, as fine-tuning a model allows a downstream task to leverage the
features learned from the pre-training dataset and quickly adapt them to a new
task. This is particularly useful for achieving adversarial robustness, as
adversarially training models from scratch is very computationally expensive.
However, high robustness in transfer learning still requires adversarial
training during the fine-tuning phase, which requires up to an order of
magnitude more time than standard fine-tuning. In this work, we revisit the use
of the fast gradient sign method (FGSM) in robust transfer learning to improve
the computational cost of adversarial fine-tuning. We surprisingly find that
FGSM is much more stable in adversarial fine-tuning than when training from
scratch. In particular, FGSM fine-tuning does not suffer from any issues with
catastrophic overfitting at standard perturbation budgets of $\varepsilon=4$ or
$\varepsilon=8$. This stability is further enhanced with parameter-efficient
fine-tuning methods, where FGSM remains stable even up to $\varepsilon=32$ for
linear probing. We demonstrate how this stability translates into performance
across multiple datasets. Compared to fine-tuning with the more commonly used
method of projected gradient descent (PGD), on average, FGSM only loses 0.39%
and 1.39% test robustness for $\varepsilon=4$ and $\varepsilon=8$ while using
$4\times$ less training time. Surprisingly, FGSM may not only be a
significantly more efficient alternative to PGD in adversarially robust
transfer learning but also a well-performing one.

</details>


### [237] [Mitigating Semantic Collapse in Generative Personalization with a Surprisingly Simple Test-Time Embedding Adjustment](https://arxiv.org/abs/2506.22685)
*Anh Bui,Trang Vu,Trung Le,Junae Kim,Tamas Abraham,Rollin Omari,Amar Kaur,Dinh Phung*

Main category: cs.LG

TL;DR: 论文研究了生成式个性化中的语义坍缩问题，提出了一种无需训练的推理时调整方法，显著改善了文本与图像的语义对齐。


<details>
  <summary>Details</summary>
Motivation: 生成式个性化中，学习到的视觉概念$V^*$会逐渐偏离原始文本含义，导致多概念输入提示的语义丰富性降低，输出图像过于简化。

Method: 提出了一种无需训练的推理时调整方法，通过调整预训练嵌入的大小和方向来解决问题。

Result: 该方法在不同个性化方法中广泛适用，显著提升了文本与图像的语义对齐。

Conclusion: 该方法有效缓解了语义坍缩问题，提升了生成图像的语义丰富性和准确性。

Abstract: In this paper, we investigate the semantic collapsing problem in generative
personalization, an under-explored topic where the learned visual concept
($V^*$) gradually shifts from its original textual meaning and comes to
dominate other concepts in multi-concept input prompts. This issue not only
reduces the semantic richness of complex input prompts like "a photo of $V^*$
wearing glasses and playing guitar" into simpler, less contextually rich forms
such as "a photo of $V^*$" but also leads to simplified output images that fail
to capture the intended concept.
  We identify the root cause as unconstrained optimisation, which allows the
learned embedding $V^*$ to drift arbitrarily in the embedding space, both in
direction and magnitude. To address this, we propose a simple yet effective
training-free method that adjusts the magnitude and direction of pre-trained
embedding at inference time, effectively mitigating the semantic collapsing
problem. Our method is broadly applicable across different personalization
methods and demonstrates significant improvements in text-image alignment in
diverse use cases. Our code is anonymously published at
https://anonymous.4open.science/r/Embedding-Adjustment.

</details>


### [238] [Hierarchical Modeling and Architecture Optimization: Review and Unified Framework](https://arxiv.org/abs/2506.22621)
*Paul Saves,Edward Hallé-Hannan,Jasper Bussemaker,Youssef Diouane,Nathalie Bartoli*

Main category: cs.LG

TL;DR: 本文提出了一种统一框架，用于处理混合变量输入的仿真问题，支持连续、整数和分类变量，并引入元变量和部分定义变量以建模层次和条件结构。


<details>
  <summary>Details</summary>
Motivation: 解决混合变量输入中层次、条件和异构结构的建模与优化挑战。

Method: 提出设计空间图，结合特征建模和图论，支持代理模型和分层核函数。

Result: 方法在开源工具箱SMT 2.0中实现，并通过绿色飞机架构案例验证。

Conclusion: 框架为复杂系统设计提供了高效的建模和优化工具。

Abstract: Simulation-based problems involving mixed-variable inputs frequently feature
domains that are hierarchical, conditional, heterogeneous, or tree-structured.
These characteristics pose challenges for data representation, modeling, and
optimization. This paper reviews extensive literature on these structured input
spaces and proposes a unified framework that generalizes existing approaches.
In this framework, input variables may be continuous, integer, or categorical.
A variable is described as meta if its value governs the presence of other
decreed variables, enabling the modeling of conditional and hierarchical
structures.
  We further introduce the concept of partially-decreed variables, whose
activation depends on contextual conditions. To capture these inter-variable
hierarchical relationships, we introduce design space graphs, combining
principles from feature modeling and graph theory. This allows the definition
of general hierarchical domains suitable for describing complex system
architectures. The framework supports the use of surrogate models over such
domains and integrates hierarchical kernels and distances for efficient
modeling and optimization. The proposed methods are implemented in the
open-source Surrogate Modeling Toolbox (SMT 2.0), and their capabilities are
demonstrated through applications in Bayesian optimization for complex system
design, including a case study in green aircraft architecture.

</details>


### [239] [A hierarchical Vovk-Azoury-Warmuth forecaster with discounting for online regression in RKHS](https://arxiv.org/abs/2506.22631)
*Dmitry B. Rokhlin*

Main category: cs.LG

TL;DR: 论文提出了一种名为H-VAW-D的分层算法，用于在线回归问题，结合了DVAW框架和随机特征近似，实现了动态遗憾的最优性能。


<details>
  <summary>Details</summary>
Motivation: 研究在线回归问题，针对时间变化的函数序列，扩展有限维情况下的最优动态遗憾方法到非参数领域。

Method: 提出H-VAW-D算法，结合DVAW框架和随机特征近似，自适应学习折扣因子和随机特征数量。

Result: 算法计算复杂度为$O(T\ln T)$，动态遗憾为$O(T^{2/3}P_T^{1/3} + \sqrt{T}\ln T)$。

Conclusion: H-VAW-D算法在非参数领域实现了动态遗憾的最优性能，具有高效的计算复杂度。

Abstract: We study the problem of online regression with the unconstrained quadratic
loss against a time-varying sequence of functions from a Reproducing Kernel
Hilbert Space (RKHS). Recently, Jacobsen and Cutkosky (2024) introduced a
discounted Vovk-Azoury-Warmuth (DVAW) forecaster that achieves optimal dynamic
regret in the finite-dimensional case. In this work, we lift their approach to
the non-parametric domain by synthesizing the DVAW framework with a random
feature approximation. We propose a fully adaptive, hierarchical algorithm,
which we call H-VAW-D (Hierarchical Vovk-Azoury-Warmuth with Discounting), that
learns both the discount factor and the number of random features. We prove
that this algorithm, which has a per-iteration computational complexity of
$O(T\ln T)$, achieves an expected dynamic regret of $O(T^{2/3}P_T^{1/3} +
\sqrt{T}\ln T)$, where $P_T$ is the functional path length of a comparator
sequence.

</details>


### [240] [Layer Importance for Mathematical Reasoning is Forged in Pre-Training and Invariant after Post-Training](https://arxiv.org/abs/2506.22638)
*Aadim Nepal,Safal Shrestha,Anubhav Shrestha,Minwu Kim,Keith Ross*

Main category: cs.LG

TL;DR: 研究发现，数学推理能力提升依赖于预训练中形成的特定层结构，而非后训练方法（如指令调优、强化学习或知识蒸馏）对模型层的重大改变。


<details>
  <summary>Details</summary>
Motivation: 探讨后训练方法对大型语言模型数学推理能力提升的影响，以及这种提升是否源于模型层结构的重大改变。

Method: 通过层级消融实验，分析基础模型、指令调优、知识蒸馏和强化学习变体在数学推理任务中的表现。

Result: 数学推理任务依赖特定层结构，移除这些层会导致准确率下降高达80%；非数学任务（如事实回忆）则无此现象。

Conclusion: 数学推理需要预训练中形成的专用层，而非后训练方法的调整；这些层也是表征转换发生的主要位置。

Abstract: Large language models can exhibit improved mathematical reasoning
capabilities following post-training with instruction tuning, reinforcement
learning, or knowledge distillation. However, it remains unclear whether these
improvements are driven by major changes in transformer layers or from minor
adjustments that leave the relative layer importance structures of the base
model largely unchanged. We investigate this question through systematic
layer-wise ablation experiments, examining base, instruction-tuned,
knowledge-distilled, and reinforcement learning variants on mathematical
reasoning benchmarks. Our findings show that mathematical reasoning gives rise
to a specific layer importance structure, and this structure persists across
all post-training paradigms. Removal of such layers causes accuracy drops of up
to 80%. In contrast, non-mathematical tasks like factual recall exhibit no
critical layers. This distinction suggests that mathematical reasoning requires
specialized layers that emerge during pre-training, while other non-reasoning
tasks do not. From an information-theoretic perspective, we also observe that
these critical layers are the same layers where major representational
transformation occurs.

</details>


### [241] [Cost-effective Reduced-Order Modeling via Bayesian Active Learning](https://arxiv.org/abs/2506.22645)
*Amir Hossein Rahmati,Nathan M. Urban,Byung-Jun Yoon,Xiaoning Qian*

Main category: cs.LG

TL;DR: BayPOD-AL是一种基于贝叶斯POD的主动学习框架，旨在高效学习复杂系统的降阶模型，减少训练数据需求。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习代理方法依赖大量训练数据，限制了实际应用。BayPOD-AL通过主动学习减少数据需求。

Method: 基于不确定性感知的贝叶斯POD方法，主动选择信息量大的数据点构建训练集。

Result: 在预测杆温度演化的实验中，BayPOD-AL比其他方法更高效，且能泛化到更高时间分辨率的数据集。

Conclusion: BayPOD-AL能有效减少计算成本并提高模型泛化能力，适用于复杂系统建模。

Abstract: Machine Learning surrogates have been developed to accelerate solving systems
dynamics of complex processes in different science and engineering
applications. To faithfully capture governing systems dynamics, these methods
rely on large training datasets, hence restricting their applicability in
real-world problems. In this work, we propose BayPOD-AL, an active learning
framework based on an uncertainty-aware Bayesian proper orthogonal
decomposition (POD) approach, which aims to effectively learn reduced-order
models from high-fidelity full-order models representing complex systems.
Experimental results on predicting the temperature evolution over a rod
demonstrate BayPOD-AL's effectiveness in suggesting the informative data and
reducing computational cost related to constructing a training dataset compared
to other uncertainty-guided active learning strategies. Furthermore, we
demonstrate BayPOD-AL's generalizability and efficiency by evaluating its
performance on a dataset of higher temporal resolution than the training
dataset.

</details>


### [242] [Learning Stochastic Multiscale Models](https://arxiv.org/abs/2506.22655)
*Andrew F. Ilersich,Prasanth B. Nair*

Main category: cs.LG

TL;DR: 提出了一种从观测数据中学习随机多尺度模型的方法，通过粗网格和辅助状态捕捉未解析尺度效应，优于直接数值模拟和闭合模型。


<details>
  <summary>Details</summary>
Motivation: 解决多尺度动态系统的高维状态空间计算挑战。

Method: 使用随机微分方程形式，结合粗网格和辅助状态，采用无前向求解器的变分推断方法学习参数。

Result: 学习的多尺度模型在预测精度上优于直接数值模拟和闭合模型。

Conclusion: 该方法为多尺度建模提供了高效的数据驱动解决方案。

Abstract: The physical sciences are replete with dynamical systems that require the
resolution of a wide range of length and time scales. This presents significant
computational challenges since direct numerical simulation requires
discretization at the finest relevant scales, leading to a high-dimensional
state space. In this work, we propose an approach to learn stochastic
multiscale models in the form of stochastic differential equations directly
from observational data. Our method resolves the state on a coarse mesh while
introducing an auxiliary state to capture the effects of unresolved scales. We
learn the parameters of the multiscale model using a modern forward-solver-free
amortized variational inference method. Our approach draws inspiration from
physics-based multiscale modeling approaches, such as large-eddy simulation in
fluid dynamics, while learning directly from data. We present numerical studies
to demonstrate that our learned multiscale models achieve superior predictive
accuracy compared to direct numerical simulation and closure-type models at
equivalent resolution.

</details>


### [243] [DistShap: Scalable GNN Explanations with Distributed Shapley Values](https://arxiv.org/abs/2506.22668)
*Selahattin Akkas,Aditya Devarakonda,Ariful Azad*

Main category: cs.LG

TL;DR: DistShap是一种并行算法，通过分布式计算Shapley值来高效解释GNN预测，支持百万级特征规模。


<details>
  <summary>Details</summary>
Motivation: 随着GNN的广泛应用，解释其预测的需求增加，但现有方法计算成本高，难以处理大规模图数据。

Method: DistShap通过分布式采样子图、并行执行GNN推理，并解决分布式最小二乘问题来计算边重要性分数。

Result: DistShap在准确性上优于现有方法，并首次支持百万级特征的GNN模型，使用多达128个GPU。

Conclusion: DistShap为大规模GNN解释提供了高效且可扩展的解决方案。

Abstract: With the growing adoption of graph neural networks (GNNs), explaining their
predictions has become increasingly important. However, attributing predictions
to specific edges or features remains computationally expensive. For example,
classifying a node with 100 neighbors using a 3-layer GNN may involve
identifying important edges from millions of candidates contributing to the
prediction. To address this challenge, we propose DistShap, a parallel
algorithm that distributes Shapley value-based explanations across multiple
GPUs. DistShap operates by sampling subgraphs in a distributed setting,
executing GNN inference in parallel across GPUs, and solving a distributed
least squares problem to compute edge importance scores. DistShap outperforms
most existing GNN explanation methods in accuracy and is the first to scale to
GNN models with millions of features by using up to 128 GPUs on the NERSC
Perlmutter supercomputer.

</details>


### [244] [Residual Matrix Transformers: Scaling the Size of the Residual Stream](https://arxiv.org/abs/2506.22696)
*Brian Mak,Jeffrey Flanigan*

Main category: cs.LG

TL;DR: 论文提出了一种名为RMT的新模型，用外积记忆矩阵替代传统Transformer的残差流，具有独立扩展残差流大小、计算效率更高和下游任务表现更好的优势。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer的残差流机制在信息存储和检索上存在效率问题，作者希望通过改进机制提升性能。

Method: 用外积记忆矩阵替代残差流，构建RMT模型。

Result: RMT在相同损失下减少58%的FLOPS、25%的参数和41%的训练token，且在下游任务中表现更优。

Conclusion: RMT通过更高效的残差流扩展和方差传播特性，显著提升了Transformer的性能和效率。

Abstract: The residual stream acts as a memory bus where transformer layers both store
and access features (Elhage et al., 2021). We consider changing the mechanism
for retrieving and storing information in the residual stream, and replace the
residual stream of the transformer with an outer product memory matrix
(Kohonen, 1972, Anderson, 1972). We call this model the Residual Matrix
Transformer (RMT). We find that the RMT enjoys a number of attractive
properties: 1) the size of the residual stream can be scaled independently of
compute and model size, improving performance, 2) the RMT can achieve the same
loss as the transformer with 58% fewer FLOPS, 25% fewer parameters, and 41%
fewer training tokens tokens, and 3) the RMT outperforms the transformer on
downstream evaluations. We theoretically analyze the transformer and the RMT,
and show that the RMT allows for more efficient scaling of the residual stream,
as well as improved variance propagation properties. Code for this project can
be found at https://github.com/bmac3/residual-matrix-transformer.

</details>


### [245] [FairMarket-RL: LLM-Guided Fairness Shaping for Multi-Agent Reinforcement Learning in Peer-to-Peer Markets](https://arxiv.org/abs/2506.22708)
*Shrenik Jadhav,Birva Sevak,Srijita Das,Akhtar Hussain,Wencong Su,Van-Hai Bui*

Main category: cs.LG

TL;DR: FairMarket-RL结合大型语言模型（LLM）和强化学习（RL），提出一种公平感知的P2P交易框架，通过实时公平评分优化交易结果。


<details>
  <summary>Details</summary>
Motivation: 现有P2P交易方法缺乏公平性保障，FairMarket-RL旨在通过LLM和RL的结合解决这一问题。

Method: 使用LLM作为实时公平评估器，结合RL训练交易代理，通过FTB和FBS评分优化奖励机制。

Result: 代理在模拟P2P微电网中实现90%以上买家需求满足，公平评分高于0.80，并减少利润差距。

Conclusion: FairMarket-RL为去中心化能源系统提供了一种可扩展且公平的自主交易解决方案。

Abstract: Peer-to-peer (P2P) trading is increasingly recognized as a key mechanism for
decentralized market regulation, yet existing approaches often lack robust
frameworks to ensure fairness. This paper presents FairMarket-RL, a novel
hybrid framework that combines Large Language Models (LLMs) with Reinforcement
Learning (RL) to enable fairness-aware trading agents. In a simulated P2P
microgrid with multiple sellers and buyers, the LLM acts as a real-time
fairness critic, evaluating each trading episode using two metrics:
Fairness-To-Buyer (FTB) and Fairness-Between-Sellers (FBS). These fairness
scores are integrated into agent rewards through scheduled
{\lambda}-coefficients, forming an adaptive LLM-guided reward shaping loop that
replaces brittle, rule-based fairness constraints. Agents are trained using
Independent Proximal Policy Optimization (IPPO) and achieve equitable outcomes,
fulfilling over 90% of buyer demand, maintaining fair seller margins, and
consistently reaching FTB and FBS scores above 0.80. The training process
demonstrates that fairness feedback improves convergence, reduces buyer
shortfalls, and narrows profit disparities between sellers. With its
language-based critic, the framework scales naturally, and its extension to a
large power distribution system with household prosumers illustrates its
practical applicability. FairMarket-RL thus offers a scalable, equity-driven
solution for autonomous trading in decentralized energy systems.

</details>


### [246] [Generalized Linear Mode Connectivity for Transformers](https://arxiv.org/abs/2506.22712)
*Alexander Theus,Alessandro Cabodi,Sotiris Anagnostidis,Antonio Orvieto,Sidak Pal Singh,Valentina Boeva*

Main category: cs.LG

TL;DR: 论文提出了一种统一框架，用于捕捉神经网络参数空间中的四种对称性类别，从而扩展了线性模式连通性（LMC）的研究范围，并在Vision Transformers和GPT-2模型中发现了低或零障碍的线性插值路径。


<details>
  <summary>Details</summary>
Motivation: 研究神经网络损失景观的几何结构对理解和优化深度学习模型至关重要，尤其是线性模式连通性（LMC）现象。然而，参数空间中的对称性（如神经元排列）使得功能相同的模型看起来不同，限制了现有方法的适用范围。

Method: 引入了一个统一框架，涵盖四种对称性类别：排列、半排列、正交变换和一般可逆映射，扩展了重新参数化的范围，并将许多先前方法作为特例包含在内。

Result: 该框架首次在独立训练的Vision Transformers和GPT-2模型之间发现了低或零障碍的线性插值路径。

Conclusion: 研究揭示了损失景观中更深层次的结构，强调了对称性分析在理解模型空间几何中的重要性。

Abstract: Understanding the geometry of neural network loss landscapes is a central
question in deep learning, with implications for generalization and
optimization. A striking phenomenon is linear mode connectivity (LMC), where
independently trained models can be connected by low- or zero-loss paths,
despite appearing to lie in separate loss basins. However, this is often
obscured by symmetries in parameter space -- such as neuron permutations --
which make functionally equivalent models appear dissimilar. Prior work has
predominantly focused on neuron re-ordering through permutations, but such
approaches are limited in scope and fail to capture the richer symmetries
exhibited by modern architectures such as Transformers. In this work, we
introduce a unified framework that captures four symmetry classes:
permutations, semi-permutations, orthogonal transformations, and general
invertible maps -- broadening the set of valid reparameterizations and
subsuming many previous approaches as special cases. Crucially, this
generalization enables, for the first time, the discovery of low- and
zero-barrier linear interpolation paths between independently trained Vision
Transformers and GPT-2 models. These results reveal deeper structure in the
loss landscape and underscore the importance of symmetry-aware analysis for
understanding model space geometry.

</details>


### [247] [BEST-Route: Adaptive LLM Routing with Test-Time Optimal Compute](https://arxiv.org/abs/2506.22716)
*Dujian Ding,Ankur Mallick,Shaokun Zhang,Chi Wang,Daniel Madrigal,Mirian Del Carmen Hipolito Garcia,Menglin Xia,Laks V. S. Lakshmanan,Qingyun Wu,Victor Rühle*

Main category: cs.LG

TL;DR: BEST-Route是一种新型路由框架，通过动态选择模型和生成多个响应来优化成本与性能的权衡，实验显示可节省60%成本且性能下降不到1%。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）部署成本高，现有路由方法因单响应限制导致过度依赖昂贵模型，未能充分利用低成本模型的潜力。

Method: 提出BEST-Route框架，根据查询难度和质量阈值动态选择模型及生成多个响应，以提升小模型表现。

Result: 在真实数据集上实验表明，该方法节省60%成本，性能下降不到1%。

Conclusion: BEST-Route有效平衡成本与性能，为LLM部署提供经济高效的解决方案。

Abstract: Large language models (LLMs) are powerful tools but are often expensive to
deploy at scale. LLM query routing mitigates this by dynamically assigning
queries to models of varying cost and quality to obtain a desired trade-off.
Prior query routing approaches generate only one response from the selected
model and a single response from a small (inexpensive) model was often not good
enough to beat a response from a large (expensive) model due to which they end
up overusing the large model and missing out on potential cost savings.
However, it is well known that for small models, generating multiple responses
and selecting the best can enhance quality while remaining cheaper than a
single large-model response. We leverage this idea to propose BEST-Route, a
novel routing framework that chooses a model and the number of responses to
sample from it based on query difficulty and the quality thresholds.
Experiments on real-world datasets demonstrate that our method reduces costs by
up to 60% with less than 1% performance drop.

</details>


### [248] [Robust Tensor Completion via Gradient Tensor Nulclear L1-L2 Norm for Traffic Data Recovery](https://arxiv.org/abs/2506.22732)
*Hao Shu,Jicheng Li,Tianyv Lei,Lijun Sun*

Main category: cs.LG

TL;DR: 论文提出了一种名为RTC-GTNLN的新方法，通过引入张量L1-L2范数作为非凸秩替代，并结合梯度域特征融合策略，有效解决了交通数据中同时存在的缺失值和噪声问题。实验表明该方法优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现实中的时空交通数据常因传感器故障和通信问题同时存在缺失值和噪声，现有方法无法有效处理这种双重退化问题，因此需要更高效的数据恢复方法。

Method: 提出张量L1-L2范数作为非凸秩替代，并结合梯度域特征融合策略，构建了RTC-GTNLN模型，充分利用全局低秩性和局部一致性。

Result: 在多个真实交通数据集上的实验表明，RTC-GTNLN在同时处理缺失值和噪声的场景中优于现有方法。

Conclusion: RTC-GTNLN模型通过创新的非凸秩替代和特征融合策略，显著提升了数据恢复的准确性，适用于复杂交通数据场景。

Abstract: In real-world scenarios, spatiotemporal traffic data frequently experiences
dual degradation from missing values and noise caused by sensor malfunctions
and communication failures. Therefore, effective data recovery methods are
essential to ensure the reliability of downstream data-driven applications.
while classical tensor completion methods have been widely adopted, they are
incapable of modeling noise, making them unsuitable for complex scenarios
involving simultaneous data missingness and noise interference. Existing Robust
Tensor Completion (RTC) approaches offer potential solutions by separately
modeling the actual tensor data and noise. However, their effectiveness is
often constrained by the over-relaxation of convex rank surrogates and the
suboptimal utilization of local consistency, leading to inadequate model
accuracy. To address these limitations, we first introduce the tensor L1-L2
norm, a novel non-convex tensor rank surrogate that functions as an effective
low-rank representation tool. Leveraging an advanced feature fusion strategy,
we further develop the gradient tensor L1-L2 norm by incorporating the tensor
L1-L2 norm in the gradient domain. By integrating the gradient tensor nuclear
L1-L2 norm into the RTC framework, we propose the Robust Tensor Completion via
Gradient Tensor Nuclear L1-L2 Norm (RTC-GTNLN) model, which not only fully
exploits both global low-rankness and local consistency without trade-off
parameter, but also effectively handles the dual degradation challenges of
missing data and noise in traffic data. Extensive experiments conducted on
multiple real-world traffic datasets demonstrate that the RTC-GTNLN model
consistently outperforms existing state-of-the-art methods in complex recovery
scenarios involving simultaneous missing values and noise.

</details>


### [249] [Multimodal Atmospheric Super-Resolution With Deep Generative Models](https://arxiv.org/abs/2506.22780)
*Dibyajyoti Chakraborty,Haiwen Guan,Jason Stock,Troy Arcomano,Guido Cervone,Romit Maulik*

Main category: cs.LG

TL;DR: 基于分数的扩散模型通过学习数据的对数概率密度梯度，实现复杂分布的采样，并支持零样本条件生成。本文将其应用于高维动态系统的超分辨率任务，结合多模态数据实现准确恢复。


<details>
  <summary>Details</summary>
Motivation: 探索基于分数的扩散模型在数据与模型融合中的潜力，特别是在高维动态系统的超分辨率任务中，利用实时低分辨率数据提升生成效果。

Method: 通过学习分数函数并逆转加噪过程，结合贝叶斯框架更新预训练模型的隐式分布，应用于ERA5和IGRA数据集的超分辨率任务。

Result: 实验表明，模型能够准确恢复高维状态，并在多源低质量数据下平衡不同模态的影响。

Conclusion: 基于分数的扩散模型为数据融合和不确定性估计提供了新范式，特别适用于多模态数据的动态系统建模。

Abstract: Score-based diffusion modeling is a generative machine learning algorithm
that can be used to sample from complex distributions. They achieve this by
learning a score function, i.e., the gradient of the log-probability density of
the data, and reversing a noising process using the same. Once trained,
score-based diffusion models not only generate new samples but also enable
zero-shot conditioning of the generated samples on observed data. This promises
a novel paradigm for data and model fusion, wherein the implicitly learned
distributions of pretrained score-based diffusion models can be updated given
the availability of online data in a Bayesian formulation. In this article, we
apply such a concept to the super-resolution of a high-dimensional dynamical
system, given the real-time availability of low-resolution and experimentally
observed sparse sensor measurements from multimodal data. Additional analysis
on how score-based sampling can be used for uncertainty estimates is also
provided. Our experiments are performed for a super-resolution task that
generates the ERA5 atmospheric dataset given sparse observations from a
coarse-grained representation of the same and/or from unstructured experimental
observations of the IGRA radiosonde dataset. We demonstrate accurate recovery
of the high dimensional state given multiple sources of low-fidelity
measurements. We also discover that the generative model can balance the
influence of multiple dataset modalities during spatiotemporal reconstructions.

</details>


### [250] [Riemannian-Geometric Fingerprints of Generative Models](https://arxiv.org/abs/2506.22802)
*Hae Jin Song,Laurent Itti*

Main category: cs.LG

TL;DR: 论文提出了一种基于黎曼几何的生成模型指纹定义和计算方法，用于模型归属和区分合成数据与人类数据。


<details>
  <summary>Details</summary>
Motivation: 生成模型的快速发展和应用引发了对模型指纹和归属问题的需求，以保护知识产权、确保内容来源的可信度，并应对模型崩溃的威胁。

Method: 采用黎曼几何方法，定义和计算生成模型的指纹，利用测地距离和基于kNN的黎曼中心质量替代欧几里得距离和最近邻搜索。

Result: 提出的方法在区分多种生成模型上表现更优，涵盖不同数据集、分辨率和模态，显著提升了模型归属的准确性和泛化能力。

Conclusion: 基于黎曼几何的指纹定义和计算方法在生成模型归属和区分合成数据方面具有实际应用价值。

Abstract: Recent breakthroughs and rapid integration of generative models (GMs) have
sparked interest in the problem of model attribution and their fingerprints.
For instance, service providers need reliable methods of authenticating their
models to protect their IP, while users and law enforcement seek to verify the
source of generated content for accountability and trust. In addition, a
growing threat of model collapse is arising, as more model-generated data are
being fed back into sources (e.g., YouTube) that are often harvested for
training ("regurgitative training"), heightening the need to differentiate
synthetic from human data. Yet, a gap still exists in understanding generative
models' fingerprints, we believe, stemming from the lack of a formal framework
that can define, represent, and analyze the fingerprints in a principled way.
To address this gap, we take a geometric approach and propose a new definition
of artifact and fingerprint of GMs using Riemannian geometry, which allows us
to leverage the rich theory of differential geometry. Our new definition
generalizes previous work (Song et al., 2024) to non-Euclidean manifolds by
learning Riemannian metrics from data and replacing the Euclidean distances and
nearest-neighbor search with geodesic distances and kNN-based Riemannian center
of mass. We apply our theory to a new gradient-based algorithm for computing
the fingerprints in practice. Results show that it is more effective in
distinguishing a large array of GMs, spanning across 4 different datasets in 2
different resolutions (64 by 64, 256 by 256), 27 model architectures, and 2
modalities (Vision, Vision-Language). Using our proposed definition
significantly improves the performance on model attribution, as well as a
generalization to unseen datasets, model types, and modalities, suggesting its
practical efficacy.

</details>


### [251] [BayesLoRA: Task-Specific Uncertainty in Low-Rank Adapters](https://arxiv.org/abs/2506.22809)
*Cooper Doyle*

Main category: cs.LG

TL;DR: BayesLoRA是一个任务特定的不确定性量化框架，结合了MC-Dropout和LoRA，为下游工作流提供定制化的不确定性评估。


<details>
  <summary>Details</summary>
Motivation: 现有方法多为通用型，缺乏针对特定任务的不确定性量化，BayesLoRA旨在填补这一空白。

Method: 将MC-Dropout集成到LoRA中，通过数学和实证分析验证其在微调分布外的方差放大特性。

Result: BayesLoRA能够为智能体决策提供可靠的不确定性估计。

Conclusion: BayesLoRA为任务特定的不确定性量化提供了有效解决方案，适用于智能体决策场景。

Abstract: We propose BayesLoRA, a task-specific uncertainty quantification framework
that integrates MC-Dropout into Low-Rank Adapters (LoRA). Unlike
general-purpose transformer uncertainty methods, BayesLoRA provides guardrails
tailored to downstream workflows, enabling agents to introspect and modulate
behavior under uncertainty. We demonstrate mathematically and empirically that
LoRA adapters exhibit amplified variance outside fine-tuning distributions,
yielding reliable confidence estimates for agentic decision-making.

</details>


### [252] [Deep learning 40 years of human migration](https://arxiv.org/abs/2506.22821)
*Thomas Gaskin,Guy J. Abel*

Main category: cs.LG

TL;DR: 论文介绍了一个关于1990年至今230个国家与地区间年度移民流动与存量的详细数据集，通过深度循环神经网络学习迁移模式，并提供置信区间。


<details>
  <summary>Details</summary>
Motivation: 提供全面的移民数据，填补传统方法在时间分辨率和准确性上的不足。

Method: 使用深度循环神经网络，结合18种协变量训练模型，并通过集成网络和不确定性传播生成置信区间。

Result: 模型在未见数据上验证，显著优于传统方法，提高了时间分辨率。

Conclusion: 该模型开源，为未来移民研究提供了宝贵资源。

Abstract: We present a novel and detailed dataset on origin-destination annual
migration flows and stocks between 230 countries and regions, spanning the
period from 1990 to the present. Our flow estimates are further disaggregated
by country of birth, providing a comprehensive picture of migration over the
last 43 years. The estimates are obtained by training a deep recurrent neural
network to learn flow patterns from 18 covariates for all countries, including
geographic, economic, cultural, societal, and political information. The
recurrent architecture of the neural network means that the entire past can
influence current migration patterns, allowing us to learn long-range temporal
correlations. By training an ensemble of neural networks and additionally
pushing uncertainty on the covariates through the trained network, we obtain
confidence bounds for all our estimates, allowing researchers to pinpoint the
geographic regions most in need of additional data collection. We validate our
approach on various test sets of unseen data, demonstrating that it
significantly outperforms traditional methods estimating five-year flows while
delivering a significant increase in temporal resolution. The model is fully
open source: all training data, neural network weights, and training code are
made public alongside the migration estimates, providing a valuable resource
for future studies of human migration.

</details>


### [253] [xLSTMAD: A Powerful xLSTM-based Method for Anomaly Detection](https://arxiv.org/abs/2506.22837)
*Kamil Faber,Marcin Pietroń,Dominik Żurek,Roberto Corizzo*

Main category: cs.LG

TL;DR: xLSTMAD是一种基于xLSTM架构的新型异常检测方法，首次将xLSTM应用于异常检测任务，并在多变量时间序列数据上表现出色。


<details>
  <summary>Details</summary>
Motivation: 尽管xLSTM在时间序列预测和语言建模中表现出色，但尚未有人将其用于异常检测。本文旨在填补这一空白。

Method: 提出xLSTMAD，采用编码器-解码器架构，包括预测（xLSTMAD-F）和重建（xLSTMAD-R）两种变体，并使用MSE和SoftDTW两种损失函数。

Result: 在TSB-AD-M基准测试中，xLSTMAD优于23种基线方法，展示了卓越的准确性。

Conclusion: xLSTMAD首次展示了xLSTM在异常检测中的强大能力，为未来研究开辟了新方向。

Abstract: The recently proposed xLSTM is a powerful model that leverages expressive
multiplicative gating and residual connections, providing the temporal capacity
needed for long-horizon forecasting and representation learning. This
architecture has demonstrated success in time series forecasting, lossless
compression, and even large-scale language modeling tasks, where its linear
memory footprint and fast inference make it a viable alternative to
Transformers. Despite its growing popularity, no prior work has explored xLSTM
for anomaly detection. In this work, we fill this gap by proposing xLSTMAD, the
first anomaly detection method that integrates a full encoder-decoder xLSTM
architecture, purpose-built for multivariate time series data. Our encoder
processes input sequences to capture historical context, while the decoder is
devised in two separate variants of the method. In the forecasting approach,
the decoder iteratively generates forecasted future values xLSTMAD-F, while the
reconstruction approach reconstructs the input time series from its encoded
counterpart xLSTMAD-R. We investigate the performance of two loss functions:
Mean Squared Error (MSE), and Soft Dynamic Time Warping (SoftDTW) to consider
local reconstruction fidelity and global sequence alignment, respectively. We
evaluate our method on the comprehensive TSB-AD-M benchmark, which spans 17
real-world datasets, using state-of-the-art challenging metrics such as VUS-PR.
In our results, xLSTM showcases state-of-the-art accuracy, outperforming 23
popular anomaly detection baselines. Our paper is the first work revealing the
powerful modeling capabilities of xLSTM for anomaly detection, paving the way
for exciting new developments on this subject. Our code is available at:
https://github.com/Nyderx/xlstmad

</details>


### [254] [A Reinforcement Learning Approach for Optimal Control in Microgrids](https://arxiv.org/abs/2506.22995)
*Davide Salaorni,Federico Bianchi,Francesco Trovò,Marcello Restelli*

Main category: cs.LG

TL;DR: 本文提出了一种基于强化学习（RL）的微电网能源管理优化方法，通过数字孪生（DT）模拟储能系统动态，实验结果表明其优于基于规则的方法和其他RL基准。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源（RESs）的日益普及，传统电网需要新的方法来管理分散的能源生产和消费，微电网（MGs）为此提供了可行的解决方案。

Method: 提出了一种RL代理，通过学习历史能源生产、消费和市场数据，优化能源交易和存储策略，并利用数字孪生模拟储能系统动态。

Result: 实验验证表明，该方法优于基于规则的方法和其他RL基准，为智能微电网管理提供了稳健的解决方案。

Conclusion: 基于RL的微电网能源管理方法具有实际应用潜力，能够有效提升能源系统的智能化水平。

Abstract: The increasing integration of renewable energy sources (RESs) is transforming
traditional power grid networks, which require new approaches for managing
decentralized energy production and consumption. Microgrids (MGs) provide a
promising solution by enabling localized control over energy generation,
storage, and distribution. This paper presents a novel reinforcement learning
(RL)-based methodology for optimizing microgrid energy management.
Specifically, we propose an RL agent that learns optimal energy trading and
storage policies by leveraging historical data on energy production,
consumption, and market prices. A digital twin (DT) is used to simulate the
energy storage system dynamics, incorporating degradation factors to ensure a
realistic emulation of the analysed setting. Our approach is validated through
an experimental campaign using real-world data from a power grid located in the
Italian territory. The results indicate that the proposed RL-based strategy
outperforms rule-based methods and existing RL benchmarks, offering a robust
solution for intelligent microgrid management.

</details>


### [255] [Quantum Neural Networks for Wind Energy Forecasting: A Comparative Study of Performance and Scalability with Classical Models](https://arxiv.org/abs/2506.22845)
*Batuhan Hangun,Oguz Altun,Onder Eyecioglu*

Main category: cs.LG

TL;DR: 该论文研究了量子神经网络（QNNs）在风力涡轮机功率输出预测中的应用，通过实验验证其性能与经典方法相当甚至略优，并探讨了数据集规模和电路复杂度的影响。


<details>
  <summary>Details</summary>
Motivation: 随着智能电网和可再生能源系统的普及，机器学习在电力需求预测和系统干扰检测中扮演重要角色。QNNs作为一种新兴的量子机器学习方法，具有潜力替代经典方法。

Method: 研究评估了六种基于Z Feature Map数据编码和不同ansatz结构的QNN配置，通过交叉验证和未见数据集测试比较其预测性能和模拟时间。

Result: 实验表明，QNNs的预测性能与经典方法相当甚至略优，同时揭示了数据集规模和电路复杂度对性能的影响。

Conclusion: 该研究为能源领域的研究者提供了将量子机器学习应用于实际问题的有价值见解。

Abstract: Quantum Neural Networks (QNNs), a prominent approach in Quantum Machine
Learning (QML), are emerging as a powerful alternative to classical machine
learning methods. Recent studies have focused on the applicability of QNNs to
various tasks, such as time-series forecasting, prediction, and classification,
across a wide range of applications, including cybersecurity and medical
imaging. With the increased use of smart grids driven by the integration of
renewable energy systems, machine learning plays an important role in
predicting power demand and detecting system disturbances. This study provides
an in-depth investigation of QNNs for predicting the power output of a wind
turbine. We assess the predictive performance and simulation time of six QNN
configurations that are based on the Z Feature Map for data encoding and
varying ansatz structures. Through detailed cross-validation experiments and
tests on an unseen hold-out dataset, we experimentally demonstrate that QNNs
can achieve predictive performance that is competitive with, and in some cases
marginally better than, the benchmarked classical approaches. Our results also
reveal the effects of dataset size and circuit complexity on predictive
performance and simulation time. We believe our findings will offer valuable
insights for researchers in the energy domain who wish to incorporate quantum
machine learning into their work.

</details>


### [256] [Fragile, Robust, and Antifragile: A Perspective from Parameter Responses in Reinforcement Learning Under Stress](https://arxiv.org/abs/2506.23036)
*Zain ul Abdeen,Ming Jin*

Main category: cs.LG

TL;DR: 本文通过系统分析网络参数在内外部压力下的表现，探索强化学习策略的鲁棒性，提出了一种基于参数分类的框架，并验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 受神经科学中突触可塑性的启发，研究旨在通过内外部压力测试强化学习策略的鲁棒性，并识别出对策略性能有不同影响的参数类型。

Method: 通过突触过滤引入内部压力，对抗攻击引入外部压力，将参数分为脆弱、鲁棒或反脆弱三类，并定义参数评分量化其特性。

Result: 在Mujoco连续控制环境中验证了框架的有效性，发现反脆弱参数能提升策略在压力下的性能。

Conclusion: 研究结果为设计鲁棒和反脆弱的强化学习系统提供了基础，展示了目标过滤技术在提升策略适应性方面的潜力。

Abstract: This paper explores Reinforcement learning (RL) policy robustness by
systematically analyzing network parameters under internal and external
stresses. Inspired by synaptic plasticity in neuroscience, synaptic filtering
introduces internal stress by selectively perturbing parameters, while
adversarial attacks apply external stress through modified agent observations.
This dual approach enables the classification of parameters as fragile, robust,
or antifragile, based on their influence on policy performance in clean and
adversarial settings. Parameter scores are defined to quantify these
characteristics, and the framework is validated on PPO-trained agents in Mujoco
continuous control environments. The results highlight the presence of
antifragile parameters that enhance policy performance under stress,
demonstrating the potential of targeted filtering techniques to improve RL
policy adaptability. These insights provide a foundation for future
advancements in the design of robust and antifragile RL systems.

</details>


### [257] [Scalable Structure Learning of Bayesian Networks by Learning Algorithm Ensembles](https://arxiv.org/abs/2506.22848)
*Shengcai Liu,Hui Ou-yang,Zhiyuan Wang,Cheng Chen,Qijun Cai,Yew-Soon Ong,Ke Tang*

Main category: cs.LG

TL;DR: 论文提出了一种基于结构学习集成（SLE）的方法Auto-SLE，用于提升大规模贝叶斯网络（BN）结构学习的准确性和稳定性，并通过实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 解决现有分治策略（D&D）在大规模BN结构学习中学习精度不稳定的问题。

Method: 引入结构学习集成（SLE）并结合自动学习方法Auto-SLE，将其集成到D&D方法中。

Result: 实验表明，该方法在涉及10,000变量的数据集上通常能提升30%∼225%的准确性，并能泛化到更大规模（如30,000变量）和不同网络特性的数据集。

Conclusion: SLE及其自动学习方法在可扩展的BN结构学习中具有显著潜力。

Abstract: Learning the structure of Bayesian networks (BNs) from data is challenging,
especially for datasets involving a large number of variables. The recently
proposed divide-and-conquer (D\&D) strategies present a promising approach for
learning large BNs. However, they still face a main issue of unstable learning
accuracy across subproblems. In this work, we introduce the idea of employing
structure learning ensemble (SLE), which combines multiple BN structure
learning algorithms, to consistently achieve high learning accuracy. We further
propose an automatic approach called Auto-SLE for learning near-optimal SLEs,
addressing the challenge of manually designing high-quality SLEs. The learned
SLE is then integrated into a D\&D method. Extensive experiments firmly show
the superiority of our method over D\&D methods with single BN structure
learning algorithm in learning large BNs, achieving accuracy improvement
usually by 30\%$\sim$225\% on datasets involving 10,000 variables. Furthermore,
our method generalizes well to datasets with many more (e.g., 30000) variables
and different network characteristics than those present in the training data
for learning the SLE. These results indicate the significant potential of
employing (automatic learning of) SLEs for scalable BN structure learning.

</details>


### [258] [External Data-Enhanced Meta-Representation for Adaptive Probabilistic Load Forecasting](https://arxiv.org/abs/2506.23201)
*Haoran Li,Muhao Guo,Marija Ilic,Yang Weng,Guangchun Ruan*

Main category: cs.LG

TL;DR: 提出了一种基于超网络和专家混合机制的新框架M2oE2，用于动态适应外部数据的住宅负荷预测，显著提高了准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源和需求侧灵活性的增加，准确的住宅负荷预测对电力系统可靠性至关重要，但现有模型忽略了外部因素的异质性。

Method: 设计了一个超网络框架，动态调整基础深度学习模型的参数，并集成专家混合机制以提升效率和鲁棒性。

Result: M2oE2在多种负荷数据集上表现优于现有方法，准确性和鲁棒性显著提升。

Conclusion: M2oE2通过动态适应外部数据，为负荷预测提供了更高效和鲁棒的解决方案。

Abstract: Accurate residential load forecasting is critical for power system
reliability with rising renewable integration and demand-side flexibility.
However, most statistical and machine learning models treat external factors,
such as weather, calendar effects, and pricing, as extra input, ignoring their
heterogeneity, and thus limiting the extraction of useful external information.
We propose a paradigm shift: external data should serve as meta-knowledge to
dynamically adapt the forecasting model itself. Based on this idea, we design a
meta-representation framework using hypernetworks that modulate selected
parameters of a base Deep Learning (DL) model in response to external
conditions. This provides both expressivity and adaptability. We further
integrate a Mixture-of-Experts (MoE) mechanism to enhance efficiency through
selective expert activation, while improving robustness by filtering redundant
external inputs. The resulting model, dubbed as a Meta Mixture of Experts for
External data (M2oE2), achieves substantial improvements in accuracy and
robustness with limited additional overhead, outperforming existing
state-of-the-art methods in diverse load datasets. The dataset and source code
are publicly available at
https://github.com/haorandd/M2oE2\_load\_forecast.git.

</details>


### [259] [P$^2$U: Progressive Precision Update For Efficient Model Distribution](https://arxiv.org/abs/2506.22871)
*Homayun Afrabandpey,Hamed Rezazadegan Tavakoli*

Main category: cs.LG

TL;DR: 提出了一种名为渐进精度更新（P²U）的方法，通过在带宽受限环境中传输低精度模型及其更新，优化了模型分发的效率。


<details>
  <summary>Details</summary>
Motivation: 在带宽受限环境中高效分发模型的需求日益增长，需要一种既能减少带宽使用又能保持模型性能的方法。

Method: P²U传输低精度模型及其与高精度模型的差异更新，实验覆盖多种模型架构和数据集。

Result: P²U在准确性、带宽使用和延迟之间取得了更好的平衡，支持激进量化（如4位）而不显著影响性能。

Conclusion: P²U是一种适用于低资源环境（如联邦学习、边缘计算和物联网）的高效模型分发解决方案，且可与现有压缩技术结合使用。

Abstract: Efficient model distribution is becoming increasingly critical in
bandwidth-constrained environments. In this paper, we propose a simple yet
effective approach called Progressive Precision Update (P$^2$U) to address this
problem. Instead of transmitting the original high-precision model, P$^2$U
transmits a lower-bit precision model, coupled with a model update representing
the difference between the original high-precision model and the transmitted
low precision version. With extensive experiments on various model
architectures, ranging from small models ($1 - 6$ million parameters) to a
large model (more than $100$ million parameters) and using three different data
sets, e.g., chest X-Ray, PASCAL-VOC, and CIFAR-100, we demonstrate that P$^2$U
consistently achieves better tradeoff between accuracy, bandwidth usage and
latency. Moreover, we show that when bandwidth or startup time is the priority,
aggressive quantization (e.g., 4-bit) can be used without severely compromising
performance. These results establish P$^2$U as an effective and practical
solution for scalable and efficient model distribution in low-resource
settings, including federated learning, edge computing, and IoT deployments.
Given that P$^2$U complements existing compression techniques and can be
implemented alongside any compression method, e.g., sparsification,
quantization, pruning, etc., the potential for improvement is even greater.

</details>


### [260] [Interpretable Time Series Autoregression for Periodicity Quantification](https://arxiv.org/abs/2506.22895)
*Xinyu Chen,Vassilis Digalakis Jr,Lijun Ding,Dingyi Zhuang,Jinhua Zhao*

Main category: cs.LG

TL;DR: 提出了一种基于稀疏自回归框架的模型，用于时间序列分析，通过ℓ0范数增强可解释性，并利用混合整数优化（MIO）和决策变量剪枝（DVP）策略加速求解。


<details>
  <summary>Details</summary>
Motivation: 传统时间序列自回归模型在捕捉自相关性和周期性方面存在局限性，需要一种更可解释且高效的方法。

Method: 提出稀疏自回归框架，结合ℓ0范数约束；针对时变和多维时间序列，分别采用MIO和两阶段优化方案。

Result: DVP策略显著加速MIO求解；模型成功识别了人类移动的周期性和气候变化模式（如厄尔尼诺现象）。

Conclusion: 该模型在可解释性和效率上表现优异，适用于复杂时空数据分析。

Abstract: Time series autoregression is a classical statistical model for capturing
auto-correlations and identifying temporal patterns such as periodicity and
seasonality. In this work, we propose a novel sparse autoregression framework
from an interpretable machine learning perspective and the model
interpretability for periodicity quantification is reinforced by $\ell_0$-norm
induced sparsity constraints. On the time-varying time series data, we
reformulate the sparse autoregression and convert the involved optimization
problem into a mixed-integer optimization (MIO). To accelerate it, we develop a
subspace pursuit based decision variable pruning (DVP) strategy to reduce the
search space. On the multidimensional time series that involves complicated
spatial and temporal dimensions, we propose a spatially- and time-varying
sparse autoregression model and resolve the corresponding MIO problem by
developing a two-stage optimization scheme. In particular, the proposed scheme
makes the model scalable to large problems even with millions of decision
variables. Empirically, we conduct extensive experiments to evaluate the
proposed models on real-world time series data. First, we demonstrate that the
MIO solver can be drastically accelerated through the DVP strategy, while
maintaining the same solution quality as a full MIO solver. Applying the
time-varying sparse autoregression model to ridesharing trip data, we uncover
both daily and weekly periodicities and reveal long-term changes in regularity
of human mobility. Second, we demonstrate the spatial patterns of yearly
seasonality in climate variable time series such as temperature and
precipitation across the past four decades, and our model allows to discover
dynamic climate patterns and identify climate phenomena such as El Nino in sea
surface temperature.

</details>


### [261] [Missing-Modality-Aware Graph Neural Network for Cancer Classification](https://arxiv.org/abs/2506.22901)
*Sina Tabakhi,Haiping Lu*

Main category: cs.LG

TL;DR: MAGNET提出了一种基于图神经网络的缺失模态感知方法，通过多模态融合和患者图构建，显著提升了多组学数据分类性能。


<details>
  <summary>Details</summary>
Motivation: 多模态生物数据中缺失模态的问题限制了现有融合方法的性能，尤其是面对多样化的缺失模式和模态数量增加时的计算复杂性。

Method: MAGNET采用患者-模态多头注意力机制融合低维模态嵌入，并构建患者图进行预测，复杂度随模态数量线性增长。

Result: 在三个公共多组学数据集上的实验表明，MAGNET在真实缺失模式下优于现有融合方法。

Conclusion: MAGNET有效解决了多模态数据中的缺失问题，为生物医学数据分析提供了新工具。

Abstract: A key challenge in learning from multimodal biological data is missing
modalities, where all data from some modalities are missing for some patients.
Current fusion methods address this by excluding patients with missing
modalities, imputing missing modalities, or making predictions directly with
partial modalities. However, they often struggle with diverse missing-modality
patterns and the exponential growth of the number of such patterns as the
number of modalities increases. To address these limitations, we propose MAGNET
(Missing-modality-Aware Graph neural NETwork) for direct prediction with
partial modalities, which introduces a patient-modality multi-head attention
mechanism to fuse lower-dimensional modality embeddings based on their
importance and missingness. MAGNET's complexity increases linearly with the
number of modalities while adapting to missing-pattern variability. To generate
predictions, MAGNET further constructs a patient graph with fused multimodal
embeddings as node features and the connectivity determined by the modality
missingness, followed by a conventional graph neural network. Experiments on
three public multiomics datasets for cancer classification, with real-world
instead of artificial missingness, show that MAGNET outperforms the
state-of-the-art fusion methods. The data and code are available at
https://github.com/SinaTabakhi/MAGNET.

</details>


### [262] [Towards Time Series Generation Conditioned on Unstructured Natural Language](https://arxiv.org/abs/2506.22927)
*Jaeyun Woo,Jiseok Lee,Brian Kenji Iwana*

Main category: cs.LG

TL;DR: 本文提出了一种基于自然语言描述生成时间序列的新方法，结合扩散模型和语言模型，展示了其可行性，并构建了一个包含63,010对时间序列-描述的新数据集。


<details>
  <summary>Details</summary>
Motivation: 尽管生成式AI在图像和文本领域取得了显著进展，但时间序列生成仍不成熟，而时间序列在金融、气候等领域应用广泛。

Method: 使用扩散模型与语言模型结合，从文本描述生成时间序列。

Result: 证明了基于自然语言的时间序列生成是可行的，并展示了其在定制预测、数据增强等方面的应用潜力。

Conclusion: 该方法为时间序列生成提供了新思路，并公开了一个新的数据集以支持未来研究。

Abstract: Generative Artificial Intelligence (AI) has rapidly become a powerful tool,
capable of generating various types of data, such as images and text. However,
despite the significant advancement of generative AI, time series generative AI
remains underdeveloped, even though the application of time series is essential
in finance, climate, and numerous fields. In this research, we propose a novel
method of generating time series conditioned on unstructured natural language
descriptions. We use a diffusion model combined with a language model to
generate time series from the text. Through the proposed method, we demonstrate
that time series generation based on natural language is possible. The proposed
method can provide various applications such as custom forecasting, time series
manipulation, data augmentation, and transfer learning. Furthermore, we
construct and propose a new public dataset for time series generation,
consisting of 63,010 time series-description pairs.

</details>


### [263] [Mathematical Computation on High-dimensional Data via Array Programming and Parallel Acceleration](https://arxiv.org/abs/2506.22929)
*Chen Zhang*

Main category: cs.LG

TL;DR: 提出了一种基于空间完备性的并行计算架构，用于处理高维数据，支持科学计算和机器学习方法的集成。


<details>
  <summary>Details</summary>
Motivation: 深度学习在高维数据中面临维度诅咒的计算挑战，现有工具缺乏对高级分析的数学统计支持。

Method: 通过将高维数据分解为维度无关的结构，实现分布式处理，并集成数据挖掘和并行优化的机器学习方法。

Result: 该框架支持跨数据类型（如医学和自然图像）的科学计算。

Conclusion: 提出的架构为高维数据处理提供了一种高效且统一的解决方案。

Abstract: While deep learning excels in natural image and language processing, its
application to high-dimensional data faces computational challenges due to the
dimensionality curse. Current large-scale data tools focus on business-oriented
descriptive statistics, lacking mathematical statistics support for advanced
analysis. We propose a parallel computation architecture based on space
completeness, decomposing high-dimensional data into dimension-independent
structures for distributed processing. This framework enables seamless
integration of data mining and parallel-optimized machine learning methods,
supporting scientific computations across diverse data types like medical and
natural images within a unified system.

</details>


### [264] [Infinite Sampling: Efficient and Stable Grouped RL Training for Large Language Models](https://arxiv.org/abs/2506.22950)
*Liangyu Wang,Huanyi Xie,Xinhai Wang,Tianjin Huang,Mengdi Li,Di Wang*

Main category: cs.LG

TL;DR: 提出了Infinite Sampling框架，通过解耦组大小与GPU内存使用，显著降低内存开销并提升训练效率。


<details>
  <summary>Details</summary>
Motivation: 解决GRPO算法在训练大型语言模型时因生成和存储多响应导致的高内存开销问题。

Method: 包括微采样组、连续采样和长度感知调度器，优化内存和计算资源利用。

Result: 微采样组减少峰值内存50%以上，Infinite Sampling提升吞吐量25%以上。

Conclusion: Infinite Sampling在有限GPU内存下实现高效稳定的GRPO训练。

Abstract: Group-based reinforcement learning algorithms such as Group Reward Policy
Optimization (GRPO) have proven effective for fine-tuning large language models
(LLMs) with human feedback. However, generating and storing multiple responses
per prompt incurs substantial memory overhead, especially as the sample group
size increases, limiting scalability under constrained hardware.
  We propose Infinite Sampling, a framework that enables efficient and stable
GRPO training by decoupling group size from GPU memory usage. It consists of:
(1) micro sampling groups that decompose large groups into memory-feasible
rounds; (2) continuous sampling that interleaves generation across groups to
improve utilization; and (3) a length-aware scheduler combining
token-conditioned sequence length prediction with a two-stage plan: global
grouping via FPTAS and runtime refill via SJF.
  Experiments show that our Micro Sampling Groups reduce peak memory usage by
over 50% compared to full-group decoding (e.g., from 21.55 GB to 10.64 GB on
Qwen3-1.7B). Building on this, Infinite Sampling improves throughput by over
25% compared to the naive micro sampling group method, reducing decoding steps
while maintaining full-length completions and memory usage. Our hybrid
scheduling ensures efficient and stable GRPO training with larger groups under
realistic GPU memory constraints.

</details>


### [265] [Cybersecurity-Focused Anomaly Detection in Connected Autonomous Vehicles Using Machine Learning](https://arxiv.org/abs/2506.22984)
*Prathyush Kumar Reddy Lebaku,Lu Gao,Yunpeng Zhang,Zhixia Li,Yongxin Liu,Tanvir Arafin*

Main category: cs.LG

TL;DR: 该研究提出了一种基于机器学习的异常检测方法，用于识别联网自动驾驶车辆（CAV）中的异常驾驶行为，结合了堆叠LSTM和随机森林模型，取得了较高的预测精度。


<details>
  <summary>Details</summary>
Motivation: 联网自动驾驶车辆（CAV）易受传感器故障、网络攻击和环境干扰的影响，异常检测对保障交通安全至关重要。

Method: 通过模拟车辆行为生成数据集，使用堆叠LSTM模型捕捉时序依赖关系，并结合随机森林模型提升检测性能和可解释性。

Result: 随机森林模型的R2为0.9830，MAE为5.746；堆叠LSTM模型的R2为0.9998，MAE为82.425，两者均能有效检测异常。

Conclusion: 该方法在预测车辆轨迹和检测异常方面表现出色，为自动驾驶安全提供了可靠的技术支持。

Abstract: Anomaly detection in connected autonomous vehicles (CAVs) is crucial for
maintaining safe and reliable transportation networks, as CAVs can be
susceptible to sensor malfunctions, cyber-attacks, and unexpected environmental
disruptions. This study explores an anomaly detection approach by simulating
vehicle behavior, generating a dataset that represents typical and atypical
vehicular interactions. The dataset includes time-series data of position,
speed, and acceleration for multiple connected autonomous vehicles. We utilized
machine learning models to effectively identify abnormal driving patterns.
First, we applied a stacked Long Short-Term Memory (LSTM) model to capture
temporal dependencies and sequence-based anomalies. The stacked LSTM model
processed the sequential data to learn standard driving behaviors.
Additionally, we deployed a Random Forest model to support anomaly detection by
offering ensemble-based predictions, which enhanced model interpretability and
performance. The Random Forest model achieved an R2 of 0.9830, MAE of 5.746,
and a 95th percentile anomaly threshold of 14.18, while the stacked LSTM model
attained an R2 of 0.9998, MAE of 82.425, and a 95th percentile anomaly
threshold of 265.63. These results demonstrate the models' effectiveness in
accurately predicting vehicle trajectories and detecting anomalies in
autonomous driving scenarios.

</details>


### [266] [Kernel Outlier Detection](https://arxiv.org/abs/2506.22994)
*Can Hakan Dağıdır,Mia Hubert,Peter J. Rousseeuw*

Main category: cs.LG

TL;DR: 提出了一种新的异常检测方法KOD，用于高维数据中的异常检测，克服了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决高维数据中异常检测的挑战，避免依赖分布假设或难以调优的超参数。

Method: 采用核变换和投影追踪方法，结合新的方向搜索集成和结果组合方式。

Result: 在三个小型数据集和四个大型基准数据集上验证了KOD的有效性。

Conclusion: KOD是一种灵活且轻量级的异常检测方法。

Abstract: A new anomaly detection method called kernel outlier detection (KOD) is
proposed. It is designed to address challenges of outlier detection in
high-dimensional settings. The aim is to overcome limitations of existing
methods, such as dependence on distributional assumptions or on hyperparameters
that are hard to tune. KOD starts with a kernel transformation, followed by a
projection pursuit approach. Its novelties include a new ensemble of directions
to search over, and a new way to combine results of different direction types.
This provides a flexible and lightweight approach for outlier detection. Our
empirical evaluations illustrate the effectiveness of KOD on three small
datasets with challenging structures, and on four large benchmark datasets.

</details>


### [267] [BWLer: Barycentric Weight Layer Elucidates a Precision-Conditioning Tradeoff for PINNs](https://arxiv.org/abs/2506.23024)
*Jerry Liu,Yasa Baig,Denise Hui Jean Lee,Rajat Vadiraj Dwaraknath,Atri Rudra,Chris Ré*

Main category: cs.LG

TL;DR: 论文提出Barycentric Weight Layer（BWLer）以解决PINNs在PDE求解中的精度限制问题，通过多项式插值提升精度。


<details>
  <summary>Details</summary>
Motivation: PINNs在求解PDE时精度不足，研究目标是确定精度限制源于PDE的病态性还是MLP架构。

Method: 引入BWLer，通过重心多项式插值建模PDE解，可叠加或替换MLP，结合谱导数和预处理优化训练。

Result: BWLer显著提升精度，在多个PDE基准测试中RMSE改善高达1800倍，部分问题达到接近机器精度。

Conclusion: BWLer为PINNs提供了结合灵活性与高精度的实用路径，接近经典谱求解器的性能。

Abstract: Physics-informed neural networks (PINNs) offer a flexible way to solve
partial differential equations (PDEs) with machine learning, yet they still
fall well short of the machine-precision accuracy many scientific tasks demand.
In this work, we investigate whether the precision ceiling comes from the
ill-conditioning of the PDEs or from the typical multi-layer perceptron (MLP)
architecture. We introduce the Barycentric Weight Layer (BWLer), which models
the PDE solution through barycentric polynomial interpolation. A BWLer can be
added on top of an existing MLP (a BWLer-hat) or replace it completely
(explicit BWLer), cleanly separating how we represent the solution from how we
take derivatives for the PDE loss. Using BWLer, we identify fundamental
precision limitations within the MLP: on a simple 1-D interpolation task, even
MLPs with O(1e5) parameters stall around 1e-8 RMSE -- about eight orders above
float64 machine precision -- before any PDE terms are added. In PDE learning,
adding a BWLer lifts this ceiling and exposes a tradeoff between achievable
accuracy and the conditioning of the PDE loss. For linear PDEs we fully
characterize this tradeoff with an explicit error decomposition and navigate it
during training with spectral derivatives and preconditioning. Across five
benchmark PDEs, adding a BWLer on top of an MLP improves RMSE by up to 30x for
convection, 10x for reaction, and 1800x for wave equations while remaining
compatible with first-order optimizers. Replacing the MLP entirely lets an
explicit BWLer reach near-machine-precision on convection, reaction, and wave
problems (up to 10 billion times better than prior results) and match the
performance of standard PINNs on stiff Burgers' and irregular-geometry Poisson
problems. Together, these findings point to a practical path for combining the
flexibility of PINNs with the precision of classical spectral solvers.

</details>


### [268] [Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models](https://arxiv.org/abs/2506.23025)
*Tejas Vaidhya,Ayush Kaushal,Vineet Jain,Francis Couture Harpin,Prashant Shishodia,Majid Behbahani,Yuriy Nevmyvaka,Irina Rish*

Main category: cs.LG

TL;DR: 论文研究了三元语言模型（TriLMs）通过量化感知训练减少内存需求，并提出2-bit和1.6-bit权重压缩方案，显著提升推理效率。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）的推理效率受限于内存带宽和容量，亟需解决方案。

Method: 采用量化感知训练开发三元语言模型（TriLMs），并进行扩展性分析；提出2-bit和1.6-bit权重压缩方案及TriRun GPU内核。

Result: TriLMs在1.2万亿token上训练表现优异；TriRun内核推理速度比浮点基线快5倍。

Conclusion: 三元语言模型和高效推理技术为LLMs的构建和部署奠定了基础，推动了研究社区的发展。

Abstract: Large language models (LLMs) are increasingly used across research and
industry applications, yet their inference efficiency remains a significant
challenge. As the computational power of modern GPU architectures continuously
improves, their memory bandwidth and capacity have not scaled proportionally,
creating a critical bottleneck during inference. To address this, we
investigate ternary language models (TriLMs) that employ quantization-aware
training to significantly reduce memory requirements. We first analyze the
scalability of TriLMs by conducting a scaling law analysis, revealing that
TriLMs benefit more from increasing training data than from scaling model
parameters. Based on this observation, we introduce Spectra-1.1, an open suite
of TriLMs trained on up to 1.2 trillion tokens, demonstrating sustained
performance gains at scale. Furthermore, to improve inference efficiency, we
propose novel 2-bit and 1.6-bit packing schemes for ternary weights, which
demonstrate accelerated inference across various CPU architectures. Also,
building on the 2-bit packing, we develop a GPU kernel called TriRun that
accelerates end-to-end model inference by up to 5 times compared to
floating-point baselines. To encourage further exploration and development of
TriLMs, we will release the Spectra-1.1 suite and TriRun inference kernels.
Overall, our work lays the foundation for building and deploying efficient
LLMs, providing a valuable resource for the research community.

</details>


### [269] [Feature-Wise Mixing for Mitigating Contextual Bias in Predictive Supervised Learning](https://arxiv.org/abs/2506.23033)
*Yash Vardhan Tomar*

Main category: cs.LG

TL;DR: 本文提出了一种特征混合框架来减少机器学习模型中的上下文偏见，通过重新分配特征表示，显著降低了偏见并提高了预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有偏见缓解策略存在可扩展性和泛化性限制，需要一种更高效的方法。

Method: 采用特征混合框架，通过交叉验证训练四种分类器，并使用偏见敏感损失函数评估效果。

Result: 平均偏见减少43.35%，预测性能显著提升，且优于现有方法如SMOTE。

Conclusion: 特征混合框架有效减少偏见且计算高效，未来可应用于实际场景。

Abstract: Bias in predictive machine learning (ML) models is a fundamental challenge
due to the skewed or unfair outcomes produced by biased models. Existing
mitigation strategies rely on either post-hoc corrections or rigid constraints.
However, emerging research claims that these techniques can limit scalability
and reduce generalizability. To address this, this paper introduces a
feature-wise mixing framework to mitigate contextual bias. This was done by
redistributing feature representations across multiple contextual datasets. To
assess feature-wise mixing's effectiveness, four ML classifiers were trained
using cross-validation and evaluated with bias-sensitive loss functions,
including disparity metrics and mean squared error (MSE), which served as a
standard measure of predictive performance. The proposed method achieved an
average bias reduction of 43.35% and a statistically significant decrease in
MSE across all classifiers trained on mixed datasets. Additionally,
benchmarking against established bias mitigation techniques found that
feature-wise mixing consistently outperformed SMOTE oversampling and
demonstrated competitive effectiveness without requiring explicit bias
attribute identification. Feature-wise mixing efficiently avoids the
computational overhead typically associated with fairness-aware learning
algorithms. Future work could explore applying feature-wise mixing for
real-world fields where accurate predictions are necessary.

</details>


### [270] [ReMem: Mutual Information-Aware Fine-tuning of Pretrained Vision Transformers for Effective Knowledge Distillation](https://arxiv.org/abs/2506.23041)
*Chengyu Dong,Huan Gui,Noveen Sachdeva,Long Jin,Ke Yin,Jingbo Shang,Lichan Hong,Ed H. Chi,Zhe Zhao*

Main category: cs.LG

TL;DR: 本文提出了一种改进视觉Transformer（ViT）知识蒸馏的方法，通过互信息感知优化和MLP块重加权，提升小规模或高度不平衡数据集上的知识转移效果。


<details>
  <summary>Details</summary>
Motivation: 大规模预训练模型在知识蒸馏时效果下降，尤其是对小规模或高度不平衡数据集，本文旨在解决这一问题。

Method: 采用互信息感知优化进行微调，并对MLP块进行重加权，以提升知识转移效果。

Result: 该方法使小型学生模型能够从最强预训练模型中受益。

Conclusion: 通过互信息优化和MLP块重加权，显著提升了知识蒸馏的效果。

Abstract: Knowledge distillation from pretrained visual representation models offers an
effective approach to improve small, task-specific production models. However,
the effectiveness of such knowledge transfer drops significantly when
distilling from strong models that are pretrained in a large scale. In this
paper, we address this challenge for pretrained Vision Transformers (ViTs) by
exploring methods to fine-tune them for more effective knowledge transfer.
Motivated by the connection between mutual information and distillation
effectiveness, we propose to employ mutual information-aware optimization
during finetuning. For small or highly-imbalanced downstream datasets where
such optimization becomes less effective, we introduce a simple yet effective
heuristic of reweighting MLP blocks. This approach is inspired by our
observation that top MLP blocks are primarily responsible for mutual
information loss. Our method enables small student models to benefit from those
pretrained models among the strongest.

</details>


### [271] [Double-Diffusion: Diffusion Conditioned Diffusion Probabilistic Model For Air Quality Prediction](https://arxiv.org/abs/2506.23053)
*Hanlin Dong,Arian Prabowo,Hao Xue,Flora D. Salim*

Main category: cs.LG

TL;DR: 论文提出了一种名为Double-Diffusion的新型扩散概率模型，结合已知物理原理和随机性来预测空气质量，显著提升了预测性能并减少了推理时间。


<details>
  <summary>Details</summary>
Motivation: 空气质量预测具有时空复杂性和不确定性，现有模型难以在确定性与不确定性之间找到平衡点。

Method: 提出Double-Diffusion模型，利用已知物理原理作为条件生成方法，结合图像恢复的采样策略和新去噪架构。

Result: 在多个评估场景中表现最佳，推理时间减少50%至30%，CRPS提升3-12%。

Conclusion: Double-Diffusion首次将物理原理作为条件生成方法应用于空气质量预测，显著提升了预测性能。

Abstract: Air quality prediction is a challenging forecasting task due to its
spatio-temporal complexity and the inherent dynamics as well as uncertainty.
Most of the current models handle these two challenges by applying Graph Neural
Networks or known physics principles, and quantifying stochasticity through
probabilistic networks like Diffusion models. Nevertheless, finding the right
balancing point between the certainties and uncertainties remains an open
question. Therefore, we propose Double-Diffusion, a novel diffusion
probabilistic model that harnesses the power of known physics to guide air
quality forecasting with stochasticity. To the best of our knowledge, while
precedents have been made of using conditional diffusion models to predict air
pollution, this is the first attempt to use physics as a conditional generative
approach for air quality prediction. Along with a sampling strategy adopted
from image restoration and a new denoiser architecture, Double-Diffusion ranks
first in most evaluation scenarios across two real-life datasets compared with
other probabilistic models, it also cuts inference time by 50% to 30% while
enjoying an increase between 3-12% in Continuous Ranked Probabilistic Score
(CRPS).

</details>


### [272] [Measuring How LLMs Internalize Human Psychological Concepts: A preliminary analysis](https://arxiv.org/abs/2506.23055)
*Hiro Taiyo Hamada,Ippei Fujisawa,Genji Kawakita,Yuki Yamada*

Main category: cs.LG

TL;DR: 该论文提出了一种定量框架，通过43种标准化心理问卷评估大型语言模型（如GPT-4）与人类心理维度的概念对齐，发现GPT-4在分类准确性上显著优于其他模型。


<details>
  <summary>Details</summary>
Motivation: 研究动机是评估大型语言模型是否准确内化了塑造人类思维和行为的概念。

Method: 方法包括使用心理问卷的成对相似性分析，评估语言模型对问卷项目的重构和分类能力，并通过层次聚类比较结果与原始分类标签。

Result: GPT-4的分类准确率为66.2%，显著高于GPT-3.5（55.9%）和BERT（48.1%），且其语义相似度估计与人类反应的相关性较高。

Conclusion: 现代大型语言模型能以可测量的准确性近似人类心理结构，为开发更可解释的AI系统提供了见解。

Abstract: Large Language Models (LLMs) such as ChatGPT have shown remarkable abilities
in producing human-like text. However, it is unclear how accurately these
models internalize concepts that shape human thought and behavior. Here, we
developed a quantitative framework to assess concept alignment between LLMs and
human psychological dimensions using 43 standardized psychological
questionnaires, selected for their established validity in measuring distinct
psychological constructs. Our method evaluates how accurately language models
reconstruct and classify questionnaire items through pairwise similarity
analysis. We compared resulting cluster structures with the original
categorical labels using hierarchical clustering. A GPT-4 model achieved
superior classification accuracy (66.2\%), significantly outperforming GPT-3.5
(55.9\%) and BERT (48.1\%), all exceeding random baseline performance (31.9\%).
We also demonstrated that the estimated semantic similarity from GPT-4 is
associated with Pearson's correlation coefficients of human responses in
multiple psychological questionnaires. This framework provides a novel approach
to evaluate the alignment of the human-LLM concept and identify potential
representational biases. Our findings demonstrate that modern LLMs can
approximate human psychological constructs with measurable accuracy, offering
insights for developing more interpretable AI systems.

</details>


### [273] [Curious Causality-Seeking Agents Learn Meta Causal World](https://arxiv.org/abs/2506.23068)
*Zhiyu Zhao,Haoxuan Li,Haifeng Zhang,Jun Wang,Francesco Faccio,Jürgen Schmidhuber,Mengyue Yang*

Main category: cs.LG

TL;DR: 论文提出了一种名为“元因果图”的世界模型，用于统一表示不同潜在世界状态下因果结构的变化规则，并通过好奇心驱动的探索不断优化模型。


<details>
  <summary>Details</summary>
Motivation: 现实中因果机制常因观察窗口狭窄而显得漂移，传统假设单一固定因果规则的世界模型难以适应这种变化。

Method: 引入元因果图作为世界模型，由多个因果子图组成，每个子图由潜在状态触发。设计了一个因果寻求代理，通过好奇心驱动的干预策略识别元状态并发现因果关系。

Result: 在合成任务和机器人手臂操作任务中，该方法能有效捕捉因果动态变化并泛化到新情境。

Conclusion: 元因果图及其代理能灵活适应因果机制的变化，为复杂环境建模提供了新思路。

Abstract: When building a world model, a common assumption is that the environment has
a single, unchanging underlying causal rule, like applying Newton's laws to
every situation. In reality, what appears as a drifting causal mechanism is
often the manifestation of a fixed underlying mechanism seen through a narrow
observational window. This brings about a problem that, when building a world
model, even subtle shifts in policy or environment states can alter the very
observed causal mechanisms. In this work, we introduce the \textbf{Meta-Causal
Graph} as world models, a minimal unified representation that efficiently
encodes the transformation rules governing how causal structures shift across
different latent world states. A single Meta-Causal Graph is composed of
multiple causal subgraphs, each triggered by meta state, which is in the latent
state space. Building on this representation, we introduce a
\textbf{Causality-Seeking Agent} whose objectives are to (1) identify the meta
states that trigger each subgraph, (2) discover the corresponding causal
relationships by agent curiosity-driven intervention policy, and (3)
iteratively refine the Meta-Causal Graph through ongoing curiosity-driven
exploration and agent experiences. Experiments on both synthetic tasks and a
challenging robot arm manipulation task demonstrate that our method robustly
captures shifts in causal dynamics and generalizes effectively to previously
unseen contexts.

</details>


### [274] [Forget-MI: Machine Unlearning for Forgetting Multimodal Information in Healthcare Settings](https://arxiv.org/abs/2506.23145)
*Shahad Hardan,Darya Taratynova,Abdelmajid Essofi,Karthik Nandakumar,Mohammad Yaqub*

Main category: cs.LG

TL;DR: Forget-MI是一种新的机器遗忘方法，专注于多模态医疗数据，通过损失函数和扰动技术实现数据遗忘，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 在医疗AI中，隐私保护至关重要，现有方法难以从多模态架构中移除敏感患者数据。

Method: 提出Forget-MI，通过损失函数和扰动技术，遗忘单模态和联合表示的数据，同时保留剩余数据的知识。

Result: Forget-MI在遗忘数据集上的性能优于现有方法，MIA降低0.202，AUC和F1分数分别降低0.221和0.305，测试集性能与原始模型相当。

Conclusion: Forget-MI有效解决了多模态医疗数据遗忘问题，同时保持模型性能，代码已开源。

Abstract: Privacy preservation in AI is crucial, especially in healthcare, where models
rely on sensitive patient data. In the emerging field of machine unlearning,
existing methodologies struggle to remove patient data from trained multimodal
architectures, which are widely used in healthcare. We propose Forget-MI, a
novel machine unlearning method for multimodal medical data, by establishing
loss functions and perturbation techniques. Our approach unlearns unimodal and
joint representations of the data requested to be forgotten while preserving
knowledge from the remaining data and maintaining comparable performance to the
original model. We evaluate our results using performance on the forget
dataset, performance on the test dataset, and Membership Inference Attack
(MIA), which measures the attacker's ability to distinguish the forget dataset
from the training dataset. Our model outperforms the existing approaches that
aim to reduce MIA and the performance on the forget dataset while keeping an
equivalent performance on the test set. Specifically, our approach reduces MIA
by 0.202 and decreases AUC and F1 scores on the forget set by 0.221 and 0.305,
respectively. Additionally, our performance on the test set matches that of the
retrained model, while allowing forgetting. Code is available at
https://github.com/BioMedIA-MBZUAI/Forget-MI.git

</details>


### [275] [maneuverRecognition -- A Python package for Timeseries Classification in the domain of Vehicle Telematics](https://arxiv.org/abs/2506.23147)
*Jonathan Schuster,Fabian Transchel*

Main category: cs.LG

TL;DR: 论文介绍了maneuverRecognition包，用于车辆遥测数据中的驾驶行为识别，支持预处理、建模和评估，并提供了一个可修改的LSTM网络结构。


<details>
  <summary>Details</summary>
Motivation: 驾驶行为识别可提升保险个性化、道路安全和环保驾驶，但现有工具不足，需快速处理数据和建模。

Method: 开发maneuverRecognition包，提供预处理、建模和评估功能，包含可修改的LSTM网络结构。

Result: 使用三人智能手机传感器记录的驾驶数据验证了包的有效性。

Conclusion: maneuverRecognition包为驾驶行为识别提供了实用工具，支持快速开发和评估模型。

Abstract: In the domain of vehicle telematics the automated recognition of driving
maneuvers is used to classify and evaluate driving behaviour. This not only
serves as a component to enhance the personalization of insurance policies, but
also to increase road safety, reduce accidents and the associated costs as well
as to reduce fuel consumption and support environmentally friendly driving. In
this context maneuver recognition technically requires a continuous application
of time series classification which poses special challenges to the transfer,
preprocessing and storage of telematic sensor data, the training of predictive
models, and the prediction itself. Although much research has been done in the
field of gathering relevant data or regarding the methods to build predictive
models for the task of maneuver recognition, there is a practical need for
python packages and functions that allow to quickly transform data into the
required structure as well as to build and evaluate such models. The
maneuverRecognition package was therefore developed to provide the necessary
functions for preprocessing, modelling and evaluation and also includes a ready
to use LSTM based network structure that can be modified. The implementation of
the package is demonstrated using real driving data of three different persons
recorded via smartphone sensors.

</details>


### [276] [Data Can Speak for Itself: Quality-guided Utilization of Wireless Synthetic Data](https://arxiv.org/abs/2506.23174)
*Chen Gong,Bo Liang,Wei Gao,Chenren Xu*

Main category: cs.LG

TL;DR: 论文提出了一种量化合成数据质量的方法（亲和性与多样性），并引入SynCheck方案优化合成数据使用，显著提升任务性能。


<details>
  <summary>Details</summary>
Motivation: 当前无线传感任务中合成数据的质量不可预测，导致性能提升不明确，亟需量化标准与优化方案。

Method: 提出亲和性与多样性指标量化合成数据质量，并开发SynCheck方案在任务模型训练中优化数据使用。

Result: SynCheck方案显著优于传统方法，性能提升4.3%，而传统方法可能导致性能下降13.4%。

Conclusion: 通过量化合成数据质量并优化使用，SynCheck能有效提升无线传感任务的性能。

Abstract: Generative models have gained significant attention for their ability to
produce realistic synthetic data that supplements the quantity of real-world
datasets. While recent studies show performance improvements in wireless
sensing tasks by incorporating all synthetic data into training sets, the
quality of synthetic data remains unpredictable and the resulting performance
gains are not guaranteed. To address this gap, we propose tractable and
generalizable metrics to quantify quality attributes of synthetic data -
affinity and diversity. Our assessment reveals prevalent affinity limitation in
current wireless synthetic data, leading to mislabeled data and degraded task
performance. We attribute the quality limitation to generative models' lack of
awareness of untrained conditions and domain-specific processing. To mitigate
these issues, we introduce SynCheck, a quality-guided synthetic data
utilization scheme that refines synthetic data quality during task model
training. Our evaluation demonstrates that SynCheck consistently outperforms
quality-oblivious utilization of synthetic data, and achieves 4.3% performance
improvement even when the previous utilization degrades performance by 13.4%.

</details>


### [277] [Attribution assignment for deep-generative sequence models enables interpretability analysis using positive-only data](https://arxiv.org/abs/2506.23182)
*Robert Frank,Michael Widrich,Rahmad Akbar,Günter Klambauer,Geir Kjetil Sandve,Philippe A. Robert,Victor Greiff*

Main category: cs.LG

TL;DR: GAMA是一种基于集成梯度的自回归生成模型归因方法，用于解决生成模型缺乏可解释性的问题，无需负训练数据即可验证生成序列设计策略。


<details>
  <summary>Details</summary>
Motivation: 在生物序列设计中，生成模型能高效探索具有理想特性的序列空间，但缺乏可解释性方法限制了其应用。GAMA旨在填补这一空白。

Method: 开发了GAMA，基于集成梯度的归因方法，通过合成数据集验证其统计行为和生物特征恢复能力，并应用于实验抗体-抗原结合数据。

Result: GAMA在合成数据集上表现出色，能恢复生物相关特征，并在实验数据中验证了其有效性。

Conclusion: GAMA为生成模型提供了可解释性，支持无需负数据的序列设计验证，推动了生物序列设计的应用。

Abstract: Generative machine learning models offer a powerful framework for therapeutic
design by efficiently exploring large spaces of biological sequences enriched
for desirable properties. Unlike supervised learning methods, which require
both positive and negative labeled data, generative models such as LSTMs can be
trained solely on positively labeled sequences, for example, high-affinity
antibodies. This is particularly advantageous in biological settings where
negative data are scarce, unreliable, or biologically ill-defined. However, the
lack of attribution methods for generative models has hindered the ability to
extract interpretable biological insights from such models. To address this
gap, we developed Generative Attribution Metric Analysis (GAMA), an attribution
method for autoregressive generative models based on Integrated Gradients. We
assessed GAMA using synthetic datasets with known ground truths to characterize
its statistical behavior and validate its ability to recover biologically
relevant features. We further demonstrated the utility of GAMA by applying it
to experimental antibody-antigen binding data. GAMA enables model
interpretability and the validation of generative sequence design strategies
without the need for negative training data.

</details>


### [278] [Efficient Algorithms for Learning and Compressing Monophonic Halfspaces in Graphs](https://arxiv.org/abs/2506.23186)
*Marco Bressan,Victor Chepoi,Emmanuel Esposito,Maximilian Thiessen*

Main category: cs.LG

TL;DR: 论文研究了图顶点上的单音半空间概念，提出了一种基于2-可满足性的分解定理，并实现了高效的算法解决多种学习问题。


<details>
  <summary>Details</summary>
Motivation: 探索图的凸性和半空间概念在机器学习中的应用，解决相关学习问题的效率问题。

Method: 提出基于2-可满足性的分解定理，将单音半空间表示为顶点子集的不交并。

Result: 实现了高效的算法，包括多项式时间经验风险最小化，以及稳定的样本压缩方案。

Conclusion: 单音半空间在可学习性上优于测地半空间，解决了文献中的开放问题。

Abstract: Abstract notions of convexity over the vertices of a graph, and corresponding
notions of halfspaces, have recently gained attention from the machine learning
community. In this work we study monophonic halfspaces, a notion of graph
halfspaces defined through closure under induced paths. Our main result is a
$2$-satisfiability based decomposition theorem, which allows one to represent
monophonic halfspaces as a disjoint union of certain vertex subsets. Using this
decomposition, we achieve efficient and (nearly) optimal algorithms for various
learning problems, such as teaching, active, and online learning. Most notably,
we obtain a polynomial-time algorithm for empirical risk minimization.
Independently of the decomposition theorem, we obtain an efficient, stable, and
proper sample compression scheme. This makes monophonic halfspaces efficiently
learnable with proper learners and linear error rate $1/\varepsilon$ in the
realizable PAC setting. Our results answer open questions from the literature,
and show a stark contrast with geodesic halfspaces, for which most of the said
learning problems are NP-hard.

</details>


### [279] [FedRef: Communication-Efficient Bayesian Fine Tuning with Reference Model](https://arxiv.org/abs/2506.23210)
*Taehwan Yoon,Bongjun Choi*

Main category: cs.LG

TL;DR: 提出了一种基于参考模型的联邦学习方法，通过贝叶斯参数高效迁移学习优化模型，解决灾难性遗忘问题，实现高性能和低计算成本。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在保护用户隐私的同时，模型性能可能无法满足用户多样化需求，需通过优化、微调或个性化提升性能。

Method: 采用基于参考模型的联邦学习方法，结合贝叶斯参数高效迁移学习，引入最优近端项，避免每轮训练中的灾难性遗忘。

Result: 该方法在保持高模型性能的同时，降低了计算成本。

Conclusion: 提出的方法有效解决了联邦学习中的模型优化挑战，兼顾性能与效率。

Abstract: Federated learning(FL) is used for distributed scenarios to train artificial
intelligence(AI) models while ensuring users' privacy. In federated learning
scenario, the server generally never knows about users' data. This type of
concept makes the AI training process efficient in terms of data privacy.
However, regarding model performance, federated AI models may not sufficiently
satisfy AI users' expectations. Furthermore, AI users have a wide range of
different needs. It is not easy to satisfy the whole users needs. These types
of issues can be addressed through AI model optimization, fine-tuning, or
personalization to achieve optimal model performance. To address model
optimization challenges, we propose reference model-based federated learning
for optimal fine-tuning, which overcomes catastrophic forgetting in each round.
This method is derived from Bayesian parameter-efficient transfer learning,
which includes an optimal proximal term and enables overcoming the catastrophic
forgetting issue in each round by utilizing a reference model that incorporates
previous model parameters. As a result, this method achieves both high model
performance and low computing cost.

</details>


### [280] [Single Image Inpainting and Super-Resolution with Simultaneous Uncertainty Guarantees by Universal Reproducing Kernels](https://arxiv.org/abs/2506.23221)
*Bálint Horváth,Balázs Csanád Csáji*

Main category: cs.LG

TL;DR: 论文提出了一种基于统计学习的方法SGKI，用于图像缺失像素估计，同时提供不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 解决图像修复和超分辨率问题中的缺失像素估计，并提供不确定性量化。

Method: 基于Reproducing Kernel Hilbert Space (RKHS)的SGKI方法，扩展了现有核方法，利用Schur补高效计算非渐近置信带。

Result: SGKI不仅能估计缺失像素，还能为所有缺失像素构建同时保证的非渐近置信带。

Conclusion: SGKI方法在图像处理中具有高效性和实用性，尤其适用于需要不确定性量化的场景。

Abstract: The paper proposes a statistical learning approach to the problem of
estimating missing pixels of images, crucial for image inpainting and
super-resolution problems. One of the main novelties of the method is that it
also provides uncertainty quantifications together with the estimated values.
Our core assumption is that the underlying data-generating function comes from
a Reproducing Kernel Hilbert Space (RKHS). A special emphasis is put on
band-limited functions, central to signal processing, which form Paley-Wiener
type RKHSs. The proposed method, which we call Simultaneously Guaranteed Kernel
Interpolation (SGKI), is an extension and refinement of a recently developed
kernel method. An advantage of SGKI is that it not only estimates the missing
pixels, but also builds non-asymptotic confidence bands for the unobserved
values, which are simultaneously guaranteed for all missing pixels. We also
show how to compute these bands efficiently using Schur complements, we discuss
a generalization to vector-valued functions, and we present a series of
numerical experiments on various datasets containing synthetically generated
and benchmark images, as well.

</details>


### [281] [Masked Gated Linear Unit](https://arxiv.org/abs/2506.23225)
*Yukito Tajima,Nakamasa Inoue,Yusuke Sekikawa,Ikuro Sato,Rio Yokota*

Main category: cs.LG

TL;DR: 论文提出了一种新型的门控线性单元（MGLU），通过共享权重矩阵和二进制掩码减少内存读取，显著提升了推理速度和内存效率。


<details>
  <summary>Details</summary>
Motivation: 现有门控线性单元（GLU）在大型语言模型中因需要双倍内存读取而成为瓶颈，需优化其效率。

Method: 引入掩码门控线性单元（MGLU），采用元素级混合门控（MoEG）架构和硬件友好的FlashMGLU内核。

Result: MGLU在RTX5090 GPU上比标准GLU快34%，内存效率提升47%，推理速度提升19.7倍，且下游任务精度不降。

Conclusion: MGLU在保持或超越基线精度的同时，显著提升了计算效率和内存利用率。

Abstract: Gated Linear Units (GLUs) have become essential components in the
feed-forward networks of state-of-the-art Large Language Models (LLMs).
However, they require twice as many memory reads compared to feed-forward
layers without gating, due to the use of separate weight matrices for the gate
and value streams. To address this bottleneck, we introduce Masked Gated Linear
Units (MGLUs), a novel family of GLUs with an efficient kernel implementation.
The core contribution of MGLUs include: (1) the Mixture of Element-wise Gating
(MoEG) architecture that learns multiple binary masks, each determining gate or
value assignments at the element level on a single shared weight matrix
resulting in reduced memory transfer, and (2) FlashMGLU, a hardware-friendly
kernel that yields up to a 19.7 $\times$ inference-time speed-up over a naive
PyTorch MGLU and is 47% more memory-efficient and 34% faster than standard GLUs
despite added architectural complexity on an RTX5090 GPU. In LLM experiments,
the Swish-activated variant SwiMGLU preserves its memory advantages while
matching - or even surpassing - the downstream accuracy of the SwiGLU baseline.

</details>


### [282] [Sub-MoE: Efficient Mixture-of-Expert LLMs Compression via Subspace Expert Merging](https://arxiv.org/abs/2506.23266)
*Lujun Li,Zhu Qiyuan,Jiacheng Wang,Wei Li,Hao Gu,Sirui Han,Yike Guo*

Main category: cs.LG

TL;DR: Sub-MoE通过子空间专家合并框架解决MoE模型参数冲突问题，显著提升效率并保持性能。


<details>
  <summary>Details</summary>
Motivation: 解决MoE模型因参数规模大导致的内存、存储和部署挑战，以及现有专家合并方法因参数冲突而受限的问题。

Method: 采用自适应专家聚类和子空间专家合并两阶段方法，通过SVD提取共享U矩阵并合并专家特定V矩阵。

Result: 在Mixtral等模型上显著优于现有方法，保持96%|86%性能的同时减少25%|50%专家数量。

Conclusion: Sub-MoE是一种高效的MoE压缩框架，适用于大规模模型的优化部署。

Abstract: Mixture of Experts (MoE) LLMs face significant obstacles due to their massive
parameter scale, which imposes memory, storage, and deployment challenges.
Although recent expert merging methods promise greater efficiency by
consolidating multiple experts, they are fundamentally hindered by parameter
conflicts arising from expert specialization. In this paper, we present
Sub-MoE, a novel MoE compression framework via Subspace Expert Merging. Our key
insight is to perform joint Singular Value Decomposition (SVD) on concatenated
expert weights, reducing conflicting parameters by extracting shared
$U$-matrices while enabling effective merging of the expert-specific $V$
components. Specifically, Sub-MoE consists of two innovative phases: (1)
Adaptive Expert Clustering, which groups functionally coherent experts via
K-means clustering based on cosine similarity of expert outputs; and (2)
Subspace Expert Merging, which first enforces Experts Union Decomposition to
derive the shared $U$-matrix across experts in the same group, then pursues
frequency-based merging for individual $V$-matrices, and finalizes expert
reconstruction using the merged $V$-matrix. In this way, we align and fuse
experts in a shared subspace, and can be extended with intra-expert compression
for further inference optimization. Extensive experiments on Mixtral, DeepSeek,
and Qwen-1.5|3 MoE LLMs demonstrate that our Sub-MoE significantly outperforms
existing expert pruning and merging methods. Notably, our Sub-MoE maintains
96\%|86\% of original performance with 25\%|50\% expert reduction on
Mixtral-8x7B in zero-shot benchmarks. Code will be released at
https://github.com/lliai/MoERazor.

</details>


### [283] [Predicting thinking time in Reasoning models](https://arxiv.org/abs/2506.23274)
*Hans Peter Lynsgøe Raaschou-jensen,Constanza Fierro,Anders Søgaard*

Main category: cs.LG

TL;DR: 论文探讨了推理模型在复杂任务中的思考时间不可预测性问题，并提出了在线和离线预测方法，旨在为推理过程提供进度条。


<details>
  <summary>Details</summary>
Motivation: 由于推理模型在复杂任务中可能产生长时间的隐藏思考链，用户无法预知模型何时返回答案，导致体验不佳。

Method: 提出了在线和离线预测模型思考时间的方法，目标是开发一个实用的推理进度条。

Result: 研究讨论了这些方法对用户交互的影响，并提出了未来研究方向。

Conclusion: 通过预测模型的思考时间，可以改善用户体验，并为未来研究提供方向。

Abstract: Reasoning models that produce long, hidden chains of thought have emerged as
powerful tools for complex, reasoning-intensive
tasks\citep{deepseekai2025deepseekr1incentivizingreasoningcapability,
openai2024openaio1card}. However, this paradigm introduces a new user
experience challenge: users have little insight into how much time the model
will spend reasoning before returning an answer. This unpredictability, can
lead to user frustration and is likely to compound as LLMs can produce
increasingly long tasks asynchronously
\citep{kwa2025measuringaiabilitycomplete}. In this paper, we introduce and
evaluate methods for both online and offline prediction of model "thinking
time," aiming to develop a practical "progress bar for reasoning." We discuss
the implications for user interaction and future research directions.

</details>


### [284] [BAPE: Learning an Explicit Bayes Classifier for Long-tailed Visual Recognition](https://arxiv.org/abs/2506.23280)
*Chaoqun Du,Yulin Wang,Shiji Song,Gao Huang*

Main category: cs.LG

TL;DR: 论文提出了一种新方法（BAPE），通过显式建模后验概率参数并直接学习贝叶斯分类器，解决了长尾数据分布中的梯度不平衡问题，同时确保了贝叶斯最优决策规则。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习算法通过隐式估计后验概率（如最小化Softmax交叉熵损失）来解决最优分类器问题，但在长尾数据分布中效果不佳，导致梯度不平衡和无法确保贝叶斯最优决策。

Method: BAPE方法显式建模后验概率参数并通过点估计求解，直接学习贝叶斯分类器，避免了梯度下降。此外，提出了一种分布调整技术，使分类器能适应任意不平衡的测试数据分布。

Result: 在CIFAR-10-LT、CIFAR-100-LT、ImageNet-LT和iNaturalist等数据集上，该方法显著提升了深度网络的泛化性能。

Conclusion: BAPE方法通过显式建模后验概率和分布调整技术，有效解决了长尾数据分布中的问题，且与现有方法正交，具有简单高效的特点。

Abstract: Bayesian decision theory advocates the Bayes classifier as the optimal
approach for minimizing the risk in machine learning problems. Current deep
learning algorithms usually solve for the optimal classifier by
\emph{implicitly} estimating the posterior probabilities, \emph{e.g.}, by
minimizing the Softmax cross-entropy loss. This simple methodology has been
proven effective for meticulously balanced academic benchmark datasets.
However, it is not applicable to the long-tailed data distributions in the real
world, where it leads to the gradient imbalance issue and fails to ensure the
Bayes optimal decision rule. To address these challenges, this paper presents a
novel approach (BAPE) that provides a more precise theoretical estimation of
the data distributions by \emph{explicitly} modeling the parameters of the
posterior probabilities and solving them with point estimation. Consequently,
our method directly learns the Bayes classifier without gradient descent based
on Bayes' theorem, simultaneously alleviating the gradient imbalance and
ensuring the Bayes optimal decision rule. Furthermore, we propose a
straightforward yet effective \emph{distribution adjustment} technique. This
method enables the Bayes classifier trained from the long-tailed training set
to effectively adapt to the test data distribution with an arbitrary imbalance
factor, thereby enhancing performance without incurring additional
computational costs. In addition, we demonstrate the gains of our method are
orthogonal to existing learning approaches for long-tailed scenarios, as they
are mostly designed under the principle of \emph{implicitly} estimating the
posterior probabilities. Extensive empirical evaluations on CIFAR-10-LT,
CIFAR-100-LT, ImageNet-LT, and iNaturalist demonstrate that our method
significantly improves the generalization performance of popular deep networks,
despite its simplicity.

</details>


### [285] [Not All Explanations for Deep Learning Phenomena Are Equally Valuable](https://arxiv.org/abs/2506.23286)
*Alan Jeffares,Mihaela van der Schaar*

Main category: cs.LG

TL;DR: 论文主张，尽管深度学习中的反直觉现象研究有价值，但缺乏证据表明这些现象在现实应用中出现，且孤立研究效率低下。建议将其作为验证通用理论的工具，而非独立问题。


<details>
  <summary>Details</summary>
Motivation: 探讨深度学习研究中反直觉现象（如双下降、grokking、彩票假设）的实际意义，质疑其孤立研究的价值。

Method: 通过分析文献中的典型案例，评估这些现象的研究成果，并提出未来研究的实用建议。

Result: 研究发现这些现象在现实应用中证据不足，但可作为验证通用深度学习理论的独特场景。

Conclusion: 建议将深度学习现象视为验证通用理论的工具，而非独立问题，以推动领域整体进步。

Abstract: Developing a better understanding of surprising or counterintuitive phenomena
has constituted a significant portion of deep learning research in recent
years. These include double descent, grokking, and the lottery ticket
hypothesis -- among many others. Works in this area often develop ad hoc
hypotheses attempting to explain these observed phenomena on an isolated,
case-by-case basis. This position paper asserts that, in many prominent cases,
there is little evidence to suggest that these phenomena appear in real-world
applications and these efforts may be inefficient in driving progress in the
broader field. Consequently, we argue against viewing them as isolated puzzles
that require bespoke resolutions or explanations. However, despite this, we
suggest that deep learning phenomena do still offer research value by providing
unique settings in which we can refine our broad explanatory theories of more
general deep learning principles. This position is reinforced by analyzing the
research outcomes of several prominent examples of these phenomena from the
recent literature. We revisit the current norms in the research community in
approaching these problems and propose practical recommendations for future
research, aiming to ensure that progress on deep learning phenomena is well
aligned with the ultimate pragmatic goal of progress in the broader field of
deep learning.

</details>


### [286] [Hierarchical Quantized Diffusion Based Tree Generation Method for Hierarchical Representation and Lineage Analysis](https://arxiv.org/abs/2506.23287)
*Zelin Zang,WenZhe Li,Fei Chen,Yongjie Xu,Chang Yu,Zhen Lei,Stan Z. Li*

Main category: cs.LG

TL;DR: HDTree是一种基于扩散的层次化单细胞数据分析方法，通过统一的层次化编码本和量化扩散过程建模树节点转换，解决了传统方法在计算成本、性能和稳定性上的不足。


<details>
  <summary>Details</summary>
Motivation: 传统方法在建模单细胞分化轨迹时存在计算成本高、性能有限和稳定性差的问题，而现有VAEs方法仍需分支特定模块，限制了其能力。

Method: HDTree利用层次化潜在空间和量化扩散过程，统一建模树节点转换，无需分支特定模块，提高了稳定性和生成能力。

Result: HDTree在通用和单细胞数据集上表现优于现有方法，提供了更准确和高效的层次化谱系分析工具。

Conclusion: HDTree为单细胞分化路径建模提供了新工具，支持更高效的生物任务分析，代码已开源。

Abstract: In single-cell research, tracing and analyzing high-throughput single-cell
differentiation trajectories is crucial for understanding complex biological
processes. Key to this is the modeling and generation of hierarchical data that
represents the intrinsic structure within datasets. Traditional methods face
limitations in terms of computational cost, performance, generative capacity,
and stability. Recent VAEs based approaches have made strides in addressing
these challenges but still require specialized network modules for each tree
branch, limiting their stability and ability to capture deep hierarchical
relationships. To overcome these challenges, we introduce diffusion-based
approach called HDTree. HDTree captures tree relationships within a
hierarchical latent space using a unified hierarchical codebook and quantized
diffusion processes to model tree node transitions. This method improves
stability by eliminating branch-specific modules and enhancing generative
capacity through gradual hierarchical changes simulated by the diffusion
process. HDTree's effectiveness is demonstrated through comparisons on both
general-purpose and single-cell datasets, where it outperforms existing methods
in terms of accuracy and performance. These contributions provide a new tool
for hierarchical lineage analysis, enabling more accurate and efficient
modeling of cellular differentiation paths and offering insights for downstream
biological tasks. The code of HDTree is available at anonymous link
https://anonymous.4open.science/r/code_HDTree_review-A8DB.

</details>


### [287] [VALID-Mol: a Systematic Framework for Validated LLM-Assisted Molecular Design](https://arxiv.org/abs/2506.23339)
*Malikussaid,Hilal Hudan Nuha*

Main category: cs.LG

TL;DR: VALID-Mol框架通过结合提示工程、化学验证和微调LLM，将生成有效化学结构的比例从3%提升至83%，为科学领域提供了一种可推广的方法。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在分子设计中生成无效或不实用结构的问题，提升其在科学发现中的实用性。

Method: 结合提示工程、自动化化学验证和微调领域适应的LLM，确保生成可合成且性质优化的分子。

Result: 生成有效化学结构的比例显著提高（3%到83%），计算预测目标亲和力提升17倍。

Conclusion: VALID-Mol为科学领域提供了一种可推广的方法，确保LLMs在领域特定约束下的可靠应用。

Abstract: Large Language Models (LLMs) demonstrate remarkable potential for scientific
discovery, but their application in domains requiring factual accuracy and
domain-specific constraints remains challenging. In molecular design for drug
discovery, LLMs can suggest creative molecular modifications but often produce
chemically invalid or impractical structures. We present VALID-Mol, a
systematic framework for integrating chemical validation with LLM-driven
molecular design that increases the rate of generating valid chemical
structures from 3% to 83%. Our approach combines methodical prompt engineering,
automated chemical validation, and a fine-tuned domain-adapted LLM to ensure
reliable generation of synthesizable molecules with improved properties. Beyond
the specific implementation, we contribute a generalizable methodology for
scientifically-constrained LLM applications, with quantifiable reliability
improvements. Computational predictions suggest our framework can generate
promising candidates for synthesis with up to 17-fold computationally predicted
improvements in target affinity while maintaining synthetic accessibility. We
provide a detailed analysis of our prompt engineering process, validation
architecture, and fine-tuning approach, offering a reproducible blueprint for
applying LLMs to other scientific domains where domain-specific validation is
essential.

</details>


### [288] [A case for data valuation transparency via DValCards](https://arxiv.org/abs/2506.23349)
*Keziah Naggita,Julienne LaChance*

Main category: cs.LG

TL;DR: 论文指出数据估值方法存在偏见和不稳定性，提出Data Valuation Cards框架以提高透明度和减少误用。


<details>
  <summary>Details</summary>
Motivation: 随着数据为中心的机器学习兴起，数据估值方法被用于量化数据点对模型性能的贡献，但其偏见和不稳定性可能带来技术和伦理问题。

Method: 通过分析9个表格分类数据集和6种数据估值方法，研究数据预处理、子采样和估值偏差的影响。

Result: 发现数据估值方法易受预处理技术影响，可能加剧类别不平衡，并低估少数群体数据。

Conclusion: 提出Data Valuation Cards框架以提高数据估值的透明度，减少误用并增强可信度。

Abstract: Following the rise in popularity of data-centric machine learning (ML),
various data valuation methods have been proposed to quantify the contribution
of each datapoint to desired ML model performance metrics (e.g., accuracy).
Beyond the technical applications of data valuation methods (e.g., data
cleaning, data acquisition, etc.), it has been suggested that within the
context of data markets, data buyers might utilize such methods to fairly
compensate data owners. Here we demonstrate that data valuation metrics are
inherently biased and unstable under simple algorithmic design choices,
resulting in both technical and ethical implications. By analyzing 9 tabular
classification datasets and 6 data valuation methods, we illustrate how (1)
common and inexpensive data pre-processing techniques can drastically alter
estimated data values; (2) subsampling via data valuation metrics may increase
class imbalance; and (3) data valuation metrics may undervalue underrepresented
group data. Consequently, we argue in favor of increased transparency
associated with data valuation in-the-wild and introduce the novel Data
Valuation Cards (DValCards) framework towards this aim. The proliferation of
DValCards will reduce misuse of data valuation metrics, including in data
pricing, and build trust in responsible ML systems.

</details>


### [289] [Federated Timeline Synthesis: Scalable and Private Methodology For Model Training and Deployment](https://arxiv.org/abs/2506.23358)
*Pawel Renc,Michal K. Grzeszczyk,Linglong Qian,Nassim Oufattole,Jeff Rasley,Arkadiusz Sitek*

Main category: cs.LG

TL;DR: FTS是一种用于训练分布式时间序列数据的生成基础模型的新框架，应用于电子健康记录（EHR），通过合成数据实现隐私保护和高效预测。


<details>
  <summary>Details</summary>
Motivation: 解决分布式医疗数据隐私保护和模型训练效率问题。

Method: 将患者历史表示为PHTs，本地训练自回归Transformer，服务器合成数据训练全局生成器（GG）。

Result: 在MIMIC-IV数据上，GG生成的合成数据训练的模型性能与真实数据相当。

Conclusion: FTS提供隐私保护、可扩展性，并适用于多种医疗预测任务。

Abstract: We present Federated Timeline Synthesis (FTS), a novel framework for training
generative foundation models across distributed timeseries data applied to
electronic health records (EHR). At its core, FTS represents patient history as
tokenized Patient Health Timelines (PHTs), language-agnostic sequences encoding
temporal, categorical, and continuous clinical information. Each institution
trains an autoregressive transformer on its local PHTs and transmits only model
weights to a central server. The server uses the generators to synthesize a
large corpus of trajectories and train a Global Generator (GG), enabling
zero-shot inference via Monte Carlo simulation of future PHTs. We evaluate FTS
on five clinically meaningful prediction tasks using MIMIC-IV data, showing
that models trained on synthetic data generated by GG perform comparably to
those trained on real data. FTS offers strong privacy guarantees, scalability
across institutions, and extensibility to diverse prediction and simulation
tasks especially in healthcare, including counterfactual inference, early
warning detection, and synthetic trial design.

</details>


### [290] [When Additive Noise Meets Unobserved Mediators: Bivariate Denoising Diffusion for Causal Discovery](https://arxiv.org/abs/2506.23374)
*Dominik Meier,Sujai Hiremath,Promit Ghosal,Kyra Gan*

Main category: cs.LG

TL;DR: 本文提出了一种名为BiDD的新方法，用于解决在存在未观测中介变量时的双变量因果发现问题，通过去噪扩散过程改进传统加性噪声模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统加性噪声模型（ANM）在未观测中介变量存在时会失效，且现有解决方案在有限样本下表现不稳定，因此需要一种更鲁棒的方法。

Method: 提出BiDD方法，利用去噪扩散过程，通过条件独立性检验噪声与输入变量的关系，推断因果方向。

Result: 实验表明，BiDD在合成和真实数据中表现优于现有方法，尤其在存在中介变量的情况下。

Conclusion: BiDD是一种有效的因果发现方法，能够处理未观测中介变量带来的噪声，并在多种场景下保持稳定性能。

Abstract: Distinguishing cause and effect from bivariate observational data is a
foundational problem in many disciplines, but challenging without additional
assumptions. Additive noise models (ANMs) are widely used to enable
sample-efficient bivariate causal discovery. However, conventional ANM-based
methods fail when unobserved mediators corrupt the causal relationship between
variables. This paper makes three key contributions: first, we rigorously
characterize why standard ANM approaches break down in the presence of
unmeasured mediators. Second, we demonstrate that prior solutions for hidden
mediation are brittle in finite sample settings, limiting their practical
utility. To address these gaps, we propose Bivariate Denoising Diffusion (BiDD)
for causal discovery, a method designed to handle latent noise introduced by
unmeasured mediators. Unlike prior methods that infer directionality through
mean squared error loss comparisons, our approach introduces a novel
independence test statistic: during the noising and denoising processes for
each variable, we condition on the other variable as input and evaluate the
independence of the predicted noise relative to this input. We prove asymptotic
consistency of BiDD under the ANM, and conjecture that it performs well under
hidden mediation. Experiments on synthetic and real-world data demonstrate
consistent performance, outperforming existing methods in mediator-corrupted
settings while maintaining strong performance in mediator-free settings.

</details>


### [291] [Do LLMs Dream of Discrete Algorithms?](https://arxiv.org/abs/2506.23408)
*Claudionor Coelho Jr,Yanen Li,Philip Tee*

Main category: cs.LG

TL;DR: 论文提出了一种结合大型语言模型（LLMs）与逻辑推理模块的神经符号方法，以解决LLMs在严格逻辑推理和可解释性方面的不足。


<details>
  <summary>Details</summary>
Motivation: LLMs在自然语言处理和软件组件动态编排方面表现出色，但在需要严格逻辑推理和可解释性的领域存在局限性。

Method: 通过集成一阶逻辑和显式规则系统，将LLMs与基于Prolog谓词和可组合工具集的逻辑推理模块结合。

Result: 在DABStep基准测试中，该混合架构在多步推理任务中表现出更高的精确度、覆盖率和系统文档化能力。

Conclusion: 结合LLMs与模块化逻辑推理能提升系统可靠性，为复杂领域提供可扩展、可信赖且可解释的AI解决方案。

Abstract: Large Language Models (LLMs) have rapidly transformed the landscape of
artificial intelligence, enabling natural language interfaces and dynamic
orchestration of software components. However, their reliance on probabilistic
inference limits their effectiveness in domains requiring strict logical
reasoning, discrete decision-making, and robust interpretability. This paper
investigates these limitations and proposes a neurosymbolic approach that
augments LLMs with logic-based reasoning modules, particularly leveraging
Prolog predicates and composable toolsets. By integrating first-order logic and
explicit rule systems, our framework enables LLMs to decompose complex queries
into verifiable sub-tasks, orchestrate reliable solutions, and mitigate common
failure modes such as hallucination and incorrect step decomposition. We
demonstrate the practical benefits of this hybrid architecture through
experiments on the DABStep benchmark, showing improved precision, coverage, and
system documentation in multi-step reasoning tasks. Our results indicate that
combining LLMs with modular logic reasoning restores engineering rigor,
enhances system reliability, and offers a scalable path toward trustworthy,
interpretable AI agents across complex domains.

</details>


### [292] [BenchMake: Turn any scientific data set into a reproducible benchmark](https://arxiv.org/abs/2506.23419)
*Amanda S Barnard*

Main category: cs.LG

TL;DR: 开发了一个名为BenchMake的工具，用于将科学数据集转化为基准测试集，通过非负矩阵分解识别边缘案例，并生成具有统计显著性的测试集。


<details>
  <summary>Details</summary>
Motivation: 由于计算科学中基准数据集的稀缺性，评估新方法的创新性变得困难，因此需要一种工具将开放的科学数据集转化为可用的基准测试集。

Method: 使用非负矩阵分解确定边缘案例，并在凸包上划分测试集，以最大化差异和统计显著性。

Result: 在十个公开的科学数据集上测试，BenchMake生成的测试集优于现有划分和随机划分。

Conclusion: BenchMake是一种有效的工具，可将科学数据集转化为高质量的基准测试集，适用于多种数据类型。

Abstract: Benchmark data sets are a cornerstone of machine learning development and
applications, ensuring new methods are robust, reliable and competitive. The
relative rarity of benchmark sets in computational science, due to the
uniqueness of the problems and the pace of change in the associated domains,
makes evaluating new innovations difficult for computational scientists. In
this paper a new tool is developed and tested to potentially turn any of the
increasing numbers of scientific data sets made openly available into a
benchmark accessible to the community. BenchMake uses non-negative matrix
factorisation to deterministically identify and isolate challenging edge cases
on the convex hull (the smallest convex set that contains all existing data
instances) and partitions a required fraction of matched data instances into a
testing set that maximises divergence and statistical significance, across
tabular, graph, image, signal and textual modalities. BenchMake splits are
compared to establish splits and random splits using ten publicly available
benchmark sets from different areas of science, with different sizes, shapes,
distributions.

</details>


### [293] [Accurate Parameter-Efficient Test-Time Adaptation for Time Series Forecasting](https://arxiv.org/abs/2506.23424)
*Heitor R. Medeiros,Hossein Sharifi-Noghabi,Gabriel L. Oliveira,Saghar Irandoust*

Main category: cs.LG

TL;DR: PETSA提出了一种参数高效的方法，通过仅更新输入和输出的小型校准模块，在测试时调整预测模型，减少了内存和计算成本。


<details>
  <summary>Details</summary>
Motivation: 现实世界的时间序列通常具有非平稳性，这会降低预训练预测模型的性能。现有的测试时适应方法通常更新整个模型，增加了内存和计算成本。

Method: PETSA使用低秩适配器和动态门控调整表示，而无需重新训练。通过结合鲁棒项、频域项和块结构项的专业损失函数来保持准确性。

Result: 实验结果表明，PETSA在各种预测骨干上提高了适应性，且参数需求少于基线方法。

Conclusion: PETSA在减少参数的同时，实现了竞争性或更好的性能，适用于不同时间范围的预测任务。

Abstract: Real-world time series often exhibit a non-stationary nature, degrading the
performance of pre-trained forecasting models. Test-Time Adaptation (TTA)
addresses this by adjusting models during inference, but existing methods
typically update the full model, increasing memory and compute costs. We
propose PETSA, a parameter-efficient method that adapts forecasters at test
time by only updating small calibration modules on the input and output. PETSA
uses low-rank adapters and dynamic gating to adjust representations without
retraining. To maintain accuracy despite limited adaptation capacity, we
introduce a specialized loss combining three components: (1) a robust term, (2)
a frequency-domain term to preserve periodicity, and (3) a patch-wise
structural term for structural alignment. PETSA improves the adaptability of
various forecasting backbones while requiring fewer parameters than baselines.
Experimental results on benchmark datasets show that PETSA achieves competitive
or better performance across all horizons. Our code is available at:
https://github.com/BorealisAI/PETSA

</details>


### [294] [Enhancing Insider Threat Detection Using User-Based Sequencing and Transformer Encoders](https://arxiv.org/abs/2506.23446)
*Mohamed Elbasheer,Adewale Akinfaderin*

Main category: cs.LG

TL;DR: 提出了一种基于用户行为序列的Transformer方法，用于检测内部威胁，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习方法未能利用用户行为的序列依赖性，导致检测内部威胁效果不佳。

Method: 采用用户行为序列化（UBS）方法，结合Transformer Encoder建模正常行为，并通过重建误差作为异常分数。

Result: 在多个测试集上表现优异，准确率96.61%，召回率99.43%，F1分数96.38%，AUROC 95.00%。

Conclusion: 序列建模和先进异常检测方法在内部威胁检测中效果显著，优于传统方法。

Abstract: Insider threat detection presents unique challenges due to the authorized
status of malicious actors and the subtlety of anomalous behaviors. Existing
machine learning methods often treat user activity as isolated events, thereby
failing to leverage sequential dependencies in user behavior. In this study, we
propose a User-Based Sequencing (UBS) methodology, transforming the CERT
insider threat dataset into structured temporal sequences suitable for deep
sequential modeling. We deploy a Transformer Encoder architecture to model
benign user activity and employ its reconstruction errors as anomaly scores.
These scores are subsequently evaluated using three unsupervised outlier
detection algorithms: One-Class SVM (OCSVM), Local Outlier Factor (LOF), and
Isolation Forest (iForest). Across four rigorously designed test sets,
including combinations of multiple CERT dataset releases, our UBS-Transformer
pipeline consistently achieves state-of-the-art performance - notably 96.61%
accuracy, 99.43% recall, 96.38% F1-score, 95.00% AUROC, and exceptionally low
false negative (0.0057) and false positive (0.0571) rates. Comparative analyses
demonstrate that our approach substantially outperforms tabular and
conventional autoencoder baselines, underscoring the efficacy of sequential
user modeling and advanced anomaly detection in the insider threat domain.

</details>


### [295] [Can We Predict the Unpredictable? Leveraging DisasterNet-LLM for Multimodal Disaster Classification](https://arxiv.org/abs/2506.23462)
*Manaswi Kulahara,Gautam Siddharth Kashyap,Nipun Joshi,Arpita Soni*

Main category: cs.LG

TL;DR: DisasterNet-LLM是一种专用于灾害分析的大语言模型，通过多模态数据整合和先进技术，显著提升了灾害分类的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以整合多模态数据（如图像、天气记录和文本报告），限制了灾害管理的时效性和准确性。

Method: 利用高级预训练、跨模态注意力机制和自适应变换器，构建了DisasterNet-LLM模型。

Result: 实验结果显示，该模型在多模态灾害分类任务中表现优异，准确率达89.5%，F1分数88.0%，AUC 0.92%，BERTScore 0.88%。

Conclusion: DisasterNet-LLM在多模态灾害分析中优于现有模型，为灾害管理提供了更高效的工具。

Abstract: Effective disaster management requires timely and accurate insights, yet
traditional methods struggle to integrate multimodal data such as images,
weather records, and textual reports. To address this, we propose
DisasterNet-LLM, a specialized Large Language Model (LLM) designed for
comprehensive disaster analysis. By leveraging advanced pretraining,
cross-modal attention mechanisms, and adaptive transformers, DisasterNet-LLM
excels in disaster classification. Experimental results demonstrate its
superiority over state-of-the-art models, achieving higher accuracy of 89.5%,
an F1 score of 88.0%, AUC of 0.92%, and BERTScore of 0.88% in multimodal
disaster classification tasks.

</details>


### [296] [Reconciling Attribute and Structural Anomalies for Improved Graph Anomaly Detection](https://arxiv.org/abs/2506.23469)
*Chunjing Xiao,Jiahui Lu,Xovee Xu,Fan Zhou,Tianshu Xie,Wei Lu,Lifeng Xu*

Main category: cs.LG

TL;DR: TripleAD是一种基于互蒸馏的三通道图异常检测框架，通过三个模块分别检测属性、结构和混合异常，解决了现有方法在检测不同类型异常时的性能问题。


<details>
  <summary>Details</summary>
Motivation: 现有无监督方法在同时检测属性异常和结构异常时存在性能问题，TripleAD旨在通过多模块协作解决这一问题。

Method: TripleAD包含三个模块：多尺度属性估计模块、链接增强结构估计模块和属性混合曲率模块，并通过互蒸馏策略促进模块间协作。

Result: 实验表明，TripleAD在检测多种异常时优于现有基线方法。

Conclusion: TripleAD通过多模块协作和互蒸馏策略，有效提升了图异常检测的性能。

Abstract: Graph anomaly detection is critical in domains such as healthcare and
economics, where identifying deviations can prevent substantial losses.
Existing unsupervised approaches strive to learn a single model capable of
detecting both attribute and structural anomalies. However, they confront the
tug-of-war problem between two distinct types of anomalies, resulting in
suboptimal performance. This work presents TripleAD, a mutual
distillation-based triple-channel graph anomaly detection framework. It
includes three estimation modules to identify the attribute, structural, and
mixed anomalies while mitigating the interference between different types of
anomalies. In the first channel, we design a multiscale attribute estimation
module to capture extensive node interactions and ameliorate the over-smoothing
issue. To better identify structural anomalies, we introduce a link-enhanced
structure estimation module in the second channel that facilitates information
flow to topologically isolated nodes. The third channel is powered by an
attribute-mixed curvature, a new indicator that encapsulates both attribute and
structural information for discriminating mixed anomalies. Moreover, a mutual
distillation strategy is introduced to encourage communication and
collaboration between the three channels. Extensive experiments demonstrate the
effectiveness of the proposed TripleAD model against strong baselines.

</details>


### [297] [Sample Margin-Aware Recalibration of Temperature Scaling](https://arxiv.org/abs/2506.23492)
*Haolan Guo,Linwei Tao,Haoyang Luo,Minjing Dong,Chang Xu*

Main category: cs.LG

TL;DR: SMART是一种轻量级、数据高效的后处理校准方法，通过基于logit间隙的精确调整，解决了神经网络过度自信的问题，并在有限数据下实现最佳校准性能。


<details>
  <summary>Details</summary>
Motivation: 现代神经网络存在系统性过度自信问题，现有后处理校准方法在全局调整和局部表达性之间难以平衡，导致高偏差或高方差。

Method: SMART利用logit间隙作为去噪标量信号，结合软分箱的期望校准误差目标（SoftECE），实现高效校准。

Result: SMART在多种数据集和架构上表现出色，参数更少但校准性能优于现有方法。

Conclusion: SMART为神经网络预测中的不确定性量化提供了高效、鲁棒的解决方案。

Abstract: Recent advances in deep learning have significantly improved predictive
accuracy. However, modern neural networks remain systematically overconfident,
posing risks for deployment in safety-critical scenarios. Current post-hoc
calibration methods face a fundamental dilemma: global approaches like
Temperature Scaling apply uniform adjustments across all samples, introducing
high bias despite computational efficiency, while more expressive methods that
operate on full logit distributions suffer from high variance due to noisy
high-dimensional inputs and insufficient validation data. To address these
challenges, we propose Sample Margin-Aware Recalibration of Temperature
(SMART), a lightweight, data-efficient recalibration method that precisely
scales logits based on the margin between the top two logits -- termed the
logit gap. Specifically, the logit gap serves as a denoised, scalar signal
directly tied to decision boundary uncertainty, providing a robust indicator
that avoids the noise inherent in high-dimensional logit spaces while
preserving model prediction invariance. Meanwhile, SMART employs a novel
soft-binned Expected Calibration Error (SoftECE) objective that balances model
bias and variance through adaptive binning, enabling stable parameter updates
even with extremely limited calibration data. Extensive evaluations across
diverse datasets and architectures demonstrate that SMART achieves
state-of-the-art calibration performance even with substantially fewer
parameters compared to existing parametric methods, offering a principled,
robust, and highly efficient solution for practical uncertainty quantification
in neural network predictions. The source code is available at:
https://anonymous.4open.science/r/SMART-8B11.

</details>


### [298] [FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization](https://arxiv.org/abs/2506.23516)
*Seung-Wook Kim,Seongyeol Kim,Jiah Kim,Seowon Ji,Se-Ho Lee*

Main category: cs.LG

TL;DR: FedWSQ框架通过权重标准化和非均匀量化提升联邦学习性能，减少通信开销并保持高精度。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中数据异构和通信限制导致的性能下降问题。

Method: 结合权重标准化（WS）和分布感知非均匀量化（DANUQ），过滤局部更新的偏置分量并最小化量化误差。

Result: 在极端数据异构和超低比特通信场景下，FedWSQ显著优于现有方法。

Conclusion: FedWSQ有效提升了联邦学习的鲁棒性和通信效率。

Abstract: Federated learning (FL) often suffers from performance degradation due to key
challenges such as data heterogeneity and communication constraints. To address
these limitations, we present a novel FL framework called FedWSQ, which
integrates weight standardization (WS) and the proposed distribution-aware
non-uniform quantization (DANUQ). WS enhances FL performance by filtering out
biased components in local updates during training, thereby improving the
robustness of the model against data heterogeneity and unstable client
participation. In addition, DANUQ minimizes quantization errors by leveraging
the statistical properties of local model updates. As a result, FedWSQ
significantly reduces communication overhead while maintaining superior model
accuracy. Extensive experiments on FL benchmark datasets demonstrate that
FedWSQ consistently outperforms existing FL methods across various challenging
FL settings, including extreme data heterogeneity and ultra-low-bit
communication scenarios.

</details>


### [299] [Both Asymptotic and Non-Asymptotic Convergence of Quasi-Hyperbolic Momentum using Increasing Batch Size](https://arxiv.org/abs/2506.23544)
*Kento Imaizumi,Hideaki Iiduka*

Main category: cs.LG

TL;DR: 论文研究了动量方法在随机非凸优化中的有效性，特别是准双曲动量（QHM）算法，证明了增加批量大小而非降低学习率能更有效地实现收敛。


<details>
  <summary>Details</summary>
Motivation: 动量方法在深度神经网络等随机非凸优化中的理论支持有限，QHM作为通用算法，其收敛性需要进一步研究。

Method: 通过渐近和非渐近收敛分析，比较了降低学习率和增加批量大小对QHM算法的影响。

Result: 增加批量大小比降低学习率更有利于非渐近收敛，实验表明有限增加批量大小对神经网络训练有益。

Conclusion: 在QHM算法中，增加批量大小是一种更优的策略，无需降低学习率即可实现有效收敛。

Abstract: Momentum methods were originally introduced for their superiority to
stochastic gradient descent (SGD) in deterministic settings with convex
objective functions. However, despite their widespread application to deep
neural networks -- a representative case of stochastic nonconvex optimization
-- the theoretical justification for their effectiveness in such settings
remains limited. Quasi-hyperbolic momentum (QHM) is an algorithm that
generalizes various momentum methods and has been studied to better understand
the class of momentum-based algorithms as a whole. In this paper, we provide
both asymptotic and non-asymptotic convergence results for mini-batch QHM with
an increasing batch size. We show that achieving asymptotic convergence
requires either a decaying learning rate or an increasing batch size. Since a
decaying learning rate adversely affects non-asymptotic convergence, we
demonstrate that using mini-batch QHM with an increasing batch size -- without
decaying the learning rate -- can be a more effective strategy. Our experiments
show that even a finite increase in batch size can provide benefits for
training neural networks.

</details>


### [300] [A unified framework on the universal approximation of transformer-type architectures](https://arxiv.org/abs/2506.23551)
*Jingpu Cheng,Qianxiao Li,Ting Lin,Zuowei Shen*

Main category: cs.LG

TL;DR: 论文研究了Transformer类架构的通用逼近性质（UAP），提出了一个统一的理论框架，扩展了残差网络的先前结果，并引入了一个适用于广泛架构的通用充分条件。


<details>
  <summary>Details</summary>
Motivation: 探讨Transformer类架构的UAP，为设计具有UAP保证的新型架构提供理论基础。

Method: 通过分析注意力层的解析性假设，简化了UAP条件的验证，并提出了非构造性方法。

Result: 证明了多种注意力机制（如基于核和稀疏注意力）的Transformer具有UAP，并推广了先前的研究结果。

Conclusion: 该框架为设计具有UAP保证的新型Transformer架构提供了理论基础，并展示了具体实例。

Abstract: We investigate the universal approximation property (UAP) of transformer-type
architectures, providing a unified theoretical framework that extends prior
results on residual networks to models incorporating attention mechanisms. Our
work identifies token distinguishability as a fundamental requirement for UAP
and introduces a general sufficient condition that applies to a broad class of
architectures. Leveraging an analyticity assumption on the attention layer, we
can significantly simplify the verification of this condition, providing a
non-constructive approach in establishing UAP for such architectures. We
demonstrate the applicability of our framework by proving UAP for transformers
with various attention mechanisms, including kernel-based and sparse attention
mechanisms. The corollaries of our results either generalize prior works or
establish UAP for architectures not previously covered. Furthermore, our
framework offers a principled foundation for designing novel transformer
architectures with inherent UAP guarantees, including those with specific
functional symmetries. We propose examples to illustrate these insights.

</details>


### [301] [Transition Matching: Scalable and Flexible Generative Modeling](https://arxiv.org/abs/2506.23589)
*Neta Shaul,Uriel Singer,Itai Gat,Yaron Lipman*

Main category: cs.LG

TL;DR: 本文提出了一种名为Transition Matching（TM）的新生成范式，统一并改进了扩散/流模型和连续自回归生成方法，通过三种变体展示了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 扩散和流匹配模型在媒体生成方面取得了显著进展，但其设计空间已较为成熟，限制了进一步改进。同时，连续自回归模型在统一文本和媒体生成方面展现出潜力。

Method: TM将复杂生成任务分解为简单的马尔可夫转移，支持非确定性概率转移核和任意非连续监督过程。提出了三种变体：DTM（推广流匹配）、ARTM和FHTM（推广连续自回归方法）。

Result: DTM在图像质量和文本一致性上达到最优，采样效率更高；ARTM和FHTM在连续因果自回归生成中与非因果方法性能相当，FHTM首次在文本到图像任务中超越流方法。

Conclusion: TM通过灵活的转移匹配框架，为生成模型提供了新的设计空间和性能提升，展示了其在统一和推进生成技术方面的潜力。

Abstract: Diffusion and flow matching models have significantly advanced media
generation, yet their design space is well-explored, somewhat limiting further
improvements. Concurrently, autoregressive (AR) models, particularly those
generating continuous tokens, have emerged as a promising direction for
unifying text and media generation. This paper introduces Transition Matching
(TM), a novel discrete-time, continuous-state generative paradigm that unifies
and advances both diffusion/flow models and continuous AR generation. TM
decomposes complex generation tasks into simpler Markov transitions, allowing
for expressive non-deterministic probability transition kernels and arbitrary
non-continuous supervision processes, thereby unlocking new flexible design
avenues. We explore these choices through three TM variants: (i) Difference
Transition Matching (DTM), which generalizes flow matching to discrete-time by
directly learning transition probabilities, yielding state-of-the-art image
quality and text adherence as well as improved sampling efficiency. (ii)
Autoregressive Transition Matching (ARTM) and (iii) Full History Transition
Matching (FHTM) are partially and fully causal models, respectively, that
generalize continuous AR methods. They achieve continuous causal AR generation
quality comparable to non-causal approaches and potentially enable seamless
integration with existing AR text generation techniques. Notably, FHTM is the
first fully causal model to match or surpass the performance of flow-based
methods on text-to-image task in continuous domains. We demonstrate these
contributions through a rigorous large-scale comparison of TM variants and
relevant baselines, maintaining a fixed architecture, training data, and
hyperparameters.

</details>


### [302] [When Will It Fail?: Anomaly to Prompt for Forecasting Future Anomalies in Time Series](https://arxiv.org/abs/2506.23596)
*Min-Yeong Park,Won-Jeong Lee,Seong Tae Kim,Gyeong-Moon Park*

Main category: cs.LG

TL;DR: 论文提出了一种名为A2P的新框架，用于预测未来异常事件，包含异常感知预测（AAF）和合成异常提示（SAP），在多个真实数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 预测未来异常事件的实际需求未被充分解决，现有方法无法精确预测未来异常。

Method: A2P框架结合AAF学习异常关系，SAP通过可学习的异常提示池模拟多样异常模式。

Result: 在多个真实数据集上，A2P优于现有方法，能有效预测未来异常。

Conclusion: A2P为解决未来异常预测问题提供了有效方案。

Abstract: Recently, forecasting future abnormal events has emerged as an important
scenario to tackle real-world necessities. However, the solution of predicting
specific future time points when anomalies will occur, known as Anomaly
Prediction (AP), remains under-explored. Existing methods dealing with time
series data fail in AP, focusing only on immediate anomalies or failing to
provide precise predictions for future anomalies. To address the AP task, we
propose a novel framework called Anomaly to Prompt (A2P), comprised of
Anomaly-Aware Forecasting (AAF) and Synthetic Anomaly Prompting (SAP). To
enable the forecasting model to forecast abnormal time points, we adopt a
strategy to learn the relationships of anomalies. For the robust detection of
anomalies, our proposed SAP introduces a learnable Anomaly Prompt Pool (APP)
that simulates diverse anomaly patterns using signal adaptive prompt.
Comprehensive experiments on multiple real-world datasets demonstrate the
superiority of A2P over state-of-the-art methods, showcasing its ability to
predict future anomalies. Our implementation code is available at
https://github.com/KU-VGI/AP.

</details>


### [303] [A Nonlinear Low-rank Representation Model with Convolutional Neural Network for Imputing Water Quality Data](https://arxiv.org/abs/2506.23629)
*Xin Liao,Bing Yang,Cai Yu*

Main category: cs.LG

TL;DR: 提出了一种结合非线性低秩表示模型（NLR）和卷积神经网络（CNN）的方法，用于填补水质数据中的缺失值，显著提高了估计精度。


<details>
  <summary>Details</summary>
Motivation: 水质数据因传感器故障和通信延迟等问题常出现大量缺失，传统填补方法难以捕捉数据动态和深层特征，导致效果不佳。

Method: 利用CNN融合时间特征以建模时间依赖性，并提取非线性交互和局部模式以实现多维信息的深度融合。

Result: 在三个真实水质数据集上的实验表明，该方法在估计精度上显著优于现有最先进的数据填补模型。

Conclusion: 该方法为复杂动态环境中的水质监测数据处理提供了有效解决方案。

Abstract: The integrity of Water Quality Data (WQD) is critical in environmental
monitoring for scientific decision-making and ecological protection. However,
water quality monitoring systems are often challenged by large amounts of
missing data due to unavoidable problems such as sensor failures and
communication delays, which further lead to water quality data becoming
High-Dimensional and Sparse (HDS). Traditional data imputation methods are
difficult to depict the potential dynamics and fail to capture the deep data
features, resulting in unsatisfactory imputation performance. To effectively
address the above issues, this paper proposes a Nonlinear Low-rank
Representation model (NLR) with Convolutional Neural Networks (CNN) for
imputing missing WQD, which utilizes CNNs to implement two ideas: a) fusing
temporal features to model the temporal dependence of data between time slots,
and b) Extracting nonlinear interactions and local patterns to mine
higher-order relationships features and achieve deep fusion of multidimensional
information. Experimental studies on three real water quality datasets
demonstrate that the proposed model significantly outperforms existing
state-of-the-art data imputation models in terms of estimation accuracy. It
provides an effective approach for handling water quality monitoring data in
complex dynamic environments.

</details>


### [304] [Learning Modular Exponentiation with Transformers](https://arxiv.org/abs/2506.23679)
*David Demitri Africa,Sara M. Kapoor,Theo Simon Sorg*

Main category: cs.LG

TL;DR: 本文研究了Transformer模型在模幂运算中的机制可解释性，发现通过特定训练策略和结构分析，模型能够内化算术结构并实现高效计算。


<details>
  <summary>Details</summary>
Motivation: 模幂运算在数论和密码学中至关重要，但其机制可解释性尚未被充分探索。本文旨在通过训练Transformer模型并分析其内部机制，揭示数值推理的涌现过程。

Method: 使用4层编码器-解码器Transformer模型，结合策略性采样、PCA嵌入分析和激活修补技术，研究模型如何编码数论特性。

Result: 研究发现，特定训练策略（如互操作数训练）显著提升性能，并观察到模型在相关模数上的突然泛化。此外，发现仅由最后一层注意力头组成的子图即可实现常规幂运算的完整性能。

Conclusion: Transformer模型通过专用计算电路学习模算术，为更可解释和高效的神经模幂运算方法奠定了基础。

Abstract: Modular exponentiation is crucial to number theory and cryptography, yet
remains largely unexplored from a mechanistic interpretability standpoint. We
train a 4-layer encoder-decoder Transformer model to perform this operation and
investigate the emergence of numerical reasoning during training. Utilizing
principled sampling strategies, PCA-based embedding analysis, and activation
patching, we examine how number-theoretic properties are encoded within the
model. We find that reciprocal operand training leads to strong performance
gains, with sudden generalization across related moduli. These synchronized
accuracy surges reflect grokking-like dynamics, suggesting the model
internalizes shared arithmetic structure. We also find a subgraph consisting
entirely of attention heads in the final layer sufficient to achieve full
performance on the task of regular exponentiation. These results suggest that
transformer models learn modular arithmetic through specialized computational
circuits, paving the way for more interpretable and efficient neural approaches
to modular exponentiation.

</details>


### [305] [DABstep: Data Agent Benchmark for Multi-step Reasoning](https://arxiv.org/abs/2506.23719)
*Alex Egg,Martin Iglesias Goyanes,Friso Kingma,Andreu Mora,Leandro von Werra,Thomas Wolf*

Main category: cs.LG

TL;DR: DABstep是一个用于评估AI代理在现实多步数据分析任务中的新基准，包含450多个真实挑战，测试模型的数据处理和上下文推理能力。最佳代理在困难任务中仅达到14.55%准确率。


<details>
  <summary>Details</summary>
Motivation: 为加速自主数据分析研究，提供客观评估多步任务性能的基准。

Method: 基于金融分析平台的真实任务设计，结合代码处理和上下文推理，采用自动评分机制。

Result: 领先的LLM代理在困难任务中表现不佳，最高准确率仅14.55%。

Conclusion: DABstep为研究提供了新工具，揭示了当前AI在多步数据分析中的局限性。

Abstract: We introduce DABstep, a novel benchmark for evaluating AI agents on realistic
multi-step data analysis tasks. DABstep comprises over 450 real-world
challenges derived from a financial analytics platform, requiring models to
combine code-based data processing with contextual reasoning over heterogeneous
documentation. Each task demands an iterative, multi-step problem-solving
approach, testing capabilities in data manipulation, cross-referencing multiple
sources, and precise result reporting. The benchmark provides a factoid-style
answer format with automatic correctness checks for objective scoring at scale.
We evaluate leading LLM-based agents, revealing a substantial performance gap:
even the best agent achieves only 14.55% accuracy on the hardest tasks. We
detail our benchmark's design, dataset composition, task formulation,
evaluation protocol, report baseline results and analyze failure modes. DABstep
is released with a public leaderboard and toolkit to accelerate research in
autonomous data analysis.

</details>


### [306] [System-Embedded Diffusion Bridge Models](https://arxiv.org/abs/2506.23726)
*Bartlomiej Sobieski,Matthew Tivnan,Yuang Wang,Siyeop Yoon,Pengfei Jin,Dufan Wu,Quanzheng Li,Przemyslaw Biecek*

Main category: cs.LG

TL;DR: 提出了一种新的监督桥接方法（SDBs），通过将已知线性测量系统嵌入矩阵值SDE的系数中，显著改进了线性逆问题的解决效果。


<details>
  <summary>Details</summary>
Motivation: 解决逆问题（从噪声或不完整测量中恢复信号）是科学与工程中的基础任务。现有方法要么忽略测量模型的结构信息，要么假设其已知，缺乏一种既能利用已知信息又能灵活适应的方法。

Method: 引入系统嵌入扩散桥模型（SDBs），将已知线性测量系统嵌入矩阵值SDE的系数中，形成一种监督桥接方法。

Result: SDBs在多种线性逆问题中表现一致优于现有方法，且在系统训练与部署不一致时仍具有鲁棒性。

Conclusion: SDBs为实际应用中的逆问题提供了一种有前景的解决方案，尤其在需要利用已知系统结构信息的场景中。

Abstract: Solving inverse problems -- recovering signals from incomplete or noisy
measurements -- is fundamental in science and engineering. Score-based
generative models (SGMs) have recently emerged as a powerful framework for this
task. Two main paradigms have formed: unsupervised approaches that adapt
pretrained generative models to inverse problems, and supervised bridge methods
that train stochastic processes conditioned on paired clean and corrupted data.
While the former typically assume knowledge of the measurement model, the
latter have largely overlooked this structural information. We introduce System
embedded Diffusion Bridge Models (SDBs), a new class of supervised bridge
methods that explicitly embed the known linear measurement system into the
coefficients of a matrix-valued SDE. This principled integration yields
consistent improvements across diverse linear inverse problems and demonstrates
robust generalization under system misspecification between training and
deployment, offering a promising solution to real-world applications.

</details>


### [307] [Radioactive Watermarks in Diffusion and Autoregressive Image Generative Models](https://arxiv.org/abs/2506.23731)
*Michel Meintz,Jan Dubiński,Franziska Boenisch,Adam Dziedzic*

Main category: cs.LG

TL;DR: 论文分析了扩散模型和自回归图像模型中水印的放射性问题，并提出了一种针对自回归模型的新型水印方法，以确保水印在训练后仍可检测。


<details>
  <summary>Details</summary>
Motivation: 生成模型训练需要大量数据，但收集成本高。为避免未经授权使用生成图像训练新模型，需要水印具有放射性（即在训练后仍可检测）。

Method: 分析了扩散模型和自回归模型中水印的放射性问题，并借鉴大型语言模型技术，提出了一种针对自回归模型的新型水印方法。

Result: 现有扩散模型水印方法缺乏放射性，而提出的自回归模型水印方法能有效保留放射性，实现来源追踪和防止未经授权使用。

Conclusion: 新型水印方法解决了自回归模型中水印放射性问题，为生成图像的来源追踪提供了有效工具。

Abstract: Image generative models have become increasingly popular, but training them
requires large datasets that are costly to collect and curate. To circumvent
these costs, some parties may exploit existing models by using the generated
images as training data for their own models. In general, watermarking is a
valuable tool for detecting unauthorized use of generated images. However, when
these images are used to train a new model, watermarking can only enable
detection if the watermark persists through training and remains identifiable
in the outputs of the newly trained model - a property known as radioactivity.
We analyze the radioactivity of watermarks in images generated by diffusion
models (DMs) and image autoregressive models (IARs). We find that existing
watermarking methods for DMs fail to retain radioactivity, as watermarks are
either erased during encoding into the latent space or lost in the
noising-denoising process (during the training in the latent space). Meanwhile,
despite IARs having recently surpassed DMs in image generation quality and
efficiency, no radioactive watermarking methods have been proposed for them. To
overcome this limitation, we propose the first watermarking method tailored for
IARs and with radioactivity in mind - drawing inspiration from techniques in
large language models (LLMs), which share IARs' autoregressive paradigm. Our
extensive experimental evaluation highlights our method's effectiveness in
preserving radioactivity within IARs, enabling robust provenance tracking, and
preventing unauthorized use of their generated images.

</details>


### [308] [Training of Spiking Neural Networks with Expectation-Propagation](https://arxiv.org/abs/2506.23757)
*Dan Yao,Steve McLaughlin,Yoann Altmann*

Main category: cs.LG

TL;DR: 提出了一种基于期望传播的统一消息传递框架，用于训练脉冲神经网络（SNNs），无需梯度即可学习参数分布。


<details>
  <summary>Details</summary>
Motivation: 解决传统梯度方法在训练SNNs时的局限性，提供一种更高效的训练方法。

Method: 使用期望传播的消息传递框架，同时边缘化隐藏层输出等干扰参数。

Result: 在实践中比梯度方法收敛更快，适用于离散和连续权重的训练。

Conclusion: 为深度贝叶斯网络的高效训练开辟了新途径。

Abstract: In this paper, we propose a unifying message-passing framework for training
spiking neural networks (SNNs) using Expectation-Propagation. Our gradient-free
method is capable of learning the marginal distributions of network parameters
and simultaneously marginalizes nuisance parameters, such as the outputs of
hidden layers. This framework allows for the first time, training of discrete
and continuous weights, for deterministic and stochastic spiking networks,
using batches of training samples. Although its convergence is not ensured, the
algorithm converges in practice faster than gradient-based methods, without
requiring a large number of passes through the training data. The
classification and regression results presented pave the way for new efficient
training methods for deep Bayesian networks.

</details>


### [309] [Model-driven Stochastic Trace Clustering](https://arxiv.org/abs/2506.23776)
*Jari Peeperkorn,Johannes De Smedt,Jochen De Weerdt*

Main category: cs.LG

TL;DR: 提出了一种基于随机过程模型的轨迹聚类方法，通过熵相关性度量优化聚类，提高模型可解释性和性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有轨迹聚类方法忽略活动频率或概率的问题，以更好地捕捉真实世界执行动态。

Method: 使用基于直接跟随概率的熵相关性度量，优化每个聚类中的随机过程模型。

Result: 在公开数据集上表现优于现有方法，揭示了考虑随机性时聚类性能排名的变化。

Conclusion: 新方法在计算效率和模型可解释性上表现优异，为轨迹聚类提供了更有效的解决方案。

Abstract: Process discovery algorithms automatically extract process models from event
logs, but high variability often results in complex and hard-to-understand
models. To mitigate this issue, trace clustering techniques group process
executions into clusters, each represented by a simpler and more understandable
process model. Model-driven trace clustering improves on this by assigning
traces to clusters based on their conformity to cluster-specific process
models. However, most existing clustering techniques rely on either no process
model discovery, or non-stochastic models, neglecting the frequency or
probability of activities and transitions, thereby limiting their capability to
capture real-world execution dynamics. We propose a novel model-driven trace
clustering method that optimizes stochastic process models within each cluster.
Our approach uses entropic relevance, a stochastic conformance metric based on
directly-follows probabilities, to guide trace assignment. This allows
clustering decisions to consider both structural alignment with a cluster's
process model and the likelihood that a trace originates from a given
stochastic process model. The method is computationally efficient, scales
linearly with input size, and improves model interpretability by producing
clusters with clearer control-flow patterns. Extensive experiments on public
real-life datasets show that our method outperforms existing alternatives in
representing process behavior and reveals how clustering performance rankings
can shift when stochasticity is considered.

</details>


### [310] [Calibrating Graph Neural Networks with Wavelet-Aware Temperature Scaling](https://arxiv.org/abs/2506.23782)
*Xiaoyang Li,Linwei Tao,Haohui Lu,Minjing Dong,Junbin Gao,Chang Xu*

Main category: cs.LG

TL;DR: 提出了一种基于图小波的校准方法WATS，显著提升了GNN的置信度校准性能。


<details>
  <summary>Details</summary>
Motivation: GNN的置信度估计与实际预测准确性不一致，限制了其在安全关键场景中的应用。现有方法依赖粗粒度统计或节点嵌入，忽略了图拓扑的细粒度结构异质性。

Method: 提出WATS框架，利用可调热核图小波特征为节点分配特定温度，无需重新训练模型或访问邻域信息。

Result: 在七个基准数据集和两种GNN架构上，WATS的ECE最低，比现有方法提升42.3%，校准方差平均降低17.24%。

Conclusion: WATS通过图小波特征高效且显著地改进了GNN的置信度校准，适用于不同规模和密度的图。

Abstract: Graph Neural Networks (GNNs) have demonstrated strong predictive performance
on relational data; however, their confidence estimates often misalign with
actual predictive correctness, posing significant limitations for deployment in
safety-critical settings. While existing graph-aware calibration methods seek
to mitigate this limitation, they primarily depend on coarse one-hop
statistics, such as neighbor-predicted confidence, or latent node embeddings,
thereby neglecting the fine-grained structural heterogeneity inherent in graph
topology. In this work, we propose Wavelet-Aware Temperature Scaling (WATS), a
post-hoc calibration framework that assigns node-specific temperatures based on
tunable heat-kernel graph wavelet features. Specifically, WATS harnesses the
scalability and topology sensitivity of graph wavelets to refine confidence
estimates, all without necessitating model retraining or access to neighboring
logits or predictions. Extensive evaluations across seven benchmark datasets
with varying graph structures and two GNN backbones demonstrate that WATS
achieves the lowest Expected Calibration Error (ECE) among all compared
methods, outperforming both classical and graph-specific baselines by up to
42.3\% in ECE and reducing calibration variance by 17.24\% on average compared
with graph-specific methods. Moreover, WATS remains computationally efficient,
scaling well across graphs of diverse sizes and densities. Code will be
released based on publication.

</details>


### [311] [KAIROS: Scalable Model-Agnostic Data Valuation](https://arxiv.org/abs/2506.23799)
*Jiongli Zhu,Parjanya Prajakta Prashant,Alex Cloninger,Babak Salimi*

Main category: cs.LG

TL;DR: KAIROS是一个可扩展的、模型无关的框架，通过MMD评分评估训练数据的影响力，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有数据估值方法存在偏差或计算成本高的问题，需要一种更高效且准确的方法。

Method: KAIROS利用MMD评分计算每个样本对训练分布的影响，无需重新训练，支持在线更新。

Result: KAIROS在噪声、错误标签和中毒基准测试中表现优于现有方法，速度提升50倍。

Conclusion: KAIROS提供了一种高效、准确的数据估值方法，具有理论保证和实际优势。

Abstract: Training data increasingly shapes not only model accuracy but also regulatory
compliance and market valuation of AI assets. Yet existing valuation methods
remain inadequate: model-based techniques depend on a single fitted model and
inherit its biases, while algorithm-based approaches such as Data Shapley
require costly retrainings at web scale. Recent Wasserstein-based
model-agnostic methods rely on approximations that misrank examples relative to
their true leave-one-out (LOO) utility. We introduce KAIROS, a scalable,
model-agnostic valuation framework that assigns each example a distributional
influence score: its contribution to the Maximum Mean Discrepancy (MMD) between
the empirical training distribution and a clean reference set. Unlike
Wasserstein surrogates, our MMD-based influence admits a closed-form solution
that faithfully approximates the exact LOO ranking within $O(1/N^2)$ error,
requires no retraining, and naturally extends to conditional kernels for
unified label- and feature-error detection. Moreover, KAIROS supports efficient
online updates: when a new batch of size m arrives, all scores can be updated
in $O(mN)$ time, delivering up to 50x speedup without compromising ranking
quality. Empirical evaluations on noise, mislabeling, and poisoning benchmarks
show that KAIROS consistently outperforms state-of-the-art model-, Shapley-,
and Wasserstein-based baselines in both accuracy and runtime. We provide
rigorous theoretical guarantees, including symmetry for reproducible rankings
and density-separation for interpretable thresholds.

</details>


### [312] [Towards the Training of Deeper Predictive Coding Neural Networks](https://arxiv.org/abs/2506.23800)
*Chang Qi,Matteo Forasassi,Thomas Lukasiewicz,Tommaso Salvatori*

Main category: cs.LG

TL;DR: 论文提出两种新方法解决深度预测编码网络的性能下降问题，通过优化隐变量和权重更新机制，显著提升了深层网络的测试准确率。


<details>
  <summary>Details</summary>
Motivation: 研究发现深度超过五到七层的预测编码网络性能显著下降，原因是权重更新时层间误差不平衡以及深层更新缺乏有效指导。

Method: 引入两种优化隐变量的方法，使用精度加权平衡能量分布，并提出新的权重更新机制减少深层误差累积。

Result: 在多个图像分类任务中测试，七层以上网络的测试准确率大幅提升，性能接近反向传播模型。

Conclusion: 研究表明理解松弛阶段对训练大规模平衡传播模型至关重要，为复杂任务中的应用开辟了新可能性。

Abstract: Predictive coding networks trained with equilibrium propagation are neural
models that perform inference through an iterative energy minimization process.
Previous studies have demonstrated their effectiveness in shallow
architectures, but show significant performance degradation when depth exceeds
five to seven layers. In this work, we show that the reason behind this
degradation is due to exponentially imbalanced errors between layers during
weight updates, and predictions from the previous layer not being effective in
guiding updates in deeper layers. We address the first issue by introducing two
novel methods to optimize the latent variables that use precision-weighting to
re-balance the distribution of energy among layers during the `relaxation
phase', and the second issue by proposing a novel weight update mechanism that
reduces error accumulation in deeper layers. Empirically, we test our methods
on a large number of image classification tasks, resulting in large
improvements in test accuracy across networks with more than seven layers, with
performances comparable to those of backprop on similar models. These findings
suggest that a better understanding of the relaxation phase is important to
train models using equilibrium propagation at scale, and open new possibilities
for their application in complex tasks.

</details>


### [313] [Adaptive Out-of-Control Point Pattern Detection in Sequential Random Finite Set Observations](https://arxiv.org/abs/2506.23802)
*Konstantinos Bourazas,Savvas Papaioannou,Panayiotis Kolios*

Main category: cs.LG

TL;DR: 提出了一种用于监测序列随机有限集观测的自适应异常检测框架，通过检测数据生成过程的统计行为偏差来区分正常与异常数据。


<details>
  <summary>Details</summary>
Motivation: 针对序列随机有限集观测的异常检测需求，开发一种能在线学习数据生成过程正常行为并动态适应行为变化的框架。

Method: 引入了一种新型的随机有限集后验分布（Power Discounting Posteriors, PD），通过预测后验密度函数实现点模式数据的异常检测。

Result: 通过广泛的定性和定量模拟实验验证了该方法的有效性。

Conclusion: 该框架能够动态适应数据行为变化，并准确识别异常点模式。

Abstract: In this work we introduce a novel adaptive anomaly detection framework
specifically designed for monitoring sequential random finite set (RFS)
observations. Our approach effectively distinguishes between In-Control data
(normal) and Out-Of-Control data (anomalies) by detecting deviations from the
expected statistical behavior of the process. The primary contributions of this
study include the development of an innovative RFS-based framework that not
only learns the normal behavior of the data-generating process online but also
dynamically adapts to behavioral shifts to accurately identify abnormal point
patterns. To achieve this, we introduce a new class of RFS-based posterior
distributions, named Power Discounting Posteriors (PD), which facilitate
adaptation to systematic changes in data while enabling anomaly detection of
point pattern data through a novel predictive posterior density function. The
effectiveness of the proposed approach is demonstrated by extensive qualitative
and quantitative simulation experiments.

</details>


### [314] [SGD with Adaptive Preconditioning: Unified Analysis and Momentum Acceleration](https://arxiv.org/abs/2506.23803)
*Dmitry Kovalev*

Main category: cs.LG

TL;DR: 本文重新审视了带有AdaGrad型预处理的随机梯度下降（SGD），提出了统一的收敛性分析，并证明了AdaGrad和DASGO等方法的收敛速度可通过Nesterov动量加速。


<details>
  <summary>Details</summary>
Motivation: 研究SGD在自适应预处理下的收敛性，揭示AdaGrad型算法的理论优势，并解释Adam等方法的实际效率。

Method: 提出统一的收敛性分析框架，涵盖多种自适应梯度方法（如AdaGrad-Norm、AdaGrad、ASGO/One-sided Shampoo），并分析Scion和DASGO的理论联系。

Result: 证明了AdaGrad和DASGO的收敛速度可通过Nesterov动量加速，首次为DASGO提供理论保证。

Conclusion: AdaGrad型算法能同时受益于对角预处理和动量，这可能是Adam等算法实际高效的理论解释。

Abstract: In this paper, we revisit stochastic gradient descent (SGD) with AdaGrad-type
preconditioning. Our contributions are twofold. First, we develop a unified
convergence analysis of SGD with adaptive preconditioning under anisotropic or
matrix smoothness and noise assumptions. This allows us to recover
state-of-the-art convergence results for several popular adaptive gradient
methods, including AdaGrad-Norm, AdaGrad, and ASGO/One-sided Shampoo. In
addition, we establish the fundamental connection between two recently proposed
algorithms, Scion and DASGO, and provide the first theoretical guarantees for
the latter. Second, we show that the convergence of methods like AdaGrad and
DASGO can be provably accelerated beyond the best-known rates using Nesterov
momentum. Consequently, we obtain the first theoretical justification that
AdaGrad-type algorithms can simultaneously benefit from both diagonal
preconditioning and momentum, which may provide an ultimate explanation for the
practical efficiency of Adam.

</details>


### [315] [Supercm: Revisiting Clustering for Semi-Supervised Learning](https://arxiv.org/abs/2506.23824)
*Durgesh Singh,Ahcene Boubekki,Robert Jenssen,Michael C. Kampffmeyer*

Main category: cs.LG

TL;DR: 提出了一种新的半监督学习方法，通过可微分聚类模块显式结合聚类假设，简化训练策略并提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前半监督学习方法多依赖复杂的训练策略，本文旨在通过显式结合聚类假设简化方法并提升效果。

Method: 扩展可微分聚类模块，利用标注数据指导聚类中心，实现端到端训练。

Result: 模型性能优于仅监督基线，并可与其他半监督方法结合进一步提升效果。

Conclusion: 显式结合聚类假设的半监督学习方法简单有效，且具有兼容性。

Abstract: The development of semi-supervised learning (SSL) has in recent years largely
focused on the development of new consistency regularization or entropy
minimization approaches, often resulting in models with complex training
strategies to obtain the desired results. In this work, we instead propose a
novel approach that explicitly incorporates the underlying clustering
assumption in SSL through extending a recently proposed differentiable
clustering module. Leveraging annotated data to guide the cluster centroids
results in a simple end-to-end trainable deep SSL approach. We demonstrate that
the proposed model improves the performance over the supervised-only baseline
and show that our framework can be used in conjunction with other SSL methods
to further boost their performance.

</details>


### [316] [EFPI: Elastic Formation and Position Identification in Football (Soccer) using Template Matching and Linear Assignment](https://arxiv.org/abs/2506.23843)
*Joris Bekkers*

Main category: cs.LG

TL;DR: 提出了一种基于静态阵型模板和时空跟踪数据的足球阵型识别方法EFPI，通过线性求和分配优化球员位置匹配。


<details>
  <summary>Details</summary>
Motivation: 足球战术分析需要准确识别球队阵型和球员位置，现有方法灵活性不足。

Method: 使用预定义静态阵型模板，通过最小化球员实际位置与模板位置的总距离，优化匹配。加入稳定性参数避免频繁阵型变化。

Result: EFPI能有效识别阵型，适用于单帧或更长时间段，如半场或特定间隔。

Conclusion: EFPI是一种灵活且准确的阵型识别方法，已开源实现。

Abstract: Understanding team formations and player positioning is crucial for tactical
analysis in football (soccer). This paper presents a flexible method for
formation recognition and player position assignment in football using
predefined static formation templates and cost minimization from spatiotemporal
tracking data, called EFPI. Our approach employs linear sum assignment to
optimally match players to positions within a set of template formations by
minimizing the total distance between actual player locations and template
positions, subsequently selecting the formation with the lowest assignment
cost. To improve accuracy, we scale actual player positions to match the
dimensions of these formation templates in both width and length. While the
method functions effectively on individual frames, it extends naturally to
larger game segments such as complete periods, possession sequences or specific
intervals (e.g. 10 second intervals, 5 minute intervals etc.). Additionally, we
incorporate an optional stability parameter that prevents unnecessary formation
changes when assignment costs differ only marginally between time segments.
EFPI is available as open-source code through the unravelsports Python package.

</details>


### [317] [Use Sparse Autoencoders to Discover Unknown Concepts, Not to Act on Known Concepts](https://arxiv.org/abs/2506.23845)
*Kenny Peng,Rajiv Movva,Jon Kleinberg,Emma Pierson,Nikhil Garg*

Main category: cs.LG

TL;DR: SAEs在已知概念上效果有限，但在发现未知概念方面表现强大，适用于ML可解释性、社会科学等领域。


<details>
  <summary>Details</summary>
Motivation: 解决关于SAEs有用性的争议，明确其在不同场景下的适用性。

Method: 提出概念区分，分析SAEs在已知和未知概念上的表现。

Result: SAEs适用于发现未知概念，尤其在ML可解释性、社会科学等领域有潜力。

Conclusion: SAEs的价值在于发现未知概念，为多个领域提供新工具。

Abstract: While sparse autoencoders (SAEs) have generated significant excitement, a
series of negative results have added to skepticism about their usefulness.
Here, we establish a conceptual distinction that reconciles competing
narratives surrounding SAEs. We argue that while SAEs may be less effective for
acting on known concepts, SAEs are powerful tools for discovering unknown
concepts. This distinction cleanly separates existing negative and positive
results, and suggests several classes of SAE applications. Specifically, we
outline use cases for SAEs in (i) ML interpretability, explainability,
fairness, auditing, and safety, and (ii) social and health sciences.

</details>


### [318] [When Plants Respond: Electrophysiology and Machine Learning for Green Monitoring Systems](https://arxiv.org/abs/2506.23872)
*Eduard Buss,Till Aust,Heiko Hamann*

Main category: cs.LG

TL;DR: 植物作为自然传感器，通过穿戴设备PhytoNode记录电生理活动，结合AutoML分析环境数据，实现高精度环境监测。


<details>
  <summary>Details</summary>
Motivation: 利用植物的电生理活动作为环境监测的数据源，开发可持续的生物混合系统。

Method: 在户外环境中部署穿戴设备PhytoNode，记录植物电生理数据，使用AutoML分析数据并分类。

Result: 分类模型在二元任务中达到95%的F1分数，AutoML优于手动调参。

Conclusion: 该研究推动了可持续、自维持的植物集成生物混合系统在环境监测中的应用。

Abstract: Living plants, while contributing to ecological balance and climate
regulation, also function as natural sensors capable of transmitting
information about their internal physiological states and surrounding
conditions. This rich source of data provides potential for applications in
environmental monitoring and precision agriculture. With integration into
biohybrid systems, we establish novel channels of physiological signal flow
between living plants and artificial devices. We equipped *Hedera helix* with a
plant-wearable device called PhytoNode to continuously record the plant's
electrophysiological activity. We deployed plants in an uncontrolled outdoor
environment to map electrophysiological patterns to environmental conditions.
Over five months, we collected data that we analyzed using state-of-the-art and
automated machine learning (AutoML). Our classification models achieve high
performance, reaching macro F1 scores of up to 95 percent in binary tasks.
AutoML approaches outperformed manual tuning, and selecting subsets of
statistical features further improved accuracy. Our biohybrid living system
monitors the electrophysiology of plants in harsh, real-world conditions. This
work advances scalable, self-sustaining, and plant-integrated living biohybrid
systems for sustainable environmental monitoring.

</details>


### [319] [Chain of Thought in Order: Discovering Learning-Friendly Orders for Arithmetic](https://arxiv.org/abs/2506.23875)
*Yuta Sato,Kazuhiko Kawamoto,Hiroshi Kera*

Main category: cs.LG

TL;DR: 研究提出了一种重新排序解码器输入标记的方法，以优化Transformer在算术任务中的学习顺序。


<details>
  <summary>Details</summary>
Motivation: 探索中间步骤的顺序如何影响Transformer的推理难度，并提出一种学习友好的顺序。

Method: 通过训练Transformer在不同顺序的目标序列上，并识别早期损失下降快的顺序，采用两阶段分层方法进行块间和块内重新排序。

Result: 在四个顺序敏感的算术任务中，方法从数十亿候选顺序中找到了学习友好的顺序，并在乘法任务中复现了先前研究的逆序数字顺序。

Conclusion: 重新排序解码器输入标记可以显著优化Transformer的学习效率，尤其是在顺序敏感的任务中。

Abstract: The chain of thought is fundamental in Transformers, which is to perform
step-by-step reasoning. Besides what intermediate steps work, the order of
these steps critically affects the difficulty of the reasoning. This study
addresses a novel task of unraveling chain of thought - reordering decoder
input tokens to a learning-friendly sequence for Transformers to learn
arithmetic tasks. The proposed pipeline first trains a Transformer on a mixture
of target sequences arranged in different orders and then identifies benign
orders as those with fast loss drops in the early stage. As the search space
grows factorially with sequence length, we propose a two-stage hierarchical
approach for inter- and intra-block reordering. Experiments on four
order-sensitive arithmetic tasks show that our method identifies a
learning-friendly order out of a few billion candidates. Notably, on the
multiplication task, it recovered the reverse-digit order reported in prior
studies.

</details>


### [320] [Reinforcement Learning for Synchronised Flow Control in a Dual-Gate Resin Infusion System](https://arxiv.org/abs/2506.23923)
*Miguel Camacho-Sánchez,Fernando García-Torres,Jesper John Lisegaard,Rocío del Amor,Sankhya Mohanty,Valery Naranjo*

Main category: cs.LG

TL;DR: 论文提出了一种基于强化学习（RL）的策略，用于控制树脂注入过程中的流动动态，以提高复合材料制造的均匀性和质量。


<details>
  <summary>Details</summary>
Motivation: 树脂注入（RI）和树脂传递模塑（RTM）是制造高性能纤维增强复合材料的关键工艺，但树脂流动动态的控制对避免孔隙和干斑至关重要。

Method: 使用近端策略优化（PPO）的强化学习方法，通过模拟过程同步两个树脂入口和一个出口的流动前沿。

Result: 结果表明，RL方法能有效实现流动收敛，提升工艺控制和产品质量。

Conclusion: 强化学习方法在复合材料制造中具有潜力，可优化工艺控制并提高产品一致性。

Abstract: Resin infusion (RI) and resin transfer moulding (RTM) are critical processes
for the manufacturing of high-performance fibre-reinforced polymer composites,
particularly for large-scale applications such as wind turbine blades.
Controlling the resin flow dynamics in these processes is critical to ensure
the uniform impregnation of the fibre reinforcements, thereby preventing
residual porosities and dry spots that impact the consequent structural
integrity of the final component. This paper presents a reinforcement learning
(RL) based strategy, established using process simulations, for synchronising
the different resin flow fronts in an infusion scenario involving two resin
inlets and a single outlet. Using Proximal Policy Optimisation (PPO), our
approach addresses the challenge of managing the fluid dynamics in a partially
observable environment. The results demonstrate the effectiveness of the RL
approach in achieving an accurate flow convergence, highlighting its potential
towards improving process control and product quality in composites
manufacturing.

</details>


### [321] [Bridging the Gap with Retrieval-Augmented Generation: Making Prosthetic Device User Manuals Available in Marginalised Languages](https://arxiv.org/abs/2506.23958)
*Ikechukwu Ogbonna,Lesley Davidson,Soumya Banerjee,Abhishek Dasgupta,Laurence Kenney,Vikranth Harthikote Nagaraja*

Main category: cs.LG

TL;DR: 研究开发了一个AI框架，将复杂的医疗文档（如假肢设备手册）翻译成边缘化语言，解决非洲国家因语言和识字障碍导致的医疗获取问题。


<details>
  <summary>Details</summary>
Motivation: 非洲国家许多人因语言和识字障碍无法获取医疗信息，尤其是捐赠的假肢设备缺乏本地化文档。

Method: 采用检索增强生成（RAG）管道处理手册，结合NLP模型实现多语言翻译和生成式问答。

Result: 系统能实时将英文手册翻译为本地语言（如皮钦语），并提供准确回答，提升医疗信息可及性。

Conclusion: 该框架为边缘化社区提供了可扩展的医疗信息翻译解决方案，支持患者和医护人员做出知情决策。

Abstract: Millions of people in African countries face barriers to accessing healthcare
due to language and literacy gaps. This research tackles this challenge by
transforming complex medical documents -- in this case, prosthetic device user
manuals -- into accessible formats for underserved populations. This case study
in cross-cultural translation is particularly pertinent/relevant for
communities that receive donated prosthetic devices but may not receive the
accompanying user documentation. Or, if available online, may only be available
in formats (e.g., language and readability) that are inaccessible to local
populations (e.g., English-language, high resource settings/cultural context).
The approach is demonstrated using the widely spoken Pidgin dialect, but our
open-source framework has been designed to enable rapid and easy extension to
other languages/dialects. This work presents an AI-powered framework designed
to process and translate complex medical documents, e.g., user manuals for
prosthetic devices, into marginalised languages. The system enables users --
such as healthcare workers or patients -- to upload English-language medical
equipment manuals, pose questions in their native language, and receive
accurate, localised answers in real time. Technically, the system integrates a
Retrieval-Augmented Generation (RAG) pipeline for processing and semantic
understanding of the uploaded manuals. It then employs advanced Natural
Language Processing (NLP) models for generative question-answering and
multilingual translation. Beyond simple translation, it ensures accessibility
to device instructions, treatment protocols, and safety information, empowering
patients and clinicians to make informed healthcare decisions.

</details>


### [322] [ADReFT: Adaptive Decision Repair for Safe Autonomous Driving via Reinforcement Fine-Tuning](https://arxiv.org/abs/2506.23960)
*Mingfei Cheng,Xiaofei Xie,Renzhi Wang,Yuan Zhou,Ming Hu*

Main category: cs.LG

TL;DR: 提出了一种名为ADReFT的自适应决策修复方法，通过离线学习和在线修复提升自动驾驶系统的安全性。


<details>
  <summary>Details</summary>
Motivation: 现有在线修复方法缺乏通用性和适应性，导致修复效果不佳，影响驾驶体验。

Method: ADReFT结合了基于Transformer的模型，通过状态监控和决策适配器生成修复动作，并利用监督学习和强化学习进行训练。

Result: ADReFT在修复性能上表现更优。

Conclusion: ADReFT通过自适应修复方法显著提升了自动驾驶系统的安全性和可靠性。

Abstract: Autonomous Driving Systems (ADSs) continue to face safety-critical risks due
to the inherent limitations in their design and performance capabilities.
Online repair plays a crucial role in mitigating such limitations, ensuring the
runtime safety and reliability of ADSs. Existing online repair solutions
enforce ADS compliance by transforming unacceptable trajectories into
acceptable ones based on predefined specifications, such as rule-based
constraints or training datasets. However, these approaches often lack
generalizability, adaptability and tend to be overly conservative, resulting in
ineffective repairs that not only fail to mitigate safety risks sufficiently
but also degrade the overall driving experience. To address this issue, we
propose Adaptive Decision Repair (ADReFT), a novel and effective repair method
that identifies safety-critical states through offline learning from failed
tests and generates appropriate mitigation actions to improve ADS safety.
Specifically, ADReFT incorporates a transformer-based model with two joint
heads, State Monitor and Decision Adapter, designed to capture complex driving
environment interactions to evaluate state safety severity and generate
adaptive repair actions. Given the absence of oracles for state safety
identification, we first pretrain ADReFT using supervised learning with coarse
annotations, i.e., labeling states preceding violations as positive samples and
others as negative samples. It establishes ADReFT's foundational capability to
mitigate safety-critical violations, though it may result in somewhat
conservative mitigation strategies. Therefore, we subsequently finetune ADReFT
using reinforcement learning to improve its initial capability and generate
more precise and contextually appropriate repair decisions. Our evaluation
results illustrate that ADReFT achieves better repair performance.

</details>


### [323] [UMA: A Family of Universal Models for Atoms](https://arxiv.org/abs/2506.23971)
*Brandon M. Wood,Misko Dzamba,Xiang Fu,Meng Gao,Muhammed Shuaibi,Luis Barroso-Luque,Kareem Abdelmaqsoud,Vahe Gharakhanyan,John R. Kitchin,Daniel S. Levine,Kyle Michel,Anuroop Sriram,Taco Cohen,Abhishek Das,Ammar Rizvi,Sushree Jagriti Sahoo,Zachary W. Ulissi,C. Lawrence Zitnick*

Main category: cs.LG

TL;DR: Meta FAIR提出通用原子模型（UMA），通过大规模数据和新型架构设计，实现快速、准确且通用的原子模拟计算。


<details>
  <summary>Details</summary>
Motivation: 快速准确计算原子模拟性质对化学和材料科学应用（如药物发现、能源存储等）至关重要。

Method: UMA模型基于5亿个3D原子结构训练，采用混合线性专家架构，支持模型容量扩展而不牺牲速度。

Result: UMA模型在多个领域应用中表现优异，无需微调即可媲美或超越专用模型。

Conclusion: UMA的代码、权重和数据已开源，旨在推动AI模型在计算工作流中的应用。

Abstract: The ability to quickly and accurately compute properties from atomic
simulations is critical for advancing a large number of applications in
chemistry and materials science including drug discovery, energy storage, and
semiconductor manufacturing. To address this need, Meta FAIR presents a family
of Universal Models for Atoms (UMA), designed to push the frontier of speed,
accuracy, and generalization. UMA models are trained on half a billion unique
3D atomic structures (the largest training runs to date) by compiling data
across multiple chemical domains, e.g. molecules, materials, and catalysts. We
develop empirical scaling laws to help understand how to increase model
capacity alongside dataset size to achieve the best accuracy. The UMA small and
medium models utilize a novel architectural design we refer to as mixture of
linear experts that enables increasing model capacity without sacrificing
speed. For example, UMA-medium has 1.4B parameters but only ~50M active
parameters per atomic structure. We evaluate UMA models on a diverse set of
applications across multiple domains and find that, remarkably, a single model
without any fine-tuning can perform similarly or better than specialized
models. We are releasing the UMA code, weights, and associated data to
accelerate computational workflows and enable the community to continue to
build increasingly capable AI models.

</details>


### [324] [A Scalable Approach for Safe and Robust Learning via Lipschitz-Constrained Networks](https://arxiv.org/abs/2506.23977)
*Zain ul Abdeen,Vassilis Kekatos,Ming Jin*

Main category: cs.LG

TL;DR: 提出了一种基于凸训练框架的方法，通过半定松弛实现全局Lipschitz约束，解决了传统方法的非凸性和可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 在安全关键应用中，神经网络的认证鲁棒性至关重要，但现有方法因非凸性和全局半定规划（SDP）的可扩展性差而受限。

Method: 通过循环变换重新参数化神经网络，提出凸可接受条件，并结合随机子空间线性矩阵不等式（RS-LMI）分解全局约束为层间约束。

Result: 在MNIST、CIFAR-10和ImageNet上的实验表明，该方法在保持竞争力的准确率的同时，显著提高了Lipschitz边界和运行时性能。

Conclusion: 该框架为神经网络的认证鲁棒性提供了一种高效且可扩展的解决方案。

Abstract: Certified robustness is a critical property for deploying neural networks
(NN) in safety-critical applications. A principle approach to achieving such
guarantees is to constrain the global Lipschitz constant of the network.
However, accurate methods for Lipschitz-constrained training often suffer from
non-convex formulations and poor scalability due to reliance on global
semidefinite programs (SDPs). In this letter, we propose a convex training
framework that enforces global Lipschitz constraints via semidefinite
relaxation. By reparameterizing the NN using loop transformation, we derive a
convex admissibility condition that enables tractable and certifiable training.
While the resulting formulation guarantees robustness, its scalability is
limited by the size of global SDP. To overcome this, we develop a randomized
subspace linear matrix inequalities (RS-LMI) approach that decomposes the
global constraints into sketched layerwise constraints projected onto
low-dimensional subspaces, yielding a smooth and memory-efficient training
objective. Empirical results on MNIST, CIFAR-10, and ImageNet demonstrate that
the proposed framework achieves competitive accuracy with significantly
improved Lipschitz bounds and runtime performance.

</details>


### [325] [LLM Agents Are the Antidote to Walled Gardens](https://arxiv.org/abs/2506.23978)
*Samuele Marro,Philip Torr*

Main category: cs.LG

TL;DR: LLM-based agents enable universal interoperability, disrupting closed platforms by making data exchange cheaper and unavoidable, though it introduces new risks.


<details>
  <summary>Details</summary>
Motivation: The dominance of closed, proprietary platforms in the application layer limits data exchange and interoperability, which LLM-based agents can disrupt.

Method: LLM-based agents automatically translate data formats and interact with human-designed interfaces, enabling seamless data exchange.

Result: Universal interoperability undermines monopolistic behaviors and promotes data portability but introduces security risks and technical debt.

Conclusion: The ML community should embrace universal interoperability while developing frameworks to mitigate risks, restoring user freedom and competitive markets.

Abstract: While the Internet's core infrastructure was designed to be open and
universal, today's application layer is dominated by closed, proprietary
platforms. Open and interoperable APIs require significant investment, and
market leaders have little incentive to enable data exchange that could erode
their user lock-in. We argue that LLM-based agents fundamentally disrupt this
status quo. Agents can automatically translate between data formats and
interact with interfaces designed for humans: this makes interoperability
dramatically cheaper and effectively unavoidable. We name this shift universal
interoperability: the ability for any two digital services to exchange data
seamlessly using AI-mediated adapters. Universal interoperability undermines
monopolistic behaviours and promotes data portability. However, it can also
lead to new security risks and technical debt. Our position is that the ML
community should embrace this development while building the appropriate
frameworks to mitigate the downsides. By acting now, we can harness AI to
restore user freedom and competitive markets without sacrificing security.

</details>


### [326] [The Jacobian and Hessian of the Kullback-Leibler Divergence between Multivariate Gaussian Distributions (Technical Report)](https://arxiv.org/abs/2506.23996)
*Juan Maroñas*

Main category: cs.LG

TL;DR: 本文展示了如何通过一阶和二阶微分计算两个多元高斯分布之间Kullback-Leibler散度的Jacobian和Hessian矩阵。


<details>
  <summary>Details</summary>
Motivation: 旨在提供一种清晰且教学性的方法，推导多元高斯分布间Kullback-Leibler散度的Jacobian和Hessian矩阵。

Method: 基于Magnus（1999）的理论，并结合Minka的推导方法，通过一阶和二阶微分进行详细推导。

Result: 提供了详细的推导过程和结果，包括每个步骤的详细说明和技巧。

Conclusion: 本文为计算Kullback-Leibler散度的Jacobian和Hessian矩阵提供了一种系统且教学性的方法。

Abstract: This document shows how to obtain the Jacobian and Hessian matrices of the
Kullback-Leibler divergence between two multivariate Gaussian distributions,
using the first and second-order differentials. The presented derivations are
based on the theory presented by \cite{magnus99}. I've also got great
inspiration from some of the derivations in \cite{minka}.
  Since I pretend to be at most didactic, the document is split into a summary
of results and detailed derivations on each of the elements involved, with
specific references to the tricks used in the derivations, and to many of the
underlying concepts.

</details>


### [327] [The Illusion of Progress? A Critical Look at Test-Time Adaptation for Vision-Language Models](https://arxiv.org/abs/2506.24000)
*Lijun Sheng,Jian Liang,Ran He,Zilei Wang,Tieniu Tan*

Main category: cs.LG

TL;DR: TTA-VLM是一个全面的基准测试，用于评估视觉语言模型（VLM）的测试时适应（TTA）方法，解决了现有研究的局限性，并提供了多维度评估。


<details>
  <summary>Details</summary>
Motivation: 当前TTA研究存在结果重复、评估指标有限、实验设置不一致和分析不足等问题，阻碍了公平比较和实际应用。

Method: TTA-VLM实现了8种情景TTA和7种在线TTA方法，统一评估框架涵盖15个数据集，并扩展了模型和评估指标。

Result: 实验表明现有TTA方法改进有限，与训练时调优方法协作不佳，且准确性提升常以模型可信度下降为代价。

Conclusion: TTA-VLM为TTA方法提供了公平比较和全面评估，鼓励开发更可靠和通用的策略。

Abstract: Test-time adaptation (TTA) methods have gained significant attention for
enhancing the performance of vision-language models (VLMs) such as CLIP during
inference, without requiring additional labeled data. However, current TTA
researches generally suffer from major limitations such as duplication of
baseline results, limited evaluation metrics, inconsistent experimental
settings, and insufficient analysis. These problems hinder fair comparisons
between TTA methods and obscure their practical strengths and weaknesses. To
address these challenges, we introduce TTA-VLM, a comprehensive benchmark for
evaluating TTA methods on VLMs. Our benchmark implements 8 episodic TTA and 7
online TTA methods within a unified and reproducible framework, and evaluates
them across 15 widely used datasets. Unlike prior studies focused solely on
CLIP, we extend the evaluation to SigLIP--a model trained with a Sigmoid
loss--and include training-time tuning methods such as CoOp, MaPLe, and TeCoA
to assess generality. Beyond classification accuracy, TTA-VLM incorporates
various evaluation metrics, including robustness, calibration,
out-of-distribution detection, and stability, enabling a more holistic
assessment of TTA methods. Through extensive experiments, we find that 1)
existing TTA methods produce limited gains compared to the previous pioneering
work; 2) current TTA methods exhibit poor collaboration with training-time
fine-tuning methods; 3) accuracy gains frequently come at the cost of reduced
model trustworthiness. We release TTA-VLM to provide fair comparison and
comprehensive evaluation of TTA methods for VLMs, and we hope it encourages the
community to develop more reliable and generalizable TTA strategies.

</details>


### [328] [Provably Efficient and Agile Randomized Q-Learning](https://arxiv.org/abs/2506.24005)
*He Wang,Xingyu Xu,Yuejie Chi*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: While Bayesian-based exploration often demonstrates superior empirical
performance compared to bonus-based methods in model-based reinforcement
learning (RL), its theoretical understanding remains limited for model-free
settings. Existing provable algorithms either suffer from computational
intractability or rely on stage-wise policy updates which reduce responsiveness
and slow down the learning process. In this paper, we propose a novel variant
of Q-learning algorithm, refereed to as RandomizedQ, which integrates
sampling-based exploration with agile, step-wise, policy updates, for episodic
tabular RL. We establish an $\widetilde{O}(\sqrt{H^5SAT})$ regret bound, where
$S$ is the number of states, $A$ is the number of actions, $H$ is the episode
length, and $T$ is the total number of episodes. In addition, we present a
logarithmic regret bound under a mild positive sub-optimality condition on the
optimal Q-function. Empirically, RandomizedQ exhibits outstanding performance
compared to existing Q-learning variants with both bonus-based and
Bayesian-based exploration on standard benchmarks.

</details>


### [329] [Bridging Theory and Practice in Link Representation with Graph Neural Networks](https://arxiv.org/abs/2506.24018)
*Veronica Lachi,Francesco Ferrini,Antonio Longa,Bruno Lepri,Andrea Passerini,Manfred Jaeger*

Main category: cs.LG

TL;DR: 该论文首次全面研究了图神经网络（GNN）在链接表示中的表达能力，提出了一个统一框架$k_\phi$-$k_\rho$-$m$，并建立了方法层次结构。通过合成评估协议和对称性指标，发现表达能力强的模型在复杂场景中表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注图级表示，而忽略了链接表示的表达能力，因此需要填补这一理论空白。

Method: 提出$k_\phi$-$k_\rho$-$m$框架，统一现有消息传递链接模型，并通过理论分析和合成评估协议验证表达能力。

Result: 建立了链接表示方法的层次结构，并发现表达能力强的模型在高对称性场景中表现显著优于简单模型。

Conclusion: 链接表示的表达能力在实际应用中至关重要，尤其是在复杂对称性场景中，需根据数据集特点选择模型。

Abstract: Graph Neural Networks (GNNs) are widely used to compute representations of
node pairs for downstream tasks such as link prediction. Yet, theoretical
understanding of their expressive power has focused almost entirely on
graph-level representations. In this work, we shift the focus to links and
provide the first comprehensive study of GNN expressiveness in link
representation. We introduce a unifying framework, the $k_\phi$-$k_\rho$-$m$
framework, that subsumes existing message-passing link models and enables
formal expressiveness comparisons. Using this framework, we derive a hierarchy
of state-of-the-art methods and offer theoretical tools to analyze future
architectures. To complement our analysis, we propose a synthetic evaluation
protocol comprising the first benchmark specifically designed to assess
link-level expressiveness. Finally, we ask: does expressiveness matter in
practice? We use a graph symmetry metric that quantifies the difficulty of
distinguishing links and show that while expressive models may underperform on
standard benchmarks, they significantly outperform simpler ones as symmetry
increases, highlighting the need for dataset-aware model selection.

</details>


### [330] [Faster Diffusion Models via Higher-Order Approximation](https://arxiv.org/abs/2506.24042)
*Gen Li,Yuchen Zhou,Yuting Wei,Yuxin Chen*

Main category: cs.LG

TL;DR: 本文提出了一种无需重新训练的扩散模型加速方法，通过高阶ODE求解器近似概率流ODE积分，显著减少了评分函数评估次数。


<details>
  <summary>Details</summary>
Motivation: 探索无需额外训练的扩散模型加速方法，以更高效的方式逼近目标数据分布。

Method: 提出基于高阶ODE求解器的采样算法，利用高阶拉格朗日插值和连续细化近似概率流ODE积分。

Result: 在精确评分下，仅需约$d^{1+2/K} \varepsilon^{-1/K}$次评分函数评估即可逼近目标分布，且对评分误差具有鲁棒性。

Conclusion: 该方法适用于广泛的数据分布，无需平滑性或对数凹性假设，且对评分估计误差具有稳健性。

Abstract: In this paper, we explore provable acceleration of diffusion models without
any additional retraining. Focusing on the task of approximating a target data
distribution in $\mathbb{R}^d$ to within $\varepsilon$ total-variation
distance, we propose a principled, training-free sampling algorithm that
requires only the order of
  $$ d^{1+2/K} \varepsilon^{-1/K} $$
  score function evaluations (up to log factor) in the presence of accurate
scores, where $K$ is an arbitrarily large fixed integer. This result applies to
a broad class of target data distributions, without the need for assumptions
such as smoothness or log-concavity. Our theory is robust vis-a-vis inexact
score estimation, degrading gracefully as the score estimation error increases
-- without demanding higher-order smoothness on the score estimates as assumed
in previous work. The proposed algorithm draws insight from high-order ODE
solvers, leveraging high-order Lagrange interpolation and successive refinement
to approximate the integral derived from the probability flow ODE.

</details>


### [331] [Development of Hybrid Artificial Intelligence Training on Real and Synthetic Data: Benchmark on Two Mixed Training Strategies](https://arxiv.org/abs/2506.24093)
*Paul Wachter,Lukas Niehaus,Julius Schöning*

Main category: cs.LG

TL;DR: 论文研究了混合合成与真实数据训练神经网络的策略，评估了其在多种任务和架构中的泛化性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 合成数据是训练神经网络的低成本替代方案，但与真实数据存在领域差距，导致性能下降。研究旨在系统评估混合训练策略的效果。

Method: 分析了两种混合策略在三种架构和三种混合数据集上的表现，通过调整合成与真实数据的比例进行研究。

Result: 研究结果为优化合成数据在神经网络训练中的使用提供了有价值的见解。

Conclusion: 混合训练策略能有效缩小领域差距，提升神经网络的鲁棒性和性能。

Abstract: Synthetic data has emerged as a cost-effective alternative to real data for
training artificial neural networks (ANN). However, the disparity between
synthetic and real data results in a domain gap. That gap leads to poor
performance and generalization of the trained ANN when applied to real-world
scenarios. Several strategies have been developed to bridge this gap, which
combine synthetic and real data, known as mixed training using hybrid datasets.
While these strategies have been shown to mitigate the domain gap, a systematic
evaluation of their generalizability and robustness across various tasks and
architectures remains underexplored. To address this challenge, our study
comprehensively analyzes two widely used mixing strategies on three prevalent
architectures and three distinct hybrid datasets. From these datasets, we
sample subsets with varying proportions of synthetic to real data to
investigate the impact of synthetic and real components. The findings of this
paper provide valuable insights into optimizing the use of synthetic data in
the training process of any ANN, contributing to enhancing robustness and
efficacy.

</details>


### [332] [Data Uniformity Improves Training Efficiency and More, with a Convergence Framework Beyond the NTK Regime](https://arxiv.org/abs/2506.24120)
*Yuqing Wang,Shangding Gu*

Main category: cs.LG

TL;DR: 论文提出了一种数据选择的新原则，即选择更均匀分布的数据可以提高训练效率和模型性能，并通过理论和实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究数据选择中是否存在其他定量且通用的原则，能够在复杂任务中持续提升性能，尤其是在先验知识有限的情况下。

Method: 通过理论分析证明更均匀的数据分布（即更大的最小成对距离$h_{\min}$）能加速梯度下降训练并减少神经网络近似误差，同时提出适用于广泛架构的收敛框架。

Result: 实验表明，通过最大化数据点间距离选择数据能显著加速训练，并在不同数据集上实现可比或更好的性能。

Conclusion: 均匀分布的数据选择是一种有效的通用原则，能够提升训练效率和模型性能，尤其适用于复杂任务。

Abstract: Data selection plays a crucial role in data-driven decision-making, including
in large language models (LLMs), and is typically task-dependent. Properties
such as data quality and diversity have been extensively studied and are known
to enhance model performance. However, it remains unclear whether there exist
other quantitative and general principles of data selection that can
consistently improve performance, especially for complex tasks with limited
prior knowledge. In this paper, we demonstrate that selecting more uniformly
distributed data can improve training efficiency while enhancing performance.
Specifically, we establish that more uniform (less biased) distribution leads
to a larger minimum pairwise distance between data points, denoted by
$h_{\min}$, and prove that a smaller $h_{\min}$ can slow down the training
dynamics of gradient descent (GD). Moreover, we theoretically show that the
approximation error of neural networks decreases as $h_{\min}$ increases. Our
analysis introduces a convergence framework for GD beyond the Neural Tangent
Kernel (NTK) regime, applicable to a broad class of architectures, including
transformers, without requiring Lipschitz smoothness. This framework further
provides theoretical justification for the use of residual connections and
function compositions in deep neural architectures. In the end, we conduct
comprehensive experiments for supervised fine-tuning across various settings,
including different optimization strategies, model sizes, and training
datasets. The results consistently demonstrate that selecting data by
maximizing pairwise distance significantly accelerates training and achieves
comparable or better performance in LLMs across diverse datasets. Code and
Datasets are available at the link:
https://github.com/SafeRL-Lab/data-uniformity.

</details>


### [333] [Teaching Time Series to See and Speak: Forecasting with Aligned Visual and Textual Perspectives](https://arxiv.org/abs/2506.24124)
*Dong Sixun,Fan Wei,Teresa Wu,Fu Yanjie*

Main category: cs.LG

TL;DR: 提出了一种多模态对比学习框架，将时间序列转化为视觉和文本模态，并通过对比学习对齐，提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 传统时间序列预测依赖单模态数值输入，难以捕捉高级语义模式；现有基于LLM的方法受限于离散标记序列，缺乏人类视觉直觉。

Method: 构建视觉和文本模态，通过对比学习对齐，并引入变量选择模块识别信息量最大的变量。

Result: 在多个基准测试中表现优于单模态和跨模态基线，验证了多模态对齐的有效性。

Conclusion: 多模态对齐显著提升了时间序列预测性能，代码已开源。

Abstract: Time series forecasting traditionally relies on unimodal numerical inputs,
which often struggle to capture high-level semantic patterns due to their dense
and unstructured nature. While recent approaches have explored representing
time series as text using large language models (LLMs), these methods remain
limited by the discrete nature of token sequences and lack the perceptual
intuition humans typically apply, such as interpreting visual patterns. In this
paper, we propose a multimodal contrastive learning framework that transforms
raw time series into structured visual and textual perspectives. Rather than
using natural language or real-world images, we construct both modalities
directly from numerical sequences. We then align these views in a shared
semantic space via contrastive learning, enabling the model to capture richer
and more complementary representations. Furthermore, we introduce a variate
selection module that leverages the aligned representations to identify the
most informative variables for multivariate forecasting. Extensive experiments
on fifteen short-term and six long-term forecasting benchmarks demonstrate that
our approach consistently outperforms strong unimodal and cross-modal
baselines, highlighting the effectiveness of multimodal alignment in enhancing
time series forecasting. Code is available at:
https://github.com/Ironieser/TimesCLIP.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [334] [Cooperation as Black Box: Conceptual Fluctuation and Diagnostic Tools for Misalignment in MAS](https://arxiv.org/abs/2506.22876)
*Shayak Nandi,Fernanda M. Eliott*

Main category: cs.MA

TL;DR: 论文提出了一种诊断多智能体系统中意义层面错位的框架——错位马赛克（Misalignment Mosaic），用于分析语言、框架和设计假设导致的错位。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统中的错位常被归因于技术问题，但许多错位源于设计阶段的概念模糊和规范投射。

Method: 通过兔鸭错觉的类比，说明视角依赖的行为解读如何导致认知不稳定，并提出了错位马赛克框架，包含四个组件：术语不一致、概念到代码的衰减、道德即合作和解释模糊性。

Result: 框架能够诊断多智能体系统中语言、框架和设计假设导致的错位，适用于合作、协调等概念。

Conclusion: 错位马赛克为诊断多智能体系统中的意义错位提供了通用工具，不仅限于合作与协调的模糊性。

Abstract: Misalignment in multi-agent systems (MAS) is often treated as a technical
failure; yet many such failures originate upstream, during the conceptual
design phase, where semantic ambiguity and normative projection take place.
This paper identifies a foundational source of interpretive misalignment in
MAS: the systemic conflation of cooperation and coordination, and the moral
overreading that follows. Using the Rabbit-Duck illusion, we illustrate how
perspective-dependent readings of agent behavior can create epistemic
instability. To address this, we introduce the Misalignment Mosaic, a
diagnostic framework for diagnosing meaning-level misalignment in MAS. It
comprises four components: 1. Terminological Inconsistency, 2. Concept-to-Code
Decay, 3. Morality as Cooperation, and 4. Interpretive Ambiguity. The Mosaic
enables researchers to examine how misalignment arises not only through policy
or reward structures but also through language, framing, and design
assumptions. While this paper focuses on the specific ambiguity between
coordination and cooperation, the Mosaic generalizes to other overloaded
concepts in MAS, such as alignment, autonomy, and trust. Rather than define
cooperation once and for all, we offer a framework to diagnose meaning itself
as a source of misalignment.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [335] [Conversations with Andrea: Visitors' Opinions on Android Robots in a Museum](https://arxiv.org/abs/2506.22466)
*Marcel Heisler,Christian Becker-Asano*

Main category: cs.RO

TL;DR: 研究分析了Andrea机器人在博物馆中与访客的自主互动，探讨了访客对其用途、改进建议及性别线索的影响。


<details>
  <summary>Details</summary>
Motivation: 探索机器人在公共空间中的实际应用效果，了解访客对其功能和改进的需求。

Method: 在博物馆设置Andrea机器人，与访客进行自主对话，并通过结构化访谈和系统日志分析收集数据。

Result: 机器人总体评价积极，性别线索无显著影响；访客主要希望其提供展品信息，改进需求包括多语言支持和更快响应。

Conclusion: 研究为机器人实际应用提供了改进方向，未来将优化系统以满足访客需求。

Abstract: The android robot Andrea was set up at a public museum in Germany for six
consecutive days to have conversations with visitors, fully autonomously. No
specific context was given, so visitors could state their opinions regarding
possible use-cases in structured interviews, without any bias. Additionally the
44 interviewees were asked for their general opinions of the robot, their
reasons (not) to interact with it and necessary improvements for future use.
The android's voice and wig were changed between different days of operation to
give varying cues regarding its gender. This did not have a significant impact
on the positive overall perception of the robot. Most visitors want the robot
to provide information about exhibits in the future, while opinions on other
roles, like a receptionist, were both wanted and explicitly not wanted by
different visitors. Speaking more languages (than only English) and faster
response times were the improvements most desired. These findings from the
interviews are in line with an analysis of the system logs, which revealed,
that after chitchat and personal questions, most of the 4436 collected requests
asked for information related to the museum and to converse in a different
language. The valuable insights gained from these real-world interactions are
now used to improve the system to become a useful real-world application.

</details>


### [336] [Unsupervised Discovery of Behavioral Primitives from Sensorimotor Dynamic Functional Connectivity](https://arxiv.org/abs/2506.22473)
*Fernando Diaz Ledezma,Valentin Marcel,Matej Hoffmann*

Main category: cs.RO

TL;DR: 该论文提出了一种框架，通过动态功能连接分析机器人多模态感官信号，揭示其底层结构，并识别运动基元。


<details>
  <summary>Details</summary>
Motivation: 研究高维感官运动信息的动态功能连接，以帮助机器人或新生儿理解未处理的感官运动时间序列。

Method: 使用瞬时互信息捕捉时间变化的功能连接，结合无限关系模型和非负矩阵分解识别传感器运动模块及其动态交互。

Result: 揭示了传感器运动关系，并分解出运动基元，可用于行为选择。

Conclusion: 该方法未来可应用于机器人学习和人类运动轨迹或脑信号分析。

Abstract: The movements of both animals and robots give rise to streams of
high-dimensional motor and sensory information. Imagine the brain of a newborn
or the controller of a baby humanoid robot trying to make sense of unprocessed
sensorimotor time series. Here, we present a framework for studying the dynamic
functional connectivity between the multimodal sensory signals of a robotic
agent to uncover an underlying structure. Using instantaneous mutual
information, we capture the time-varying functional connectivity (FC) between
proprioceptive, tactile, and visual signals, revealing the sensorimotor
relationships. Using an infinite relational model, we identified sensorimotor
modules and their evolving connectivity. To further interpret these dynamic
interactions, we employed non-negative matrix factorization, which decomposed
the connectivity patterns into additive factors and their corresponding
temporal coefficients. These factors can be considered the agent's motion
primitives or movement synergies that the agent can use to make sense of its
sensorimotor space and later for behavior selection. In the future, the method
can be deployed in robot learning as well as in the analysis of human movement
trajectories or brain signals.

</details>


### [337] [Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop](https://arxiv.org/abs/2506.23351)
*Tianxing Chen,Kaixuan Wang,Zhaohui Yang,Yuhao Zhang,Zanxin Chen,Baijun Chen,Wanxi Dong,Ziyuan Liu,Dong Chen,Tianshuo Yang,Haibao Yu,Xiaokang Yang,Yusen Qin,Zhiqiang Xie,Yao Mu,Ping Luo,Tian Nian,Weiliang Deng,Yiheng Ge,Yibin Liu,Zixuan Li,Dehui Wang,Zhixuan Liang,Haohui Xie,Rijie Zeng,Yunfei Ge,Peiqing Cong,Guannan He,Zhaoming Han,Ruocheng Yin,Jingxiang Guo,Lunkai Lin,Tianling Xu,Hongzhe Bi,Xuewu Lin,Tianwei Lin,Shujie Luo,Keyu Li,Ziyan Zhao,Ke Fan,Heyang Xu,Bo Peng,Wenlong Gao,Dongjiang Li,Feng Jin,Hui Shen,Jinming Li,Chaowei Cui,Yuchen,Yaxin Peng,Lingdong Zeng,Wenlong Dong,Tengfei Li,Weijie Ke,Jun Chen,Erdemt Bao,Tian Lan,Tenglong Liu,Jin Yang,Huiping Zhuang,Baozhi Jia,Shuai Zhang,Zhengfeng Zou,Fangheng Guan,Tianyi Jia,Ke Zhou,Hongjiu Zhang,Yating Han,Cheng Fang,Yixian Zou,Chongyang Xu,Qinglun Zhang,Shen Cheng,Xiaohe Wang,Ping Tan,Haoqiang Fan,Shuaicheng Liu,Jiaheng Chen,Chuxuan Huang,Chengliang Lin,Kaijun Luo,Boyu Yue,Yi Liu,Jinyu Chen,Zichang Tan,Liming Deng,Shuo Xu,Zijian Cai,Shilong Yin,Hao Wang,Hongshan Liu,Tianyang Li,Long Shi,Ran Xu,Huilin Xu,Zhengquan Zhang,Congsheng Xu,Jinchang Yang,Feng Xu*

Main category: cs.RO

TL;DR: 论文介绍了RoboTwin双臂协作挑战赛，旨在推动双臂机器人在复杂任务中的研究，吸引了全球团队参与并取得了重要成果。


<details>
  <summary>Details</summary>
Motivation: 推动双臂机器人在复杂物理环境中的自主感知、推理和行动能力，尤其是在处理刚性、可变形和触觉敏感物体时的协作需求。

Method: 基于RoboTwin仿真平台和AgileX COBOT-Magic机器人平台，设计了三个阶段的比赛，包含17种双臂操作任务。

Result: 吸引了64个全球团队和400多名参与者，产生了如SEM和AnchorDP3等高性能解决方案，并为通用双臂策略学习提供了宝贵见解。

Conclusion: 挑战赛为未来研究提供了框架和方向，支持开发鲁棒且通用的双臂操作策略。

Abstract: Embodied Artificial Intelligence (Embodied AI) is an emerging frontier in
robotics, driven by the need for autonomous systems that can perceive, reason,
and act in complex physical environments. While single-arm systems have shown
strong task performance, collaborative dual-arm systems are essential for
handling more intricate tasks involving rigid, deformable, and
tactile-sensitive objects. To advance this goal, we launched the RoboTwin
Dual-Arm Collaboration Challenge at the 2nd MEIS Workshop, CVPR 2025. Built on
the RoboTwin Simulation platform (1.0 and 2.0) and the AgileX COBOT-Magic Robot
platform, the competition consisted of three stages: Simulation Round 1,
Simulation Round 2, and a final Real-World Round. Participants totally tackled
17 dual-arm manipulation tasks, covering rigid, deformable, and tactile-based
scenarios. The challenge attracted 64 global teams and over 400 participants,
producing top-performing solutions like SEM and AnchorDP3 and generating
valuable insights into generalizable bimanual policy learning. This report
outlines the competition setup, task design, evaluation methodology, key
findings and future direction, aiming to support future research on robust and
generalizable bimanual manipulation policies. The Challenge Webpage is
available at https://robotwin-benchmark.github.io/cvpr-2025-challenge/.

</details>


### [338] [DriveBLIP2: Attention-Guided Explanation Generation for Complex Driving Scenarios](https://arxiv.org/abs/2506.22494)
*Shihong Ling,Yue Wan,Xiaowei Jia,Na Du*

Main category: cs.RO

TL;DR: DriveBLIP2框架通过注意力机制提升自动驾驶场景中的解释生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在复杂多目标环境中表现不佳，尤其在自动驾驶等实时应用中。

Method: 提出注意力图生成器，突出关键对象以生成清晰解释。

Result: 在DRAMA数据集上，BLEU、ROUGE、CIDEr和SPICE分数显著提升。

Conclusion: 目标注意力机制可增强自动驾驶中视觉语言模型的可解释性。

Abstract: This paper introduces a new framework, DriveBLIP2, built upon the BLIP2-OPT
architecture, to generate accurate and contextually relevant explanations for
emerging driving scenarios. While existing vision-language models perform well
in general tasks, they encounter difficulties in understanding complex,
multi-object environments, particularly in real-time applications such as
autonomous driving, where the rapid identification of key objects is crucial.
To address this limitation, an Attention Map Generator is proposed to highlight
significant objects relevant to driving decisions within critical video frames.
By directing the model's focus to these key regions, the generated attention
map helps produce clear and relevant explanations, enabling drivers to better
understand the vehicle's decision-making process in critical situations.
Evaluations on the DRAMA dataset reveal significant improvements in explanation
quality, as indicated by higher BLEU, ROUGE, CIDEr, and SPICE scores compared
to baseline models. These findings underscore the potential of targeted
attention mechanisms in vision-language models for enhancing explainability in
real-time autonomous driving.

</details>


### [339] [MGPRL: Distributed Multi-Gaussian Processes for Wi-Fi-based Multi-Robot Relative Localization in Large Indoor Environments](https://arxiv.org/abs/2506.23514)
*Sai Krishna Ghanta,Ramviyas Parasuraman*

Main category: cs.RO

TL;DR: MGPRL是一种基于Wi-Fi信号的多机器人相对定位框架，利用高斯过程和凸包对齐实现高效定位，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决GPS缺失环境下多机器人定位依赖昂贵或短程传感器的问题，降低计算开销和环境限制。

Method: 使用高斯过程预测RSSI信号，结合凸包对齐实现相对位姿估计，无需预校准或离线指纹。

Result: 在仿真和实际实验中，MGPRL在定位精度和计算效率上优于现有方法。

Conclusion: MGPRL为资源受限设备提供了一种高效、无需预校准的多机器人定位解决方案，并开源为ROS包。

Abstract: Relative localization is a crucial capability for multi-robot systems
operating in GPS-denied environments. Existing approaches for multi-robot
relative localization often depend on costly or short-range sensors like
cameras and LiDARs. Consequently, these approaches face challenges such as high
computational overhead (e.g., map merging) and difficulties in disjoint
environments. To address this limitation, this paper introduces MGPRL, a novel
distributed framework for multi-robot relative localization using convex-hull
of multiple Wi-Fi access points (AP). To accomplish this, we employ
co-regionalized multi-output Gaussian Processes for efficient Radio Signal
Strength Indicator (RSSI) field prediction and perform uncertainty-aware
multi-AP localization, which is further coupled with weighted convex hull-based
alignment for robust relative pose estimation. Each robot predicts the RSSI
field of the environment by an online scan of APs in its environment, which are
utilized for position estimation of multiple APs. To perform relative
localization, each robot aligns the convex hull of its predicted AP locations
with that of the neighbor robots. This approach is well-suited for devices with
limited computational resources and operates solely on widely available Wi-Fi
RSSI measurements without necessitating any dedicated pre-calibration or
offline fingerprinting. We rigorously evaluate the performance of the proposed
MGPRL in ROS simulations and demonstrate it with real-world experiments,
comparing it against multiple state-of-the-art approaches. The results showcase
that MGPRL outperforms existing methods in terms of localization accuracy and
computational efficiency. Finally, we open source MGPRL as a ROS package
https://github.com/herolab-uga/MGPRL.

</details>


### [340] [Directed Shape Morphing using Kirigami-enhanced Thermoplastics](https://arxiv.org/abs/2506.22572)
*Mrunmayi Mungekar,Sanjith Menon,M. Ravi Shankar,M. Khalid Jawed*

Main category: cs.RO

TL;DR: 提出一种简单方法，利用均匀加热和常见工具（如烤箱和剪刀）将平面塑料片自主转化为复杂三维结构。


<details>
  <summary>Details</summary>
Motivation: 探索一种无需复杂控制即可实现复杂形状自变形的方法，适用于自适应设计和规模化制造。

Method: 结合热收缩热塑性塑料和定制Kirigami图案，形成双层复合材料，通过均匀加热驱动变形。

Result: 成功制造出多种复杂结构（如碗、金字塔等），并通过有限元模拟验证变形机制。

Conclusion: 该方法通过几何设计实现低信息刺激下的高复杂度变形，为自适应设计和制造提供了通用平台。

Abstract: We present a simple, accessible method for autonomously transforming flat
plastic sheets into intricate three-dimensional structures using only uniform
heating and common tools such as household ovens and scissors. Our approach
combines heat-shrinkable thermoplastics with Kirigami patterns tailored to the
target 3D shape, creating bilayer composites that morph into a wide range of
complex structures, e.g., bowls, pyramids, and even custom ergonomic surfaces
like mouse covers. Critically, the transformation is driven by a
low-information stimulus (uniform heat) yet produces highly intricate shapes
through programmed geometric design. The morphing behavior, confirmed by finite
element simulations, arises from strain mismatch between the contracting
thermoplastic layer and the constraining Kirigami layer. By decoupling material
composition from mechanical response, this method avoids detailed process
control and enables a broad class of self-morphing structures, offering a
versatile platform for adaptive design and scalable manufacturing.

</details>


### [341] [Pixels-to-Graph: Real-time Integration of Building Information Models and Scene Graphs for Semantic-Geometric Human-Robot Understanding](https://arxiv.org/abs/2506.22593)
*Antonello Longo,Chanyoung Chung,Matteo Palieri,Sung-Kyun Kim,Ali Agha,Cataldo Guaragnella,Shehryar Khattak*

Main category: cs.RO

TL;DR: Pix2G方法通过轻量级实时处理图像和LiDAR数据，生成场景图，支持资源受限机器人在未知环境中自主探索。


<details>
  <summary>Details</summary>
Motivation: 解决人类操作员与机器人之间因3D几何信息与2D BIM地图差异导致的协作障碍。

Method: 提出Pix2G方法，利用CPU实时处理图像和LiDAR数据，生成去噪2D地图和结构化3D点云，并通过多层图连接。

Result: 在NASA JPL NeBula-Spot机器人上验证，成功实时探索杂乱车库和办公室环境。

Conclusion: Pix2G有效填补了人类与机器人环境理解的鸿沟，适用于资源受限平台。

Abstract: Autonomous robots are increasingly playing key roles as support platforms for
human operators in high-risk, dangerous applications. To accomplish challenging
tasks, an efficient human-robot cooperation and understanding is required.
While typically robotic planning leverages 3D geometric information, human
operators are accustomed to a high-level compact representation of the
environment, like top-down 2D maps representing the Building Information Model
(BIM). 3D scene graphs have emerged as a powerful tool to bridge the gap
between human readable 2D BIM and the robot 3D maps. In this work, we introduce
Pixels-to-Graph (Pix2G), a novel lightweight method to generate structured
scene graphs from image pixels and LiDAR maps in real-time for the autonomous
exploration of unknown environments on resource-constrained robot platforms. To
satisfy onboard compute constraints, the framework is designed to perform all
operation on CPU only. The method output are a de-noised 2D top-down
environment map and a structure-segmented 3D pointcloud which are seamlessly
connected using a multi-layer graph abstracting information from object-level
up to the building-level. The proposed method is quantitatively and
qualitatively evaluated during real-world experiments performed using the NASA
JPL NeBula-Spot legged robot to autonomously explore and map cluttered garage
and urban office like environments in real-time.

</details>


### [342] [Robust Peg-in-Hole Assembly under Uncertainties via Compliant and Interactive Contact-Rich Manipulation](https://arxiv.org/abs/2506.22766)
*Yiting Chen,Kenneth Kimble,Howard H. Qian,Podshara Chanrungmaneekul,Robert Seney,Kaiyu Hang*

Main category: cs.RO

TL;DR: 提出了一种基于接触约束的鲁棒性机器人轴孔装配方法，通过碰撞包容性交互规划，实现无需精确感知的轴孔装配。


<details>
  <summary>Details</summary>
Motivation: 解决工业应用中轴孔装配在紧密公差下的鲁棒性和适应性问题，尤其是感知和物理不确定性带来的挑战。

Method: 利用轴与孔的接触约束，通过碰撞包容性交互规划，分步定位目标孔并优化插入动作。

Result: 系统在多种轴孔场景（不同尺寸、形状、材料）中表现出鲁棒性，无需学习即可泛化。

Conclusion: 提出的方法通过构建操作漏斗，为轴孔装配提供了一种不确定性吸收范式，适用于实际工业应用。

Abstract: Robust and adaptive robotic peg-in-hole assembly under tight tolerances is
critical to various industrial applications. However, it remains an open
challenge due to perceptual and physical uncertainties from contact-rich
interactions that easily exceed the allowed clearance. In this paper, we study
how to leverage contact between the peg and its matching hole to eliminate
uncertainties in the assembly process under unstructured settings. By examining
the role of compliance under contact constraints, we present a manipulation
system that plans collision-inclusive interactions for the peg to 1)
iteratively identify its task environment to localize the target hole and 2)
exploit environmental contact constraints to refine insertion motions into the
target hole without relying on precise perception, enabling a robust solution
to peg-in-hole assembly. By conceptualizing the above process as the
composition of funneling in different state spaces, we present a formal
approach to constructing manipulation funnels as an uncertainty-absorbing
paradigm for peg-in-hole assembly. The proposed system effectively generalizes
across diverse peg-in-hole scenarios across varying scales, shapes, and
materials in a learning-free manner. Extensive experiments on a NIST Assembly
Task Board (ATB) and additional challenging scenarios validate its robustness
in real-world applications.

</details>


### [343] [Learning Efficient Robotic Garment Manipulation with Standardization](https://arxiv.org/abs/2506.22769)
*Changshi Zhou,Feng Luan,Jiarui Hu,Shaoqiang Meng,Zhipeng Wang,Yanchao Dong,Yanmin Zhou,Bin He*

Main category: cs.RO

TL;DR: APS-Net提出了一种结合展开和标准化的统一框架，通过双臂多基元策略和动态抛掷技术，显著提升了服装展开和标准化的效率。


<details>
  <summary>Details</summary>
Motivation: 服装操作对机器人来说具有挑战性，现有方法忽视了标准化的重要性，而标准化能显著简化后续任务。

Method: 采用双臂多基元策略（动态抛掷和精确放置），结合因子化奖励函数（覆盖率、关键点距离和IoU）和空间动作掩码优化动作选择。

Result: 在仿真中，APS-Net在长袖服装上表现优于现有方法，覆盖率提高3.9%，IoU提高5.2%，关键点距离减少0.14。

Conclusion: 标准化显著简化了折叠任务，APS-Net为服装操作提供了一种高效统一的解决方案。

Abstract: Garment manipulation is a significant challenge for robots due to the complex
dynamics and potential self-occlusion of garments. Most existing methods of
efficient garment unfolding overlook the crucial role of standardization of
flattened garments, which could significantly simplify downstream tasks like
folding, ironing, and packing. This paper presents APS-Net, a novel approach to
garment manipulation that combines unfolding and standardization in a unified
framework. APS-Net employs a dual-arm, multi-primitive policy with dynamic
fling to quickly unfold crumpled garments and pick-and-place (p and p) for
precise alignment. The purpose of garment standardization during unfolding
involves not only maximizing surface coverage but also aligning the garment's
shape and orientation to predefined requirements. To guide effective robot
learning, we introduce a novel factorized reward function for standardization,
which incorporates garment coverage (Cov), keypoint distance (KD), and
intersection-over-union (IoU) metrics. Additionally, we introduce a spatial
action mask and an Action Optimized Module to improve unfolding efficiency by
selecting actions and operation points effectively. In simulation, APS-Net
outperforms state-of-the-art methods for long sleeves, achieving 3.9 percent
better coverage, 5.2 percent higher IoU, and a 0.14 decrease in KD (7.09
percent relative reduction). Real-world folding tasks further demonstrate that
standardization simplifies the folding process. Project page: see
https://hellohaia.github.io/APS/

</details>


### [344] [SPI-BoTER: Error Compensation for Industrial Robots via Sparse Attention Masking and Hybrid Loss with Spatial-Physical Information](https://arxiv.org/abs/2506.22788)
*Xuao Hou,Yongquan Jia,Shijin Zhang,Yuqiang Wu*

Main category: cs.RO

TL;DR: 本文提出了一种结合物理模型与Transformer架构的SPI-BoTER方法，用于工业机器人末端执行器的高精度误差补偿，在小样本条件下显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 工业机器人轨迹精度需求日益严格，现有误差补偿方法存在建模简化、物理一致性不足和数据需求大等问题，难以同时实现高精度与强泛化。

Method: 提出SPI-BoTER方法，融合机器人运动学方程与稀疏自注意力Transformer架构，采用参数自适应的混合损失函数进行迭代优化，并结合梯度下降进行逆关节角补偿。

Result: 在UR5机械臂小样本数据集上，3D绝对定位误差为0.2515 mm（标准差0.15 mm），比传统DNN方法误差降低35.16%；逆角补偿算法平均147次迭代收敛至0.01 mm精度。

Conclusion: SPI-BoTER结合物理可解释性与数据适应性，为工业机器人高精度控制提供了有效解决方案，有望推动智能制造中精密任务的可靠执行。

Abstract: The widespread application of industrial robots in fields such as cutting and
welding has imposed increasingly stringent requirements on the trajectory
accuracy of end-effectors. However, current error compensation methods face
several critical challenges, including overly simplified mechanism modeling, a
lack of physical consistency in data-driven approaches, and substantial data
requirements. These issues make it difficult to achieve both high accuracy and
strong generalization simultaneously. To address these challenges, this paper
proposes a Spatial-Physical Informed Attention Residual Network (SPI-BoTER).
This method integrates the kinematic equations of the robotic manipulator with
a Transformer architecture enhanced by sparse self-attention masks. A
parameter-adaptive hybrid loss function incorporating spatial and physical
information is employed to iteratively optimize the network during training,
enabling high-precision error compensation under small-sample conditions.
Additionally, inverse joint angle compensation is performed using a gradient
descent-based optimization method. Experimental results on a small-sample
dataset from a UR5 robotic arm (724 samples, with a train:test:validation split
of 8:1:1) demonstrate the superior performance of the proposed method. It
achieves a 3D absolute positioning error of 0.2515 mm with a standard deviation
of 0.15 mm, representing a 35.16\% reduction in error compared to conventional
deep neural network (DNN) methods. Furthermore, the inverse angle compensation
algorithm converges to an accuracy of 0.01 mm within an average of 147
iterations. This study presents a solution that combines physical
interpretability with data adaptability for high-precision control of
industrial robots, offering promising potential for the reliable execution of
precision tasks in intelligent manufacturing.

</details>


### [345] [Hierarchical Vision-Language Planning for Multi-Step Humanoid Manipulation](https://arxiv.org/abs/2506.22827)
*André Schakkal,Ben Zandonati,Zhutian Yang,Navid Azizan*

Main category: cs.RO

TL;DR: 本文提出了一种分层规划与控制框架，用于实现可靠的多步骤人形机器人操作。系统包含三层：低层RL控制器、中层模仿学习技能策略和高层视觉语言规划模块。实验验证了其可行性。


<details>
  <summary>Details</summary>
Motivation: 为了实现人形机器人在工业和家庭环境中可靠执行复杂多步骤操作任务。

Method: 分层框架包括低层RL控制器、中层模仿学习技能策略和高层视觉语言规划模块。

Result: 在40次实验中，系统实现了72.5%的成功率。

Conclusion: 分层系统可行，视觉语言模型在技能规划和监控中具有优势。

Abstract: Enabling humanoid robots to reliably execute complex multi-step manipulation
tasks is crucial for their effective deployment in industrial and household
environments. This paper presents a hierarchical planning and control framework
designed to achieve reliable multi-step humanoid manipulation. The proposed
system comprises three layers: (1) a low-level RL-based controller responsible
for tracking whole-body motion targets; (2) a mid-level set of skill policies
trained via imitation learning that produce motion targets for different steps
of a task; and (3) a high-level vision-language planning module that determines
which skills should be executed and also monitors their completion in real-time
using pretrained vision-language models (VLMs). Experimental validation is
performed on a Unitree G1 humanoid robot executing a non-prehensile
pick-and-place task. Over 40 real-world trials, the hierarchical system
achieved a 72.5% success rate in completing the full manipulation sequence.
These experiments confirm the feasibility of the proposed hierarchical system,
highlighting the benefits of VLM-based skill planning and monitoring for
multi-step manipulation scenarios. See https://vlp-humanoid.github.io/ for
video demonstrations of the policy rollout.

</details>


### [346] [Safe Reinforcement Learning with a Predictive Safety Filter for Motion Planning and Control: A Drifting Vehicle Example](https://arxiv.org/abs/2506.22894)
*Bei Zhou,Baha Zarrouki,Mattia Piccinini,Cheng Hu,Lei Xie,Johannes Betz*

Main category: cs.RO

TL;DR: 提出了一种基于安全强化学习的运动规划方法，用于自动驾驶漂移，结合模型漂移动力学和预测安全过滤器，确保安全高效的学习和稳定操作。


<details>
  <summary>Details</summary>
Motivation: 传统运动规划方法在高速漂移时难以应对不稳定性和不可预测性，现有学习方法的探索能力有限且未充分解决安全问题。

Method: 结合强化学习代理和模型漂移动力学，通过预测安全过滤器在线调整动作以避免不安全状态。

Result: 在Matlab-Carsim平台上验证，显著提升了漂移性能、减少了跟踪误差并提高了计算效率。

Conclusion: 该方法有望扩展自动驾驶车辆在安全关键操作中的能力。

Abstract: Autonomous drifting is a complex and crucial maneuver for safety-critical
scenarios like slippery roads and emergency collision avoidance, requiring
precise motion planning and control. Traditional motion planning methods often
struggle with the high instability and unpredictability of drifting,
particularly when operating at high speeds. Recent learning-based approaches
have attempted to tackle this issue but often rely on expert knowledge or have
limited exploration capabilities. Additionally, they do not effectively address
safety concerns during learning and deployment. To overcome these limitations,
we propose a novel Safe Reinforcement Learning (RL)-based motion planner for
autonomous drifting. Our approach integrates an RL agent with model-based drift
dynamics to determine desired drift motion states, while incorporating a
Predictive Safety Filter (PSF) that adjusts the agent's actions online to
prevent unsafe states. This ensures safe and efficient learning, and stable
drift operation. We validate the effectiveness of our method through
simulations on a Matlab-Carsim platform, demonstrating significant improvements
in drift performance, reduced tracking errors, and computational efficiency
compared to traditional methods. This strategy promises to extend the
capabilities of autonomous vehicles in safety-critical maneuvers.

</details>


### [347] [Energy-Constrained Resilient Multi-Robot Coverage Control](https://arxiv.org/abs/2506.22942)
*Kartik A. Pant,Jaehyeok Kim,James M. Goppert,Inseok Hwang*

Main category: cs.RO

TL;DR: 提出了一种多机器人覆盖控制的弹性网络设计与控制方法，解决机器人同时充电时网络拓扑中断的问题。


<details>
  <summary>Details</summary>
Motivation: 多机器人同时离开任务空间充电会导致通信和感知网络拓扑中断，影响覆盖性能。

Method: 将多机器人系统的运动、能量和网络动态建模为混合系统，设计模式切换条件和能量感知的轴承刚性网络拓扑。

Result: 通过数值模拟验证了方法的有效性，确保能量约束和网络连通性。

Conclusion: 提出的方法能有效维持多机器人系统的覆盖性能和网络弹性。

Abstract: The problem of multi-robot coverage control becomes significantly challenging
when multiple robots leave the mission space simultaneously to charge their
batteries, disrupting the underlying network topology for communication and
sensing. To address this, we propose a resilient network design and control
approach that allows robots to achieve the desired coverage performance while
satisfying energy constraints and maintaining network connectivity throughout
the mission. We model the combined motion, energy, and network dynamics of the
multirobot systems (MRS) as a hybrid system with three modes, i.e., coverage,
return-to-base, and recharge, respectively. We show that ensuring the energy
constraints can be transformed into designing appropriate guard conditions for
mode transition between each of the three modes. Additionally, we present a
systematic procedure to design, maintain, and reconfigure the underlying
network topology using an energy-aware bearing rigid network design, enhancing
the structural resilience of the MRS even when a subset of robots departs to
charge their batteries. Finally, we validate our proposed method using
numerical simulations.

</details>


### [348] [SPICE-HL3: Single-Photon, Inertial, and Stereo Camera dataset for Exploration of High-Latitude Lunar Landscapes](https://arxiv.org/abs/2506.22956)
*David Rodríguez-Martínez,Dave van der Meer,Junlin Song,Abishek Bera,C. J. Pérez-del-Pulgar,Miguel Angel Olivares-Mendez*

Main category: cs.RO

TL;DR: 论文介绍了一个在LunaLab设施中记录的高纬度月球环境模拟数据集，包含图像、惯性测量和轮式里程数据，用于验证感知任务。


<details>
  <summary>Details</summary>
Motivation: 高纬度月球区域的视觉环境对机器人极具挑战性，需要在地球上模拟这些条件以支持未来月球任务。

Method: 使用多种传感器（包括新型SPAD相机）在LunaLab中记录不同光照和速度条件下的数据。

Result: 生成了88个序列共130万张图像的数据集，涵盖从黎明到夜晚的多种光照条件。

Conclusion: 该数据集为高纬度月球任务和感知退化环境下的机器人操作提供了宝贵资源。

Abstract: Exploring high-latitude lunar regions presents an extremely challenging
visual environment for robots. The low sunlight elevation angle and minimal
light scattering result in a visual field dominated by a high dynamic range
featuring long, dynamic shadows. Reproducing these conditions on Earth requires
sophisticated simulators and specialized facilities. We introduce a unique
dataset recorded at the LunaLab from the SnT - University of Luxembourg, an
indoor test facility designed to replicate the optical characteristics of
multiple lunar latitudes. Our dataset includes images, inertial measurements,
and wheel odometry data from robots navigating seven distinct trajectories
under multiple illumination scenarios, simulating high-latitude lunar
conditions from dawn to night time with and without the aid of headlights,
resulting in 88 distinct sequences containing a total of 1.3M images. Data was
captured using a stereo RGB-inertial sensor, a monocular monochrome camera, and
for the first time, a novel single-photon avalanche diode (SPAD) camera. We
recorded both static and dynamic image sequences, with robots navigating at
slow (5 cm/s) and fast (50 cm/s) speeds. All data is calibrated, synchronized,
and timestamped, providing a valuable resource for validating perception tasks
from vision-based autonomous navigation to scientific imaging for future lunar
missions targeting high-latitude regions or those intended for robots operating
across perceptually degraded environments. The dataset can be downloaded from
https://zenodo.org/records/13970078?preview=1, and a visual overview is
available at https://youtu.be/d7sPeO50_2I. All supplementary material can be
found at https://github.com/spaceuma/spice-hl3.

</details>


### [349] [Scenario-Based Hierarchical Reinforcement Learning for Automated Driving Decision Making](https://arxiv.org/abs/2506.23023)
*M. Youssef Abdelhamid,Lennart Vater,Zlatan Ajanovic*

Main category: cs.RO

TL;DR: SAD-RL框架通过分层策略和场景化环境提升自动驾驶决策算法的泛化能力和学习效率。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统需在复杂开放环境中安全运行，现有RL方法在复杂任务中泛化能力不足且学习效率低。

Method: 提出SAD-RL框架，结合分层策略（高层选择模板，低层执行）和场景化环境，控制训练体验并引入挑战性场景。

Result: 实验表明SAD-RL能高效实现安全行为，消融研究证实分层策略和场景多样性是关键。

Conclusion: SAD-RL为复杂驾驶任务提供了一种有效的RL解决方案。

Abstract: Developing decision-making algorithms for highly automated driving systems
remains challenging, since these systems have to operate safely in an open and
complex environments. Reinforcement Learning (RL) approaches can learn
comprehensive decision policies directly from experience and already show
promising results in simple driving tasks. However, current approaches fail to
achieve generalizability for more complex driving tasks and lack learning
efficiency. Therefore, we present Scenario-based Automated Driving
Reinforcement Learning (SAD-RL), the first framework that integrates
Reinforcement Learning (RL) of hierarchical policy in a scenario-based
environment. A high-level policy selects maneuver templates that are evaluated
and executed by a low-level control logic. The scenario-based environment
allows to control the training experience for the agent and to explicitly
introduce challenging, but rate situations into the training process. Our
experiments show that an agent trained using the SAD-RL framework can achieve
safe behaviour in easy as well as challenging situations efficiently. Our
ablation studies confirmed that both HRL and scenario diversity are essential
for achieving these results.

</details>


### [350] [Event-based Stereo Visual-Inertial Odometry with Voxel Map](https://arxiv.org/abs/2506.23078)
*Zhaoxing Zhang,Xiaoxiang Wang,Chengliang Zhang,Yangyang Guo,Zikang Yuan,Xin Yang*

Main category: cs.RO

TL;DR: Voxel-ESVIO是一种基于事件相机的立体视觉-惯性里程计系统，通过体素地图管理高效筛选高质量3D点，提升状态估计精度。


<details>
  <summary>Details</summary>
Motivation: 事件相机的高动态范围和优异时间分辨率使其成为视觉里程计的重要传感器，但事件流中的固有噪声影响了高质量地图点的选择，从而影响状态估计精度。

Method: 利用基于体素的点选择和体素感知的点管理，以体素为单位优化地图点的选择和更新，高效提取抗噪声的地图点。

Result: 在三个公开基准测试中，Voxel-ESVIO在精度和计算效率上均优于现有方法。

Conclusion: Voxel-ESVIO通过体素地图管理有效解决了事件相机噪声问题，显著提升了视觉-惯性里程计的性能。

Abstract: The event camera, renowned for its high dynamic range and exceptional
temporal resolution, is recognized as an important sensor for visual odometry.
However, the inherent noise in event streams complicates the selection of
high-quality map points, which critically determine the precision of state
estimation. To address this challenge, we propose Voxel-ESVIO, an event-based
stereo visual-inertial odometry system that utilizes voxel map management,
which efficiently filter out high-quality 3D points. Specifically, our
methodology utilizes voxel-based point selection and voxel-aware point
management to collectively optimize the selection and updating of map points on
a per-voxel basis. These synergistic strategies enable the efficient retrieval
of noise-resilient map points with the highest observation likelihood in
current frames, thereby ensureing the state estimation accuracy. Extensive
evaluations on three public benchmarks demonstrate that our Voxel-ESVIO
outperforms state-of-the-art methods in both accuracy and computational
efficiency.

</details>


### [351] [Minimizing Acoustic Noise: Enhancing Quiet Locomotion for Quadruped Robots in Indoor Applications](https://arxiv.org/abs/2506.23114)
*Zhanxiang Cao,Buqing Nie,Yang Zhang,Yue Gao*

Main category: cs.RO

TL;DR: 研究通过优化步态设计和控制策略，显著降低了四足机器人在运动时的噪音，使其更适合噪音敏感的室内环境。


<details>
  <summary>Details</summary>
Motivation: 四足机器人在复杂户外环境中的移动能力已有显著提升，但其运动时产生的噪音在噪音敏感的室内环境中被忽视，而这一问题在服务和医疗等场景中至关重要。

Method: 提出了一种结合优化步态设计和定制控制策略的新方法，以减少噪音排放。

Result: 该方法在运动时平均降低了约8 dBA的噪音。

Conclusion: 实验结果表明，该方法有效提升了四足机器人在噪音敏感环境中的适用性，展示了其静音操作的潜力。

Abstract: Recent advancements in quadruped robot research have significantly improved
their ability to traverse complex and unstructured outdoor environments.
However, the issue of noise generated during locomotion is generally
overlooked, which is critically important in noise-sensitive indoor
environments, such as service and healthcare settings, where maintaining low
noise levels is essential. This study aims to optimize the acoustic noise
generated by quadruped robots during locomotion through the development of
advanced motion control algorithms. To achieve this, we propose a novel
approach that minimizes noise emissions by integrating optimized gait design
with tailored control strategies. This method achieves an average noise
reduction of approximately 8 dBA during movement, thereby enhancing the
suitability of quadruped robots for deployment in noise-sensitive indoor
environments. Experimental results demonstrate the effectiveness of this
approach across various indoor settings, highlighting the potential of
quadruped robots for quiet operation in noise-sensitive environments.

</details>


### [352] [Learning Motion Skills with Adaptive Assistive Curriculum Force in Humanoid Robots](https://arxiv.org/abs/2506.23125)
*Zhanxiang Cao,Yang Zhang,Buqing Nie,Huangxuan Lin,Haoyang Li,Yue Gao*

Main category: cs.RO

TL;DR: A2CF是一种自适应辅助课程力方法，通过双代理系统加速人形机器人复杂动作的学习，显著提升收敛速度和降低失败率。


<details>
  <summary>Details</summary>
Motivation: 受婴儿和运动员依赖外部支持学习复杂动作的启发，提出A2CF方法，旨在通过自适应辅助力加速机器人技能学习。

Method: A2CF采用双代理系统，辅助力代理根据机器人状态施加力，并随着技能提升逐步减少辅助。

Result: 在行走、舞蹈和后空翻任务中，A2CF比基线方法收敛快30%，失败率降低40%，并生成无需支持的稳健策略。

Conclusion: A2CF通过自适应辅助力显著加速高维机器人控制中复杂技能的获取，实验验证了其有效性。

Abstract: Learning policies for complex humanoid tasks remains both challenging and
compelling. Inspired by how infants and athletes rely on external support--such
as parental walkers or coach-applied guidance--to acquire skills like walking,
dancing, and performing acrobatic flips, we propose A2CF: Adaptive Assistive
Curriculum Force for humanoid motion learning. A2CF trains a dual-agent system,
in which a dedicated assistive force agent applies state-dependent forces to
guide the robot through difficult initial motions and gradually reduces
assistance as the robot's proficiency improves. Across three
benchmarks--bipedal walking, choreographed dancing, and backflip--A2CF achieves
convergence 30% faster than baseline methods, lowers failure rates by over 40%,
and ultimately produces robust, support-free policies. Real-world experiments
further demonstrate that adaptively applied assistive forces significantly
accelerate the acquisition of complex skills in high-dimensional robotic
control.

</details>


### [353] [ParticleFormer: A 3D Point Cloud World Model for Multi-Object, Multi-Material Robotic Manipulation](https://arxiv.org/abs/2506.23126)
*Suning Huang,Qianzhong Chen,Xiaohan Zhang,Jiankai Sun,Mac Schwager*

Main category: cs.RO

TL;DR: ParticleFormer是一个基于Transformer的点云世界模型，通过混合点云重建损失训练，能够捕捉多材料、多物体交互的全局和局部动态特征，无需复杂场景重建。


<details>
  <summary>Details</summary>
Motivation: 现有3D世界模型局限于单材料动态且需要耗时3D场景重建，ParticleFormer旨在解决这些问题，直接利用真实机器人感知数据训练。

Method: 采用Transformer架构，结合混合点云重建损失，监督全局和局部动态特征，适用于多材料、多物体交互。

Result: 在3D场景预测和下游操控任务中表现优异，仿真和真实实验中均优于基线方法。

Conclusion: ParticleFormer在多材料、多物体交互中表现出色，为机器人操控提供了高效动态模型。

Abstract: 3D world models (i.e., learning-based 3D dynamics models) offer a promising
approach to generalizable robotic manipulation by capturing the underlying
physics of environment evolution conditioned on robot actions. However,
existing 3D world models are primarily limited to single-material dynamics
using a particle-based Graph Neural Network model, and often require
time-consuming 3D scene reconstruction to obtain 3D particle tracks for
training. In this work, we present ParticleFormer, a Transformer-based point
cloud world model trained with a hybrid point cloud reconstruction loss,
supervising both global and local dynamics features in multi-material,
multi-object robot interactions. ParticleFormer captures fine-grained
multi-object interactions between rigid, deformable, and flexible materials,
trained directly from real-world robot perception data without an elaborate
scene reconstruction. We demonstrate the model's effectiveness both in 3D scene
forecasting tasks, and in downstream manipulation tasks using a Model
Predictive Control (MPC) policy. In addition, we extend existing dynamics
learning benchmarks to include diverse multi-material, multi-object interaction
scenarios. We validate our method on six simulation and three real-world
experiments, where it consistently outperforms leading baselines by achieving
superior dynamics prediction accuracy and less rollout error in downstream
visuomotor tasks. Experimental videos are available at
https://particleformer.github.io/.

</details>


### [354] [Flatness-based Finite-Horizon Multi-UAV Formation Trajectory Planning and Directionally Aware Collision Avoidance Tracking](https://arxiv.org/abs/2506.23129)
*Hossein B. Jond,Logan Beaver,Martin Jiroušek,Naiemeh Ahmadlou,Veli Bakırcıoğlu,Martin Saska*

Main category: cs.RO

TL;DR: 提出了一种基于无人机动力学微分平坦性的碰撞避免有限时间编队控制方案，无需依赖数值方法，解决了初始状态敏感性问题。


<details>
  <summary>Details</summary>
Motivation: 现有最优控制方法依赖数值方法且对初始猜测敏感，难以实现无人机编队的无碰撞控制。

Method: 利用微分平坦性设计有限时间最优控制问题，通过Pontryagin原理求解编队轨迹，并结合方向感知的碰撞避免策略。

Result: 仿真验证了四无人机编队（重）成形问题的有效性。

Conclusion: 该方法有效解决了无人机编队的无碰撞控制问题，具有实际应用潜力。

Abstract: Collision-free optimal formation control of unmanned aerial vehicle (UAV)
teams is challenging. The state-of-the-art optimal control approaches often
rely on numerical methods sensitive to initial guesses. This paper presents an
innovative collision-free finite-time formation control scheme for multiple
UAVs leveraging the differential flatness of the UAV dynamics, eliminating the
need for numerical methods. We formulate a finite-time optimal control problem
to plan a formation trajectory for feasible initial states. This formation
trajectory planning optimal control problem involves a collective performance
index to meet the formation requirements of achieving relative positions and
velocity consensus. It is solved by applying Pontryagin's principle.
Subsequently, a collision-constrained regulating problem is addressed to ensure
collision-free tracking of the planned formation trajectory. The tracking
problem incorporates a directionally aware collision avoidance strategy that
prioritizes avoiding UAVs in the forward path and relative approach. It assigns
lower priority to those on the sides with an oblique relative approach and
disregards UAVs behind and not in the relative approach. The simulation results
for a four-UAV team (re)formation problem confirm the efficacy of the proposed
control scheme.

</details>


### [355] [DexH2R: A Benchmark for Dynamic Dexterous Grasping in Human-to-Robot Handover](https://arxiv.org/abs/2506.23152)
*Youzhuo Wang,Jiayi Ye,Chuyang Xiao,Yiming Zhong,Heng Tao,Hang Yu,Yumeng Liu,Jingyi Yu,Yuexin Ma*

Main category: cs.RO

TL;DR: 论文提出DexH2R数据集和DynamicGrasp方法，解决人机手部交接任务中的动态抓取问题。


<details>
  <summary>Details</summary>
Motivation: 现有数据集主要关注静态物体或合成动作，与真实场景差异大，限制了动态灵巧抓取方法的发展。

Method: 利用遥操作收集数据，提出DynamicGrasp方法，并评估多种先进模型。

Result: 提供了高质量数据集和有效解决方案，推动了人机交接研究。

Conclusion: DexH2R数据集和DynamicGrasp方法填补了研究空白，为未来研究提供了基准。

Abstract: Handover between a human and a dexterous robotic hand is a fundamental yet
challenging task in human-robot collaboration. It requires handling dynamic
environments and a wide variety of objects and demands robust and adaptive
grasping strategies. However, progress in developing effective dynamic
dexterous grasping methods is limited by the absence of high-quality,
real-world human-to-robot handover datasets. Existing datasets primarily focus
on grasping static objects or rely on synthesized handover motions, which
differ significantly from real-world robot motion patterns, creating a
substantial gap in applicability. In this paper, we introduce DexH2R, a
comprehensive real-world dataset for human-to-robot handovers, built on a
dexterous robotic hand. Our dataset captures a diverse range of interactive
objects, dynamic motion patterns, rich visual sensor data, and detailed
annotations. Additionally, to ensure natural and human-like dexterous motions,
we utilize teleoperation for data collection, enabling the robot's movements to
align with human behaviors and habits, which is a crucial characteristic for
intelligent humanoid robots. Furthermore, we propose an effective solution,
DynamicGrasp, for human-to-robot handover and evaluate various state-of-the-art
approaches, including auto-regressive models and diffusion policy methods,
providing a thorough comparison and analysis. We believe our benchmark will
drive advancements in human-to-robot handover research by offering a
high-quality dataset, effective solutions, and comprehensive evaluation
metrics.

</details>


### [356] [Mode Collapse Happens: Evaluating Critical Interactions in Joint Trajectory Prediction Models](https://arxiv.org/abs/2506.23164)
*Maarten Hugenholtz,Anna Meszaros,Jens Kober,Zlatan Ajanovic*

Main category: cs.RO

TL;DR: 论文提出了一种新的评估框架，用于检测多模态轨迹预测中的模式崩溃问题，并引入了相关指标，以提高自动驾驶系统的安全性。


<details>
  <summary>Details</summary>
Motivation: 现有模型在多模态预测中可能仅预测最可能的模式（模式崩溃），且缺乏对交互模式多样性的评估，传统指标也无法量化评估模式崩溃。

Method: 提出了一种评估框架，引入模式崩溃、模式正确性和覆盖率的指标，重点关注预测的时序维度。

Result: 测试了四种多智能体轨迹预测模型，发现模式崩溃确实存在，且即使接近交互事件，模型仍可能无法预测正确的交互模式。

Conclusion: 该框架有助于研究者深入理解模式崩溃问题，推动更一致和准确的预测模型发展，提升自动驾驶安全性。

Abstract: Autonomous Vehicle decisions rely on multimodal prediction models that
account for multiple route options and the inherent uncertainty in human
behavior. However, models can suffer from mode collapse, where only the most
likely mode is predicted, posing significant safety risks. While existing
methods employ various strategies to generate diverse predictions, they often
overlook the diversity in interaction modes among agents. Additionally,
traditional metrics for evaluating prediction models are dataset-dependent and
do not evaluate inter-agent interactions quantitatively. To our knowledge, none
of the existing metrics explicitly evaluates mode collapse. In this paper, we
propose a novel evaluation framework that assesses mode collapse in joint
trajectory predictions, focusing on safety-critical interactions. We introduce
metrics for mode collapse, mode correctness, and coverage, emphasizing the
sequential dimension of predictions. By testing four multi-agent trajectory
prediction models, we demonstrate that mode collapse indeed happens. When
looking at the sequential dimension, although prediction accuracy improves
closer to interaction events, there are still cases where the models are unable
to predict the correct interaction mode, even just before the interaction mode
becomes inevitable. We hope that our framework can help researchers gain new
insights and advance the development of more consistent and accurate prediction
models, thus enhancing the safety of autonomous driving systems.

</details>


### [357] [InfGen: Scenario Generation as Next Token Group Prediction](https://arxiv.org/abs/2506.23316)
*Zhenghao Peng,Yuxin Liu,Bolei Zhou*

Main category: cs.RO

TL;DR: InfGen是一个基于Transformer的交通场景生成框架，支持动态、长期场景的模拟，并能持续插入新车辆。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动的交通模拟方法依赖静态初始化或日志回放，难以建模动态、长期场景。

Method: InfGen将场景表示为序列化的token（交通信号、车辆状态、运动向量），通过Transformer模型自回归生成交通状态和轨迹。

Result: 实验表明InfGen能生成真实、多样且自适应的交通行为，且强化学习策略在其模拟场景中表现更优。

Conclusion: InfGen是一个高保真度的自动驾驶模拟环境，支持动态场景生成。

Abstract: Realistic and interactive traffic simulation is essential for training and
evaluating autonomous driving systems. However, most existing data-driven
simulation methods rely on static initialization or log-replay data, limiting
their ability to model dynamic, long-horizon scenarios with evolving agent
populations. We propose InfGen, a scenario generation framework that outputs
agent states and trajectories in an autoregressive manner. InfGen represents
the entire scene as a sequence of tokens, including traffic light signals,
agent states, and motion vectors, and uses a transformer model to simulate
traffic over time. This design enables InfGen to continuously insert new agents
into traffic, supporting infinite scene generation. Experiments demonstrate
that InfGen produces realistic, diverse, and adaptive traffic behaviors.
Furthermore, reinforcement learning policies trained in InfGen-generated
scenarios achieve superior robustness and generalization, validating its
utility as a high-fidelity simulation environment for autonomous driving. More
information is available at https://metadriverse.github.io/infgen/.

</details>


### [358] [Simplifying Data-Driven Modeling of the Volume-Flow-Pressure Relationship in Hydraulic Soft Robotic Actuators](https://arxiv.org/abs/2506.23326)
*Sang-Yoep Lee,Leonardo Zamora Yanez,Jacob Rogatinsky,Vi T. Vo,Tanvi Shingade,Tommaso Ranzani*

Main category: cs.RO

TL;DR: 研究提出了一种数据驱动的方法，用于建模液压软执行器的体积-流量-压力关系，重点关注低复杂度高精度模型。


<details>
  <summary>Details</summary>
Motivation: 传统物理模型难以捕捉软机器人系统的复杂非线性行为，因此需要一种更有效的方法。

Method: 采用回归分析，使用指数、多项式和神经网络模型（带或不带自回归输入）对堆叠气球执行器系统进行建模。

Result: 结果表明，较简单的模型（尤其是多元多项式）能以较少的参数有效预测压力动态。

Conclusion: 该研究为实时软机器人应用提供了一种实用解决方案，平衡了模型复杂性和计算效率，并可能适用于其他需要显式解析模型的技术。

Abstract: Soft robotic systems are known for their flexibility and adaptability, but
traditional physics-based models struggle to capture their complex, nonlinear
behaviors. This study explores a data-driven approach to modeling the
volume-flow-pressure relationship in hydraulic soft actuators, focusing on
low-complexity models with high accuracy. We perform regression analysis on a
stacked balloon actuator system using exponential, polynomial, and neural
network models with or without autoregressive inputs. The results demonstrate
that simpler models, particularly multivariate polynomials, effectively predict
pressure dynamics with fewer parameters. This research offers a practical
solution for real-time soft robotics applications, balancing model complexity
and computational efficiency. Moreover, the approach may benefit various
techniques that require explicit analytical models.

</details>


### [359] [Moving Matter: Using a Single, Simple Robot to Reconfigure a Connected Set of Building Blocks](https://arxiv.org/abs/2506.23333)
*Javier Garcia,Jonas Friemel,Ramin Kosfeld,Michael Yannuzzi,Peter Kramer,Christian Rieck,Christian Scheffer,Arne Schmidt,Harm Kube,Dan Biediger,Sándor P. Fekete,Aaron T. Becker*

Main category: cs.RO

TL;DR: 论文研究了通过单个机器人重新配置连接瓷砖排列为目标形状的方法，评估了基于直方图的算法与两种启发式算法的性能。


<details>
  <summary>Details</summary>
Motivation: 探索在保持连接性的前提下，如何高效地将瓷砖排列重新配置为目标形状，并验证Becker等人提出的直方图算法的实际效果。

Method: 实现并评估了Becker等人的直方图算法，使用模拟和实际环境中的尺蠖型机器人，并与两种现有启发式算法进行比较。

Result: 直方图算法在模拟和实际环境中均表现出色，尤其在起始和目标配置分离良好的情况下，性能接近最优解。

Conclusion: 直方图算法是一种高效且可靠的瓷砖重新配置方法，适用于实际机器人应用。

Abstract: We implement and evaluate different methods for the reconfiguration of a
connected arrangement of tiles into a desired target shape, using a single
active robot that can move along the tile structure. This robot can pick up,
carry, or drop off one tile at a time, but it must maintain a single connected
configuration at all times.
  Becker et al. (CCCG 2025) recently proposed an algorithm that uses histograms
as canonical intermediate configurations, guaranteeing performance within a
constant factor of the optimal solution if the start and target configuration
are well-separated. We implement and evaluate this algorithm, both in a
simulated and practical setting, using an inchworm type robot to compare it
with two existing heuristic algorithms.

</details>


### [360] [Safe and Performant Deployment of Autonomous Systems via Model Predictive Control and Hamilton-Jacobi Reachability Analysis](https://arxiv.org/abs/2506.23346)
*Hao Wang,Armand Jordana,Ludovic Righetti,Somil Bansal*

Main category: cs.RO

TL;DR: 提出了一种基于MPC和HJ可达性的框架，优化自主系统的任务性能同时确保安全约束。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在保证安全的同时高效完成任务，缺乏安全保证或牺牲性能。

Method: 结合模型预测控制（MPC）和Hamilton-Jacobi（HJ）可达性理论，确保递归可行性并适用于高维系统。

Result: 在4D Dubins Car和6自由度Kuka iiwa机械臂的仿真实验中，框架显著提升了系统的安全约束满足率。

Conclusion: 该框架在保证安全的同时优化了任务性能，适用于高维自主系统。

Abstract: While we have made significant algorithmic developments to enable autonomous
systems to perform sophisticated tasks, it remains difficult for them to
perform tasks effective and safely. Most existing approaches either fail to
provide any safety assurances or substantially compromise task performance for
safety. In this work, we develop a framework, based on model predictive control
(MPC) and Hamilton-Jacobi (HJ) reachability, to optimize task performance for
autonomous systems while respecting the safety constraints. Our framework
guarantees recursive feasibility for the MPC controller, and it is scalable to
high-dimensional systems. We demonstrate the effectiveness of our framework
with two simulation studies using a 4D Dubins Car and a 6 Dof Kuka iiwa
manipulator, and the experiments show that our framework significantly improves
the safety constraints satisfaction of the systems over the baselines.

</details>


### [361] [GS-NBV: a Geometry-based, Semantics-aware Viewpoint Planning Algorithm for Avocado Harvesting under Occlusions](https://arxiv.org/abs/2506.23369)
*Xiao'ao Song,Konstantinos Karydis*

Main category: cs.RO

TL;DR: 提出了一种基于几何和语义感知的视点规划算法，用于自动化采摘不规则形状的水果（如牛油果），通过视点采样、评估和执行实现高效采摘。


<details>
  <summary>Details</summary>
Motivation: 牛油果因其不规则形状、重量和非结构化生长环境，采摘点识别具有挑战性，需要特定视点以实现成功采摘。

Method: 算法分为三步：视点采样（约束搜索空间为1D圆并均匀采样四点）、评估（引入新的采摘评分指标）和执行。

Result: 仿真实验表明，该方法在遮挡严重的情况下实现了100%的成功率，优于两种现有算法。

Conclusion: 该方法高效且鲁棒，适用于不规则水果的自动化采摘。

Abstract: Efficient identification of picking points is critical for automated fruit
harvesting. Avocados present unique challenges owing to their irregular shape,
weight, and less-structured growing environments, which require specific
viewpoints for successful harvesting. We propose a geometry-based,
semantics-aware viewpoint-planning algorithm to address these challenges. The
planning process involves three key steps: viewpoint sampling, evaluation, and
execution. Starting from a partially occluded view, the system first detects
the fruit, then leverages geometric information to constrain the viewpoint
search space to a 1D circle, and uniformly samples four points to balance the
efficiency and exploration. A new picking score metric is introduced to
evaluate the viewpoint suitability and guide the camera to the next-best view.
We validate our method through simulation against two state-of-the-art
algorithms. Results show a 100% success rate in two case studies with
significant occlusions, demonstrating the efficiency and robustness of our
approach. Our code is available at https://github.com/lineojcd/GSNBV

</details>


### [362] [A Model Predictive Control Framework to Enhance Safety and Quality in Mobile Additive Manufacturing Systems](https://arxiv.org/abs/2506.23400)
*Yifei Li,Joshua A. Robbins,Guha Manogharan,Herschel C. Pangborn,Ilya Kovalenko*

Main category: cs.RO

TL;DR: 提出了一种基于模型预测控制的移动增材制造平台，以在动态环境中确保安全导航并保持高打印质量。


<details>
  <summary>Details</summary>
Motivation: 传统增材制造系统受限于静态设置和人工依赖，导致生产周期长且扩展性有限。移动机器人可提升灵活性，但现有系统忽视打印质量和小型精密部件的生产。

Method: 集成增材制造系统与移动机器人，采用模型预测控制框架，优化导航和打印质量。通过三个案例研究验证系统可行性。

Result: 系统在动态环境中实现了安全导航和高打印质量，适用于大规模结构和小型精密部件的生产。

Conclusion: 提出的移动增材制造平台解决了传统系统的局限性，为定制化生产提供了更灵活、高效的解决方案。

Abstract: In recent years, the demand for customized, on-demand production has grown in
the manufacturing sector. Additive Manufacturing (AM) has emerged as a
promising technology to enhance customization capabilities, enabling greater
flexibility, reduced lead times, and more efficient material usage. However,
traditional AM systems remain constrained by static setups and human worker
dependencies, resulting in long lead times and limited scalability. Mobile
robots can improve the flexibility of production systems by transporting
products to designated locations in a dynamic environment. By integrating AM
systems with mobile robots, manufacturers can optimize travel time for
preparatory tasks and distributed printing operations. Mobile AM robots have
been deployed for on-site production of large-scale structures, but often
neglect critical print quality metrics like surface roughness. Additionally,
these systems do not have the precision necessary for producing small,
intricate components. We propose a model predictive control framework for a
mobile AM platform that ensures safe navigation on the plant floor while
maintaining high print quality in a dynamic environment. Three case studies are
used to test the feasibility and reliability of the proposed systems.

</details>


### [363] [Risk-Based Filtering of Valuable Driving Situations in the Waymo Open Motion Dataset](https://arxiv.org/abs/2506.23433)
*Tim Puphal,Vipul Ramtekkar,Kenji Nishimiya*

Main category: cs.RO

TL;DR: 提出了一种基于风险的过滤方法，从大型数据集中识别有价值的驾驶场景，用于改进自动驾驶软件。


<details>
  <summary>Details</summary>
Motivation: 改进自动驾驶软件需要丰富的道路用户交互数据，但现有方法难以高效识别高价值场景。

Method: 使用概率风险模型检测高风险场景，包括直接交互（一阶）和间接传播（二阶）的驾驶情况。

Result: 在Waymo Open Motion Dataset中验证了方法的有效性，相比基线方法（Kalman难度和TTP），能识别更复杂和互补的场景。

Conclusion: 该方法提升了自动驾驶测试的数据质量，相关风险数据已开源。

Abstract: Improving automated vehicle software requires driving data rich in valuable
road user interactions. In this paper, we propose a risk-based filtering
approach that helps identify such valuable driving situations from large
datasets. Specifically, we use a probabilistic risk model to detect high-risk
situations. Our method stands out by considering a) first-order situations
(where one vehicle directly influences another and induces risk) and b)
second-order situations (where influence propagates through an intermediary
vehicle). In experiments, we show that our approach effectively selects
valuable driving situations in the Waymo Open Motion Dataset. Compared to the
two baseline interaction metrics of Kalman difficulty and Tracks-To-Predict
(TTP), our filtering approach identifies complex and complementary situations,
enriching the quality in automated vehicle testing. The risk data is made
open-source: https://github.com/HRI-EU/RiskBasedFiltering.

</details>


### [364] [Online Human Action Detection during Escorting](https://arxiv.org/abs/2506.23573)
*Siddhartha Mondal,Avik Mitra,Chayan Sarkar*

Main category: cs.RO

TL;DR: 论文提出了一种新型神经网络架构，用于实时行人重识别和动作预测，以提升拥挤环境中机器人护送服务的效率。


<details>
  <summary>Details</summary>
Motivation: 当前护送机器人主要依赖导航策略，假设被护送者会顺利跟随，但在拥挤环境中常因无法理解人类动态行为而失效。

Method: 提出了一种能同时完成行人重识别和动作预测的神经网络架构，动态调整机器人速度以适应被护送者行为。

Result: 在对比评估中，该系统表现出更高的效率和效果，显著提升了复杂环境中的机器人护送服务。

Conclusion: 该研究为解决拥挤环境中机器人护送服务的挑战提供了有效方案，具有实际应用潜力。

Abstract: The deployment of robot assistants in large indoor spaces has seen
significant growth, with escorting tasks becoming a key application. However,
most current escorting robots primarily rely on navigation-focused strategies,
assuming that the person being escorted will follow without issue. In crowded
environments, this assumption often falls short, as individuals may struggle to
keep pace, become obstructed, get distracted, or need to stop unexpectedly. As
a result, conventional robotic systems are often unable to provide effective
escorting services due to their limited understanding of human movement
dynamics. To address these challenges, an effective escorting robot must
continuously detect and interpret human actions during the escorting process
and adjust its movement accordingly. However, there is currently no existing
dataset designed specifically for human action detection in the context of
escorting. Given that escorting often occurs in crowded environments, where
other individuals may enter the robot's camera view, the robot also needs to
identify the specific human it is escorting (the subject) before predicting
their actions. Since no existing model performs both person re-identification
and action prediction in real-time, we propose a novel neural network
architecture that can accomplish both tasks. This enables the robot to adjust
its speed dynamically based on the escortee's movements and seamlessly resume
escorting after any disruption. In comparative evaluations against strong
baselines, our system demonstrates superior efficiency and effectiveness,
showcasing its potential to significantly improve robotic escorting services in
complex, real-world scenarios.

</details>


### [365] [Passage-traversing optimal path planning with sampling-based algorithms](https://arxiv.org/abs/2506.23614)
*Jing Huang,Hao Su,Kwok Wai Samuel Au*

Main category: cs.RO

TL;DR: 论文提出了一种新的最优路径规划范式PTOPP，通过优化路径通过的通道来实现特定目标，特别适用于机器人路径规划中的自由空间优化。


<details>
  <summary>Details</summary>
Motivation: 现有路径规划方法在自由空间优化方面存在局限性，PTOPP旨在通过通道检测和自由空间分解解决这些问题。

Method: 提出基于邻近图的通道检测和自由空间分解方法，并结合采样最优规划器解决PTOPP问题。

Result: PTOPP在配置性、解的最优性和效率上显著优于现有方法（如基于间隙的方法）。

Conclusion: PTOPP为自由空间优化提供了一种高效且通用的解决方案，适用于广泛的路径规划问题。

Abstract: This paper introduces a new paradigm of optimal path planning, i.e.,
passage-traversing optimal path planning (PTOPP), that optimizes paths'
traversed passages for specified optimization objectives. In particular, PTOPP
is utilized to find the path with optimal accessible free space along its
entire length, which represents a basic requirement for paths in robotics. As
passages are places where free space shrinks and becomes constrained, the core
idea is to leverage the path's passage traversal status to characterize its
accessible free space comprehensively. To this end, a novel passage detection
and free space decomposition method using proximity graphs is proposed,
enabling fast detection of sparse but informative passages and environment
decompositions. Based on this preprocessing, optimal path planning with
accessible free space objectives or constraints is formulated as PTOPP problems
compatible with sampling-based optimal planners. Then, sampling-based
algorithms for PTOPP, including their dependent primitive procedures, are
developed leveraging partitioned environments for fast passage traversal check.
All these methods are implemented and thoroughly tested for effectiveness and
efficiency validation. Compared to existing approaches, such as clearance-based
methods, PTOPP demonstrates significant advantages in configurability, solution
optimality, and efficiency, addressing prior limitations and incapabilities. It
is believed to provide an efficient and versatile solution to accessible free
space optimization over conventional avenues and more generally, to a broad
class of path planning problems that can be formulated as PTOPP.

</details>


### [366] [Towards Universal Shared Control in Teleoperation Without Haptic Feedback](https://arxiv.org/abs/2506.23624)
*Max Grobbel,Tristan Schneider,Sören Hohmann*

Main category: cs.RO

TL;DR: 论文提出了一种通过多目标优化将用户输入转换为无碰撞UR5e关节轨迹的方法，以解决非触觉VR控制器缺乏运动反馈的问题，同时抑制玻璃中液体的晃动。


<details>
  <summary>Details</summary>
Motivation: 非触觉VR控制器缺乏关键的运动反馈，影响了操作的精确性和安全性。

Method: 通过嵌入多目标优化问题，将用户输入转换为无碰撞的UR5e关节轨迹，并主动抑制液体晃动。

Result: 控制器平均规划延迟为13毫秒，证实了实时性能。

Conclusion: 该方法为增强远程操作提供了可行方案，并支持进一步扩展目标。

Abstract: Teleoperation with non-haptic VR controllers deprives human operators of
critical motion feedback. We address this by embedding a multi-objective
optimization problem that converts user input into collision-free UR5e joint
trajectories while actively suppressing liquid slosh in a glass. The controller
maintains 13 ms average planning latency, confirming real-time performance and
motivating the augmentation of this teleoperation approach to further
objectives.

</details>


### [367] [A comprehensive control architecture for semi-autonomous dual-arm robots in agriculture settings](https://arxiv.org/abs/2506.23723)
*Jozsef Palmieri,Paolo Di Lillo,Stefano Chiaverini,Alessandro Marino*

Main category: cs.RO

TL;DR: 提出了一种用于葡萄园采摘的16自由度双臂移动机器人控制架构，采用分层二次规划（HQP）方法处理多优先级约束，并支持半自主操作。


<details>
  <summary>Details</summary>
Motivation: 复杂农业环境中移动机器人需灵活高效的架构，以同时完成感知、控制和任务执行，如葡萄采摘。

Method: 使用16-DOF双臂移动机器人，通过HQP方法处理等式和不等式约束，结合感知系统选择葡萄串并避免碰撞。

Result: 在实验室和真实葡萄园中验证了自主和半自主采摘功能，成功处理了感知不确定性和环境交互力。

Conclusion: 提出的HQP框架有效支持复杂任务执行，适用于农业机器人应用，并可通过半自主操作增强人机协作。

Abstract: The adoption of mobile robotic platforms in complex environments, such as
agricultural settings, requires these systems to exhibit a flexible yet
effective architecture that integrates perception and control. In such
scenarios, several tasks need to be accomplished simultaneously, ranging from
managing robot limits to performing operational tasks and handling human
inputs. The purpose of this paper is to present a comprehensive control
architecture for achieving complex tasks such as robotized harvesting in
vineyards within the framework of the European project CANOPIES. In detail, a
16-DOF dual-arm mobile robot is employed, controlled via a Hierarchical
Quadratic Programming (HQP) approach capable of handling both equality and
inequality constraints at various priorities to harvest grape bunches selected
by the perception system developed within the project. Furthermore, given the
complexity of the scenario and the uncertainty in the perception system, which
could potentially lead to collisions with the environment, the handling of
interaction forces is necessary. Remarkably, this was achieved using the same
HQP framework. This feature is further leveraged to enable semi-autonomous
operations, allowing a human operator to assist the robotic counterpart in
completing harvesting tasks. Finally, the obtained results are validated
through extensive testing conducted first in a laboratory environment to prove
individual functionalities, then in a real vineyard, encompassing both
autonomous and semi-autonomous grape harvesting operations.

</details>


### [368] [Validation of AI-Based 3D Human Pose Estimation in a Cyber-Physical Environment](https://arxiv.org/abs/2506.23739)
*Lisa Marie Otto,Michael Kaiser,Daniel Seebacher,Steffen Müller*

Main category: cs.RO

TL;DR: 论文提出了一种结合车辆在环测试与运动实验室的测试环境，用于验证自动驾驶系统与弱势道路使用者（VRUs）的交互，重点评估了人体姿态估计（HPE）在真实与虚拟场景中的一致性。


<details>
  <summary>Details</summary>
Motivation: 为确保自动驾驶系统与VRUs在城市场景中的安全交互，需要先进的测试方法。本文旨在验证虚拟与现实测试中HPE的可靠性。

Method: 结合车辆在环测试与运动实验室，使用Unreal Engine 5生成虚拟场景，通过单目摄像头AI检测3D骨骼运动，比较真实与虚拟场景中的HPE表现。

Result: 结果显示，稳定运动模式下HPE在真实与虚拟场景中表现一致，但动态运动和遮挡情况下（尤其是复杂骑行姿势）存在显著误差。

Conclusion: 研究为优化下一代基于AI的车辆感知测试方法提供了依据，并改进了CP环境中自动驾驶车辆与VRUs的交互模型。

Abstract: Ensuring safe and realistic interactions between automated driving systems
and vulnerable road users (VRUs) in urban environments requires advanced
testing methodologies. This paper presents a test environment that combines a
Vehiclein-the-Loop (ViL) test bench with a motion laboratory, demonstrating the
feasibility of cyber-physical (CP) testing of vehicle-pedestrian and
vehicle-cyclist interactions. Building upon previous work focused on pedestrian
localization, we further validate a human pose estimation (HPE) approach
through a comparative analysis of real-world (RW) and virtual representations
of VRUs. The study examines the perception of full-body motion using a
commercial monocular camera-based 3Dskeletal detection AI. The virtual scene is
generated in Unreal Engine 5, where VRUs are animated in real time and
projected onto a screen to stimulate the camera. The proposed stimulation
technique ensures the correct perspective, enabling realistic vehicle
perception. To assess the accuracy and consistency of HPE across RW and CP
domains, we analyze the reliability of detections as well as variations in
movement trajectories and joint estimation stability. The validation includes
dynamic test scenarios where human avatars, both walking and cycling, are
monitored under controlled conditions. Our results show a strong alignment in
HPE between RW and CP test conditions for stable motion patterns, while notable
inaccuracies persist under dynamic movements and occlusions, particularly for
complex cyclist postures. These findings contribute to refining CP testing
approaches for evaluating next-generation AI-based vehicle perception and to
enhancing interaction models of automated vehicles and VRUs in CP environments.

</details>


### [369] [PAC Bench: Do Foundation Models Understand Prerequisites for Executing Manipulation Policies?](https://arxiv.org/abs/2506.23725)
*Atharva Gundawar,Som Sagar,Ransalu Senanayake*

Main category: cs.RO

TL;DR: PAC Bench是一个新基准，用于评估视觉语言模型（VLMs）对物理属性、功能性和约束的理解，揭示其在机器人操作中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有VLMs在高层次任务中表现良好，但对低层次物理前提的理解不足，影响机器人操作的可靠性。

Method: 提出PAC Bench，包含多样化的数据集（30,000+标注）和任务，系统评估VLMs的物理理解能力。

Result: 当前VLMs在基础物理概念理解上存在显著不足，不适合可靠的机器人操作。

Conclusion: PAC Bench为评估和改进VLMs的物理推理能力提供了标准化工具，推动更鲁棒的模型开发。

Abstract: Vision-Language Models (VLMs) are increasingly pivotal for generalist robot
manipulation, enabling tasks such as physical reasoning, policy generation, and
failure detection. However, their proficiency in these high-level applications
often assumes a deep understanding of low-level physical prerequisites, a
capability that remains largely unverified. For robots to perform actions
reliably, they must comprehend intrinsic object properties (e.g., material,
weight), action affordances (e.g., graspable, stackable), and physical
constraints (e.g., stability, reachability, or an object's state, such as being
closed). Despite the widespread use of VLMs in manipulation tasks, we argue
that off-the-shelf models may lack this granular, physically grounded
understanding, as such prerequisites are often overlooked during training.
  To address this critical gap, we introduce PAC Bench, a comprehensive
benchmark designed to systematically evaluate VLMs on their understanding of
core Properties, Affordances, and Constraints (PAC) from a task executability
perspective. PAC Bench features a diverse dataset with over 30,000 annotations,
comprising 673 real-world images (115 object classes, 15 property types, and 1
to 3 affordances defined per class), 100 real-world humanoid-view scenarios,
and 120 unique simulated constraint scenarios across four tasks.
  Our evaluations reveal significant gaps in the ability of current VLMs to
grasp fundamental physical concepts, highlighting limitations in their
suitability for reliable robot manipulation and pointing to key areas for
targeted research. PAC Bench also serves as a standardized benchmark for
rigorously evaluating physical reasoning in VLMs and guiding the development of
more robust, physically grounded models for robotic applications.
  Project Page: https://pacbench.github.io/

</details>


### [370] [Exploring Accelerated Skill Acquisition via Tandem Training for Colonoscopy](https://arxiv.org/abs/2506.24046)
*Olivia Richards,Keith L. Obstein,Nabil Simaan*

Main category: cs.RO

TL;DR: 提出了一种新型结肠镜培训系统，通过远程操纵的导师结肠镜实时指导新手，加速技能获取。


<details>
  <summary>Details</summary>
Motivation: 传统结肠镜培训依赖工具交接，限制了新手对设备的多指同步控制能力的培养，需要更高效的实时指导工具。

Method: 开发了一种双控结肠镜培训系统，可自动切换专家和新手对结肠镜角度控制轮的控制。

Result: 初步用户研究表明，该系统作为技能获取工具是有效的。

Conclusion: 该系统有望加速结肠镜技能学习，未来可能通过双向驱动实现个性化教学。

Abstract: New endoscopists require a large volume of expert-proctored colonoscopies to
attain minimal competency. Developing multi-fingered, synchronized control of a
colonoscope requires significant time and exposure to the device. Current
training methods inhibit this development by relying on tool hand-off for
expert demonstrations. There is a need for colonoscopy training tools that
enable in-hand expert guidance in real-time. We present a new concept of a
tandem training system that uses a telemanipulated preceptor colonoscope to
guide novice users as they perform a colonoscopy. This system is capable of
dual-control and can automatically toggle between expert and novice control of
a standard colonoscope's angulation control wheels. Preliminary results from a
user study with novice and expert users show the effectiveness of this device
as a skill acquisition tool. We believe that this device has the potential to
accelerate skill acquisition for colonoscopy and, in the future, enable
individualized instruction and responsive teaching through bidirectional
actuation.

</details>


### [371] [Motion Tracking with Muscles: Predictive Control of a Parametric Musculoskeletal Canine Model](https://arxiv.org/abs/2506.23768)
*Vittorio La Barbera,Steven Bohez,Leonard Hasenclever,Yuval Tassa,John R. Hutchinson*

Main category: cs.RO

TL;DR: 提出了一种基于3D肌肉网格的狗骨骼肌肉模型，并开发了兼容多种控制算法的运动捕捉任务和改进的肌肉动力学模型。通过模拟肌肉激活模式与实验EMG数据对比验证了模型的有效性。


<details>
  <summary>Details</summary>
Motivation: 填补生物力学、机器人和计算神经科学之间的研究空白，为肌肉驱动和神经肌肉控制研究提供平台。

Method: 使用3D肌肉网格生成骨骼肌肉模型，开发运动捕捉任务和改进的肌肉动力学模型，并通过EMG数据验证。

Result: 模拟肌肉激活模式与实验EMG数据一致，验证了模型的有效性。

Conclusion: 该模型为相关领域研究提供了可靠工具，未来将公开模型和运动捕捉数据以促进研究。

Abstract: We introduce a novel musculoskeletal model of a dog, procedurally generated
from accurate 3D muscle meshes. Accompanying this model is a motion
capture-based locomotion task compatible with a variety of control algorithms,
as well as an improved muscle dynamics model designed to enhance convergence in
differentiable control frameworks. We validate our approach by comparing
simulated muscle activation patterns with experimentally obtained
electromyography (EMG) data from previous canine locomotion studies. This work
aims to bridge gaps between biomechanics, robotics, and computational
neuroscience, offering a robust platform for researchers investigating muscle
actuation and neuromuscular control.We plan to release the full model along
with the retargeted motion capture clips to facilitate further research and
development.

</details>


### [372] [Data-Driven Predictive Planning and Control for Aerial 3D Inspection with Back-face Elimination](https://arxiv.org/abs/2506.23781)
*Savvas Papaioannou,Panayiotis Kolios,Christos G. Panayiotou,Marios M. Polycarpou*

Main category: cs.RO

TL;DR: 提出了一种基于数据驱动预测控制的3D检测方法，统一感知、规划与控制，适用于现成UAS。


<details>
  <summary>Details</summary>
Motivation: 现有方法将感知、规划和控分离，且缺乏长时程规划能力，限制了UAS自动化检测的应用。

Method: 采用数据驱动预测控制框架，结合背向消除技术，在线生成长时程3D检测轨迹。

Result: 无需已知UAS动态模型，适用于黑盒UAS，提高了检测的准确性和适应性。

Conclusion: 该方法为UAS自动化检测提供了高效、灵活的解决方案。

Abstract: Automated inspection with Unmanned Aerial Systems (UASs) is a transformative
capability set to revolutionize various application domains. However, this task
is inherently complex, as it demands the seamless integration of perception,
planning, and control which existing approaches often treat separately.
Moreover, it requires accurate long-horizon planning to predict action
sequences, in contrast to many current techniques, which tend to be myopic. To
overcome these limitations, we propose a 3D inspection approach that unifies
perception, planning, and control within a single data-driven predictive
control framework. Unlike traditional methods that rely on known UAS dynamic
models, our approach requires only input-output data, making it easily
applicable to off-the-shelf black-box UASs. Our method incorporates back-face
elimination, a visibility determination technique from 3D computer graphics,
directly into the control loop, thereby enabling the online generation of
accurate, long-horizon 3D inspection trajectories.

</details>


### [373] [Multi-Timescale Hierarchical Reinforcement Learning for Unified Behavior and Control of Autonomous Driving](https://arxiv.org/abs/2506.23771)
*Guizhe Jin,Zhuoren Li,Bo Leng,Ran Yu,Lu Xiong*

Main category: cs.RO

TL;DR: 提出了一种多时间尺度分层强化学习方法，用于自动驾驶，结合长短时间尺度的策略设计，提升驾驶效率、一致性和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的自动驾驶方法忽视策略结构设计，导致驾驶行为波动或无法统一驾驶行为与控制的最优性。

Method: 采用分层策略结构，高层和低层策略分别生成长时间尺度运动指导和短时间尺度控制命令，并设计分层安全机制。

Result: 在仿真和HighD数据集的高速公路多车道场景中，显著提升自动驾驶性能，提高效率、一致性和安全性。

Conclusion: 多时间尺度分层强化学习方法有效解决了自动驾驶中的策略设计问题，实现了驾驶行为与控制的统一优化。

Abstract: Reinforcement Learning (RL) is increasingly used in autonomous driving (AD)
and shows clear advantages. However, most RL-based AD methods overlook policy
structure design. An RL policy that only outputs short-timescale vehicle
control commands results in fluctuating driving behavior due to fluctuations in
network outputs, while one that only outputs long-timescale driving goals
cannot achieve unified optimality of driving behavior and control. Therefore,
we propose a multi-timescale hierarchical reinforcement learning approach. Our
approach adopts a hierarchical policy structure, where high- and low-level RL
policies are unified-trained to produce long-timescale motion guidance and
short-timescale control commands, respectively. Therein, motion guidance is
explicitly represented by hybrid actions to capture multimodal driving
behaviors on structured road and support incremental low-level extend-state
updates. Additionally, a hierarchical safety mechanism is designed to ensure
multi-timescale safety. Evaluation in simulator-based and HighD dataset-based
highway multi-lane scenarios demonstrates that our approach significantly
improves AD performance, effectively increasing driving efficiency, action
consistency and safety.

</details>


### [374] [World4Omni: A Zero-Shot Framework from Image Generation World Model to Robotic Manipulation](https://arxiv.org/abs/2506.23919)
*Haonan Chen,Bangjun Wang,Jingxiang Guo,Tianrui Zhang,Yiwen Hou,Xuchuan Huang,Chenrui Tie,Lin Shao*

Main category: cs.RO

TL;DR: 提出了一种利用预训练多模态图像生成模型作为世界模型来指导策略学习的新框架，无需任务特定训练即可实现通用机器人操作。


<details>
  <summary>Details</summary>
Motivation: 提高机器人操作的数据效率和泛化能力。

Method: 利用预训练多模态图像生成模型生成未来状态预测，结合零样本低级控制模块。

Result: 在仿真和真实环境中验证了方法在多种操作任务中的有效性，无需额外数据收集或微调。

Conclusion: 该方法为通用机器人操作提供了一种高效且泛化性强的解决方案。

Abstract: Improving data efficiency and generalization in robotic manipulation remains
a core challenge. We propose a novel framework that leverages a pre-trained
multimodal image-generation model as a world model to guide policy learning. By
exploiting its rich visual-semantic representations and strong generalization
across diverse scenes, the model generates open-ended future state predictions
that inform downstream manipulation. Coupled with zero-shot low-level control
modules, our approach enables general-purpose robotic manipulation without
task-specific training. Experiments in both simulation and real-world
environments demonstrate that our method achieves effective performance across
a wide range of manipulation tasks with no additional data collection or
fine-tuning. Supplementary materials are available on our website:
https://world4omni.github.io/.

</details>


### [375] [Adapt Your Body: Mitigating Proprioception Shifts in Imitation Learning](https://arxiv.org/abs/2506.23944)
*Fuhang Kuang,Jiacheng You,Yingdong Hu,Tong Zhang,Chuan Wen,Yang Gao*

Main category: cs.RO

TL;DR: 论文提出了一种解决模仿学习中本体感觉偏移问题的方法，通过域适应框架和Wasserstein距离对齐训练与部署分布。


<details>
  <summary>Details</summary>
Motivation: 模仿学习中直接使用所有本体感觉状态会导致性能下降，原因是训练与部署时的本体感觉分布存在显著差异。

Method: 提出域适应框架，利用部署时的滚动数据，通过Wasserstein距离量化差异，并添加噪声对齐分布。

Result: 在机器人操作任务中验证了方法的有效性，优于直接丢弃本体感觉或其他基线方法。

Conclusion: 该方法成功解决了本体感觉偏移问题，使模仿策略能有效利用本体感觉信息。

Abstract: Imitation learning models for robotic tasks typically rely on multi-modal
inputs, such as RGB images, language, and proprioceptive states. While
proprioception is intuitively important for decision-making and obstacle
avoidance, simply incorporating all proprioceptive states leads to a surprising
degradation in imitation learning performance. In this work, we identify the
underlying issue as the proprioception shift problem, where the distributions
of proprioceptive states diverge significantly between training and deployment.
To address this challenge, we propose a domain adaptation framework that
bridges the gap by utilizing rollout data collected during deployment. Using
Wasserstein distance, we quantify the discrepancy between expert and rollout
proprioceptive states and minimize this gap by adding noise to both sets of
states, proportional to the Wasserstein distance. This strategy enhances
robustness against proprioception shifts by aligning the training and
deployment distributions. Experiments on robotic manipulation tasks demonstrate
the efficacy of our method, enabling the imitation policy to leverage
proprioception while mitigating its adverse effects. Our approach outperforms
the naive solution which discards proprioception, and other baselines designed
to address distributional shifts.

</details>


### [376] [Predictive Risk Analysis and Safe Trajectory Planning for Intelligent and Connected Vehicles](https://arxiv.org/abs/2506.23999)
*Zeyu Han,Mengchi Cai,Chaoyi Chen,Qingwen Meng,Guangwei Wang,Ying Liu,Qing Xu,Jianqiang Wang,Keqiang Li*

Main category: cs.RO

TL;DR: 提出了一种基于预测风险分析的智能网联车辆安全轨迹规划框架，结合未来轨迹预测和时空离散化风险分析，验证了方法的有效性和实时性。


<details>
  <summary>Details</summary>
Motivation: 现有风险评估理论仅基于当前信息，忽略了未来预测，无法满足智能网联车辆安全轨迹规划的需求。

Method: 框架包括局部风险感知算法预测未来轨迹、时空离散化预测风险分析，以及基于分析的安全轨迹生成。

Result: 仿真和车辆实验验证了方法的有效性和实时性。

Conclusion: 提出的框架能够有效结合未来预测，提升智能网联车辆的安全轨迹规划能力。

Abstract: The safe trajectory planning of intelligent and connected vehicles is a key
component in autonomous driving technology. Modeling the environment risk
information by field is a promising and effective approach for safe trajectory
planning. However, existing risk assessment theories only analyze the risk by
current information, ignoring future prediction. This paper proposes a
predictive risk analysis and safe trajectory planning framework for intelligent
and connected vehicles. This framework first predicts future trajectories of
objects by a local risk-aware algorithm, following with a
spatiotemporal-discretised predictive risk analysis using the prediction
results. Then the safe trajectory is generated based on the predictive risk
analysis. Finally, simulation and vehicle experiments confirm the efficacy and
real-time practicability of our approach.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [377] [Capacity Planning in Stable Matching with Truthful or Strategic Preference Uncertainty](https://arxiv.org/abs/2506.22560)
*Maria Bazotte,Margarida Carvalho,Thibaut Vidal*

Main category: cs.GT

TL;DR: 论文研究了两阶段随机匹配问题，考虑了偏好不确定性和策略性行为对容量规划的影响，提出基于样本平均近似的方法和启发式算法，优化匹配结果。


<details>
  <summary>Details</summary>
Motivation: 现实中的匹配市场（如学校选择）中，偏好报告通常在容量决策之后，且可能存在策略性误报，因此需要研究偏好不确定性和策略行为对容量设计的影响。

Method: 采用两阶段随机匹配模型，第一阶段进行容量规划，第二阶段基于报告的偏好计算稳定匹配。使用样本平均近似（SAA）处理不确定性，并提出启发式算法求解。

Result: 基于SAA的方法在学生匹配偏好和录取结果上优于平均场景方法，策略性行为显著影响容量设计。

Conclusion: 偏好不确定性和策略行为对匹配市场的容量规划有重要影响，需在设计机制时予以考虑。

Abstract: Recent studies on many-to-one matching markets have explored agents with
flexible capacity and truthful preference reporting, focusing on mechanisms
that jointly design capacities and select a matching. However, in real-world
applications such as school choice and residency matching, preferences are
revealed after capacity decisions are made, with matching occurring afterward;
uncertainty about agents' preferences must be considered during capacity
planning. Moreover, even under strategy-proof mechanisms, agents may
strategically misreport preferences based on beliefs about admission chances.
We introduce a two-stage stochastic matching problem with uncertain
preferences, using school choice as a case study. In the first stage, the
clearinghouse expands schools' capacities before observing students' reported
preferences. Students either report their true preferences, producing exogenous
uncertainty, or act strategically, submitting reported preferences based on
their true preferences and admission chances (which depend on capacities),
introducing endogenous uncertainty. In the second stage, the clearinghouse
computes the student-optimal stable matching based on schools' priorities and
students' reported preferences. In strategic cases, endogenous reported
preferences are utility-maximizing transformations of capacity decisions and
exogenous true preferences; we handle uncertainty using sample average
approximation(SAA). We develop behavior-based mathematical formulations and,
due to problem complexity, propose Lagrangian- and local-search-based
behavior-specific heuristics for near-optimal solutions. Our SAA-based
approaches outperform the average scenario approach on students' matching
preferences and admission outcomes, emphasizing the impact of stochastic
preferences on capacity decisions. Student behavior notably influences capacity
design, stressing the need to consider misreports.

</details>


### [378] [Learning Truthful Mechanisms without Discretization](https://arxiv.org/abs/2506.22911)
*Yunxuan Ma,Siqiang Wang,Zhijian Duan,Yukun Cheng,Xiaotie Deng*

Main category: cs.GT

TL;DR: TEDI是一种无需离散化的算法，用于学习真实且效用最大化的机制，解决了现有方法因离散化导致的效率问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的方法通常依赖结果空间的离散化以确保真实性，但随着问题规模增大会导致效率低下。

Method: 提出基于定价规则的新菜单机制，使用Partial GroupMax Network参数化定价规则，并开发了新的训练技术（如协方差技巧和连续采样）。

Result: TEDI在理论分析中保证了真实性、完全表达性和维度不敏感性，实验表明其性能优于或与现有方法相当。

Conclusion: TEDI是首个无需结果离散化的真实机制学习方法，提升了算法效率，为自动化机制设计和可微分经济学提供了新思路。

Abstract: This paper introduces TEDI (Truthful, Expressive, and Dimension-Insensitive
approach), a discretization-free algorithm to learn truthful and
utility-maximizing mechanisms. Existing learning-based approaches often rely on
discretization of outcome spaces to ensure truthfulness, which leads to
inefficiency with increasing problem size. To address this limitation, we
formalize the concept of pricing rules, defined as functions that map outcomes
to prices. Based on this concept, we propose a novel menu mechanism, which can
be equivalent to a truthful direct mechanism under specific conditions. The
core idea of TEDI lies in its parameterization of pricing rules using Partial
GroupMax Network, a new network architecture designed to universally
approximate partial convex functions. To learn optimal pricing rules, we
develop novel training techniques, including covariance trick and continuous
sampling, to derive unbiased gradient estimators compatible with first-order
optimization. Theoretical analysis establishes that TEDI guarantees
truthfulness, full expressiveness, and dimension-insensitivity. Experimental
evaluation in the studied auction setting demonstrates that TEDI achieves
strong performance, competitive with or exceeding state-of-the-art methods.
  This work presents the first approaches to learn truthful mechanisms without
outcome discretization, thereby enhancing algorithmic efficiency. The proposed
concepts, network architecture, and learning techniques might offer potential
value and provide new insights for automated mechanism design and
differentiable economics.

</details>


### [379] [Markov Chains of Evolutionary Games with a Small Number of Players](https://arxiv.org/abs/2506.23134)
*Athanasios Kehagias*

Main category: cs.GT

TL;DR: 研究有限玩家进化游戏的转移概率矩阵，分析其特性。


<details>
  <summary>Details</summary>
Motivation: 探讨在玩家数量有限的情况下，进化游戏的动态行为及其转移概率矩阵的性质。

Method: 使用Sandholm的简化版群体游戏框架，构建转移概率矩阵，并分析具体例子（如囚徒困境、猎鹿博弈、石头剪刀布）和不同修订协议（最佳响应、成对比较等）。

Result: 为每种修订协议构建了转移概率矩阵，并研究了其特性。

Conclusion: 通过具体例子和协议，揭示了有限玩家进化游戏的动态行为及其转移概率矩阵的性质。

Abstract: We construct and study the transition probability matrix of evolutionary
games in which the number of players is finite (and relatively small) of such
games. We use a simplified version of the population games studied by Sandholm.
After laying out a general framework we concentrate on specific examples,
involving the Iterated Prisoner's Dilemma, the Iterated Stag Hunt, and the
Rock-Paper-Scissors game. Also we consider several revision protocols: Best
Response, Pairwise Comparison, Pairwise Proportional Comparison etc. For each
of these we explicitly construct the MC transition probability matrix and study
its properties.

</details>


### [380] [Interdependent Bilateral Trade: Information vs Approximation](https://arxiv.org/abs/2506.23896)
*Shahar Dobzinski,Alon Eden,Kira Goldner,Ariel Shaulker,Thodoris Tsilivis*

Main category: cs.GT

TL;DR: 本文研究了双边贸易中福利最大化问题，特别关注相互依赖价值的情况，提出了基于信息结构的分类方法，并探讨了近似机制的可行性。


<details>
  <summary>Details</summary>
Motivation: 以往研究仅针对私有价值情况提出激励兼容的近似机制，而相互依赖价值的情况更具挑战性，因为玩家的价值取决于他人的私有信息。

Method: 通过量化玩家私有信号对其自身估值的影响来分类信息结构，并分析不同结构下近似机制的可行性。

Result: 研究揭示了在特定信息结构下近似机制的可能性与不可能性，并探讨了自然信息结构家族的近似比率。

Conclusion: 本文为相互依赖价值下的双边贸易福利最大化提供了新的理论框架和分类方法。

Abstract: Welfare maximization in bilateral trade has been extensively studied in
recent years. Previous literature obtained incentive-compatible approximation
mechanisms only for the private values case. In this paper, we study welfare
maximization in bilateral trade with interdependent values. Designing
mechanisms for interdependent settings is much more challenging because the
values of the players depend on the private information of the others,
requiring complex belief updates and strategic inference. We propose to
classify information structures by quantifying the influence that a player's
private signal has on their own valuation. We then paint a picture of where
approximations are possible and impossible based on these information
structures. Finally, we also study the possible approximation ratios for a
natural family of information structures.

</details>


### [381] [Quickest Detection of Adversarial Attacks Against Correlated Equilibria](https://arxiv.org/abs/2506.24040)
*Kiarash Kazari,Aris Kanellopoulos,György Dán*

Main category: cs.GT

TL;DR: 研究对抗环境中战略游戏的关联均衡，提出一种快速检测攻击的方法，通过零和博弈框架和广义CUSUM方案，有效限制潜在对手的效用损失。


<details>
  <summary>Details</summary>
Motivation: 在对抗环境中，玩家需要快速检测潜在攻击以避免效用损失，而对手可能破坏公共信号。

Method: 采用零和博弈框架和快速变化检测方法，定义一类对抗策略，并证明广义CUSUM方案在攻击检测中渐近最优。

Result: 在Sioux-Falls基准交通路由游戏中，提出的检测方案能有效限制对手的效用损失。

Conclusion: 广义CUSUM方案在对抗环境中具有高效检测能力，能显著减少潜在攻击的负面影响。

Abstract: We consider correlated equilibria in strategic games in an adversarial
environment, where an adversary can compromise the public signal used by the
players for choosing their strategies, while players aim at detecting a
potential attack as soon as possible to avoid loss of utility. We model the
interaction between the adversary and the players as a zero-sum game and we
derive the maxmin strategies for both the defender and the attacker using the
framework of quickest change detection. We define a class of adversarial
strategies that achieve the optimal trade-off between attack impact and attack
detectability and show that a generalized CUSUM scheme is asymptotically
optimal for the detection of the attacks. Our numerical results on the
Sioux-Falls benchmark traffic routing game show that the proposed detection
scheme can effectively limit the utility loss by a potential adversary.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [382] [Towards Efficient and Accurate Spiking Neural Networks via Adaptive Bit Allocation](https://arxiv.org/abs/2506.23717)
*Xingting Yao,Qinghao Hu,Fei Zhou,Tielong Liu,Gang Li,Peisong Wang,Jian Cheng*

Main category: cs.NE

TL;DR: 本文提出了一种自适应比特分配策略，用于直接训练的脉冲神经网络（SNN），通过细粒度的层间资源分配提升效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 多比特SNN在追求高能效和高精度时，随着比特数增加，内存和计算需求不成比例地增长，导致性能提升受限。

Method: 参数化权重和脉冲的时间长度与比特宽度，使其可通过梯度学习；提出改进的脉冲神经元以处理可变比特宽度和时间长度；理论分析比特宽度学习中的步长不匹配问题并提出解决机制。

Result: 在多个数据集上实验表明，该方法能降低内存和计算成本，同时提高准确性，例如在ImageNet上SEWResNet-34实现了2.69%的准确率提升和4.16倍的比特预算降低。

Conclusion: 自适应比特分配策略显著提升了SNN的效率和准确性，为高能效AI提供了新思路。

Abstract: Multi-bit spiking neural networks (SNNs) have recently become a heated
research spot, pursuing energy-efficient and high-accurate AI. However, with
more bits involved, the associated memory and computation demands escalate to
the point where the performance improvements become disproportionate. Based on
the insight that different layers demonstrate different importance and extra
bits could be wasted and interfering, this paper presents an adaptive bit
allocation strategy for direct-trained SNNs, achieving fine-grained layer-wise
allocation of memory and computation resources. Thus, SNN's efficiency and
accuracy can be improved. Specifically, we parametrize the temporal lengths and
the bit widths of weights and spikes, and make them learnable and controllable
through gradients. To address the challenges caused by changeable bit widths
and temporal lengths, we propose the refined spiking neuron, which can handle
different temporal lengths, enable the derivation of gradients for temporal
lengths, and suit spike quantization better. In addition, we theoretically
formulate the step-size mismatch problem of learnable bit widths, which may
incur severe quantization errors to SNN, and accordingly propose the step-size
renewal mechanism to alleviate this issue. Experiments on various datasets,
including the static CIFAR and ImageNet and the dynamic CIFAR-DVS and
DVS-GESTURE, demonstrate that our methods can reduce the overall memory and
computation cost while achieving higher accuracy. Particularly, our
SEWResNet-34 can achieve a 2.69\% accuracy gain and 4.16$\times$ lower bit
budgets over the advanced baseline work on ImageNet. This work will be fully
open-sourced.

</details>


### [383] [Marker Gene Method : Identifying Stable Solutions in a Dynamic Environment](https://arxiv.org/abs/2506.23734)
*Hao Shi,Xi Li,Fangfang Xie*

Main category: cs.NE

TL;DR: 本文提出了一种名为标记基因方法（MGM）的框架，通过动态基准和自适应权重机制解决竞争性协同进化算法（CCEAs）中的不稳定收敛问题。


<details>
  <summary>Details</summary>
Motivation: 竞争性协同进化算法常因复杂动态（如不可传递性和红皇后效应）导致不稳定收敛，MGM旨在解决这一问题。

Method: MGM利用标记基因作为动态基准，结合自适应权重机制平衡探索与开发，并通过严格数学证明验证其在严格竞争博弈框架下的稳定性。

Result: 实验表明，MGM在经典石头剪刀布游戏、ZDT基准测试及Shapley偏置游戏中均显著提升了稳定性和性能。

Conclusion: MGM是一个理论严谨且实证有效的框架，显著增强了CCEAs在复杂竞争环境中的稳定性和鲁棒性。

Abstract: Competitive Co-evolutionary Algorithms (CCEAs) are often hampered by complex
dynamics like intransitivity and the Red Queen effect, leading to unstable
convergence. To counter these challenges, this paper introduces the Marker Gene
Method (MGM), a framework that establishes stability by using a 'marker gene'
as a dynamic benchmark and an adaptive weighting mechanism to balance
exploration and exploitation. We provide rigorous mathematical proofs
demonstrating that MGM creates strong attractors near Nash Equilibria within
the Strictly Competitive Game framework. Empirically, MGM demonstrates its
efficacy across a spectrum of challenges: it stabilizes the canonical
Rock-Paper-Scissors game, significantly improves the performance of C-RMOEA/D
on ZDT benchmarks, and, when augmented with a Memory Pool (MP) extension, it
successfully tames the notoriously pathological Shapley Biased Game. This work
presents a theoretically sound and empirically validated framework that
substantially enhances the stability and robustness of CCEAs in complex
competitive environments.

</details>


### [384] [More Efficient Real-Valued Gray-Box Optimization through Incremental Distribution Estimation in RV-GOMEA](https://arxiv.org/abs/2506.23738)
*Renzo J. Scholman,Tanja Alderliesten,Peter A. N. Bosman*

Main category: cs.NE

TL;DR: 研究了增量分布估计是否提升RV-GOMEA的效率，发现优化后评估次数可减少1.5-3倍。


<details>
  <summary>Details</summary>
Motivation: RV-GOMEA未采用增量学习，而其他高效算法如NES和CMA-ES已使用，因此研究增量学习对RV-GOMEA的潜在提升。

Method: 在RV-GOMEA中引入增量分布估计，并在不同依赖程度的基准问题上测试。

Result: 优化后评估次数减少1.5倍（问题特定调参）或2-3倍（通用调参）。

Conclusion: 增量分布估计显著提升RV-GOMEA效率，尤其在通用调参下效果更佳。

Abstract: The Gene-pool Optimal Mixing EA (GOMEA) family of EAs offers a specific means
to exploit problem-specific knowledge through linkage learning, i.e.,
inter-variable dependency detection, expressed using subsets of variables, that
should undergo joint variation. Such knowledge can be exploited if faster
fitness evaluations are possible when only a few variables are changed in a
solution, enabling large speed-ups. The recent-most version of Real-Valued
GOMEA (RV-GOMEA) can learn a conditional linkage model during optimization
using fitness-based linkage learning, enabling fine-grained dependency
exploitation in learning and sampling a Gaussian distribution. However, while
the most efficient Gaussian-based EAs, like NES and CMA-ES, employ incremental
learning of the Gaussian distribution rather than performing full re-estimation
every generation, the recent-most RV-GOMEA version does not employ such
incremental learning. In this paper, we therefore study whether incremental
distribution estimation can lead to efficiency enhancements of RV-GOMEA. We
consider various benchmark problems with varying degrees of overlapping
dependencies. We find that, compared to RV-GOMEA and VKD-CMA-ES, the required
number of evaluations to reach high-quality solutions can be reduced by a
factor of up to 1.5 if population sizes are tuned problem-specifically, while a
reduction by a factor of 2-3 can be achieved with generic population-sizing
guidelines.

</details>


### [385] [Unsupervised Sparse Coding-based Spiking Neural Network for Real-time Spike Sorting](https://arxiv.org/abs/2506.24041)
*Alexis Melot,Sean U. N. Wood,Yannick Coffinier,Pierre Yger,Fabien Alibart*

Main category: cs.NE

TL;DR: 该论文提出了一种名为Neuromorphic Sparse Sorter (NSS)的新型尖峰排序方法，用于实时、低功耗的边缘计算，并展示了其在神经解码性能上的优势。


<details>
  <summary>Details</summary>
Motivation: 在脑机接口（BMIs）中，实现实时、低功耗的尖峰排序是一个关键挑战，同时需要保持高性能的神经解码能力。

Method: NSS是一种紧凑的两层脉冲神经网络，利用局部竞争算法（LCA）进行稀疏编码，以从噪声事件中提取相关特征，并在无监督模式下在线学习。

Result: 在模拟和真实世界的四极信号测试中，NSS表现优于WaveClus3和PCA+KMeans等方法，特别是在Intel Loihi 2平台上，使用2位分级尖峰时，F1分数提高了10%，功耗为8.6mW。

Conclusion: NSS在尖峰排序任务中表现出色，为边缘计算提供了高效的解决方案，同时展示了在神经形态平台上的潜力。

Abstract: Spike sorting is a crucial step in decoding multichannel extracellular neural
signals, enabling the identification of individual neuronal activity. A key
challenge in brain-machine interfaces (BMIs) is achieving real-time, low-power
spike sorting at the edge while keeping high neural decoding performance. This
study introduces the Neuromorphic Sparse Sorter (NSS), a compact two-layer
spiking neural network optimized for efficient spike sorting. NSS leverages the
Locally Competitive Algorithm (LCA) for sparse coding to extract relevant
features from noisy events with reduced computational demands. NSS learns to
sort detected spike waveforms in an online fashion and operates entirely
unsupervised. To exploit multi-bit spike coding capabilities of neuromorphic
platforms like Intel's Loihi 2, a custom neuron model was implemented, enabling
flexible power-performance trade-offs via adjustable spike bit-widths.
Evaluations on simulated and real-world tetrode signals with biological drift
showed NSS outperformed established pipelines such as WaveClus3 and PCA+KMeans.
With 2-bit graded spikes, NSS on Loihi 2 outperformed NSS implemented with
leaky integrate-and-fire neuron and achieved an F1-score of 77% (+10%
improvement) while consuming 8.6mW (+1.65mW) when tested on a drifting
recording, with a computational processing time of 0.25ms (+60 us) per
inference.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [386] [VoteSplat: Hough Voting Gaussian Splatting for 3D Scene Understanding](https://arxiv.org/abs/2506.22799)
*Minchao Jiang,Shunyu Jia,Jiaming Gu,Xiaoyuan Lu,Guangming Zhu,Anqi Dong,Liang Zhang*

Main category: cs.GR

TL;DR: VoteSplat结合3D高斯泼溅与霍夫投票，提出了一种高效且低成本的3D场景理解框架，支持开放词汇对象定位和点云理解。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯泼溅方法主要关注几何和外观建模，缺乏深度场景理解且训练成本高。

Method: 利用SAM进行实例分割，生成2D投票图，并通过高斯基元嵌入空间偏移向量，结合深度约束优化定位。

Result: 实验证明VoteSplat在开放词汇3D实例定位、点云理解等任务中表现优异。

Conclusion: VoteSplat为3D场景理解提供了一种高效且语义明确的解决方案。

Abstract: 3D Gaussian Splatting (3DGS) has become horsepower in high-quality, real-time
rendering for novel view synthesis of 3D scenes. However, existing methods
focus primarily on geometric and appearance modeling, lacking deeper scene
understanding while also incurring high training costs that complicate the
originally streamlined differentiable rendering pipeline. To this end, we
propose VoteSplat, a novel 3D scene understanding framework that integrates
Hough voting with 3DGS. Specifically, Segment Anything Model (SAM) is utilized
for instance segmentation, extracting objects, and generating 2D vote maps. We
then embed spatial offset vectors into Gaussian primitives. These offsets
construct 3D spatial votes by associating them with 2D image votes, while depth
distortion constraints refine localization along the depth axis. For
open-vocabulary object localization, VoteSplat maps 2D image semantics to 3D
point clouds via voting points, reducing training costs associated with
high-dimensional CLIP features while preserving semantic unambiguity. Extensive
experiments demonstrate effectiveness of VoteSplat in open-vocabulary 3D
instance localization, 3D point cloud understanding, click-based 3D object
localization, hierarchical segmentation, and ablation studies. Our code is
available at https://sy-ja.github.io/votesplat/

</details>


### [387] [DOBB-BVH: Efficient Ray Traversal by Transforming Wide BVHs into Oriented Bounding Box Trees using Discrete Rotations](https://arxiv.org/abs/2506.22849)
*Michael A. Kern,Alain Galvan,David Oldcorn,Daniel Skinner,Rohan Mehalwal,Leo Reyes Lozano,Matthäus G. Chajdas*

Main category: cs.GR

TL;DR: 提出了一种新型OBB构建技术，通过固定离散旋转集优化计算和内存效率，显著提升光线追踪性能。


<details>
  <summary>Details</summary>
Motivation: 在光线追踪中，OBB层次结构比轴对齐包围盒更精确，但计算和内存成本高。研究旨在优化OBB构建效率。

Method: 采用固定离散旋转集统一内部节点的OBB变换，结合k-DOPs扩展至多子节点层次结构，作为后处理步骤集成现有流程。

Result: 实验显示构建时间增加12.6%，但光线追踪性能平均提升18.5%（主光线）、32.4%（次光线），最高达65%。

Conclusion: 该方法显著提升光线追踪性能，适用于实时应用，且易于集成现有流程。

Abstract: Oriented bounding box (OBB) bounding volume hierarchies offer a more precise
fit than axis-aligned bounding box hierarchies in scenarios with thin elongated
and arbitrarily rotated geometry, enhancing intersection test performance in
ray tracing. However, determining optimally oriented bounding boxes can be
computationally expensive and have high memory requirements. Recent research
has shown that pre-built hierarchies can be efficiently converted to OBB
hierarchies on the GPU in a bottom-up pass, yielding significant ray tracing
traversal improvements. In this paper, we introduce a novel OBB construction
technique where all internal node children share a consistent OBB transform,
chosen from a fixed set of discrete quantized rotations. This allows for
efficient encoding and reduces the computational complexity of OBB
transformations. We further extend our approach to hierarchies with multiple
children per node by leveraging Discrete Orientation Polytopes (k-DOPs),
demonstrating improvements in traversal performance while limiting the build
time impact for real-time applications. Our method is applied as a
post-processing step, integrating seamlessly into existing hierarchy
construction pipelines. Despite a 12.6% increase in build time, our
experimental results demonstrate an average improvement of 18.5% in primary,
32.4% in secondary rays, and maximum gain of 65% in ray intersection
performance, highlighting its potential for advancing real-time applications.

</details>


### [388] [Confident Splatting: Confidence-Based Compression of 3D Gaussian Splatting via Learnable Beta Distributions](https://arxiv.org/abs/2506.22973)
*AmirHossein Naghi Razlighi,Elaheh Badali Golezani,Shohreh Kasaei*

Main category: cs.GR

TL;DR: 提出一种基于可学习置信分数的3D高斯泼溅压缩方法，通过Beta分布建模置信分数，优化低置信度泼溅的修剪，同时保持视觉保真度。


<details>
  <summary>Details</summary>
Motivation: 解决3D高斯泼溅技术中因生成数百万泼溅导致的存储和计算开销过高的问题。

Method: 使用Beta分布建模可学习置信分数，通过重构感知损失优化置信分数，修剪低置信度泼溅。

Result: 实验显示该方法在压缩和保真度之间取得了良好的平衡。

Conclusion: 提出的方法架构无关，适用于任何高斯泼溅变体，且置信平均值可作为场景质量评估的新指标。

Abstract: 3D Gaussian Splatting enables high-quality real-time rendering but often
produces millions of splats, resulting in excessive storage and computational
overhead. We propose a novel lossy compression method based on learnable
confidence scores modeled as Beta distributions. Each splat's confidence is
optimized through reconstruction-aware losses, enabling pruning of
low-confidence splats while preserving visual fidelity. The proposed approach
is architecture-agnostic and can be applied to any Gaussian Splatting variant.
In addition, the average confidence values serve as a new metric to assess the
quality of the scene. Extensive experiments demonstrate favorable trade-offs
between compression and fidelity compared to prior work. Our code and data are
publicly available at
https://github.com/amirhossein-razlighi/Confident-Splatting

</details>


### [389] [The ultimate display: Where will all the pixels come from?](https://arxiv.org/abs/2506.23001)
*Benjamin Watson,David Luebke*

Main category: cs.GR

TL;DR: 通过减少计算像素数量，采用时间自适应采样的渲染器可能实现高分辨率墙显示器的快速更新。


<details>
  <summary>Details</summary>
Motivation: 探索如何在高分辨率墙显示器上实现每秒数百次的快速更新。

Method: 打破传统的帧模式，采用时间自适应采样技术。

Result: 可能实现打印机分辨率级别的墙显示器高速更新。

Conclusion: 减少像素计算并采用时间自适应采样是解决高分辨率显示器快速更新的潜在方案。

Abstract: Could the answer be to compute fewer pixels? Renderers that break traditional
framed patterns and opt for temporally adaptive sampling might be the key to
printer-resolution wall displays that update hundreds of times per second.

</details>


### [390] [Glyph-Based Multiscale Visualization of Turbulent Multi-Physics Statistics](https://arxiv.org/abs/2506.23092)
*Arisa Cowe,Tyson Neuroth,Qi Wu,Martin Rieth,Jacqueline Chen,Myoungkyu Lee,Kwan-Liu Ma*

Main category: cs.GR

TL;DR: 提出了一种新颖的多尺度流场局部空间统计可视化方法，结合曲线波变换、水平集限制的质心Voronoi剖分和符号设计，支持多场和多尺度的交互式分析。


<details>
  <summary>Details</summary>
Motivation: 多物理问题涉及广泛尺度，理解跨尺度交互对复杂问题至关重要，但多变量、多尺度数据的可视化仍具挑战性。

Method: 使用曲线波变换进行尺度分解，水平集限制的质心Voronoi剖分划分空间区域，设计符号整合多尺度和多场信息。

Result: 通过湍流燃烧数据和不可压缩湍流通道数据的案例研究，验证了方法的有效性。

Conclusion: 该方法帮助科学家更好地理解湍流中多场和多尺度之间的交互。

Abstract: Many scientific and engineering problems involving multi-physics span a wide
range of scales. Understanding the interactions across these scales is
essential for fully comprehending such complex problems. However, visualizing
multivariate, multiscale data within an integrated view where correlations
across space, scales, and fields are easily perceived remains challenging. To
address this, we introduce a novel local spatial statistical visualization of
flow fields across multiple fields and turbulence scales. Our method leverages
the curvelet transform for scale decomposition of fields of interest, a
level-set-restricted centroidal Voronoi tessellation to partition the spatial
domain into local regions for statistical aggregation, and a set of glyph
designs that combines information across scales and fields into a single, or
reduced set of perceivable visual representations. Each glyph represents data
aggregated within a Voronoi region and is positioned at the Voronoi site for
direct visualization in a 3D view centered around flow features of interest. We
implement and integrate our method into an interactive visualization system
where the glyph-based technique operates in tandem with linked 3D spatial views
and 2D statistical views, supporting a holistic analysis. We demonstrate with
case studies visualizing turbulent combustion data--multi-scalar compressible
flows--and turbulent incompressible channel flow data. This new capability
enables scientists to better understand the interactions between multiple
fields and length scales in turbulent flows.

</details>


### [391] [Data-Driven Compute Overlays for Interactive Geographic Simulation and Visualization](https://arxiv.org/abs/2506.23364)
*Patrick Komon,Gerald Kimmersdorfer,Adam Celarek,Manuela Waldner*

Main category: cs.GR

TL;DR: 提出了一种基于WebGPU的交互式数据驱动计算覆盖层，用于原生和基于Web的3D地理地图应用，支持多数据源GPU计算，并在雪盖和雪崩模拟中展示了其高效性。


<details>
  <summary>Details</summary>
Motivation: 提升3D地理地图应用中数据驱动的交互式模拟性能，特别是在大规模雪崩模拟中，实现实时参数调整和结果可视化。

Method: 采用多步骤GPU计算工作流，从多数据源生成数据驱动覆盖层，支持交互式参数调整。

Result: 实验表明，该方法能在毫秒到秒级完成大规模雪崩模拟，比现有Python实现快多个数量级。

Conclusion: 该方法显著提升了3D地理地图应用中数据驱动模拟的效率和交互性，适用于实时场景。

Abstract: We present interactive data-driven compute overlays for native and web-based
3D geographic map applications based on WebGPU. Our data-driven overlays are
generated in a multi-step compute workflow from multiple data sources on the
GPU. We demonstrate their potential by showing results from snow cover and
avalanche simulations, where simulation parameters can be adjusted
interactively and results are visualized instantly. Benchmarks show that our
approach can compute large-scale avalanche simulations in milliseconds to
seconds, depending on the size of the terrain and the simulation parameters,
which is multiple orders of magnitude faster than a state-of-the-art Python
implementation.

</details>


### [392] [Escher Tile Deformation via Closed-Form Solution](https://arxiv.org/abs/2506.23388)
*Crane He Chen,Vladimir G. Kim*

Main category: cs.GR

TL;DR: 提出了一种实时变形Escher瓷砖的方法，通过周期性位移场实现无缝变形，支持多种表示形式，并提供用户可控的交互工具。


<details>
  <summary>Details</summary>
Motivation: 解决Escher瓷砖在变形过程中可能出现的间隙或重叠问题，同时支持艺术家的精细控制需求。

Method: 通过解析解确定周期性位移场，同时考虑瓷砖的边界和内部纹理，支持17种壁纸群和多种表示形式。

Result: 实现了无缝变形，并通过示例展示了在照片编辑和形状雕刻等应用中的有效性。

Conclusion: 该方法为Escher瓷砖的变形提供了高效且可控的解决方案，适用于制造和动画等领域。

Abstract: We present a real-time deformation method for Escher tiles -- interlocking
organic forms that seamlessly tessellate the plane following symmetry rules. We
formulate the problem as determining a periodic displacement field. The goal is
to deform Escher tiles without introducing gaps or overlaps. The resulting
displacement field is obtained in closed form by an analytical solution. Our
method processes tiles of 17 wallpaper groups across various representations
such as images and meshes. Rather than treating tiles as mere boundaries, we
consider them as textured shapes, ensuring that both the boundary and interior
deform simultaneously. To enable fine-grained artistic input, our interactive
tool features a user-controllable adaptive fall-off parameter, allowing precise
adjustment of locality and supporting deformations with meaningful semantic
control. We demonstrate the effectiveness of our method through various
examples, including photo editing and shape sculpting, showing its use in
applications such as fabrication and animation.

</details>


### [393] [Uncertain Mode Surfaces in 3D Symmetric Second-Order Tensor Field Ensembles](https://arxiv.org/abs/2506.23406)
*Tim Gerrits*

Main category: cs.GR

TL;DR: 本文提出了一种将不确定退化张量特征推广到任意模态值的不确定模态表面的方法，形成了一个统一的框架来分析张量场集合中的不确定模态拓扑特征。


<details>
  <summary>Details</summary>
Motivation: 张量场分析通常依赖于拓扑特征，如退化张量线和中立表面，但现有方法在可视化不确定性时往往无法捕捉全局行为。

Method: 将不确定退化张量特征推广到任意模态值的不确定模态表面，支持表面和线几何，形成统一框架。

Result: 在工程和材料科学的多个实际模拟数据集上验证了方法的有效性。

Conclusion: 该方法为张量场集合中的不确定模态拓扑特征分析提供了全面且统一的解决方案。

Abstract: The analysis of 3D symmetric second-order tensor fields often relies on
topological features such as degenerate tensor lines, neutral surfaces, and
their generalization to mode surfaces, which reveal important structural
insights into the data. However, uncertainty in such fields is typically
visualized using derived scalar attributes or tensor glyph representations,
which often fail to capture the global behavior. Recent advances have
introduced uncertain topological features for tensor field ensembles by
focusing on degenerate tensor locations. Yet, mode surfaces, including neutral
surfaces and arbitrary mode surfaces are essential to a comprehensive
understanding of tensor field topology. In this work, we present a
generalization of uncertain degenerate tensor features to uncertain mode
surfaces of arbitrary mode values, encompassing uncertain degenerate tensor
lines as a special case. Our approach supports both surface and line
geometries, forming a unified framework for analyzing uncertain mode-based
topological features in tensor field ensembles. We demonstrate the
effectiveness of our method on several real-world simulation datasets from
engineering and materials science.

</details>


### [394] [Synthetically Expressive: Evaluating gesture and voice for emotion and empathy in VR and 2D scenarios](https://arxiv.org/abs/2506.23777)
*Haoyang Du,Kiran Chhatre,Christopher Peters,Brian Keegan,Rachel McDonnell,Cathy Ennis*

Main category: cs.GR

TL;DR: 研究评估了真实与合成手势和语音在不同沉浸环境（VR vs. 2D）及情感背景下对用户体验的影响，发现VR增强自然手势-语音配对感知，但未改善合成配对。


<details>
  <summary>Details</summary>
Motivation: 探讨虚拟人类中语音和手势的整合及其在沉浸环境中传达情感细节的能力。

Method: 评估真实与合成手势和语音在不同沉浸环境和情感背景下的用户感知。

Result: VR增强自然手势-语音配对感知，但对合成配对无效，凸显两者间的感知差距。

Conclusion: 需重新评估手势的适用性并优化AI驱动的合成技术以适应沉浸环境。

Abstract: The creation of virtual humans increasingly leverages automated synthesis of
speech and gestures, enabling expressive, adaptable agents that effectively
engage users. However, the independent development of voice and gesture
generation technologies, alongside the growing popularity of virtual reality
(VR), presents significant questions about the integration of these signals and
their ability to convey emotional detail in immersive environments. In this
paper, we evaluate the influence of real and synthetic gestures and speech,
alongside varying levels of immersion (VR vs. 2D displays) and emotional
contexts (positive, neutral, negative) on user perceptions. We investigate how
immersion affects the perceived match between gestures and speech and the
impact on key aspects of user experience, including emotional and empathetic
responses and the sense of co-presence. Our findings indicate that while VR
enhances the perception of natural gesture-voice pairings, it does not
similarly improve synthetic ones - amplifying the perceptual gap between them.
These results highlight the need to reassess gesture appropriateness and refine
AI-driven synthesis for immersive environments. See video:
https://youtu.be/WMfjIB1X-dc

</details>


### [395] [GaVS: 3D-Grounded Video Stabilization via Temporally-Consistent Local Reconstruction and Rendering](https://arxiv.org/abs/2506.23957)
*Zinuo You,Stamatios Georgoulis,Anpei Chen,Siyu Tang,Dengxin Dai*

Main category: cs.GR

TL;DR: GaVS是一种基于3D的视频稳定方法，通过局部重建和渲染范式解决现有方法的几何失真、过度裁剪等问题，表现优于现有2D和2.5D方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频稳定方法存在几何失真、过度裁剪和泛化能力差等问题，影响用户体验。

Method: GaVS采用3D相机位姿，通过高斯散射基元预测和多视角动态感知光度监督，实现时间一致的局部重建和渲染，避免帧裁剪。

Result: 在多样化的相机运动和场景动态数据集上，GaVS在任务指标和几何一致性上优于现有2D和2.5D方法，用户研究也验证了其优越性。

Conclusion: GaVS通过3D基础方法显著提升了视频稳定效果，解决了现有技术的局限性。

Abstract: Video stabilization is pivotal for video processing, as it removes unwanted
shakiness while preserving the original user motion intent. Existing
approaches, depending on the domain they operate, suffer from several issues
(e.g. geometric distortions, excessive cropping, poor generalization) that
degrade the user experience. To address these issues, we introduce
\textbf{GaVS}, a novel 3D-grounded approach that reformulates video
stabilization as a temporally-consistent `local reconstruction and rendering'
paradigm. Given 3D camera poses, we augment a reconstruction model to predict
Gaussian Splatting primitives, and finetune it at test-time, with multi-view
dynamics-aware photometric supervision and cross-frame regularization, to
produce temporally-consistent local reconstructions. The model are then used to
render each stabilized frame. We utilize a scene extrapolation module to avoid
frame cropping. Our method is evaluated on a repurposed dataset, instilled with
3D-grounded information, covering samples with diverse camera motions and scene
dynamics. Quantitatively, our method is competitive with or superior to
state-of-the-art 2D and 2.5D approaches in terms of conventional task metrics
and new geometry consistency. Qualitatively, our method produces noticeably
better results compared to alternatives, validated by the user study.

</details>


### [396] [Navigating with Annealing Guidance Scale in Diffusion Space](https://arxiv.org/abs/2506.24108)
*Shai Yehezkel,Omer Dahary,Andrey Voynov,Daniel Cohen-Or*

Main category: cs.GR

TL;DR: 提出了一种动态调整引导尺度的调度器，显著提升了文本到图像生成的质量和提示对齐。


<details>
  <summary>Details</summary>
Motivation: 现有的Classifier-Free Guidance (CFG)在引导尺度选择上对生成效果影响显著，但缺乏动态调整机制。

Method: 通过基于条件噪声信号学习调度策略，动态调整引导尺度。

Result: 实验表明，该方法显著提升了图像质量和提示对齐，且无需额外计算或内存开销。

Conclusion: 提出的调度器改进了CFG，为文本到图像生成提供了更好的质量和提示对齐权衡。

Abstract: Denoising diffusion models excel at generating high-quality images
conditioned on text prompts, yet their effectiveness heavily relies on careful
guidance during the sampling process. Classifier-Free Guidance (CFG) provides a
widely used mechanism for steering generation by setting the guidance scale,
which balances image quality and prompt alignment. However, the choice of the
guidance scale has a critical impact on the convergence toward a visually
appealing and prompt-adherent image. In this work, we propose an annealing
guidance scheduler which dynamically adjusts the guidance scale over time based
on the conditional noisy signal. By learning a scheduling policy, our method
addresses the temperamental behavior of CFG. Empirical results demonstrate that
our guidance scheduler significantly enhances image quality and alignment with
the text prompt, advancing the performance of text-to-image generation.
Notably, our novel scheduler requires no additional activations or memory
consumption, and can seamlessly replace the common classifier-free guidance,
offering an improved trade-off between prompt alignment and quality.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [397] [Exploring Artificial Intelligence Tutor Teammate Adaptability to Harness Discovery Curiosity and Promote Learning in the Context of Interactive Molecular Dynamics](https://arxiv.org/abs/2506.22520)
*Mustafa Demir,Jacob Miratsky,Jonathan Nguyen,Chun Kit Chan,Punya Mishra,Abhishek Singharoy*

Main category: cs.HC

TL;DR: 研究探讨AI导师如何通过激发好奇心行为提升学生在分子动力学任务中的学习效果和团队表现。


<details>
  <summary>Details</summary>
Motivation: 探索AI导师的好奇心触发行为对学生好奇心和团队协作的影响。

Method: 采用Wizard-of-Oz范式，通过混合方法设计，11名高中生参与4项分子动力学任务，评估团队表现和沟通行为。

Result: 高表现团队任务完成度更高，问题复杂度与AI好奇心触发行为相关，CRQA指标显示动态同步。

Conclusion: AI作为队友和教育者的双重角色能提供适应性反馈，维持学生好奇心和参与度。

Abstract: This study examines the impact of an Artificial Intelligence tutor teammate
(AI) on student curiosity-driven engagement and learning effectiveness during
Interactive Molecular Dynamics (IMD) tasks on the Visual Molecular Dynamics
platform. It explores the role of the AI's curiosity-triggering and response
behaviors in stimulating and sustaining student curiosity, affecting the
frequency and complexity of student-initiated questions. The study further
assesses how AI interventions shape student engagement, foster discovery
curiosity, and enhance team performance within the IMD learning environment.
Using a Wizard-of-Oz paradigm, a human experimenter dynamically adjusts the AI
tutor teammate's behavior through a large language model. By employing a
mixed-methods exploratory design, a total of 11 high school students
participated in four IMD tasks that involved molecular visualization and
calculations, which increased in complexity over a 60-minute period. Team
performance was evaluated through real-time observation and recordings, whereas
team communication was measured by question complexity and AI's
curiosity-triggering and response behaviors. Cross Recurrence Quantification
Analysis (CRQA) metrics reflected structural alignment in coordination and were
linked to communication behaviors. High-performing teams exhibited superior
task completion, deeper understanding, and increased engagement. Advanced
questions were associated with AI curiosity-triggering, indicating heightened
engagement and cognitive complexity. CRQA metrics highlighted dynamic
synchronization in student-AI interactions, emphasizing structured yet adaptive
engagement to promote curiosity. These proof-of-concept findings suggest that
the AI's dual role as a teammate and educator indicates its capacity to provide
adaptive feedback, sustaining engagement and epistemic curiosity.

</details>


### [398] [Supra-threshold control of peripheral LOD](https://arxiv.org/abs/2506.22583)
*Benjamin Watson,Neff Walker,Larry F Hodges*

Main category: cs.HC

TL;DR: 论文探讨了超阈值LOD控制与阈值LOD控制的差异，发现任务依赖的可靠感知水平是关键，并提出细节对比度比细节大小更能预测感知性。


<details>
  <summary>Details</summary>
Motivation: 现有LOD控制基于阈值感知，但实际应用中LOD操作多发生在超阈值范围，而超阈值感知与阈值感知差异显著，因此需要研究超阈值LOD控制是否也应不同。

Method: 通过两个实验研究视觉外围的超阈值LOD控制。

Result: 发现LOD需支持任务依赖的可靠感知水平；高于此水平时，应最小化LOD操作的感知性，细节对比度比大小更能预测感知性；低于此水平时，需最大化感知性，并随偏心距增加或对比度降低改进LOD。

Conclusion: 研究结果与现有阈值LOD控制方案直接矛盾，建议重新审视中心凹显示的LOD控制。

Abstract: Level of detail (LOD) is widely used to control visual feedback in
interactive applications. LOD control is typically based on perception at
threshold - the conditions in which a stimulus first becomes perceivable. Yet
most LOD manipulations are quite perceivable and occur well above threshold.
Moreover, research shows that supra-threshold perception differs drastically
from perception at threshold. In that case, should supra-threshold LOD control
also differ from LOD control at threshold?
  In two experiments, we examine supra-threshold LOD control in the visual
periphery and find that indeed, it should differ drastically from LOD control
at threshold. Specifically, we find that LOD must support a task-dependent
level of reliable perceptibility. Above that level, perceptibility of LOD
control manipulations should be minimized, and detail contrast is a better
predictor of perceptibility than detail size. Below that level, perceptibility
must be maximized, and LOD should be improved as eccentricity rises or contrast
drops. This directly contradicts prevailing threshold-based LOD control
schemes, and strongly suggests a reexamination of LOD control for foveal
display.

</details>


### [399] [A tangible user interface for assessing cognitive mapping ability](https://arxiv.org/abs/2506.22597)
*Ehud Sharlin,Benjamin Watson,Steve Sutphen,Lili Liu,Robert Lederer,John Frazer*

Main category: cs.HC

TL;DR: 论文介绍了一种名为CMP的新型计算机化工具，用于评估认知地图能力，提高了测试的一致性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 认知地图能力对日常生活至关重要，但年龄、疾病或损伤可能影响其功能。现有评估方法需要改进。

Method: 开发了CMP工具，采用实体用户界面进行空间操作，并通过实验测试验证其敏感性。

Result: CMP对影响认知地图表现的因素敏感，显示出更高的灵活性、可访问性和控制性。

Conclusion: CMP是一种有效的认知地图评估工具，适用于临床和研究用途。

Abstract: Wayfinding, the ability to recall the environment and navigate through it, is
an essential cognitive skill relied upon almost every day in a person's life. A
crucial component of wayfinding is the construction of cognitive maps, mental
representations of the environments through which a person travels. Age,
disease or injury can severely affect cognitive mapping, making assessment of
this basic survival skill particularly important to clinicians and therapists.
Cognitive mapping has also been the focus of decades of basic research by
cognitive psychologists. Both communities have evolved a number of techniques
for assessing cognitive mapping ability. We present the Cognitive Map Probe
(CMP), a new computerized tool for assessment of cognitive mapping ability that
increases consistency and promises improvements in flexibility, accessibility,
sensitivity and control. The CMP uses a tangible user interface that affords
spatial manipulation. We describe the design of the CMP, and find that it is
sensitive to factors known to affect cognitive mapping performance in extensive
experimental testing.

</details>


### [400] [Do Electric Vehicles Induce More Motion Sickness Than Fuel Vehicles? A Survey Study in China](https://arxiv.org/abs/2506.22674)
*Weiyin Xie,Chunxi Huang,Jiyao Wang,Dengbo He*

Main category: cs.HC

TL;DR: 电动汽车（EVs）比燃油车（FVs）更易引发晕动病（MS），且症状更严重。研究发现个体差异、车内活动和路况是影响MS严重性的因素，而车辆拥有量和乘坐频率影响MS频率。


<details>
  <summary>Details</summary>
Motivation: 电动汽车的普及伴随着用户对其引发晕动病的广泛抱怨，但EV与FV在晕动病发生率和严重性上的关联尚未量化。本研究旨在验证EV是否更易引发MS并探索相关因素。

Method: 通过问卷调查收集过去一年内乘客在EV和FV中的晕动病经历，共收集到639份有效数据。

Result: 结果显示，FV的晕动病发生率更高，但EV引发的症状更严重。晕动病严重性与个体差异、车内活动和路况相关，而频率与车辆拥有量和乘坐频率相关。

Conclusion: 研究结果为未来量化EV和FV中晕动病诱因及优化EV设计以减少晕动病提供了方向。

Abstract: Electric vehicles (EVs) are a promising alternative to fuel vehicles (FVs),
given some unique characteristics of EVs, for example, the low air pollution
and maintenance cost. However, the increasing prevalence of EVs is accompanied
by widespread complaints regarding the high likelihood of motion sickness (MS)
induction, especially when compared to FVs, which has become one of the major
obstacles to the acceptance and popularity of EVs. Despite the prevalence of
such complaints online and among EV users, the association between vehicle type
(i.e., EV versus FV) and MS prevalence and severity has not been quantified.
Thus, this study aims to investigate the existence of EV-induced MS and explore
the potential factors leading to it. A survey study was conducted to collect
passengers' MS experience in EVs and FVs in the past one year. In total, 639
valid responses were collected from mainland China. The results show that FVs
were associated with a higher frequency of MS, while EVs were found to induce
more severe MS symptoms. Further, we found that passengers' MS severity was
associated with individual differences (i.e., age, gender, sleep habits,
susceptibility to motion-induced MS), in-vehicle activities (i.e., chatting
with others and watching in-vehicle displays), and road conditions (i.e.,
congestion and slope), while the MS frequency was associated with the vehicle
ownership and riding frequency. The results from this study can guide the
directions of future empirical studies that aim to quantify the inducers of MS
in EVs and FVs, as well as the optimization of EVs to reduce MS.

</details>


### [401] [Insights in Adaptation: Examining Self-reflection Strategies of Job Seekers with Visual Impairments in India](https://arxiv.org/abs/2506.22741)
*Akshay Nayak Kolgar,Yash Prakash,Sampath Jayarathna,Hae-Na Lee,Vikas Ashok*

Main category: cs.HC

TL;DR: 研究探讨了印度视障人士在数字就业中的挑战，发现尽管有数字素养和培训，他们仍难以满足行业需求，缺乏反馈机制。


<details>
  <summary>Details</summary>
Motivation: 数字就业环境变化为视障人士带来机会，但印度视障人群失业率高，需研究原因。

Method: 对20名印度视障人士进行半结构化访谈。

Result: 视障人士虽具备数字素养，但难以满足行业要求，且缺乏反馈。现有干预工具无法满足需求。

Conclusion: 未来需设计协作干预系统，提供个性化反馈，改善视障人士就业结果。

Abstract: Significant changes in the digital employment landscape, driven by rapid
technological advancements and the COVID-19 pandemic, have introduced new
opportunities for blind and visually impaired (BVI) individuals in developing
countries like India. However, a significant portion of the BVI population in
India remains unemployed despite extensive accessibility advancements and job
search interventions. Therefore, we conducted semi-structured interviews with
20 BVI persons who were either pursuing or recently sought employment in the
digital industry. Our findings reveal that despite gaining digital literacy and
extensive training, BVI individuals struggle to meet industry requirements for
fulfilling job openings. While they engage in self-reflection to identify
shortcomings in their approach and skills, they lack constructive feedback from
peers and recruiters. Moreover, the numerous job intervention tools are limited
in their ability to meet the unique needs of BVI job seekers. Our results
therefore provide key insights that inform the design of future collaborative
intervention systems that offer personalized feedback for BVI individuals,
effectively guiding their self-reflection process and subsequent job search
behaviors, and potentially leading to improved employment outcomes.

</details>


### [402] [Memory as a Service (MaaS): Rethinking Contextual Memory as Service-Oriented Modules for Collaborative Agents](https://arxiv.org/abs/2506.22815)
*Haichang Li*

Main category: cs.HC

TL;DR: 论文提出了一种新的内存设计视角“Memory as a Service”（MaaS），旨在解决当前LLM代理系统中内存设计的局限性，通过解耦内存与特定实体的绑定，实现跨实体协作。


<details>
  <summary>Details</summary>
Motivation: 当前LLM代理系统中的内存设计仍局限于“绑定内存”，导致内存孤岛问题，阻碍跨实体协作。

Method: 提出MaaS框架，将内存解耦为模块化服务，支持独立调用、动态组合和精细治理。

Result: MaaS通过内存的双重性（私有性与公共服务潜力），实现了跨实体的可控互操作性。

Conclusion: MaaS为跨实体协作提供了新的设计思路，并呼吁研究社区探索服务导向内存的治理、安全和伦理问题。

Abstract: This position paper aims to rethink the role and design of memory in Large
Language Model (LLM)-based agent systems. We observe that while current memory
practices have begun to transcend the limitations of single interactions, they
remain conceptually grounded in "bound memory" in terms of design concept-where
memory is treated as local state attached to specific context or entities,
forming "memory silos" that impede cross-entity collaboration. To overcome this
architectural bottleneck, this paper proposes the timely design perspective of
"Memory as a Service" (MaaS). MaaS advocates decoupling memory from its
conventional role as an interaction byproduct and encapsulating it as a modular
service that can be independently callable, dynamically composable, and finely
governed. At its core, MaaS leverages the duality of memory-its inherently
private nature and its potential for public service-to grant memory controlled,
on-demand interoperability across entities. This paper introduces a
two-dimensional design space defined by entity structure and service type,
illustrating how MaaS aligns with current memory practices while naturally
extending them to cross-entity collaborative scenarios. Finally, we outline an
open research agenda spanning governance, security, and ethical ecosystems, and
call upon the broader research community to explore this shift toward
service-oriented memory for collaborative agents operating across entity
boundaries.

</details>


### [403] [Dichoptic Opacity: Managing Occlusion in Stereoscopic Displays via Dichoptic Presentation](https://arxiv.org/abs/2506.22841)
*George Bell,Alma Cantu*

Main category: cs.HC

TL;DR: 提出了一种新的遮挡管理方法“双视透明度”，通过对比每只眼睛的遮挡物透明度，改善了遮挡物与被遮挡物的同时理解。


<details>
  <summary>Details</summary>
Motivation: 传统透明度调整方法可能损害深度关系的理解并丢失遮挡物的重要信息，需要改进。

Method: 采用双视透明度技术，对比每只眼睛的遮挡物透明度。

Result: 用户研究表明该方法具有潜力，用户参与度高且明显偏好双视透明度。

Conclusion: 双视透明度是一种有前景的遮挡管理方法，值得进一步研究其透明度的最佳值和范围。

Abstract: Adjusting transparency is a common method of mitigating occlusion but is
often detrimental for understanding the relative depth relationships between
objects as well as removes potentially important information from the occluding
object. We propose using dichoptic opacity, a novel method for occlusion
management that contrasts the transparency of occluders presented to each eye.
This allows for better simultaneous understanding of both occluder and
occluded. A user study highlights the technique's potential, showing strong
user engagement and a clear preference for dichoptic opacity over traditional
presentations. While it does not determine optimal transparency values, it
reveals promising trends in both percentage and range that merit further
investigation.

</details>


### [404] [Coordinated 2D-3D Visualization of Volumetric Medical Data in XR with Multimodal Interactions](https://arxiv.org/abs/2506.22926)
*Qixuan Liu,Shi Qiu,Yinqiao Wang,Xiwen Wu,Kenneth Siu Ho Chok,Chi-Wing Fu,Pheng-Ann Heng*

Main category: cs.HC

TL;DR: 论文提出了一种基于XR的系统，结合多层多平面重建与3D网格模型，以及手势与LLM语音命令的多模态交互框架，提升了医学数据的空间理解和交互效率。


<details>
  <summary>Details</summary>
Motivation: 医学影像技术的3D数据可视化对非专业人士具有挑战性，需要更直观的交互方式。

Method: 开发了XR系统，整合多层多平面重建、3D网格模型，并引入手势与LLM语音命令的多模态交互。

Result: 用户研究和专家访谈显示，系统显著提升了任务完成时间、可用性和交互效率。

Conclusion: 该系统在医学培训和临床实践中有潜力，未来需进一步优化。

Abstract: Volumetric medical imaging technologies produce detailed 3D representations
of anatomical structures. However, effective medical data visualization and
exploration pose significant challenges, especially for individuals with
limited medical expertise. We introduce a novel XR-based system with two key
innovations: (1) a coordinated visualization module integrating Multi-layered
Multi-planar Reconstruction with 3D mesh models and (2) a multimodal
interaction framework combining hand gestures with LLM-enabled voice commands.
We conduct preliminary evaluations, including a 15-participant user study and
expert interviews, to demonstrate the system's abilities to enhance spatial
understanding and reduce cognitive load. Experimental results show notable
improvements in task completion times, usability metrics, and interaction
effectiveness enhanced by LLM-driven voice control. While identifying areas for
future refinement, our findings highlight the potential of this immersive
visualization system to advance medical training and clinical practice. Our
demo application and supplemental materials are available for download at:
https://osf.io/bpjq5/.

</details>


### [405] [Immersive Technologies and Elderly Users: Current use, Limitations and Future Perspectives](https://arxiv.org/abs/2506.22932)
*Zoe Anastasiadou,Andreas Lanitis*

Main category: cs.HC

TL;DR: 本文综述了老年人使用扩展现实（XR）技术的现状，旨在帮助开发者设计更友好、易用的XR应用。


<details>
  <summary>Details</summary>
Motivation: 随着老年人口比例增加，需要利用新兴技术（如XR）支持老年人日常生活。

Method: 通过文献综述分析老年人的身心状态及现有XR应用的设计特点。

Result: 总结了老年人使用XR的主要困难及现有设计范例。

Conclusion: 为开发者提供了设计老年人友好XR应用的参考和灵感。

Abstract: The increase of the percentage of elderly population in modern societies
dictates the use of emerging technologies as a means of supporting elder
members of the society. Within this scope, Extended Reality (XR) technologies
pose as a promising technology for improving the daily lives of the elderly
population. This paper presents a literature review that describes the most
common characteristics of the physical and mental state of the elderly,
allowing readers, and specifically XR developers, to understand the main
difficulties faced by elderly users of extended reality applications so they
can develop accessible, user friendly and engaging applications for the target
audience. Furthermore, a review of existing extended reality applications that
target the elder population is presented, allowing readers to get acquainted
with existing design paradigms that can inspire future developments.

</details>


### [406] [GamerAstra: Enhancing Video Game Accessibility for Blind and Low-Vision Players through a Multi-Agent AI Framework](https://arxiv.org/abs/2506.22937)
*Tianrun Qiu,Changxin Chen,Sizhe Cheng,Yiming Yang,Yixiao Guo,Zhicong Lu,Yuxin Ma*

Main category: cs.HC

TL;DR: GamerAstra是一个通用无障碍框架，通过多模态技术和多代理设计帮助盲人和低视力玩家更好地参与游戏。


<details>
  <summary>Details</summary>
Motivation: 解决盲人和低视力玩家在游戏中因视觉元素不可访问、界面导航困难和交互输入受限而面临的挑战。

Method: 结合大型语言模型和视觉语言模型，提供多模态交互和可定制辅助功能，支持不同程度的视力障碍。

Result: 技术评估和用户研究表明，GamerAstra显著提升了游戏的可玩性和沉浸感。

Conclusion: GamerAstra为游戏领域的智能无障碍框架发展提供了潜在方向。

Abstract: Blind and low-vision (BLV) players encounter critical challenges in engaging
with video games due to the inaccessibility of visual elements, difficulties in
navigating interfaces, and limitations in sending interaction input. Moreover,
the development of specialized accessibility features typically requires
substantial programming effort and is often implemented on a game-by-game
basis. To address these challenges, we introduce \textit{GamerAstra}, a
generalized accessibility framework that leverages a multi-agent design to
facilitate access to video games for BLV players. It integrates multi-modal
techniques including large language models and vision-language models, enabling
interaction with games lacking native accessibility support. The framework
further incorporates customizable assistance granularities to support varying
degrees of visual impairment and enhances interface navigation through multiple
input modalities. The evaluation through technical assessments and user studies
indicate that \textit{GamerAstra} effectively enhances playability and delivers
a more immersive gaming experience for BLV players. These findings also
underscore potential avenues for advancing intelligent accessibility frameworks
in the gaming domain.

</details>


### [407] [Context, Credibility, and Control: User Reflections on AI Assisted Misinformation Tools](https://arxiv.org/abs/2506.22940)
*Varun Sangwan,Heidi Makitalo*

Main category: cs.HC

TL;DR: 研究探讨协作式AI系统如何提升用户在社交媒体上识别和评估虚假信息的能力，通过交互界面设计提高批判性思维。


<details>
  <summary>Details</summary>
Motivation: 传统方法（如个人判断或基础事实核查）在应对情绪化或缺乏上下文的内容时效果有限，需改进。

Method: 设计并评估了一个交互界面，整合实时解释、来源聚合和辩论式互动等协作AI功能。

Result: 用户研究中，79%参与者认为辩论模式比标准聊天机器人更有效，多源视图平均有用性评分为4.6/5。

Conclusion: 未来虚假信息缓解工具应注重伦理设计、可解释性和互动性，以提升用户媒体素养和信任度。

Abstract: This paper investigates how collaborative AI systems can enhance user agency
in identifying and evaluating misinformation on social media platforms.
Traditional methods, such as personal judgment or basic fact-checking, often
fall short when faced with emotionally charged or context-deficient content. To
address this, we designed and evaluated an interactive interface that
integrates collaborative AI features, including real-time explanations, source
aggregation, and debate-style interaction. These elements aim to support
critical thinking by providing contextual cues and argumentative reasoning in a
transparent, user-centered format. In a user study with 14 participants, 79%
found the debate mode more effective than standard chatbot interfaces, and the
multiple-source view received an average usefulness rating of 4.6 out of 5. Our
findings highlight the potential of context-rich, dialogic AI systems to
improve media literacy and foster trust in digital information environments. We
argue that future tools for misinformation mitigation should prioritize ethical
design, explainability, and interactive engagement to empower users in a
post-truth era.

</details>


### [408] [Positioning AI Tools to Support Online Harm Reduction Practice: Applications and Design Directions](https://arxiv.org/abs/2506.22941)
*Kaixuan Wang,Jason T. Jacques,Chenxin Diao*

Main category: cs.HC

TL;DR: 论文探讨了如何利用大型语言模型（LLMs）为吸毒者（PWUD）提供准确且可操作的信息，以改善其健康结果。通过定性研讨会，研究揭示了LLMs的潜力与挑战，并提出了合作设计路径。


<details>
  <summary>Details</summary>
Motivation: 现有在线渠道在适应性、可访问性和减少污名化方面存在不足，无法满足吸毒者的多样化需求。LLMs为改善信息提供提供了新机会，但其在高风险领域的应用尚未充分探索。

Method: 通过定性研讨会，汇集学术界、减害实践者和在线社区管理者等多元利益相关者，探讨LLMs的能力、潜在用例和核心设计考量。

Result: 研究发现LLMs能解决部分信息障碍（如提供多语言、低污名化互动），但其有效性取决于伦理对齐、情境理解、沟通能力和明确操作边界等挑战的克服。

Conclusion: 论文提出了与专家和吸毒者合作设计的路径，强调开发有帮助、安全且负责任的LLM系统，为减害生态系统的LLM开发提供了实证基础和设计考量。

Abstract: Access to accurate and actionable harm reduction information can directly
impact the health outcomes of People Who Use Drugs (PWUD), yet existing online
channels often fail to meet their diverse and dynamic needs due to limitations
in adaptability, accessibility, and the pervasive impact of stigma. Large
Language Models (LLMs) present a novel opportunity to enhance information
provision, but their application in such a high-stakes domain is under-explored
and presents socio-technical challenges. This paper investigates how LLMs can
be responsibly designed to support the information needs of PWUD. Through a
qualitative workshop involving diverse stakeholder groups (academics, harm
reduction practitioners, and an online community moderator), we explored LLM
capabilities, identified potential use cases, and delineated core design
considerations. Our findings reveal that while LLMs can address some existing
information barriers (e.g., by offering responsive, multilingual, and
potentially less stigmatising interactions), their effectiveness is contingent
upon overcoming challenges related to ethical alignment with harm reduction
principles, nuanced contextual understanding, effective communication, and
clearly defined operational boundaries. We articulate design pathways
emphasising collaborative co-design with experts and PWUD to develop LLM
systems that are helpful, safe, and responsibly governed. This work contributes
empirically grounded insights and actionable design considerations for the
responsible development of LLMs as supportive tools within the harm reduction
ecosystem.

</details>


### [409] [Against 'softmaxing' culture](https://arxiv.org/abs/2506.22968)
*Daniel Mwesigwa*

Main category: cs.HC

TL;DR: 论文探讨了AI如何通过“softmaxing culture”现象同质化语言和文化，提出了从“文化是什么”转向“文化何时出现”的评估方法转变。


<details>
  <summary>Details</summary>
Motivation: AI模型正在通过平均化语言差异导致文化同质化，这成为AI评估中的核心挑战。

Method: 提出两个关键转变：从“文化是什么”转向“文化何时出现”，以及将文化普遍性与具体情境结合。

Result: 传统ML和HCI评估方法存在局限性，需要更复杂的文化响应视角。

Conclusion: 呼吁超越技术需求，采用更复杂的文化评估方法，以应对文化的多样性。

Abstract: AI is flattening culture. Evaluations of "culture" are showing the myriad
ways in which large AI models are homogenizing language and culture, averaging
out rich linguistic differences into generic expressions. I call this
phenomenon "softmaxing culture," and it is one of the fundamental challenges
facing AI evaluations today. Efforts to improve and strengthen evaluations of
culture are central to the project of cultural alignment in large AI systems.
This position paper argues that machine learning (ML) and human-computer
interaction (HCI) approaches to evaluation are limited. I propose two key
shifts. First, instead of asking "what is culture?" at the start of system
evaluations, I propose beginning with the question: "when is culture?" Second,
while I acknowledge the philosophical claim that cultural universals exist, the
challenge is not simply to describe them, but to situate them in relation to
their particulars. Taken together, these conceptual shifts invite evaluation
approaches that move beyond technical requirements, toward perspectives more
responsive to the complexities of culture.

</details>


### [410] [Deep Learning in Mild Cognitive Impairment Diagnosis using Eye Movements and Image Content in Visual Memory Tasks](https://arxiv.org/abs/2506.23016)
*Tomás Silva Santos Rocha,Anastasiia Mikhailova,Moreno I. Coco,José Santos-Victor*

Main category: cs.HC

TL;DR: 本研究利用眼动数据和深度学习模型VTNet，通过视觉记忆任务区分健康对照组和轻度认知障碍患者，模型性能与现有研究相当。


<details>
  <summary>Details</summary>
Motivation: 全球痴呆症患病率预计到2050年将翻倍，亟需可扩展的诊断工具。

Method: 使用44名参与者（24名MCI，20名HC）的眼动数据训练VTNet模型，结合时间序列和空间数据，并测试图像分辨率和任务表现对模型的影响。

Result: 最佳模型（700×700像素热图）达到68%敏感性和76%特异性，性能与类似研究相当。

Conclusion: 研究为MCI自动化诊断工具开发提供了支持，未来需优化模型和标准化任务。

Abstract: The global prevalence of dementia is projected to double by 2050,
highlighting the urgent need for scalable diagnostic tools. This study utilizes
digital cognitive tasks with eye-tracking data correlated with memory processes
to distinguish between Healthy Controls (HC) and Mild Cognitive Impairment
(MCI), a precursor to dementia. A deep learning model based on VTNet was
trained using eye-tracking data from 44 participants (24 MCI, 20 HCs) who
performed a visual memory task. The model utilizes both time series and spatial
data derived from eye-tracking. It was modified to incorporate scan paths, heat
maps, and image content. These modifications also enabled testing parameters
such as image resolution and task performance, analyzing their impact on model
performance. The best model, utilizing $700\times700px$ resolution heatmaps,
achieved 68% sensitivity and 76% specificity. Despite operating under more
challenging conditions (e.g., smaller dataset size, shorter task duration, or a
less standardized task), the model's performance is comparable to an
Alzheimer's study using similar methods (70% sensitivity and 73% specificity).
These findings contribute to the development of automated diagnostic tools for
MCI. Future work should focus on refining the model and using a standardized
long-term visual memory task.

</details>


### [411] [Mind the Dark: A Gamified Exploration of Deceptive Design Awareness for Children in the Digital Age](https://arxiv.org/abs/2506.23017)
*Noverah Khan,Hira Eiraj Daud,Suleman Shahid*

Main category: cs.HC

TL;DR: 论文研究了儿童对技术中欺骗性设计元素的认知，开发了一款游戏化应用以提高儿童的识别能力，结果显示早期教育显著提升了儿童的意识和应对能力。


<details>
  <summary>Details</summary>
Motivation: 儿童在数字设备使用中独立性增强，但对欺骗性设计的认知不足，亟需早期教育以减少其脆弱性。

Method: 开发了一款游戏化应用，用于教育儿童识别和应对各种欺骗性设计元素。

Result: 教育显著提高了儿童对欺骗性设计的意识，并改变了他们在社交媒体、视频游戏和流媒体平台上的行为。

Conclusion: 早期教育对培养儿童识别和应对欺骗性设计的能力至关重要，有助于塑造具备数字素养的新一代。

Abstract: This paper addresses the critical issue of deceptive design elements
prevalent in technology, and their potential impact on children. Recent
research highlights the impact of dark patterns on adults and adolescents,
while studies involving children are scarce. In an era where children wield
greater independence with digital devices, their vulnerability to dark patterns
amplifies without early education. Our findings show a significant positive
impact of dark pattern education on children's awareness, revealing that
heightened awareness considerably alters children's navigation of social media,
video games, and streaming platforms. To this end, we developed a gamified
application aimed at instructing children on identifying and responding to
various dark patterns. Our evaluation results emphasize the critical role of
early education in empowering children to recognize and counter deceptive
design, thereby cultivating a digitally literate generation capable of making
informed choices in the complex landscape of digital technology.

</details>


### [412] [CSBrain: A Cross-scale Spatiotemporal Brain Foundation Model for EEG Decoding](https://arxiv.org/abs/2506.23075)
*Yuchen Zhou,Jiamin Wu,Zichen Ren,Zhouheng Yao,Weiheng Lu,Kunyu Peng,Qihao Zheng,Chunfeng Song,Wanli Ouyang,Chao Gou*

Main category: cs.HC

TL;DR: CSBrain提出了一种跨尺度时空脑基础模型，通过多尺度特征聚合和结构化稀疏注意力，显著提升了EEG信号的解码性能。


<details>
  <summary>Details</summary>
Motivation: EEG信号具有跨尺度的时空结构特性，现有模型忽视这一特性导致表示和泛化能力不足。

Method: 引入跨尺度时空标记化（CST）和结构化稀疏注意力（SSA），交替堆叠以整合多尺度依赖关系。

Result: 在11个EEG任务和16个数据集上，CSBrain均优于任务专用模型和现有基础模型。

Conclusion: 跨尺度建模是关键归纳偏置，CSBrain为未来脑-AI研究提供了稳健的骨干模型。

Abstract: Understanding and decoding brain activity from electroencephalography (EEG)
signals is a fundamental challenge in neuroscience and AI, with applications in
cognition, emotion recognition, diagnosis, and brain-computer interfaces. While
recent EEG foundation models advance generalized decoding via unified
architectures and large-scale pretraining, they adopt a scale-agnostic dense
modeling paradigm inherited from NLP and vision. This design neglects a core
property of neural activity: cross-scale spatiotemporal structure. EEG task
patterns span a wide range of temporal and spatial scales, from short bursts to
slow rhythms, and from localized cortical responses to distributed
interactions. Ignoring this diversity leads to suboptimal representations and
weak generalization. We propose CSBrain, a Cross-scale Spatiotemporal Brain
foundation model for generalized EEG decoding. CSBrain introduces: (i)
Cross-scale Spatiotemporal Tokenization (CST), which aggregates multi-scale
features from localized temporal windows and anatomical brain regions into
compact scale-aware tokens; and (ii) Structured Sparse Attention (SSA), which
captures cross-window and cross-region dependencies, enhancing scale diversity
while removing spurious correlations. CST and SSA are alternately stacked to
progressively integrate multi-scale dependencies. Experiments on 11 EEG tasks
across 16 datasets show that CSBrain consistently outperforms task-specific and
foundation model baselines. These results establish cross-scale modeling as a
key inductive bias and position CSBrain as a robust backbone for future
brain-AI research.

</details>


### [413] [A User Experience 3.0 (UX 3.0) Paradigm Framework: Designing for Human-Centered AI Experiences](https://arxiv.org/abs/2506.23116)
*Wei Xu*

Main category: cs.HC

TL;DR: 论文提出UX 3.0范式框架，以应对AI时代用户体验实践的新需求。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术的推动和用户需求的变化，用户体验实践进入转型阶段（UX 3.0），需要新的方法来支持人机交互AI（HCAI）系统的开发。

Method: 提出一个UX 3.0范式框架，用于指导和响应HCAI系统的用户体验实践。

Result: 框架旨在为AI时代的用户体验实践提供新的方法和指导。

Conclusion: UX 3.0框架为HCAI系统的用户体验实践提供了适应性和前瞻性的解决方案。

Abstract: User experience (UX) practices have evolved in stages and are entering a
transformative phase (UX 3.0), driven by AI technologies and shifting user
needs. Human-centered AI (HCAI) experiences are emerging, necessitating new UX
approaches to support UX practices in the AI era. We propose a UX 3.0 paradigm
framework to respond and guide UX practices in developing HCAI systems.

</details>


### [414] [ImprovMate: Multimodal AI Assistant for Improv Actor Training](https://arxiv.org/abs/2506.23180)
*Riccardo Drago,Yotam Sechayk,Mustafa Doga Dogan,Andrea Sanna,Takeo Igarashi*

Main category: cs.HC

TL;DR: ImprovMate利用大型语言模型（LLM）为即兴表演演员提供自动生成的叙事提示和线索，减轻认知负担，提升创造力。


<details>
  <summary>Details</summary>
Motivation: 传统即兴表演训练中，演员需同时处理叙事连贯性和认知负荷，而现有AI技术多依赖人工干预，未能充分利用LLM的潜力。

Method: 基于专业即兴演员的反馈，ImprovMate设计了模拟现场训练的练习，如突发故事解决和反应性思维练习，并通过参考表保持连贯性。

Result: 试点研究表明，演员接受AI技术，尤其是当AI与传统实践相似并带来新意时。

Conclusion: ImprovMate通过结合随机性和结构化指导，为即兴表演训练提供了创新工具。

Abstract: Improvisation training for actors presents unique challenges, particularly in
maintaining narrative coherence and managing cognitive load during
performances. Previous research on AI in improvisation performance often
predates advances in large language models (LLMs) and relies on human
intervention. We introduce ImprovMate, which leverages LLMs as GPTs to automate
the generation of narrative stimuli and cues, allowing actors to focus on
creativity without keeping track of plot or character continuity. Based on
insights from professional improvisers, ImprovMate incorporates exercises that
mimic live training, such as abrupt story resolution and reactive thinking
exercises, while maintaining coherence via reference tables. By balancing
randomness and structured guidance, ImprovMate provides a groundbreaking tool
for improv training. Our pilot study revealed that actors might embrace AI
techniques if the latter mirrors traditional practices, and appreciate the
fresh twist introduced by our approach with the AI-generated cues.

</details>


### [415] [Vibe coding: programming through conversation with artificial intelligence](https://arxiv.org/abs/2506.23253)
*Advait Sarkar,Ian Drosos*

Main category: cs.HC

TL;DR: 论文探讨了“氛围编程”这一新兴编程范式，开发者主要通过与大语言模型交互生成代码而非直接编写代码。研究发现，氛围编程遵循迭代目标满足循环，结合模糊提示与详细技术规范，调试过程混合AI辅助与手动操作，编程专业知识转向上下文管理和快速评估。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索开发者如何通过与大语言模型交互生成代码，以及这种新兴编程范式的工作流程、挑战和影响。

Method: 方法包括分析一系列视频记录的氛围编程会话，使用框架分析法研究开发者的目标、工作流程、提示技术、调试方法和挑战。

Result: 研究发现氛围编程是迭代循环过程，结合高模糊提示与详细技术规范，调试依赖混合方法，编程专业知识转向上下文管理。

Conclusion: 结论指出氛围编程并未消除编程专业知识需求，而是重新分配为上下文管理和快速评估，代表AI辅助编程的演进，体现了“材料脱离”的早期表现。

Abstract: We examine "vibe coding": an emergent programming paradigm where developers
primarily write code by interacting with code-generating large language models
rather than writing code directly. We analysed a curated set of videos
depicting extended vibe coding sessions with rich think-aloud reflections.
Using framework analysis, we investigated programmers' goals, workflows,
prompting techniques, debugging approaches, and challenges encountered. We find
that vibe coding follows iterative goal satisfaction cycles where developers
alternate between prompting AI, evaluating generated code through rapid
scanning and application testing, and manual editing. Prompting strategies
blend vague, high-level directives with detailed technical specifications.
Debugging remains a hybrid process combining AI assistance with manual
practices. Critically, vibe coding does not eliminate the need for programming
expertise but rather redistributes it toward context management, rapid code
evaluation, and decisions about when to transition between AI-driven and manual
manipulation of code. Trust in AI tools during vibe coding is dynamic and
contextual, developed through iterative verification rather than blanket
acceptance. Vibe coding is an evolution of AI-assisted programming that
represents an early manifestation of "material disengagement", where
practitioners orchestrate code production and manipulation, mediated through
AI, while maintaining selective and strategic oversight.

</details>


### [416] [Accessible Data Access and Analysis by People who are Blind or Have Low Vision](https://arxiv.org/abs/2506.23443)
*Samuel Reinders,Munazza Zaib,Matthew Butler,Bongshin Lee,Ingrid Zukerman,Lizhen Qu,Kim Marriott*

Main category: cs.HC

TL;DR: 开发新型辅助技术，帮助盲人或低视力人群探索和分析数据，结合触觉显示和对话代理。


<details>
  <summary>Details</summary>
Motivation: 解决盲人或低视力人群在数据访问和分析中的障碍，提升就业机会。

Method: 通过触觉图形和语音结合的方式设计系统，支持数据分析和交互。

Result: 预期在辅助技术、多模态界面和自然语言处理方面取得创新。

Conclusion: 该系统有望填补公平性差距，并在多个技术领域实现突破。

Abstract: Our work aims to develop new assistive technologies that enable blind or low
vision (BLV) people to explore and analyze data readily. At present, barriers
exist for BLV people to explore and analyze data, restricting access to
government, health and personal data, and limiting employment opportunities.
This work explores the co-design and development of an innovative system to
support data access, with a focus on the use of refreshable tactile displays
(RTDs) and conversational agents. The envisaged system will use a combination
of tactile graphics and speech to communicate with BLV users, and proactively
assist with data analysis tasks. As well as addressing significant equity gaps,
our work expects to produce innovations in assistive technology, multimodal
interfaces, dialogue systems, and natural language understanding and
generation.

</details>


### [417] [Reducing Motion Sickness in Passengers of Autonomous Personal Mobility Vehicles by Presenting a Driving Path](https://arxiv.org/abs/2506.23457)
*Yuya Ide,Hailong Liu,Takahiro Wada*

Main category: cs.HC

TL;DR: 研究探讨了在自动驾驶个人移动车辆（APMV）中提供路径信息对乘客头部运动和晕动症的影响，发现路径提示显著降低了晕动症评分并延迟了症状出现。


<details>
  <summary>Details</summary>
Motivation: 在共享空间中，APMV频繁的避障动作可能导致乘客被动姿态调整和晕动症风险增加，因此研究路径信息的作用。

Method: 通过对比手动驾驶（MD）、无路径信息的自动驾驶（AD w/o path）和有路径信息的自动驾驶（AD w/ path）进行实验。

Result: 提供路径信息显著降低了晕动症评分，乘客头部运动更主动与车辆转向对齐。

Conclusion: 路径信息有助于减少晕动症，但头部运动延迟与晕动症的生理机制仍需进一步研究。

Abstract: Autonomous personal mobility vehicles (APMVs) are small mobility devices
designed for individual automated transportation in shared spaces. In such
environments, frequent pedestrian avoidance maneuvers may cause rapid steering
adjustments and passive postural responses from passengers, thereby increasing
the risk of motion sickness. This study investigated the effects of providing
path information on 16 passengers' head movement behavior and motion sickness
while riding an APMV. Through a controlled experiment comparing manual driving
(MD), autonomous driving without path information (AD w/o path), and autonomous
driving with path information (AD w/ path), we found that providing path cues
significantly reduced MISC scores and delayed the onset of motion sickness
symptoms. In addition, participants were more likely to proactively align their
head movements with the direction of vehicle rotation in both MD and AD w/ path
conditions. Although a small correlation was observed between the delay in yaw
rotation of the passenger's head relative to the vehicle and the occurrence of
motion sickness, the underlying physiological mechanism remains to be
elucidated.

</details>


### [418] [Neuro-Informed Joint Learning Enhances Cognitive Workload Decoding in Portable BCIs](https://arxiv.org/abs/2506.23458)
*Xiaoxiao Yang,Chan Feng,Jiancheng Chen*

Main category: cs.HC

TL;DR: 论文提出MuseCogNet，一种结合自监督和监督学习的联合框架，用于提升便携式EEG设备在认知负荷检测中的性能。


<details>
  <summary>Details</summary>
Motivation: 便携式EEG设备（如Muse头带）在移动性上具有优势，但信号的非平稳性限制了数据质量和解码精度，需要在便携性和性能之间权衡。

Method: 提出MuseCogNet框架，结合自监督重建损失（基于平均池化）和监督交叉熵损失，模拟人类自下而上和自上而下的注意力机制。

Result: 在公开的Muse数据集上显著优于现有方法，为生态环境中的神经认知监测提供了可行路径。

Conclusion: MuseCogNet通过联合学习框架有效解决了便携式EEG设备的性能限制，为实际应用提供了新思路。

Abstract: Portable and wearable consumer-grade electroencephalography (EEG) devices,
like Muse headbands, offer unprecedented mobility for daily brain-computer
interface (BCI) applications, including cognitive load detection. However, the
exacerbated non-stationarity in portable EEG signals constrains data fidelity
and decoding accuracy, creating a fundamental trade-off between portability and
performance. To mitigate such limitation, we propose MuseCogNet (Muse-based
Cognitive Network), a unified joint learning framework integrating
self-supervised and supervised training paradigms. In particular, we introduce
an EEG-grounded self-supervised reconstruction loss based on average pooling to
capture robust neurophysiological patterns, while cross-entropy loss refines
task-specific cognitive discriminants. This joint learning framework resembles
the bottom-up and top-down attention in humans, enabling MuseCogNet to
significantly outperform state-of-the-art methods on a publicly available Muse
dataset and establish an implementable pathway for neurocognitive monitoring in
ecological settings.

</details>


### [419] [Immersive Technologies in Training and Healthcare: From Space Missions to Psychophysiological Research](https://arxiv.org/abs/2506.23545)
*Barbara Karpowicz,Maciej Grzeszczuk,Adam Kuzdraliński,Monika Kornacka,Aliaksandr Marozau,Wiktor Stawski,Pavlo Zinevych,Grzegorz Marcin Wójcik,Tomasz Kowalewski,Grzegorz Pochwatko,Wiesław Kopeć*

Main category: cs.HC

TL;DR: XR技术（VR/AR/XR）在培训、诊断和心理研究中具有广泛应用，尤其在临床心理学、太空探索和医学教育等领域显著提升人类表现。


<details>
  <summary>Details</summary>
Motivation: 探讨XR技术如何在高风险和严格监管环境中通过沉浸式系统提升人类表现。

Method: 利用XR技术创建受控但生态有效的环境，用于认知和情感过程的测量，以及开发VR宇航员培训和诊断系统。

Result: XR技术在心理研究、太空探索和医学教育中均取得积极效果，如提升学习效果和治疗依从性。

Conclusion: XR技术在多领域具有巨大潜力，能够显著提升人类表现和培训效果。

Abstract: Virtual, Augmented, and eXtended Reality (VR/AR/XR) technologies are
increasingly recognized for their applications in training, diagnostics, and
psychological research, particularly in high-risk and highly regulated
environments. In this panel we discuss how immersive systems enhance human
performance across multiple domains, including clinical psychology, space
exploration, and medical education. In psychological research and training, XR
can offer a controlled yet ecologically valid setting for measuring cognitive
and affective processes. In space exploration, we discuss the development of
VR-based astronaut training and diagnostic systems, allowing astronauts to
perform real-time health assessments. In medical education and rehabilitation,
we cover procedural training and patient engagement. From virtual surgical
simulations to gamified rehabilitation exercises, immersive environments
enhance both learning outcomes and treatment adherence.

</details>


### [420] [Interactive Reasoning: Visualizing and Controlling Chain-of-Thought Reasoning in Large Language Models](https://arxiv.org/abs/2506.23678)
*Rock Yuren Pang,K. J. Kevin Feng,Shangbin Feng,Chu Li,Weijia Shi,Yulia Tsvetkov,Jeffrey Heer,Katharina Reinecke*

Main category: cs.HC

TL;DR: 论文提出了一种交互式推理设计，通过可视化思维链（CoT）输出为层次化主题，并支持用户审查和修改，以提高大型语言模型（LLM）的输出质量。


<details>
  <summary>Details</summary>
Motivation: 现有的思维链内容冗长且缺乏组织，难以审查，且缺乏用户反馈机会。

Method: 引入交互式推理设计，并在Hippo原型中实现，用于AI辅助决策。

Result: 用户研究表明，交互式推理能帮助用户快速识别错误、高效定制模型响应，并更好地理解模型推理和输出。

Conclusion: 该工作为将用户监督纳入LLM推理过程的新范式做出了贡献。

Abstract: The output quality of large language models (LLMs) can be improved via
"reasoning": generating segments of chain-of-thought (CoT) content to further
condition the model prior to producing user-facing output. While these chains
contain valuable information, they are verbose and lack explicit organization,
making them tedious to review. Moreover, they lack opportunities for user
feedback, such as to remove unwanted considerations, add desired ones, or
clarify unclear assumptions. We introduce Interactive Reasoning, an interaction
design that visualizes chain-of-thought outputs as a hierarchy of topics and
enables user review and modification. We implement interactive reasoning in
Hippo, a prototype for AI-assisted decision making in the face of uncertain
trade-offs. In a user study with 16 participants, we find that interactive
reasoning in Hippo allows users to quickly identify and interrupt erroneous
generations, efficiently steer the model towards customized responses, and
better understand both model reasoning and model outputs. Our work contributes
to a new paradigm that incorporates user oversight into LLM reasoning
processes.

</details>


### [421] [If You Had to Pitch Your Ideal Software -- Evaluating Large Language Models to Support User Scenario Writing for User Experience Experts and Laypersons](https://arxiv.org/abs/2506.23694)
*Patrick Stadler,Christopher Lazik,Christopher Katins,Thomas Kosch*

Main category: cs.HC

TL;DR: 研究探讨了UX新手在使用LLM辅助工具时是否能写出与专家相当的用户场景描述，结果显示LLM能显著提升新手表现，尤其在受众导向方面。


<details>
  <summary>Details</summary>
Motivation: 理解用户需求是需求分析的关键，但新手是否能像专家一样写出有效的用户场景尚不明确。

Method: 通过60名参与者（30名专家和30名新手）的实验，比较他们在有无LLM辅助下撰写的用户场景。

Result: LLM辅助下，新手写的用户场景在结构和清晰度上与专家相当，且在受众导向上表现更优。

Conclusion: LLM工具能有效提升新手在需求分析中的表现，为未来工具设计提供启示。

Abstract: The process of requirements analysis requires an understanding of the end
users of a system. Thus, expert stakeholders, such as User Experience (UX)
designers, usually create various descriptions containing information about the
users and their possible needs. In our paper, we investigate to what extent UX
novices are able to write such descriptions into user scenarios. We conducted a
user study with 60 participants consisting of 30 UX experts and 30 novices who
were asked to write a user scenario with or without the help of an
LLM-supported writing assistant. Our findings show that LLMs empower laypersons
to write reasonable user scenarios and provide first-hand insights for
requirements analysis that are comparable to UX experts in terms of structure
and clarity, while especially excelling at audience-orientation. We present our
qualitative and quantitative findings, including user scenario anatomies,
potential influences, and differences in the way participants approached the
task.

</details>


### [422] [The Impact of AI on Educational Assessment: A Framework for Constructive Alignment](https://arxiv.org/abs/2506.23815)
*Patrick Stokkink*

Main category: cs.HC

TL;DR: 论文探讨了AI（尤其是大语言模型）对教育的影响，提出了基于Constructive Alignment理论和Bloom分类学的理论框架，建议调整评估方式以适应AI的使用。


<details>
  <summary>Details</summary>
Motivation: 随着AI在教育中的普及，传统评估方式是否仍能有效衡量学生表现成为问题。

Method: 基于Constructive Alignment理论和Bloom分类学，分析AI对不同学习目标的影响，并提出评估调整建议。

Result: 发现教师对AI使用的态度存在偏见，建议制定结构化指南并提供AI工具培训。

Conclusion: 需通过统一指南和教师培训，确保评估方式与AI使用一致。

Abstract: The influence of Artificial Intelligence (AI), and specifically Large
Language Models (LLM), on education is continuously increasing. These models
are frequently used by students, giving rise to the question whether current
forms of assessment are still a valid way to evaluate student performance and
comprehension. The theoretical framework developed in this paper is grounded in
Constructive Alignment (CA) theory and Bloom's taxonomy for defining learning
objectives. We argue that AI influences learning objectives of different Bloom
levels in a different way, and assessment has to be adopted accordingly.
Furthermore, in line with Bloom's vision, formative and summative assessment
should be aligned on whether the use of AI is permitted or not.
  Although lecturers tend to agree that education and assessment need to be
adapted to the presence of AI, a strong bias exists on the extent to which
lecturers want to allow for AI in assessment. This bias is caused by a
lecturer's familiarity with AI and specifically whether they use it themselves.
To avoid this bias, we propose structured guidelines on a university or faculty
level, to foster alignment among the staff. Besides that, we argue that
teaching staff should be trained on the capabilities and limitations of AI
tools. In this way, they are better able to adapt their assessment methods.

</details>


### [423] [Email as the Interface to Generative AI Models: Seamless Administrative Automation](https://arxiv.org/abs/2506.23850)
*Andres Navarro,Carlos de Quinto,José Alberto Hernández*

Main category: cs.HC

TL;DR: 论文提出了一种将大型语言模型（LLM）与电子邮件接口集成的框架，用于自动化企业环境中的行政任务，特别是解决无障碍问题。


<details>
  <summary>Details</summary>
Motivation: 通过将电子邮件与OCR和智能自动化结合，为非技术人员提供便捷的复杂表单填写和文档处理工具，弥合高级AI能力与实际可用性之间的差距。

Method: 系统将电子邮件正文视为自然语言提示，附件作为上下文信息，通过LLM自动化处理任务。

Result: 实证评估显示，系统能在8秒内完成复杂表单，人工监督下员工时间减少3-4倍，成本降低64%。

Conclusion: 基于电子邮件的LLM集成是一种可行且经济高效的方法，可推动高级自动化在组织中的普及，无需专业知识或重大流程变更。

Abstract: This paper introduces a novel architectural framework that integrates Large
Language Models (LLMs) with email interfaces to automate administrative tasks,
specifically targeting accessibility barriers in enterprise environments. The
system connects email communication channels with Optical Character Recognition
(OCR) and intelligent automation, enabling non-technical administrative staff
to delegate complex form-filling and document processing tasks using familiar
email interfaces. By treating the email body as a natural language prompt and
attachments as contextual information, the workflow bridges the gap between
advanced AI capabilities and practical usability. Empirical evaluation shows
that the system can complete complex administrative forms in under 8 seconds of
automated processing, with human supervision reducing total staff time by a
factor of three to four compared to manual workflows. The top-performing LLM
accurately filled 16 out of 29 form fields and reduced the total cost per
processed form by 64% relative to manual completion. These findings demonstrate
that email-based LLM integration is a viable and cost-effective approach for
democratizing advanced automation in organizational settings, supporting
widespread adoption without requiring specialized technical knowledge or major
workflow changes. This aligns with broader trends in leveraging LLMs to enhance
accessibility and automate complex tasks for non-technical users, making
technology more inclusive and efficient.

</details>


### [424] [Autonomy by Design: Preserving Human Autonomy in AI Decision-Support](https://arxiv.org/abs/2506.23952)
*Stefan Buijsman,Sarah Carter,Juan Pablo Bermúdez*

Main category: cs.HC

TL;DR: 本文探讨了AI决策支持系统如何影响领域特定自主性，提出了一个保护自主性的框架。


<details>
  <summary>Details</summary>
Motivation: 研究AI对领域特定自主性的影响，填补现有研究的空白。

Method: 通过分析医学、金融和教育领域的实证案例，结合先前研究，探讨AI对自主性的影响。

Result: 发现缺乏可靠的失败指标和潜在的无意识价值转变会削弱自主性。

Conclusion: 提出了一个框架，包括角色规范、失败机制和反思实践，以保护领域特定自主性。

Abstract: AI systems increasingly support human decision-making across domains of
professional, skill-based, and personal activity. While previous work has
examined how AI might affect human autonomy globally, the effects of AI on
domain-specific autonomy -- the capacity for self-governed action within
defined realms of skill or expertise -- remain understudied. We analyze how AI
decision-support systems affect two key components of domain-specific autonomy:
skilled competence (the ability to make informed judgments within one's domain)
and authentic value-formation (the capacity to form genuine domain-relevant
values and preferences). By engaging with prior investigations and analyzing
empirical cases across medical, financial, and educational domains, we
demonstrate how the absence of reliable failure indicators and the potential
for unconscious value shifts can erode domain-specific autonomy both
immediately and over time. We then develop a constructive framework for
autonomy-preserving AI support systems. We propose specific socio-technical
design patterns -- including careful role specification, implementation of
defeater mechanisms, and support for reflective practice -- that can help
maintain domain-specific autonomy while leveraging AI capabilities. This
framework provides concrete guidance for developing AI systems that enhance
rather than diminish human agency within specialized domains of action.

</details>


### [425] [Access InContext: Futuring Accessible Prototyping Tools and Methods](https://arxiv.org/abs/2506.24057)
*Patricia Piedade,Peter A Hayton,Cynthia Bennett,Anna R L Carter,Clara Crivellaro,Alan Dix,Jess McGowan,Katta Spiel,Miriam Sturdee,Garreth W. Tigwell,Hugo Nicolau*

Main category: cs.HC

TL;DR: 探讨无障碍研究中原型设计工具和方法的局限性，提出改进方向，并在CHI 2025工作坊中推动相关讨论与实践。


<details>
  <summary>Details</summary>
Motivation: 现有原型设计工具和方法存在无障碍障碍，限制了残障人士和研究人员的参与，亟需改进以促进数字包容性。

Method: 通过工作坊形式，汇集HCI研究人员、设计师和实践者，讨论无障碍原型的障碍与机遇，并进行实践性创意和制作练习。

Result: 工作坊旨在推动无障碍原型设计的创新工具和方法，提升设计过程的包容性。

Conclusion: 改进原型设计工具和方法对实现技术包容性至关重要，工作坊为相关讨论和实践提供了平台。

Abstract: The popularity of accessibility research has grown recently, improving
digital inclusion for people with disabilities. However, researchers, including
those who have disabilities, have attempted to include people with disabilities
in all aspects of design, and they have identified a myriad of practical
accessibility barriers posed by tools and methods leveraged by human-computer
interaction (HCI) researchers during prototyping. To build a more inclusive
technological landscape, we must question the effectiveness of existing
prototyping tools and methods, repurpose/retrofit existing resources, and build
new tools and methods to support the participation of both researchers and
people with disabilities within the prototyping design process of novel
technologies. This full-day workshop at CHI 2025 will provide a platform for
HCI researchers, designers, and practitioners to discuss barriers and
opportunities for creating accessible prototyping and promote hands-on ideation
and fabrication exercises aimed at futuring accessible prototyping.

</details>


### [426] [Bridging Service Design, Visualizations, and Visual Analytics in Healthcare Digital Twins: Challenges, Gaps, and Research Opportunities](https://arxiv.org/abs/2506.24104)
*Mariia Ershova,Graziano Blasilli*

Main category: cs.HC

TL;DR: 本文探讨了将服务设计与可视化分析结合以提升医疗数字孪生（DT）的实际应用价值。


<details>
  <summary>Details</summary>
Motivation: 医疗数字孪生系统缺乏结构化服务设计方法，限制了其实际应用潜力。

Method: 通过整合服务设计与可视化分析，提出研究方向和框架。

Result: 为医疗数字孪生社区提供了增强解决方案实用性的思路。

Conclusion: 服务设计与可视化分析的结合有望提升医疗数字孪生的实际效果。

Abstract: Digital twins (DT) are increasingly used in healthcare to model patients,
processes, and physiological systems. While recent solutions leverage
visualization, visual analytics, and user interaction, these systems rarely
incorporate structured service design methodologies. Bridging service design
with visual analytics and visualization can be valuable for the healthcare DT
community. This paper aims to introduce the service design discipline to
visualization researchers by framing this integration gap and suggesting
research directions to enhance the real-world applicability of DT solutions.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [427] [Momentum-based Accelerated Algorithm for Distributed Optimization under Sector-Bound Nonlinearity](https://arxiv.org/abs/2506.22855)
*Mohammadreza Doostmohammadian,Hamid R. Rabiee*

Main category: eess.SY

TL;DR: 该论文提出了一种基于梯度追踪的加速分布式优化算法，适用于局部非凸优化问题，通过引入动量项和权重平衡网络设计，提高了收敛速度并解决了信息共享网络中的非线性问题。


<details>
  <summary>Details</summary>
Motivation: 分布式优化通过并行和去中心化学习过程改进了集中式机器学习方法，但现有算法在局部非凸优化和动态网络环境下表现不佳。本文旨在解决这些问题。

Method: 提出了一种基于梯度追踪的加速共识算法，结合了动量项（heavy-ball方法）和权重平衡网络设计，以处理局部非凸性和网络非线性问题。

Result: 通过扰动理论和特征谱分析，证明了算法在存在非线性映射和局部非凸性时的收敛性，并适用于动态有向网络。

Conclusion: 该算法在收敛速度和适应性方面优于现有方法，特别适用于动态网络环境和非线性信息共享场景。

Abstract: Distributed optimization advances centralized machine learning methods by
enabling parallel and decentralized learning processes over a network of
computing nodes. This work provides an accelerated consensus-based distributed
algorithm for locally non-convex optimization using the gradient-tracking
technique. The proposed algorithm (i) improves the convergence rate by adding
momentum towards the optimal state using the heavy-ball method, while (ii)
addressing general sector-bound nonlinearities over the information-sharing
network. The link nonlinearity includes any sign-preserving odd sector-bound
mapping, for example, log-scale data quantization or clipping in practical
applications. For admissible momentum and gradient-tracking parameters, using
perturbation theory and eigen-spectrum analysis, we prove convergence even in
the presence of sector-bound nonlinearity and for locally non-convex cost
functions. Further, in contrast to most existing weight-stochastic algorithms,
we adopt weight-balanced (WB) network design. This WB design and
perturbation-based analysis allow to handle dynamic directed network of agents
to address possible time-varying setups due to link failures or packet drops.

</details>


### [428] [A Multi-Criteria Evaluation Framework for Siting Fusion Energy Facilities: Application and Evaluation of U.S. Coal Power Plants](https://arxiv.org/abs/2506.22489)
*Muhammad R. Abdussami,Kevin Daley,Gabrielle Hoelzle,Aditi Verma*

Main category: eess.SY

TL;DR: 本文提出了一种综合选址方法，用于评估核聚变能源设施的选址，结合专家判断、地理空间数据和多标准决策工具，并以美国现有燃煤电厂为例进行分析。


<details>
  <summary>Details</summary>
Motivation: 随着燃煤电厂寿命结束，其场地可能成为核聚变能源设施的潜在选址，因此需要一种系统化的方法来评估这些场地的适用性。

Method: 采用22项选址标准，结合模糊完全一致性方法（F-FUCOM）确定权重，并使用加权求和法（WSM）对场地进行排序。

Result: 通过案例研究，为核聚变能源设施的选址提供了一种可扩展且透明的决策支持工具。

Conclusion: 该方法为核聚变能源设施的选址提供了科学依据，并具有广泛的应用潜力。

Abstract: This paper proposes a comprehensive methodology for siting fusion energy
facilities, integrating expert judgment, geospatial data, and multi-criteria
decision making tools to evaluate site suitability systematically. As a case
study, we apply this framework to all currently operational coal power plant
sites in the United States to examine their potential for hosting future fusion
facilities at a time when these coal plants are shut down on reaching their end
of life - timelines which are expected to coincide with the potential
deployment of fusion energy facilities. Drawing on 22 siting criteria -
including state and federal policies, risk and hazard assessments, and spatial
and infrastructural parameters - we implement two MultiCriteria Decision-Making
(MCDM) methods: the Fuzzy Full Consistency Method (F-FUCOM) to derive attribute
weights and the Weighted Sum Method (WSM) to rank sites based on composite
suitability scores. By focusing on fusion-specific siting needs and
demonstrating the framework through a coal site application, this study
contributes a scalable and transparent decision-support tool for identifying
optimal fusion energy deployment locations.

</details>


### [429] [Hierarchical Decentralized Stochastic Control for Cyber-Physical Systems](https://arxiv.org/abs/2506.22971)
*Kesav Kazam Ramachandran Anantharaman,Rahul Meshram*

Main category: eess.SY

TL;DR: 本文提出了一种两时间尺度的分层分散控制架构，用于网络物理系统的控制，包含全局控制器和局部控制器，分别采用无限和有限时间范围的MDP优化框架。


<details>
  <summary>Details</summary>
Motivation: 研究网络物理系统的分散控制问题，通过分层架构实现全局和局部优化的协同。

Method: 提出COpt和FOpt两种优化框架，分别基于无限和有限时间范围的MDP，分析其最优策略存在性及关系。

Result: 证明了两种框架下最优策略的存在性，并给出了两者最优值函数差异的界限。

Conclusion: 在特定条件下，两种优化框架可以达到相同的最优值，为系统设计提供了灵活性。

Abstract: This paper presents a two-timescale hierarchical decentralized architecture
for control of Cyber-Physical Systems. The architecture consists of $N$
independent sub-processes, a global controller, and $N$ local controllers, each
formulated as a Markov Decision Process (MDP). The global controller, operating
at a slower timescale optimizes the infinite-horizon discounted cumulative
reward under budget constraints. For the local controllers, operating at a
faster timescale, we propose two different optimization frameworks, namely the
COpt and FOpt. In the COpt framework, the local controller also optimizes an
infinite-horizon MDP, while in the FOpt framework, the local controller
optimizes a finite-horizon MDP. The FOpt framework mimics a federal structure,
where the local controllers have more autonomy in their decision making. First,
the existence of stationary deterministic optimal policies for both these
frameworks is established. Then, various relationships between the two
frameworks are studied, including a bound on the difference between the two
optimal value functions. Additionally, sufficiency conditions are provided such
that the two frameworks lead to the same optimal values.

</details>


### [430] [Data-Efficient Excavation Force Estimation for Wheel Loaders](https://arxiv.org/abs/2506.22579)
*Armin Abdolmohammadi,Navid Mojahed,Shima Nazari,Bahram Ravani*

Main category: eess.SY

TL;DR: 提出了一种数据高效的方法，通过校准土壤参数来预测挖掘力，减少对大量数据或机器学习的依赖。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要大量数据或模拟，限制了可扩展性和适应性。

Method: 利用前一次铲斗装载周期的力数据校准土壤参数，采用多阶段优化策略。

Result: 在高保真模拟中验证，预测误差为10%至15%。

Conclusion: 该方法展示了在线和可扩展的高效路径规划潜力。

Abstract: Accurate excavation force prediction is essential for enabling autonomous
operation and optimizing control strategies in earthmoving machinery.
Conventional methods typically require extensive data collection or simulations
across diverse soil types, limiting scalability and adaptability. This paper
proposes a data-efficient framework that calibrates soil parameters using force
data from the prior bucket-loading cycle. Leveraging an analytical soil-tool
interaction model, the fundamental earthmoving equation (FEE), our approach
uses a multi-stage optimization strategy, on soil parameters during the loading
phase. These fitted parameters are then used to predict excavation forces in
the upcoming digging cycle, allowing the system to adapt its control inputs
without the need for extensive data collection or machine learning-based model
training. The framework is validated in high-fidelity simulations using the
Algoryx Dynamics engine, across multiple soil types and excavation
trajectories, demonstrating accurate force predictions with root-mean-square
errors of 10\% to 15\% in primary test cases. This cycle-to-cycle adaptation
strategy showcases the potential for online and scalable efficient path
planning for wheel loader operations.

</details>


### [431] [QoS-aware State-Augmented Learnable Algorithm for Wireless Coexistence Parameter Management](https://arxiv.org/abs/2506.22652)
*Mohammad Reza Fasihi,Brian L. Mark*

Main category: eess.SY

TL;DR: 提出了一种基于状态增强约束强化学习的无线共存参数管理框架QaSAL-CPM，通过实时响应约束违规优化性能目标，在5G NR-U与Wi-Fi共存场景中表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决5G NR-U与Wi-Fi在非授权频谱中的高效公平共存问题。

Method: 采用状态增强约束强化学习，将双变量嵌入观察空间，实时优化性能目标。

Result: 在模拟中，QaSAL-CPM实现了可靠的QoS合规性和更强的策略鲁棒性。

Conclusion: 该框架为下一代无线网络的实时共存优化提供了可扩展的解决方案。

Abstract: Efficient and fair coexistence in unlicensed spectrum is essential to support
heterogeneous networks such as 5G NR-U and Wi-Fi, which often contend for
shared wireless resources. We introduce a general framework for wireless
Coexistence Parameter Management (CPM) based on state-augmented constrained
reinforcement learning. We propose a novel algorithm, QaSAL-CPM, which
incorporates state-augmentation by embedding the dual variables in the
constrained optimization formulation directly into the agent's observation
space. This method enables the agent to respond to constraint violations in
real time while continuing to optimize a primary performance objective. Through
extensive simulations of 5G NR-U and Wi-Fi coexistence scenarios, we show that
QaSAL-CPM achieves reliable QoS compliance and improved policy robustness
across various transmitter densities compared to previous approaches. The
proposed framework offers a scalable and adaptive solution for real-time
coexistence optimization in next-generation wireless networks.

</details>


### [432] [A Correlation-Based Design of RIS for Reduced Power Consumption and Simplified Control Circuitry](https://arxiv.org/abs/2506.22702)
*Zina Mohamed,Ammar B. Kouki,Sonia Aïssa*

Main category: eess.SY

TL;DR: 论文提出了一种基于相关性的新型RIS设计（Connected-RIS），通过共享控制信号简化硬件结构并降低能耗。


<details>
  <summary>Details</summary>
Motivation: 旨在简化无线通信中可重构智能表面（RIS）的硬件结构并减少能耗。

Method: 通过分析表面元素相位偏移值的相关性，设计了一种共享控制信号的RIS结构（Connected-RIS），并分析了其性能。

Result: 该设计显著减少了负载阻抗和控制信号数量，降低了硬件成本和功耗（能耗减少86-92%，控制信号减少83-98%），同时保持了足够的覆盖增益。

Conclusion: Connected-RIS设计在降低硬件复杂性和能耗方面具有显著优势，同时满足通信性能需求。

Abstract: Aiming at simplifying the hardware structure and reducing the energy
consumption in wireless communication via reconfigurable intelligent surfaces
(RIS), this paper introduces a novel RIS design founded on the correlation
between the phase shift values of the surface elements. First, a correlation
analysis is conducted, considering the azimuth angle of a target device within
a coverage region spanning from $-80^{\circ}$ to $80^{\circ}$. The correlation
is demonstrated for different deployment cases, creating the basis for the new
RIS structure, termed Connected-RIS, where correlated elements are designed to
share the same control signal. The fundamental performance of the proposed
design is then analyzed in terms of control signals, power consumption, and
communication system performance, comparing it to two RIS structures with full
control: one with the same size as the proposed design, and the other employing
the minimum number of elements necessary to satisfy the fair coverage
criterion. The correlation-based RIS design enables three-dimensional passive
beamforming and significantly reduces the number of required load impedances
and control signals, thereby lowering the hardware cost and simplifying the
control circuitry. It also achieves substantial power savings as compared to
the baseline schemes, while maintaining sufficient gain for a fair radio
coverage. For instance, numerical simulations demonstrate that the proposed
design reduces the power consumption by almost 86-92\% and the control signals
by 83-98\% compared to operation with fully controlled RIS.

</details>


### [433] [X-pSRAM: A Photonic SRAM with Embedded XOR Logic for Ultra-Fast In-Memory Computing](https://arxiv.org/abs/2506.22707)
*Md Abdullah-Al Kaiser,Sugeet Sunder,Ajey P. Jacob,Akhilesh R. Jaiswal*

Main category: eess.SY

TL;DR: 论文提出了一种新型差分光子静态随机存取存储器（pSRAM）单元，支持超快内存内布尔异或（XOR）计算，利用光计算解决传统冯·诺依曼架构的数据移动瓶颈。


<details>
  <summary>Details</summary>
Motivation: 传统冯·诺依曼架构因数据在内存和处理单元间频繁移动而面临性能和能效瓶颈，光计算因其高速和低能耗特性成为潜在解决方案。

Method: 采用交叉耦合微环谐振器和差分光电二极管设计XOR增强型pSRAM（X-pSRAM），支持全光域10 GHz读写和计算，并利用波分复用（WDM）实现单次n位XOR计算。

Result: 在GlobalFoundries 45SPCLO节点验证中，X-pSRAM的XOR计算能耗为13.2 fJ/bit，显著提升了并行处理能力和计算效率。

Conclusion: X-pSRAM为下一代光计算在密码学、超维计算和神经网络等领域的应用提供了重要技术基础。

Abstract: Traditional von Neumann architectures suffer from fundamental bottlenecks due
to continuous data movement between memory and processing units, a challenge
that worsens with technology scaling as electrical interconnect delays become
more significant. These limitations impede the performance and energy
efficiency required for modern data-intensive applications. In contrast,
photonic in-memory computing presents a promising alternative by harnessing the
advantages of light, enabling ultra-fast data propagation without
length-dependent impedance, thereby significantly reducing computational
latency and energy consumption. This work proposes a novel differential
photonic static random access memory (pSRAM) bitcell that facilitates
electro-optic data storage while enabling ultra-fast in-memory Boolean XOR
computation. By employing cross-coupled microring resonators and differential
photodiodes, the XOR-augmented pSRAM (X-pSRAM) bitcell achieves at least 10 GHz
read, write, and compute operations entirely in the optical domain.
Additionally, wavelength-division multiplexing (WDM) enables n-bit XOR
computation in a single-shot operation, supporting massively parallel
processing and enhanced computational efficiency. Validated on GlobalFoundries'
45SPCLO node, the X-pSRAM consumed 13.2 fJ energy per bit for XOR computation,
representing a significant advancement toward next-generation optical computing
with applications in cryptography, hyperdimensional computing, and neural
networks.

</details>


### [434] [Online Coreset Selection for Learning Dynamic Systems](https://arxiv.org/abs/2506.22804)
*Jingyuan Li,Dawei Shi,Ling Shi*

Main category: eess.SY

TL;DR: 提出了一种在线核心集选择方法，用于动态系统中数据驱动建模，以提高数据效率并确保收敛性。


<details>
  <summary>Details</summary>
Motivation: 动态系统中流数据的增加使得如何高效选择信息数据以表征系统动态成为关键挑战。

Method: 设计了基于集合成员识别的在线核心集选择方法，包括堆叠多面体表示、几何选择准则和在线约束简化方法。

Result: 分析了核心集可行集的收敛性，并推导了选择概率和核心集数据数量的上界。

Conclusion: 通过仿真验证了方法的有效性。

Abstract: With the increasing availability of streaming data in dynamic systems, a
critical challenge in data-driven modeling for control is how to efficiently
select informative data to characterize system dynamics. In this work, we
design an online coreset selection method under the framework of set-membership
identification for systems subject to process disturbances, with the objective
of improving data efficiency while ensuring convergence guarantees.
Specifically, we first propose a stacked polyhedral representation that
over-approximates the feasible set of system parameters. Leveraging a
generalized Gr\"unbaum's inequality, we design a geometric selection criterion
for constructing the coreset. To reduce computational complexity, an online
double-description-based constraint reduction method is introduced to simplify
the polyhedral representation. Finally, we analyze the convergence of the
feasible set with respect to the coreset and derive upper bounds on the
selection probability and the expected number of data in the coreset. The
effectiveness of the proposed method is demonstrated through comprehensive
simulation studies.

</details>


### [435] [Identification of Cellular Automata on Spaces of Bernoulli Probability Measures](https://arxiv.org/abs/2506.22867)
*Faizal Hafiz,Amelia Kunze,Enrico Formenti,Davide La Torre*

Main category: eess.SY

TL;DR: 该研究提出了一种基于概率测度的元胞自动机（CAMs）框架，用于建模具有不确定性的系统，并通过自适应差分进化算法（SaDE）准确识别局部规则。


<details>
  <summary>Details</summary>
Motivation: 传统元胞自动机（CCAs）在建模具有不确定性的系统时存在局限性，因此研究转向概率测度空间上的元胞自动机（CAMs）以更好地处理不确定性。

Method: 将局部规则识别问题转化为参数估计问题，并采用自适应差分进化算法（SaDE）进行求解。

Result: 在二维CAMs中，针对不同邻域类型和半径，成功识别了局部规则。

Conclusion: CAMs框架结合SaDE算法能够有效建模和识别具有不确定性的系统动态。

Abstract: Classical Cellular Automata (CCAs) are a powerful computational framework for
modeling global spatio-temporal dynamics with local interactions. While CCAs
have been applied across numerous scientific fields, identifying the local rule
that governs observed dynamics remains a challenging task. Moreover, the
underlying assumption of deterministic cell states often limits the
applicability of CCAs to systems characterized by inherent uncertainty. This
study, therefore, focuses on the identification of Cellular Automata on spaces
of probability measures (CAMs), where cell states are represented by
probability distributions. This framework enables the modeling of systems with
probabilistic uncertainty and spatially varying dynamics. Moreover, we
formulate the local rule identification problem as a parameter estimation
problem and propose a meta-heuristic search based on Self-adaptive Differential
Evolution (SaDE) to estimate local rule parameters accurately from the observed
data. The efficacy of the proposed approach is demonstrated through local rule
identification in two-dimensional CAMs with varying neighborhood types and
radii.

</details>


### [436] [Real-Time Energy Management Strategies for Community Microgrids](https://arxiv.org/abs/2506.22931)
*Moslem Uddin,Huadong Mo,Daoyi Dong*

Main category: eess.SY

TL;DR: 本文提出了一种混合社区微电网的实时能源管理框架，通过多目标优化降低运营成本，比较了规则控制（RBC）和深度强化学习（DRL-PPO）两种策略。结果显示DRL-PPO在成本、排放和可靠性方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 解决混合社区微电网的能源管理问题，优化运营成本并提高可再生能源利用率。

Method: 采用多目标优化方法，比较规则控制（RBC）和深度强化学习（DRL-PPO）两种策略。

Result: DRL-PPO比RBC降低运营成本18%、CO2排放20%，系统可靠性提高87.5%，可再生能源利用率增加13%。

Conclusion: DRL-PPO方法在微电网运营中具有成本效益和韧性，特别适用于偏远地区。

Abstract: This study presents a real-time energy management framework for hybrid
community microgrids integrating photovoltaic, wind, battery energy storage
systems, diesel generators, and grid interconnection. The proposed approach
formulates the dispatch problem as a multi-objective optimization task that
aims to minimize operational costs. Two control strategies are proposed and
evaluated: a conventional rule-based control (RBC) method and an advanced deep
reinforcement learning (DRL) approach utilizing proximal policy optimization
(PPO). A realistic case study based on Australian load and generation profiles
is used to validate the framework. Simulation results demonstrate that DRL-PPO
reduces operational costs by 18%, CO_2 emissions by 20%, and improves system
reliability by 87.5% compared to RBC. Beside, DRL-PPO increases renewable
energy utilization by 13%, effectively reducing dependence on diesel generation
and grid imports. These findings demonstrate the potential of DRL-based
approaches to enable cost-effective and resilient microgrid operations,
particularly in regional and remote communities.

</details>


### [437] [Extreme Scenario Characterization for High Renewable Energy Penetrated Power Systems over Long Time Scales](https://arxiv.org/abs/2506.23169)
*Kai Kang,Feng Liu,Yifan Su,Zhaojian Wang*

Main category: eess.SY

TL;DR: 本文提出了一种量化高可再生能源渗透下电力系统极端场景的方法，包括风险指数和极端场景生成技术，以提升系统长期安全可靠性。


<details>
  <summary>Details</summary>
Motivation: 高可再生能源渗透的电力系统受天气影响大，面临长期电力短缺和波动问题，需有效表征极端场景。

Method: 提出风险指数量化问题，采用基于过滤的方法和混合高斯模型与蒙特卡洛模拟生成极端场景。

Result: 案例研究表明，该方法能有效识别极端场景，显著提升系统长期安全可靠性。

Conclusion: 所提方法为高可再生能源电力系统提供了有效的极端场景表征工具。

Abstract: Power systems with high renewable energy penetration are highly influenced by
weather conditions, often facing significant challenges such as persistent
power shortages and severe power fluctuations over long time scales. This paper
addresses the critical need for effective characterization of extreme scenarios
under these situations. First, novel risk indices are proposed to quantify the
severity of continuous power shortages and substantial power fluctuations over
long-term operations. These indices are independent of specific scheduling
strategies and incorporate the system's resource regulation capabilities. By
employing a filtering-based approach, the proposed indices focus on retaining
key characteristics of continuous power shortages and fluctuation events,
enabling the identification of extreme scenarios on long time scales. Secondly,
an extreme scenario generation method is developed using Gaussian mixture
models and sequential Monte Carlo simulation. Especially, this method
periodically evaluates the severity of generated scenarios based on the defined
risk indices, retaining extreme scenarios while discarding less critical ones.
Finally, case studies based on real-world data demonstrate the efficacy of the
proposed method. The results confirm that integrating the identified extreme
scenarios significantly enhances the system's ability to ensure long-term
security and reliability under high renewable energy penetration.

</details>


### [438] [Data-driven Implementations of Various Generalizations of Balanced Truncation](https://arxiv.org/abs/2506.23204)
*Umair Zulfiqar*

Main category: eess.SY

TL;DR: 论文提出了一种非侵入式ADI框架，用于广义平衡截断方法，仅需原始传递函数的样本即可实现。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如基于正交的框架）虽理论上无需原始状态空间实现，但依赖于传递函数谱分解的样本，而实际获取这些样本的方法尚不可行。

Method: 采用非侵入式ADI框架，仅需原始传递函数的样本，无需谱分解样本。

Result: 实现了广义平衡截断方法的非侵入式实现，解决了现有方法的局限性。

Conclusion: 提出的ADI框架为广义平衡截断提供了更实用的非侵入式实现方案。

Abstract: There exist two main frameworks for non-intrusive implementations of
approximate balanced truncation: the quadrature-based framework and the
ADI-based framework. Both approaches rely solely on samples of the transfer
function to construct truncated balanced models, eliminating the need for
access to the original model's state-space realization. Recently, the
quadrature-based framework has been extended to various generalizations of
balanced truncation, including positive-real balanced truncation, bounded-real
balanced truncation, and balanced stochastic truncation. While this extension
is theoretically nonintrusive-meaning it does not require the original
state-space realization-it depends on samples of spectral factorizations of the
transfer function. Since practical methods for obtaining such samples are
currently unavailable, this extension remains largely a theoretical
contribution. In this work, we present a non-intrusive ADI-type framework for
these generalized balanced truncation methods that requires only samples of the
original transfer function for implementation.

</details>


### [439] [Revisiting Z Transform Laplace Inversion: To Correct flaws in Signal and System Theory](https://arxiv.org/abs/2506.23242)
*Yuxin Yang,Hang Zhou,Chaojie Li,Xin Li,Yingyi Yan,Mingyang Zheng*

Main category: eess.SY

TL;DR: 重新审视Z变换与拉普拉斯逆变换的关系，修正了传统推导中忽略无限弧贡献的问题，提出更准确的采样数据系统建模方法。


<details>
  <summary>Details</summary>
Motivation: 传统推导中忽略无限弧贡献导致不一致性，尤其是在不连续点（如t=0）处。

Method: 通过完整包含Bromwich轮廓的所有边界贡献，修正拉普拉斯逆变换与Z变换的一致性。

Result: 修正后的拉普拉斯逆变换与离散时间傅里叶变换（DTFT）混叠理论结果一致，改进了Z变换和阶跃函数在不连续点的行为。

Conclusion: 为采样数据系统的建模和分析提供了更准确的理论基础。

Abstract: This paper revisits the classical formulation of the Z-transform and its
relationship to the inverse Laplace transform (L-1), originally developed by
Ragazzini in sampled-data theory. It identifies a longstanding mathematical
oversight in standard derivations, which typically neglect the contribution
from the infinite arc in the complex plane during inverse Laplace evaluation.
This omission leads to inconsistencies, especially at discontinuities such as t
= 0. By incorporating the full Bromwich contour, including all boundary
contributions, we restore internal consistency between L-1 and the Z-transform,
aligning the corrected L-1 with results from Discrete-Time Fourier Transform
(DTFT) aliasing theory. Consequently, this necessitates a structural revision
of the Z-transform, inverse Laplace transform, and the behavior of the
Heaviside step function at discontinuities, providing a more accurate
foundation for modeling and analysis of sampled-data systems.

</details>


### [440] [Joint Trajectory and Resource Optimization for HAPs-SAR Systems with Energy-Aware Constraints](https://arxiv.org/abs/2506.23248)
*Bang Huang,Kihong Park,Xiaowei Pang,Mohamed-Slim Alouini*

Main category: eess.SY

TL;DR: 论文研究了高空平台站合成孔径雷达（HAPs-SAR）系统的轨迹规划和资源分配的联合优化，提出了一种动态轨迹模型和能量感知的混合整数非线性规划（MINLP）问题，并通过次优的连续凸近似（SCA）框架解决。


<details>
  <summary>Details</summary>
Motivation: 支持实时感知并节省HAPs的有限能量预算，同时通过太阳能收集增强系统可持续性。

Method: 开发动态轨迹模型，分析雷达感知、数据传输和飞行的能耗，提出SCA框架解决MINLP问题。

Result: 仿真验证了算法的收敛性，平衡了SAR性能、通信可靠性和能源效率，并通过9目标场景的SAR成像模拟确认了方案的可行性。

Conclusion: 提出的框架在优化HAPs-SAR系统的轨迹和资源分配方面具有实际可行性和有效性。

Abstract: This paper investigates the joint optimization of trajectory planning and
resource allocation for a high-altitude platform stations synthetic aperture
radar (HAPs-SAR) system. To support real-time sensing and conserve the limited
energy budget of the HAPs, the proposed framework assumes that the acquired
radar data are transmitted in real time to a ground base station for SAR image
reconstruction. A dynamic trajectory model is developed, and the power
consumption associated with radar sensing, data transmission, and circular
flight is comprehensively analyzed. In addition, solar energy harvesting is
considered to enhance system sustainability. An energy-aware mixed-integer
nonlinear programming (MINLP) problem is formulated to maximize radar beam
coverage while satisfying operational constraints. To solve this challenging
problem, a sub-optimal successive convex approximation (SCA)-based framework is
proposed, incorporating iterative optimization and finite search. Simulation
results validate the convergence of the proposed algorithm and demonstrate its
effectiveness in balancing SAR performance, communication reliability, and
energy efficiency. A final SAR imaging simulation on a 9-target lattice
scenario further confirms the practical feasibility of the proposed solution.

</details>


### [441] [Load Limiting Control for Component Life Extension](https://arxiv.org/abs/2506.23302)
*Chams Eddine Mballo,Robert Walters,Jonnalagadda V. R. Prasad*

Main category: eess.SY

TL;DR: 本文提出了一种新型的直升机关键部件寿命延长控制方案，旨在解决现有方案忽略谐波载荷疲劳损伤和无法区分机动动作的问题。


<details>
  <summary>Details</summary>
Motivation: 开发一种比现有方案更高效且保守性更低的寿命延长控制方案，以解决谐波载荷疲劳损伤和机动动作区分问题。

Method: 提出负载限制控制（LLC）方案，将谐波负载限制视为边界，通过计算控制裕度（CM）并将其作为飞行员提示。

Result: 仿真显示LLC方案能有效限制飞行中的谐波桨距连杆负载，飞行员在训练后可在0.5秒内熟练跟踪提示。

Conclusion: LLC方案是一种可行的解决方案，能显著提升直升机部件的寿命延长控制效果。

Abstract: This paper presents the development of a novel life-extending control scheme
for critical helicopter components subjected to significant fatigue loading.
The primary objective is to synthesize a more efficient and less conservative
life-extending control scheme than those currently available in the literature.
The proposed Load Limiting Control (LLC) scheme is a viable solution that
addresses several issues that current life-extending control schemes suffer
from, such as the neglect of fatigue damage induced by the harmonic component
of loads and the inability to distinguish between aggressive and non-aggressive
maneuvers. The proposed LLC scheme treats desired harmonic load limits as limit
boundaries and recasts the problem of load limiting as a vehicle limit by
computing a Control Margin (CM) using a limit detection and avoidance module.
The computed CM is used as a cue to the pilot. The limit detection and
avoidance module comprises an optimization algorithm, a model predictive
controller, and a computationally simple on-board dynamical model. Simulations
were conducted to demonstrate the effectiveness of the LLC scheme in limiting
harmonic pitch link loads during flight. One significant outcome is that, with
sufficient training, the pilot can skillfully track the cue within 0.5 seconds
of initiating the tracking task.

</details>


### [442] [ANN-Based Grid Impedance Estimation for Adaptive Gain Scheduling in VSG Under Dynamic Grid Conditions](https://arxiv.org/abs/2506.23304)
*Quang-Manh Hoang,Van Nam Nguyen,Taehyung Kim,Guilherme Vieira Hollweg,Wencong Su,Van-Hai Bui*

Main category: eess.SY

TL;DR: 提出了一种基于人工神经网络的虚拟同步发电机自适应增益调度控制方案，以应对电网阻抗变化，提升稳定性。


<details>
  <summary>Details</summary>
Motivation: 虚拟同步发电机在弱电网下表现良好，但在强电网下可能不稳定，而电网阻抗随时间变化，需要自适应控制方案。

Method: 使用人工神经网络估计电网阻抗，并通过自适应增益调度函数调整控制器参数。

Result: 在不同电网条件下，稳定时间和超调百分比保持一致，且能高精度、低延迟地估计未知电网阻抗。

Conclusion: 该方法适用于实时增益调度控制，显著提升了虚拟同步发电机在不同电网条件下的稳定性。

Abstract: In contrast to grid-following inverters, Virtual Synchronous Generators
(VSGs) perform well under weak grid conditions but may become unstable when the
grid is strong. Grid strength depends on grid impedance, which unfortunately
varies over time. In this paper, we propose a novel adaptive gain-scheduling
control scheme for VSGs. First, an Artificial Neural Network (ANN) estimates
the fundamental-frequency grid impedance; then these estimates are fed into an
adaptive gain-scheduling function to recalculate controller parameters under
varying grid conditions. The proposed method is validated in Simulink and
compared with a conventional VSG employing fixed controller gains. The results
demonstrate that settling times and overshoot percentages remain consistent
across different grid conditions. Additionally, previously unseen grid
impedance values are estimated with high accuracy and minimal time delay,
making the approach well suited for real-time gain-scheduling control.

</details>


### [443] [Predictor-Based Compensators for Networked Control Systems with Stochastic Delays and Sampling Intervals](https://arxiv.org/abs/2506.23421)
*Matheus Wagner,Marcelo M. Morato,Antônio Augusto Fröhlich,Julio E. Normey-Rico*

Main category: eess.SY

TL;DR: 论文提出了一种针对线性多输入多输出网络控制系统的建模方法，并基于滤波Smith预测器设计补偿方案，以减轻随机时延对闭环性能的不利影响。


<details>
  <summary>Details</summary>
Motivation: 网络控制系统中随机时延和采样间隔的随机性给控制器设计和分析带来挑战，导致保守设计和性能下降。

Method: 采用滤波Smith预测器作为补偿方案，通过数值模拟验证其在协同自适应巡航控制系统中的效果。

Result: 补偿方案实现了接近理想的平均闭环性能，显著降低了响应变异性，最坏情况跟踪误差信号能量比理想基线系统减少了45%。

Conclusion: 提出的补偿方案有效改善了网络控制系统的性能，尤其在随机时延环境下表现优异。

Abstract: The stochastic nature of time delays and sampling intervals in Networked
Control Systems poses significant challenges for controller synthesis and
analysis, often leading to conservative designs and degraded performance. This
work presents a modeling approach for Linear Multiple-Input Multiple-Output
Networked Control Systems and introduces a compensation scheme based on the
Filtered Smith Predictor to mitigate the adverse effects of stochastic time
delays on closed-loop performance. The proposed scheme is evaluated through
numerical simulations of a well-established Cooperative Adaptive Cruise Control
system. Results demonstrate that the compensator achieves near-ideal average
closed-loop performance and significantly reduces response variability compared
to a traditional Filtered Smith Predictor. Notably, it yields a 45% reduction
in worst-case tracking error signal energy relative to an ideal baseline system
with no time delays and constant sampling intervals.

</details>


### [444] [Power Flow Analysis of a 5-Bus Power System Based on Newton-Raphson Method](https://arxiv.org/abs/2506.23425)
*Sampson E. Nwachukwu*

Main category: eess.SY

TL;DR: 论文探讨了电力系统稳态分析中的潮流计算方法，重点比较了传统环路法与牛顿-拉夫逊法（NR），并通过5总线系统的仿真验证了NR方法的优越性。


<details>
  <summary>Details</summary>
Motivation: 电力系统潮流分析对确保电网高效、可靠运行至关重要。传统环路法在小规模系统中可行，但在复杂网络中表现不佳，因此需要更高效的方法。

Method: 研究采用牛顿-拉夫逊法对5总线系统进行潮流分析，结合PowerWorld Simulator和MATLAB实现仿真与验证。

Result: NR方法因其二次收敛性和数值稳定性，在潮流分析中表现出更高的准确性和鲁棒性。

Conclusion: 牛顿-拉夫逊法是分析复杂电力系统潮流的有效方法，适用于多种运行条件下的性能评估。

Abstract: Load flow analysis is a fundamental technique used by electrical engineers to
simulate and evaluate power system behavior under steady-state conditions. It
enables efficient operation and control by determining how active and reactive
power flows throughout the system. Selecting an appropriate solution method is
critical to ensuring reliable and economical operation of power generation,
transmission, and distribution networks. While the conventional loop method may
be used in small-scale systems, it is limited by its reliance on
impedance-based load data and its inability to scale to complex networks. In
contrast, iterative techniques such as the Gauss-Seidel (GS) and Newton-Raphson
(NR) methods are better suited for analyzing large systems. Of these, the NR
method offers significant advantages due to its quadratic convergence and
improved numerical stability. This study presents a power flow analysis of a
5-bus system using the Newton-Raphson approach. The system was modeled and
simulated in PowerWorld Simulator (PWS), and a custom MATLAB implementation was
developed to verify the results under a base case scenario. The comparative
analysis demonstrates that the NR method provides accurate and robust solutions
for power flow problems, making it well-suited for evaluating system
performance under various operating conditions.

</details>


### [445] [Power-Gas Infrastructure Planning under Weather-induced Supply and Demand Uncertainties](https://arxiv.org/abs/2506.23509)
*Rahman Khorramfar,Dharik Mallapragada,Saurabh Amin*

Main category: eess.SY

TL;DR: 论文提出两种基于分布鲁棒优化的方法（MDRO和WDRO），用于电力-天然气联合基础设施规划，考虑需求和可再生能源供应的不确定性，并结合气候变化的分布变化。


<details>
  <summary>Details</summary>
Motivation: 传统能源规划模型未充分考虑天气引起的不确定性，可能导致低碳电网转型受阻和极端天气下的供应短缺风险。

Method: 采用基于矩（MDRO）和Wasserstein距离（WDRO）的分布鲁棒优化方法，结合条件风险价值（CVaR）度量规划者的风险规避。

Result: 通过新英格兰案例研究验证了模型的有效性，并与随机规划（SP）结果进行了比较。

Conclusion: 提出的DRO方法能有效应对不确定性，支持低碳电网转型。

Abstract: Implementing economy-wide decarbonization strategies based on decarbonizing
the power grid via variable renewable energy (VRE) expansion and
electrification of end-uses requires new approaches for energy infrastructure
planning that consider, among other factors, weather-induced uncertainty in
demand and VRE supply. An energy planning model that fails to account for these
uncertainties can hinder the intended transition efforts to a low-carbon grid
and increase the risk of supply shortage especially during extreme weather
conditions. Here, we consider the generation and transmission expansion problem
of joint power-gas infrastructure and operations planning under the uncertainty
of both demand and renewable supply. We propose two distributionally robust
optimization approaches based on moment (MDRO) and Wasserstein distance (WDRO)
ambiguity sets to endogenize these uncertainties and account for the change in
the underlying distribution of these parameters that is caused by the climate
change, among other factors. Furthermore, our model considers the risk-aversion
of the energy planners in the modeling framework via the conditional
value-at-risk (CVaR) metric. An equivalent mixed-integer linear programming
(MILP) reformulation of both modeling frameworks is presented, and a
computationally efficient approximation scheme to obtain near-optimal solutions
is proposed. We demonstrate the resulting DRO planning models and solution
strategy via a New England case study under different levels of end-use
electrification and decarbonization targets. Our experiments systematically
explore different modeling aspects and compare the DRO models with stochastic
programming (SP) results.

</details>


### [446] [A Bidirectional Power Router for Traceable Multi-energy Management](https://arxiv.org/abs/2506.23554)
*Shiu Mochiyama,Ryo Takahashi,Yoshihiko Susuki*

Main category: eess.SY

TL;DR: 论文通过实验验证了一种基于线路切换的双向电力路由器的动态功率流处理能力，并提出了一种基于功率流监测的切换算法，以提高可再生能源自消纳和本地住宅电力系统的韧性。


<details>
  <summary>Details</summary>
Motivation: 解决可再生能源自消纳和本地住宅电力系统韧性提升的挑战。

Method: 设计并实验验证了一种基于线路切换的双向电力路由器，并提出了一种基于功率流监测的切换算法。

Result: 实验验证了路由器处理动态双向功率流的能力，并展示了算法的有效性。

Conclusion: 提出的双向电力路由器和切换算法能够有效提升电力系统的稳定性和可再生能源的利用效率。

Abstract: To address challenges in improving self-consumption of renewables and
resilience in local residential power systems, the earlier work of the authors
introduced a novel multi-energy management concept, integrating bidirectional
power routing and electricity-hydrogen conversion. This paper focuses on an
experimental verification of the bidirectional power router based on
line-switching, the essential hardware to realize the concept. The primary
contribution is the validation of the router's capability to handle dynamic
change of bidirectional power flow. Furthermore, to achieve bidirectional power
routing without affecting the smooth and stable operation of the power system,
a novel algorithm for router's switching is designed based on power flow
monitoring. The effectiveness of the proposed method is demonstrated through an
experiment using a setup with a commercially available stationary battery.

</details>


### [447] [Reliability Assessment of Power System Based on the Dichotomy Method](https://arxiv.org/abs/2506.23649)
*Wenjie Wan,Han Hu,Feiyu Chen,Xiaoyu Liu,Kequan Zhao*

Main category: eess.SY

TL;DR: 本文提出了一种基于布尔格表示理论的状态空间二分法，用于高效划分电力系统状态空间，并通过格子划分计算可靠性指标，显著提升了效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 随着电力系统规模的扩大，传统状态评估方法（如状态枚举和蒙特卡洛模拟）在效率和准确性上遇到瓶颈，亟需新方法解决这一问题。

Method: 研究布尔格表示理论，提出状态空间的二分法划分，将空间分割为不相交的子格，并通过格子计算可靠性指标；同时设计了定制化的蒙特卡洛采样方法计算EENS。

Result: 实验表明，该方法在RBTS系统上仅需500次OPF操作即可达到解析LOLP，比传统方法快数百倍；蒙特卡洛采样方法在测试系统上收敛于数千次OPF操作。

Conclusion: 所提方法显著提升了电力系统可靠性评估的效率和准确性，为大规模系统提供了可行的解决方案。

Abstract: With a sustainable increase in the scale of power system, the number of
states in the state space grows exponentially, and the reliability assessment
of the power system faces enormous challenges. Traditional state-by-state
assessment methods, such as state enumeration (SE) and Monte Carlo simulation
(MCS) methods, have encountered performance bottlenecks in terms of efficiency
and accuracy. In this paper, the Boolean lattice representation theory of the
state space was studied, and a dichotomy method was proposed to efficiently
partition the state space into some disjoint sub-lattices with a relatively
small number of optimal power flow (OPF) operations. Based on lattice
partition, the reliability indices of the entire space can be calculated
lattice-by-lattice. In addition, alone with the partitioning procedure, the
calculated loss of load probability (LOLP) monotonically increases and rapidly
tends to the analytic value with the designated error bound. Moreover, we
designed a customized Monte Carlo sampling method in lattices of interest to
compute expected energy not supply (EENS). The experiments are conducted on the
RBTS and RTS-79 systems. The results show that the proposed method achieves the
analytic LOLP of the RBTS system after five hundreds of OPF operations, which
is about hundreds of times faster than traditional methods, and the designed
Monte Carlo sampling method converged after thousands of OPF operations on test
systems.

</details>


### [448] [A Data-Ensemble-Based Approach for Sample-Efficient LQ Control of Linear Time-Varying Systems](https://arxiv.org/abs/2506.23716)
*Sahel Vahedi Noori,Maryam Babazadeh*

Main category: eess.SY

TL;DR: 本文提出了一种高效的数据驱动控制框架，用于线性时变系统的有限时域LQ控制，通过非迭代SDP算法直接从数据计算最优反馈增益。


<details>
  <summary>Details</summary>
Motivation: 解决线性时变系统的有限时域LQ控制问题，避免传统方法对模型识别的依赖，提高样本效率和最优性。

Method: 将LQ问题转化为非凸优化问题，分析其对偶结构，利用KKT条件推导最优解与Q函数参数的关系，提出非迭代SDP算法。

Result: 算法在完全未知的LTV系统中提供全局最优性保证，且在LTI系统中仅需单条轨迹即可确定最优策略。

Conclusion: 该方法为时变环境下的数据驱动控制提供了新视角，仿真显示其在最优性和样本效率上优于现有方法。

Abstract: This paper presents a sample-efficient, data-driven control framework for
finite-horizon linear quadratic (LQ) control of linear time-varying (LTV)
systems. In contrast to the time-invariant case, the time-varying LQ problem
involves a differential Riccati equation (DRE) with time-dependent parameters
and terminal boundary constraints. We formulate the LQ problem as a nonconvex
optimization problem and conduct a rigorous analysis of its dual structure. By
exploiting the inherent convexity of the dual problem and analyzing the KKT
conditions, we derive an explicit relationship between the optimal dual
solution and the parameters of the associated Q-function in time-varying case.
This theoretical insight supports the development of a novel, sample-efficient,
non-iterative semidefinite programming (SDP) algorithm that directly computes
the optimal sequence of feedback gains from an ensemble of input-state data
sequences without model identification. The resulting convex, data-dependent
framework provides global optimality guarantees for completely unknown LTV
systems. As a special case, the method also applies to finite-horizon LQ
control of linear time-invariant (LTI) systems. In this setting, a single
input-state trajectory suffices to identify the optimal LQ feedback policy,
improving significantly over existing Q-learning approaches for finite horizon
LTI systems that typically require data from multiple episodes. The approach
provides a new optimization-based perspective on Q-learning in time-varying
settings and contributes to the broader understanding of data-driven control in
non-stationary environments. Simulation results show that, compared to recent
methods, the proposed approach achieves superior optimality and sample
efficiency on LTV systems, and indicates potential for stabilizing and optimal
control of nonlinear systems.

</details>


### [449] [A Digital Twinning Approach to Decarbonisation: Research Challenges](https://arxiv.org/abs/2506.23733)
*Blair Archibald,Paul Harvey,Michele Sevegnani*

Main category: eess.SY

TL;DR: 论文探讨了英国交通运输领域温室气体排放问题，提出通过联邦数字孪生方法实现系统级脱碳。


<details>
  <summary>Details</summary>
Motivation: 交通运输占英国温室气体排放的27%，但现有脱碳努力局限于单一领域，缺乏系统级视角。

Method: 提出联邦数字孪生方法，整合多模式运输数据，解决数字孪生设计、生成、验证等挑战。

Result: 通过系统级视角和知识共享，为脱碳提供动态适应能力。

Conclusion: 联邦数字孪生方法有望解决交通运输脱碳的系统性挑战。

Abstract: Transportation accounts for around 27% of green house gas emissions in the
UK. While an obvious priority area for decarbonisation, and aligned to the UK
government goal of reducing emissions by 68% for 2030, the free-market nature
of the transportation sector combined with its fundamentally implicit and
pervasive connections to all aspects of society and national infrastructure
mean that all decarbonisation efforts to date have been siloed within a single
transport sector, e.g. only considering greener aviation fuels. Truly
decarbonising transport requires radical changes to the entire transport
infrastructure, and since that transport does not happen in isolation, a single
user often using multiple modes, we need a view over the whole transport
system. The first step to solving a problem is to understand it. As a result of
the fragmented nature of the transportation sector, there is currently no
system level view. Without the ability to monitor even adjacent transport
domains, the ability for people or organisations to (dynamically) adapt their
operations for decarbonisation outcomes is unrealistic. As transportation is a
complex social-techno-economic system, information and knowledge sharing is a
must to be able to understand and explore potential solutions to the
decarbonisation challenge. We believe a Federated Digital Twinning Approach has
the potential to tackle transport decarbonisation problems, and, in this
extended abstract, we give an overview of the research required to tackle the
fundamental challenges around digital twin design, generation, validation and
verification.

</details>


### [450] [On sample-based functional observability of linear systems](https://arxiv.org/abs/2506.23744)
*Isabelle Krauss,Victor G. Lopez,Matthias A. Müller*

Main category: eess.SY

TL;DR: 研究了基于采样的功能可观测性，提出了系统满足功能可观测性的充要条件，并给出了采样方案的约束条件。


<details>
  <summary>Details</summary>
Motivation: 探讨在测量信息有限（不频繁或不规则）的情况下，如何通过输出信息推断系统状态的函数。

Method: 提出充要条件，并分析采样方案以满足这些条件。

Result: 给出了系统在采样框架下功能可观测的条件，并通过数值示例验证了结果。

Conclusion: 研究为有限输出信息下的状态函数推断提供了理论支持，并展示了实际应用的可能性。

Abstract: Sample-based observability characterizes the ability to reconstruct the
internal state of a dynamical system by using limited output information, i.e.,
when measurements are only infrequently and/or irregularly available. In this
work, we investigate the concept of functional observability, which refers to
the ability to infer a function of the system state from the outputs, within a
samplebased framework. Here, we give necessary and sufficient conditions for a
system to be sample-based functionally observable, and formulate conditions on
the sampling schemes such that these are satisfied. Furthermore, we provide a
numerical example, where we demonstrate the applicability of the obtained
results.

</details>


### [451] [Active Estimation of Multiplicative Faults in Dynamical Systems](https://arxiv.org/abs/2506.23769)
*Gabriel de Albuquerque Gleizer,Peyman Mohajerin Esfahani,Tamas Keviczky*

Main category: eess.SY

TL;DR: 论文提出了一种实时故障估计方法，通过处理输入输出变量估计乘性故障信号，并设计输入信号以提高估计精度。


<details>
  <summary>Details</summary>
Motivation: 解决线性时不变系统中乘性故障信号的估计问题，并优化输入信号以提高估计准确性。

Method: 基于残差生成器和多输出回归生成器，结合移动水平线性回归估计参数变化，并提供噪声下的渐近性能保证。

Result: 提出了最优输入设计问题的高效算法和最优性界限，数值实验验证了方法的有效性和输入设计的重要性。

Conclusion: 该方法在噪声环境下表现良好，最优输入设计显著提高了故障估计的准确性。

Abstract: This paper addresses the problem of estimating multiplicative fault signals
in linear time-invariant systems by processing its input and output variables,
as well as designing an input signal to maximize the accuracy of such
estimates. The proposed real-time fault estimator is based on a residual
generator used for fault detection and a multiple-output regressor generator,
which feed a moving-horizon linear regression that estimates the parameter
changes. Asymptotic performance guarantees are provided in the presence of
noise. Motivated by the performance bounds, an optimal input design problem is
formulated, for which we provide efficient algorithms and optimality bounds.
Numerical examples demonstrate the efficacy of our approach and the importance
of the optimal input design for accurate fault estimation.

</details>


### [452] [Statistical Modeling for Accurate Characterization of Doppler Effect in LEO-Terrestrial Networks](https://arxiv.org/abs/2506.23817)
*Islam M. Tanash,Risto Wichman,Nuria Gonzalez-Prelcic*

Main category: eess.SY

TL;DR: 本文提出了一种分析低地球轨道（LEO）卫星通信系统中多普勒频移及其差异的通用框架，考虑了地球曲率和任意仰角，并通过用户聚类技术减少频移干扰。


<details>
  <summary>Details</summary>
Motivation: 解决LEO卫星高速运动引起的多普勒频移及其差异对多载波系统性能的干扰问题。

Method: 使用球面几何推导多普勒频移的闭式表达式，并通过统计分析和用户聚类技术减少频移差异。

Result: 推导了多普勒频移及其差异的统计特性，并通过仿真验证了模型的有效性。

Conclusion: 提出的框架和用户聚类技术能有效减少多普勒频移干扰，适用于实际卫星通信系统。

Abstract: Low Earth Orbit (LEO) satellite communication is a promising solution for
global wireless coverage, especially in underserved and remote areas. However,
the high relative velocity of LEO satellites induces significant Doppler shifts
that disrupt subcarrier orthogonality and degrade multicarrier system
performance. While the common time-varying Doppler shift can be compensated
relative to a reference point, the residual differential Doppler across users
within the coverage cell remains a significant challenge, causing severe
intercarrier interference. This paper presents a generalized analytical
framework for characterizing both the Doppler shift magnitude and the
differential Doppler in LEO systems. Unlike prior works limited by flat-Earth
assumptions or specific orbital configurations, our model incorporates Earth's
curvature and supports arbitrary elevation angles. Using spherical geometry, we
derive closed-form expressions for Doppler shift based on the central angle
between the satellite and ground users. We further provide a statistical
characterization of both the Doppler shift magnitude and the differential
Doppler in terms of their cumulative distribution function (CDF) and
probability density function (PDF) for uniformly distributed users within a
spherical cap cell. Additionally, we derive a tight upper bound for the Doppler
shift CDF and an exact expression for the maximum differential Doppler
experienced across the coverage region. To mitigate intra-cell Doppler
variation, we implement a user clustering technique that partitions the
coverage area based on a Doppler disparity threshold into spherical sub-cells,
ensuring compliance with 3GPP tolerances. Extensive simulations over realistic
satellite constellations validate our analysis and reveal the impact of
altitude, beamwidth, and satellite-user geometry on Doppler behavior.

</details>


### [453] [Orchestrated Couplings: A Time-Varying Edge Weight Framework for Efficient Event-Triggered Multiagent Networks](https://arxiv.org/abs/2506.24017)
*Emre Yildirim,Tansel Yucelen,Arman Sargolzaei*

Main category: eess.SY

TL;DR: 提出了一种基于时变边权重的事件触发控制框架，以减少多智能体网络中的节点间信息交换并提升性能。


<details>
  <summary>Details</summary>
Motivation: 减少多智能体网络中节点间的信息交换，同时提升网络的整体性能。

Method: 提出时变边权重的事件触发控制框架，动态调整边权重以优化网络性能。

Result: 证明了闭环稳定性，避免了Zeno行为，并通过数值示例验证了框架的有效性。

Conclusion: 该框架在减少事件触发次数的同时，提升了网络的收敛速度和控制效果。

Abstract: In this paper, we focus on reducing node-to-node information exchange in
distributed control of multiagent networks while improving the overall network
performance. Specifically, we consider a multiagent network that is composed of
leader and follower nodes over a time-varying, connected, and undirected graph.
In contrast to existing works on the event-triggered distributed control
literature, we propose a time-varying edge weight event-triggered control
framework. In this framework, each node dynamically adjusts its edge weights by
increasing them during the transient (active) phase and decreasing them during
the steady-state (idle) phase of the multiagent network. This not only reduces
the number of events in the network but also improves the performance (i.e.,
convergence speed and control effort) of the overall multiagent network.
System-theoretically, we first prove the closed-loop stability of the proposed
event-triggered distributed control framework, where we then show that this
framework does not exhibit a Zeno behavior. Finally, illustrative numerical
examples are provided to demonstrate the efficacy of this framework.

</details>


### [454] [Time Shift Governor-Guided MPC with Collision Cone CBFs for Safe Adaptive Cruise Control in Dynamic Environments](https://arxiv.org/abs/2506.24083)
*Robin Inho Kee,Taehyeun Kim,Anouck Girard,Ilya Kolmanovsky*

Main category: eess.SY

TL;DR: 论文提出了一种基于时间移位调控器（TSG）和模型预测控制（MPC）结合控制屏障函数（CBFs）的自适应巡航控制（ACC）方法。


<details>
  <summary>Details</summary>
Motivation: 解决在曲线道路跟踪中快速移动障碍物或前车行为突变时的约束问题。

Method: 采用MPC-CBF框架，结合TSG调整目标参考以强制满足约束条件。

Result: 仿真结果表明TSG-guided MPC-CBF方法有效。

Conclusion: 该方法在复杂场景下表现出良好的适应性。

Abstract: This paper introduces a Time Shift Governor (TSG)-guided Model Predictive
Controller with Control Barrier Functions (CBFs)-based constraints for adaptive
cruise control (ACC). This MPC-CBF approach is defined for obstacle-free curved
road tracking, while following distance and obstacle avoidance constraints are
handled using standard CBFs and relaxed Collision Cone CBFs. In order to
address scenarios involving rapidly moving obstacles or rapidly changing
leading vehicle's behavior, the TSG augmentation is employed which alters the
target reference to enforce constraints. Simulation results demonstrate the
effectiveness of the TSG-guided MPC-CBF approach.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [455] [Evaluating Sound Similarity Metrics for Differentiable, Iterative Sound-Matching](https://arxiv.org/abs/2506.22628)
*Amir Salimi,Abram Hindle,Osmar R. Zaiane*

Main category: cs.SD

TL;DR: 论文探讨了迭代声音匹配中损失函数的选择问题，提出了一种可微分迭代声音匹配方法，并验证了损失函数性能对合成器的依赖性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索是否存在一种普遍最优的损失函数，还是损失函数的选择应基于合成方法和设计师的偏好。

Method: 通过实现四种可微分损失函数与三种合成器的组合，进行了300次随机声音匹配实验，评估了参数差异、频谱距离和主观听感得分。

Result: 实验结果表明，损失函数的性能高度依赖于合成器，且三种评估方法的一致性中等。

Conclusion: 结论是应扩展声音匹配实验的范围，并为特定合成技术开发定制化的相似性度量，而非追求通用解决方案。

Abstract: Manual sound design with a synthesizer is inherently iterative: an artist
compares the synthesized output to a mental target, adjusts parameters, and
repeats until satisfied. Iterative sound-matching automates this workflow by
continually programming a synthesizer under the guidance of a loss function (or
similarity measure) toward a target sound. Prior comparisons of loss functions
have typically favored one metric over another, but only within narrow
settings: limited synthesis methods, few loss types, often without blind
listening tests. This leaves open the question of whether a universally optimal
loss exists, or the choice of loss remains a creative decision conditioned on
the synthesis method and the sound designer's preference. We propose
differentiable iterative sound-matching as the natural extension of the
available literature, since it combines the manual approach to sound design
with modern advances in machine learning. To analyze the variability of loss
function performance across synthesizers, we implemented a mix of four novel
and established differentiable loss functions, and paired them with
differentiable subtractive, additive, and AM synthesizers. For each of the
sixteen synthesizer--loss combinations, we ran 300 randomized sound-matching
trials. Performance was measured using parameter differences,
spectrogram-distance metrics, and manually assigned listening scores. We
observed a moderate level of consistency among the three performance measures.
Our post-hoc analysis shows that the loss function performance is highly
dependent on the synthesizer. These findings underscore the value of expanding
the scope of sound-matching experiments and developing new similarity metrics
tailored to specific synthesis techniques rather than pursuing
one-size-fits-all solutions.

</details>


### [456] [Enhancing Neural Audio Fingerprint Robustness to Audio Degradation for Music Identification](https://arxiv.org/abs/2506.22661)
*R. Oguz Araz,Guillem Cortès-Sebastià,Emilio Molina,Joan Serrà,Xavier Serra,Yuki Mitsufuji,Dmitry Bogdanov*

Main category: cs.SD

TL;DR: 论文提出了一种改进音频指纹识别的方法，通过优化自监督学习和系统评估度量学习方法，提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有神经音频指纹识别方法在训练中模拟音频降级不真实，且依赖过时的损失函数，导致性能不佳。

Method: 利用音乐信号特性和真实房间声学优化自监督学习，并系统评估多种度量学习方法。

Result: 自适应的三元组损失表现最佳，多正样本训练对不同损失函数有显著不同影响，方法在合成和真实数据集上达到最优。

Conclusion: 通过优化自监督和度量学习方法，显著提升了音频指纹识别的性能。

Abstract: Audio fingerprinting (AFP) allows the identification of unknown audio content
by extracting compact representations, termed audio fingerprints, that are
designed to remain robust against common audio degradations. Neural AFP methods
often employ metric learning, where representation quality is influenced by the
nature of the supervision and the utilized loss function. However, recent work
unrealistically simulates real-life audio degradation during training,
resulting in sub-optimal supervision. Additionally, although several modern
metric learning approaches have been proposed, current neural AFP methods
continue to rely on the NT-Xent loss without exploring the recent advances or
classical alternatives. In this work, we propose a series of best practices to
enhance the self-supervision by leveraging musical signal properties and
realistic room acoustics. We then present the first systematic evaluation of
various metric learning approaches in the context of AFP, demonstrating that a
self-supervised adaptation of the triplet loss yields superior performance. Our
results also reveal that training with multiple positive samples per anchor has
critically different effects across loss functions. Our approach is built upon
these insights and achieves state-of-the-art performance on both a large,
synthetically degraded dataset and a real-world dataset recorded using
microphones in diverse music venues.

</details>


### [457] [WavShape: Information-Theoretic Speech Representation Learning for Fair and Privacy-Aware Audio Processing](https://arxiv.org/abs/2506.22789)
*Oguzhan Baser,Ahmet Ege Tanriverdi,Kaan Kale,Sandeep P. Chinchali,Sriram Vishwanath*

Main category: cs.SD

TL;DR: WavShape框架通过信息论方法优化语音嵌入，减少敏感属性泄露，同时保留任务相关信息。


<details>
  <summary>Details</summary>
Motivation: 解决语音嵌入中敏感属性（如说话者身份、口音等）的泄露问题，避免偏见和隐私风险。

Method: 利用Donsker-Varadhan互信息估计，设计基于互信息的编码器，过滤敏感属性并保留任务相关信息。

Result: 在三个数据集上，WavShape将嵌入与敏感属性的互信息减少81%，同时保留97%的任务相关信息。

Conclusion: 结合信息论与自监督语音模型，WavShape推动了公平、隐私保护且高效的语音系统发展。

Abstract: Speech embeddings often retain sensitive attributes such as speaker identity,
accent, or demographic information, posing risks in biased model training and
privacy leakage. We propose WavShape, an information-theoretic speech
representation learning framework that optimizes embeddings for fairness and
privacy while preserving task-relevant information. We leverage mutual
information (MI) estimation using the Donsker-Varadhan formulation to guide an
MI-based encoder that systematically filters sensitive attributes while
maintaining speech content essential for downstream tasks. Experimental results
on three known datasets show that WavShape reduces MI between embeddings and
sensitive attributes by up to 81% while retaining 97% of task-relevant
information. By integrating information theory with self-supervised speech
models, this work advances the development of fair, privacy-aware, and
resource-efficient speech systems.

</details>


### [458] [A Self-Training Approach for Whisper to Enhance Long Dysarthric Speech Recognition](https://arxiv.org/abs/2506.22810)
*Shiyao Wang,Jiaming Zhou,Shiwan Zhao,Yong Qin*

Main category: cs.SD

TL;DR: 本文提出了一种改进的自训练方法，用于提升Whisper模型在长语音识别任务中的性能，特别是在针对构音障碍语音（DSR）的应用中。该方法在SAP挑战赛中取得了第二名的成绩。


<details>
  <summary>Details</summary>
Motivation: 现有的构音障碍语音数据集通常局限于孤立词、命令短语和少量句子，限制了研究的广度和深度。Speech Accessibility Project (SAP) 发布了一个大规模、多样化的数据集，为构建独立于说话者和文本的DSR系统提供了机会。

Method: 采用了一种新颖的自训练方法，通过增加训练数据并适应推理过程中可能遇到的不完整语音片段，改进了Whisper模型。

Result: 在SAP挑战赛中，该系统在词错误率（WER）和语义得分（Semantic Score）两项指标上均获得第二名。

Conclusion: 提出的自训练方法显著提升了Whisper模型在构音障碍语音识别任务中的性能，为未来的DSR研究提供了新的方向。

Abstract: Dysarthric speech recognition (DSR) enhances the accessibility of smart
devices for dysarthric speakers with limited mobility. Previously, DSR research
was constrained by the fact that existing datasets typically consisted of
isolated words, command phrases, and a limited number of sentences spoken by a
few individuals. This constrained research to command-interaction systems and
speaker adaptation. The Speech Accessibility Project (SAP) changed this by
releasing a large and diverse English dysarthric dataset, leading to the SAP
Challenge to build speaker- and text-independent DSR systems. We enhanced the
Whisper model's performance on long dysarthric speech via a novel self-training
method. This method increased training data and adapted the model to handle
potentially incomplete speech segments encountered during inference. Our system
achieved second place in both Word Error Rate and Semantic Score in the SAP
Challenge.

</details>


### [459] [TOMI: Transforming and Organizing Music Ideas for Multi-Track Compositions with Full-Song Structure](https://arxiv.org/abs/2506.23094)
*Qi He,Gus Xia,Ziyu Wang*

Main category: cs.SD

TL;DR: 论文提出了一种名为TOMI的深度音乐生成方法，通过概念层次结构生成和转换音乐创意，并利用指令调优的基础LLM模型实现多轨电子音乐的生成。


<details>
  <summary>Details</summary>
Motivation: 探索音乐生成中的概念层次结构，以提升音乐的结构连贯性和创意表达。

Method: 引入TOMI方法，通过四维空间（片段、段落、音轨、转换）表示多轨音乐生成过程，并基于指令调优的LLM模型实现。

Result: 实验表明，该方法生成的电子音乐质量更高，结构更连贯。

Conclusion: TOMI方法在音乐生成中表现出色，支持人机交互创作，具有实际应用潜力。

Abstract: Hierarchical planning is a powerful approach to model long sequences
structurally. Aside from considering hierarchies in the temporal structure of
music, this paper explores an even more important aspect: concept hierarchy,
which involves generating music ideas, transforming them, and ultimately
organizing them--across musical time and space--into a complete composition. To
this end, we introduce TOMI (Transforming and Organizing Music Ideas) as a
novel approach in deep music generation and develop a TOMI-based model via
instruction-tuned foundation LLM. Formally, we represent a multi-track
composition process via a sparse, four-dimensional space characterized by clips
(short audio or MIDI segments), sections (temporal positions), tracks
(instrument layers), and transformations (elaboration methods). Our model is
capable of generating multi-track electronic music with full-song structure,
and we further integrate the TOMI-based model with the REAPER digital audio
workstation, enabling interactive human-AI co-creation. Experimental results
demonstrate that our approach produces higher-quality electronic music with
stronger structural coherence compared to baselines.

</details>


### [460] [The Florence Price Art Song Dataset and Piano Accompaniment Generator](https://arxiv.org/abs/2506.23130)
*Tao-Tao He,Martin E. Malandro,Douglas Shadle*

Main category: cs.SD

TL;DR: 论文介绍了弗洛伦斯·B·普莱斯的音乐作品数字化及其风格伴奏生成模型的研究。


<details>
  <summary>Details</summary>
Motivation: 弗洛伦斯·B·普莱斯作为20世纪初的作曲家，其作品融合了美国南方文化、非洲传统和西方古典音乐，但长期被忽视。近年来她的音乐重新受到关注，本研究旨在通过数字化和生成模型推广其作品。

Method: 研究团队发布了112首普莱斯作品的数字目录（MuseScore、MusicXML、MIDI、PDF），并利用这些数据微调了一个符号音乐生成模型，用于生成旋律伴奏。

Result: 盲听实验表明，该模型生成的伴奏比基线模型更符合普莱斯的风格。

Conclusion: 研究成功创建了弗洛伦斯·普莱斯钢琴伴奏生成器，并公开了数据集和模型，有助于推广其音乐风格。

Abstract: Florence B. Price was a composer in the early 20th century whose music
reflects her upbringing in the American South, her African heritage, and her
Western classical training. She is noted as the first African-American woman to
have a symphony performed by a major orchestra. Her music has recently received
renewed attention from both the public and the research community, decades
after her death. In addition to other genres, Price was a prolific composer for
solo voice and piano. Music historians have documented the existence of 134 art
songs and piano/voice arrangements for spirituals and folk songs written by
Price. We release a digital catalog of 112 of these works in MuseScore,
MusicXML, MIDI, and PDF format. We also use this dataset to fine-tune a
symbolic music generation model to generate accompaniments to melodies, and we
conduct a blind listening experiment that shows that accompaniments generated
by our model are perceived as being reflective of Florence Price's style more
frequently than accompaniments generated by a baseline model. We release our
model as the Florence Price Piano Accompaniment Generator alongside our
dataset.

</details>


### [461] [XY-Tokenizer: Mitigating the Semantic-Acoustic Conflict in Low-Bitrate Speech Codecs](https://arxiv.org/abs/2506.23325)
*Yitian Gong,Luozhijie Jin,Ruifan Deng,Dong Zhang,Xin Zhang,Qinyuan Cheng,Zhaoye Fei,Shimin Li,Xipeng Qiu*

Main category: cs.SD

TL;DR: XY-Tokenizer是一种新型语音编解码器，通过多阶段多任务学习平衡语义丰富性和声学保真度，性能优于现有编解码器。


<details>
  <summary>Details</summary>
Motivation: 现有语音编解码器难以同时满足高质量音频重建和语言模型易建模的需求，需平衡语义和声学能力。

Method: 提出XY-Tokenizer，采用多阶段多任务学习缓解语义与声学能力的冲突。

Result: XY-Tokenizer在语义和声学任务中表现优异，文本对齐优于SpeechTokenizer和Mimi，声学重建性能接近BigCodec。

Conclusion: XY-Tokenizer在语义和声学任务中均达到先进水平，解决了现有编解码器的局限性。

Abstract: Speech codecs serve as bridges between speech signals and large language
models. An ideal codec for speech language models should not only preserve
acoustic information but also capture rich semantic information. However,
existing speech codecs struggle to balance high-quality audio reconstruction
with ease of modeling by language models. In this study, we analyze the
limitations of previous codecs in balancing semantic richness and acoustic
fidelity. We propose XY-Tokenizer, a novel codec that mitigates the conflict
between semantic and acoustic capabilities through multi-stage, multi-task
learning. Experimental results demonstrate that XY-Tokenizer achieves
performance in both semantic and acoustic tasks comparable to that of
state-of-the-art codecs operating at similar bitrates, even though those
existing codecs typically excel in only one aspect. Specifically, XY-Tokenizer
achieves strong text alignment, surpassing distillation-based semantic modeling
methods such as SpeechTokenizer and Mimi, while maintaining a speaker
similarity score of 0.83 between reconstructed and original audio. The
reconstruction performance of XY-Tokenizer is comparable to that of BigCodec,
the current state-of-the-art among acoustic-only codecs, which achieves a
speaker similarity score of 0.84 at a similar bitrate. Code and models are
available at https://github.com/gyt1145028706/XY-Tokenizer.

</details>


### [462] [You Sound a Little Tense: L2 Tailored Clear TTS Using Durational Vowel Properties](https://arxiv.org/abs/2506.23367)
*Paige Tuttösí,H. Henny Yeung,Yue Wang,Jean-Julien Aucouturier,Angelica Lim*

Main category: cs.SD

TL;DR: 本文提出了一种专为第二语言（L2）学习者设计的文本转语音（TTS）系统，通过调整元音时长提升清晰度，实验表明其效果优于整体语速减慢，但学习者未察觉此改进。


<details>
  <summary>Details</summary>
Motivation: 针对第二语言学习者在语音理解上的困难，设计一种更有效的TTS系统，提升其语音识别的准确性和体验。

Method: 利用美国英语中紧张元音（较长）和松弛元音（较短）的时长差异，为Matcha-TTS系统创建“清晰模式”。

Result: 实验显示，清晰模式使法语母语的英语学习者转录错误减少至少9.15%，且被认为更鼓舞人心和尊重，但学习者未意识到其实际效果。

Conclusion: 实际清晰度与感知清晰度不一致，且现有ASR系统（如Whisper）无法准确评估TTS对L2学习者的可理解性。

Abstract: We present the first text-to-speech (TTS) system tailored to second language
(L2) speakers. We use duration differences between American English tense
(longer) and lax (shorter) vowels to create a "clarity mode" for Matcha-TTS.
Our perception studies showed that French-L1, English-L2 listeners had fewer
(at least 9.15%) transcription errors when using our clarity mode, and found it
more encouraging and respectful than overall slowed down speech. Remarkably,
listeners were not aware of these effects: despite the decreased word error
rate in clarity mode, listeners still believed that slowing all target words
was the most intelligible, suggesting that actual intelligibility does not
correlate with perceived intelligibility. Additionally, we found that
Whisper-ASR did not use the same cues as L2 speakers to differentiate difficult
vowels and is not sufficient to assess the intelligibility of TTS systems for
these individuals.

</details>


### [463] [From Large-scale Audio Tagging to Real-Time Explainable Emergency Vehicle Sirens Detection](https://arxiv.org/abs/2506.23437)
*Stefano Giacomelli,Marco Giordano,Claudia Rinaldi,Fabio Graziosi*

Main category: cs.SD

TL;DR: E2PANNs是一种轻量级卷积神经网络，专为紧急车辆警笛检测优化，在计算效率和实时性能上表现优异。


<details>
  <summary>Details</summary>
Motivation: 智能交通系统和自动驾驶技术需要准确识别紧急车辆警笛，但现有方法缺乏大规模数据集且计算需求高。

Method: 基于PANNs框架开发E2PANNs，利用专用数据集AudioSet EV进行微调和评估，并通过边缘设备测试实时性能。

Result: E2PANNs在紧急车辆警笛检测领域达到新水平，计算高效且适合边缘设备应用。

Conclusion: E2PANNs为紧急车辆警笛检测提供了高效、轻量级的解决方案，适用于实时和关键安全应用。

Abstract: Accurate recognition of Emergency Vehicle (EV) sirens is critical for the
integration of intelligent transportation systems, smart city monitoring
systems, and autonomous driving technologies. Modern automatic solutions are
limited by the lack of large scale, curated datasets and by the computational
demands of state of the art sound event detection models. This work introduces
E2PANNs (Efficient Emergency Pre trained Audio Neural Networks), a lightweight
Convolutional Neural Network architecture derived from the PANNs framework,
specifically optimized for binary EV siren detection. Leveraging our dedicated
subset of AudioSet (AudioSet EV) we fine-tune and evaluate E2PANNs across
multiple reference datasets and test its viability on embedded hardware. The
experimental campaign includes ablation studies, cross-domain benchmarking, and
real-time inference deployment on edge device. Interpretability analyses
exploiting Guided Backpropagation and ScoreCAM algorithms provide insights into
the model internal representations and validate its ability to capture distinct
spectrotemporal patterns associated with different types of EV sirens. Real
time performance is assessed through frame wise and event based detection
metrics, as well as a detailed analysis of false positive activations. Results
demonstrate that E2PANNs establish a new state of the art in this research
domain, with high computational efficiency, and suitability for edge-based
audio monitoring and safety-critical applications.

</details>


### [464] [RELATE: Subjective evaluation dataset for automatic evaluation of relevance between text and audio](https://arxiv.org/abs/2506.23582)
*Yusuke Kanamori,Yuki Okamoto,Taisei Takano,Shinnosuke Takamichi,Yuki Saito,Hiroshi Saruwatari*

Main category: cs.SD

TL;DR: 构建RELATE数据集和预测模型，提升文本-音频相关性评估效率。


<details>
  <summary>Details</summary>
Motivation: 传统主观评估成本高，客观评估与主观评分相关性不明确。

Method: 构建RELATE数据集，并开发预测主观评分的模型。

Result: 模型优于传统CLAPScore，适用于多种声音类别。

Conclusion: RELATE数据集和模型为文本-音频相关性评估提供高效解决方案。

Abstract: In text-to-audio (TTA) research, the relevance between input text and output
audio is an important evaluation aspect. Traditionally, it has been evaluated
from both subjective and objective perspectives. However, subjective evaluation
is costly in terms of money and time, and objective evaluation is unclear
regarding the correlation to subjective evaluation scores. In this study, we
construct RELATE, an open-sourced dataset that subjectively evaluates the
relevance. Also, we benchmark a model for automatically predicting the
subjective evaluation score from synthesized audio. Our model outperforms a
conventional CLAPScore model, and that trend extends to many sound categories.

</details>


### [465] [Efficient Interleaved Speech Modeling through Knowledge Distillation](https://arxiv.org/abs/2506.23670)
*Mohammadmahdi Nouriborji,Morteza Rohanian*

Main category: cs.SD

TL;DR: 论文提出了一种通过层对齐蒸馏方法压缩大型多模态Transformer的紧凑语音生成模型TinyWave，性能损失极小，适用于实时应用。


<details>
  <summary>Details</summary>
Motivation: 当前语音语言模型在部署环境中面临尺寸和延迟限制，需要更紧凑且高效的模型。

Method: 采用层对齐蒸馏技术，匹配隐藏状态、注意力图和软化logits，压缩模型至3倍，训练了50,000小时公开音频数据。

Result: TinyWave在Libri-Light上仅比教师模型低1.4个归一化困惑度点，在StoryCloze和SALMon任务上达到教师模型93-97%的准确率。

Conclusion: TinyWave适用于实时对话代理、辅助技术和低资源环境，模型和代码已开源。

Abstract: Current speech language models exceed the size and latency constraints of
many deployment environments. We build compact, expressive speech generation
models through layer-aligned distillation, matching hidden states, attention
maps, and softened logits to compress large multimodal transformers by 3x with
minimal loss in performance. We introduce TinyWave, a family of 2B-parameter
models for speech-to-speech and interleaved speech-text generation, trained on
50,000 hours of public audio. TinyWave supports (i) speech-only generation
using phonetic or expressive tokens and (ii) mixed speech-text continuations.
Evaluation on Libri-Light shows TinyWave within 1.4 normalized perplexity
points of its teacher. Accuracy on spoken StoryCloze and SALMon reaches 93-97%
of the teacher's performance, outperforming size-matched baselines. These
models are optimized for deployment on commodity hardware, enabling
applications in real-time conversational agents, assistive technologies, and
low-resource environments. We release models, training code, and evaluation
scripts to support reproducible research on compact, expressive speech
generation.

</details>


### [466] [Scaling Self-Supervised Representation Learning for Symbolic Piano Performance](https://arxiv.org/abs/2506.23869)
*Louis Bradshaw,Honglu Fan,Alexander Spangher,Stella Biderman,Simon Colton*

Main category: cs.SD

TL;DR: 研究了基于大量钢琴符号转录的自回归Transformer生成模型，通过预训练和微调在音乐生成和分类任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 探索生成模型在符号音乐领域的潜力，特别是在钢琴音乐生成和分类任务中的应用。

Method: 预训练60,000小时音乐数据，微调高质量子集，结合SimCLR框架生成对比MIDI嵌入。

Result: 生成模型在钢琴音乐连贯性上优于现有符号生成技术，对比模型在分类任务中达到SOTA。

Conclusion: 预训练模型在符号音乐任务中具有强大潜力，微调后能高效适应下游任务。

Abstract: We study the capabilities of generative autoregressive transformer models
trained on large amounts of symbolic solo-piano transcriptions. After first
pretraining on approximately 60,000 hours of music, we use a comparatively
smaller, high-quality subset, to finetune models to produce musical
continuations, perform symbolic classification tasks, and produce
general-purpose contrastive MIDI embeddings by adapting the SimCLR framework to
symbolic music. When evaluating piano continuation coherence, our generative
model outperforms leading symbolic generation techniques and remains
competitive with proprietary audio generation models. On MIR classification
benchmarks, frozen representations from our contrastive model achieve
state-of-the-art results in linear probe experiments, while direct finetuning
demonstrates the generalizability of pretrained representations, often
requiring only a few hundred labeled examples to specialize to downstream
tasks.

</details>


### [467] [Emergent musical properties of a transformer under contrastive self-supervised learning](https://arxiv.org/abs/2506.23873)
*Yuexuan Kong,Gabriel Meseguer-Brocal,Vincent Lostanlen,Mathieu Lagrange,Romain Hennequin*

Main category: cs.SD

TL;DR: 论文挑战了对比自监督学习在局部音乐信息检索任务中表现不佳的假设，通过ViT-1D模型展示了其在局部任务中的潜力。


<details>
  <summary>Details</summary>
Motivation: 探索对比自监督学习与Transformer结合在局部音乐信息检索任务中的表现，挑战传统认为其不适用的观点。

Method: 使用一维时间-频率域ViT-1D模型，通过NT-Xent损失进行对比自监督学习。

Result: 序列令牌在局部任务中表现优异，且模型捕捉到高级音乐特征（如onset）。

Conclusion: 对比自监督学习与Transformer结合在音乐序列建模中具有被忽视的能力，为音乐理解提供了新视角。

Abstract: In music information retrieval (MIR), contrastive self-supervised learning
for general-purpose representation models is effective for global tasks such as
automatic tagging. However, for local tasks such as chord estimation, it is
widely assumed that contrastively trained general-purpose self-supervised
models are inadequate and that more sophisticated SSL is necessary; e.g.,
masked modeling. Our paper challenges this assumption by revealing the
potential of contrastive SSL paired with a transformer in local MIR tasks. We
consider a lightweight vision transformer with one-dimensional patches in the
time--frequency domain (ViT-1D) and train it with simple contrastive SSL
through normalized temperature-scaled cross-entropy loss (NT-Xent). Although
NT-Xent operates only over the class token, we observe that, potentially thanks
to weight sharing, informative musical properties emerge in ViT-1D's sequence
tokens. On global tasks, the temporal average of class and sequence tokens
offers a performance increase compared to the class token alone, showing useful
properties in the sequence tokens. On local tasks, sequence tokens perform
unexpectedly well, despite not being specifically trained for. Furthermore,
high-level musical features such as onsets emerge from layer-wise attention
maps and self-similarity matrices show different layers capture different
musical dimensions. Our paper does not focus on improving performance but
advances the musical interpretation of transformers and sheds light on some
overlooked abilities of contrastive SSL paired with transformers for sequence
modeling in MIR.

</details>


### [468] [StreamFlow: Streaming Flow Matching with Block-wise Guided Attention Mask for Speech Token Decoding](https://arxiv.org/abs/2506.23986)
*Dake Guo,Jixun Yao,Linhan Ma,Wang He,Lei Xie*

Main category: cs.SD

TL;DR: StreamFlow是一种新型神经架构，通过扩散变换器（DiT）实现流式流匹配，解决了传统方法在流式语音生成中的音频质量下降问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖全局感受野，难以实现流式能力，且逐令牌流式生成常导致音频质量下降。

Method: 提出StreamFlow，采用局部块级感受野策略和分层注意力掩码，调节DiT的感受野。

Result: 实验表明，StreamFlow在语音质量上与非流式方法相当，优于其他流式方法，且首次包延迟仅180毫秒。

Conclusion: StreamFlow有效解决了流式语音生成的挑战，平衡了音频质量和实时性。

Abstract: Recent advancements in discrete token-based speech generation have
highlighted the importance of token-to-waveform generation for audio quality,
particularly in real-time interactions. Traditional frameworks integrating
semantic tokens with flow matching (FM) struggle with streaming capabilities
due to their reliance on a global receptive field. Additionally, directly
implementing token-by-token streaming speech generation often results in
degraded audio quality. To address these challenges, we propose StreamFlow, a
novel neural architecture that facilitates streaming flow matching with
diffusion transformers (DiT). To mitigate the long-sequence extrapolation
issues arising from lengthy historical dependencies, we design a local
block-wise receptive field strategy. Specifically, the sequence is first
segmented into blocks, and we introduce block-wise attention masks that enable
the current block to receive information from the previous or subsequent block.
These attention masks are combined hierarchically across different DiT-blocks
to regulate the receptive field of DiTs. Both subjective and objective
experimental results demonstrate that our approach achieves performance
comparable to non-streaming methods while surpassing other streaming methods in
terms of speech quality, all the while effectively managing inference time
during long-sequence generation. Furthermore, our method achieves a notable
first-packet latency of only 180 ms.\footnote{Speech samples:
https://dukguo.github.io/StreamFlow/}

</details>


### [469] [Aria-MIDI: A Dataset of Piano MIDI Files for Symbolic Music Modeling](https://arxiv.org/abs/2504.15071)
*Louis Bradshaw,Simon Colton*

Main category: cs.SD

TL;DR: 论文介绍了一个通过音频转录生成的大规模MIDI数据集，包含100万份文件，约10万小时的钢琴演奏音频。


<details>
  <summary>Details</summary>
Motivation: 创建大规模、高质量的MIDI数据集以支持音乐研究和生成任务。

Method: 采用多阶段数据处理流程，包括语言模型爬取音频、音频分类器修剪与分段。

Result: 生成了包含100万份MIDI文件的数据集，并提供统计分析和元数据标签。

Conclusion: 该数据集为音乐研究和生成任务提供了丰富资源，技术方法具有可扩展性。

Abstract: We introduce an extensive new dataset of MIDI files, created by transcribing
audio recordings of piano performances into their constituent notes. The data
pipeline we use is multi-stage, employing a language model to autonomously
crawl and score audio recordings from the internet based on their metadata,
followed by a stage of pruning and segmentation using an audio classifier. The
resulting dataset contains over one million distinct MIDI files, comprising
roughly 100,000 hours of transcribed audio. We provide an in-depth analysis of
our techniques, offering statistical insights, and investigate the content by
extracting metadata tags, which we also provide. Dataset available at
https://github.com/loubbrad/aria-midi.

</details>
