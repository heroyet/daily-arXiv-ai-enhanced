<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 85]
- [cs.GT](#cs.GT) [Total: 3]
- [cs.HC](#cs.HC) [Total: 11]
- [cs.SD](#cs.SD) [Total: 4]
- [cs.RO](#cs.RO) [Total: 36]
- [cs.NE](#cs.NE) [Total: 2]
- [cs.LG](#cs.LG) [Total: 52]
- [eess.SY](#eess.SY) [Total: 9]
- [cs.GR](#cs.GR) [Total: 4]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Fine-Grained Preference Optimization Improves Spatial Reasoning in VLMs](https://arxiv.org/abs/2506.21656)
*Yifan Shen,Yuanzhe Liu,Jingyuan Zhu,Xu Cao,Xiaofeng Zhang,Yixiao He,Wenming Ye,James Matthew Rehg,Ismini Lourentzou*

Main category: cs.CV

TL;DR: SpatialReasoner-R1通过M3CTS生成高质量空间推理监督，结合fDPO优化细粒度偏好，显著提升空间推理任务性能。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在细粒度空间推理和多步逻辑对齐方面表现不足，需改进。

Method: 采用M3CTS生成多样且逻辑一致的LongCoT推理轨迹，提出fDPO优化细粒度偏好，结合空间奖励机制评估响应。

Result: fDPO在空间质量和数量任务上分别提升4.1%和9.0%，SpatialReasoner-R1在SPATIALRGPT-Bench上领先基线9.8%。

Conclusion: SpatialReasoner-R1在空间推理任务中表现优异，同时保持通用视觉语言任务的竞争力。

Abstract: Current Vision-Language Models (VLMs) struggle with fine-grained spatial
reasoning, particularly when multi-step logic and precise spatial alignment are
required. In this work, we introduce SpatialReasoner-R1, a vision-language
reasoning model designed to address these limitations. To construct
high-quality supervision for spatial reasoning, we design a Multi-Model Monte
Carlo Tree Search (M3CTS) method that generates diverse, logically consistent
Long Chain-of-Thought (LongCoT) reasoning trajectories. In addition, we propose
fine-grained Direct Preference Optimization (fDPO), which introduces
segment-specific preference granularity for descriptive grounding and logical
reasoning, guided by a spatial reward mechanism that evaluates candidate
responses based on visual consistency, spatial grounding, and logical
coherence. Experimental results demonstrate that fDPO achieves an average
improvement of 4.1% over standard DPO across spatial quality tasks, and a 9.0%
gain in spatial quantity tasks. SpatialReasoner-R1, trained with fDPO, sets a
new SoTA on SPATIALRGPT-Bench, outperforming the strongest baseline by 9.8% in
average accuracy, while maintaining competitive performance on general
vision-language tasks.

</details>


### [2] [ADNet: Leveraging Error-Bias Towards Normal Direction in Face Alignment](https://arxiv.org/abs/2109.05721)
*Yangyu Huang,Hao Yang,Chong Li,Jongyoo Kim,Fangyun Wei*

Main category: cs.CV

TL;DR: 论文提出ADL和AAM方法解决人脸对齐中的误差偏差问题，通过ADNet实现端到端训练，在多个数据集上达到最优性能。


<details>
  <summary>Details</summary>
Motivation: 人脸对齐中误差分布存在偏差，沿切线方向扩散，影响模型收敛。

Method: 提出各向异性方向损失（ADL）和各向异性注意力模块（AAM），分别用于坐标和热图回归。

Result: ADNet在300W、WFLW和COFW数据集上取得最优结果。

Conclusion: ADL和AAM互补学习人脸结构和纹理细节，ADNet表现出高效性和鲁棒性。

Abstract: The recent progress of CNN has dramatically improved face alignment
performance. However, few works have paid attention to the error-bias with
respect to error distribution of facial landmarks. In this paper, we
investigate the error-bias issue in face alignment, where the distributions of
landmark errors tend to spread along the tangent line to landmark curves. This
error-bias is not trivial since it is closely connected to the ambiguous
landmark labeling task. Inspired by this observation, we seek a way to leverage
the error-bias property for better convergence of CNN model. To this end, we
propose anisotropic direction loss (ADL) and anisotropic attention module (AAM)
for coordinate and heatmap regression, respectively. ADL imposes strong binding
force in normal direction for each landmark point on facial boundaries. On the
other hand, AAM is an attention module which can get anisotropic attention mask
focusing on the region of point and its local edge connected by adjacent
points, it has a stronger response in tangent than in normal, which means
relaxed constraints in the tangent. These two methods work in a complementary
manner to learn both facial structures and texture details. Finally, we
integrate them into an optimized end-to-end training pipeline named ADNet. Our
ADNet achieves state-of-the-art results on 300W, WFLW and COFW datasets, which
demonstrates the effectiveness and robustness.

</details>


### [3] [TanDiT: Tangent-Plane Diffusion Transformer for High-Quality 360° Panorama Generation](https://arxiv.org/abs/2506.21681)
*Hakan Çapuk,Andrew Bond,Muhammed Burak Kızıl,Emir Göçen,Erkut Erdem,Aykut Erdem*

Main category: cs.CV

TL;DR: TanDiT是一种新方法，通过生成覆盖360度视角的切平面图像网格来合成全景场景，解决了现有模型在全景图像生成中的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有图像生成模型在全景图像生成中存在几何失真和循环一致性要求等独特挑战，TanDiT旨在解决这些问题。

Method: TanDiT使用统一的扩散模型在单次去噪迭代中同时生成切平面图像，并提出模型无关的后处理步骤以增强全局一致性。

Result: 实验表明，TanDiT能有效泛化到训练数据之外，处理复杂文本提示，并与多种生成模型集成，生成高质量全景图像。

Conclusion: TanDiT通过创新方法解决了全景图像生成的挑战，并提供了专用评估指标和基准，推动了该领域的发展。

Abstract: Recent advances in image generation have led to remarkable improvements in
synthesizing perspective images. However, these models still struggle with
panoramic image generation due to unique challenges, including varying levels
of geometric distortion and the requirement for seamless loop-consistency. To
address these issues while leveraging the strengths of the existing models, we
introduce TanDiT, a method that synthesizes panoramic scenes by generating
grids of tangent-plane images covering the entire 360$^\circ$ view. Unlike
previous methods relying on multiple diffusion branches, TanDiT utilizes a
unified diffusion model trained to produce these tangent-plane images
simultaneously within a single denoising iteration. Furthermore, we propose a
model-agnostic post-processing step specifically designed to enhance global
coherence across the generated panoramas. To accurately assess panoramic image
quality, we also present two specialized metrics, TangentIS and TangentFID, and
provide a comprehensive benchmark comprising captioned panoramic datasets and
standardized evaluation scripts. Extensive experiments demonstrate that our
method generalizes effectively beyond its training data, robustly interprets
detailed and complex text prompts, and seamlessly integrates with various
generative models to yield high-quality, diverse panoramic images.

</details>


### [4] [FreeEnricher: Enriching Face Landmarks without Additional Cost](https://arxiv.org/abs/2212.09525)
*Yangyu Huang,Xi Chen,Jongyoo Kim,Hao Yang,Chong Li,Jiaolong Yang,Dong Chen*

Main category: cs.CV

TL;DR: 提出了一种通过稀疏标记数据集生成密集面部标记的框架，无需额外成本即可提升现有面部对齐网络的性能。


<details>
  <summary>Details</summary>
Motivation: 密集面部标记在美容医学和面部美化等场景中需求高，但现有研究多集中于稀疏标记。

Method: 利用稀疏标记数据集（如300W和WFLW），通过弱监督学习细化能力并适应密集标记，设计多个操作符实现这一目标。

Result: 在密集300W测试集及原始稀疏300W和WFLW测试集上均达到最先进精度。

Conclusion: 该框架可作为即插即用模块，显著提升面部对齐任务的标记密度和精度。

Abstract: Recent years have witnessed significant growth of face alignment. Though
dense facial landmark is highly demanded in various scenarios, e.g., cosmetic
medicine and facial beautification, most works only consider sparse face
alignment. To address this problem, we present a framework that can enrich
landmark density by existing sparse landmark datasets, e.g., 300W with 68
points and WFLW with 98 points. Firstly, we observe that the local patches
along each semantic contour are highly similar in appearance. Then, we propose
a weakly-supervised idea of learning the refinement ability on original sparse
landmarks and adapting this ability to enriched dense landmarks. Meanwhile,
several operators are devised and organized together to implement the idea.
Finally, the trained model is applied as a plug-and-play module to the existing
face alignment networks. To evaluate our method, we manually label the dense
landmarks on 300W testset. Our method yields state-of-the-art accuracy not only
in newly-constructed dense 300W testset but also in the original sparse 300W
and WFLW testsets without additional cost.

</details>


### [5] [FOCUS: Internal MLLM Representations for Efficient Fine-Grained Visual Question Answering](https://arxiv.org/abs/2506.21710)
*Liangyu Zhong,Fabio Rosenthal,Joachim Sicking,Fabian Hüger,Thorsten Bagdonat,Hanno Gottschalk,Leo Schwinn*

Main category: cs.CV

TL;DR: FOCUS是一种无需训练的视觉裁剪方法，利用MLLM内部表示引导搜索最相关图像区域，显著提升细粒度VQA任务的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉裁剪方法在细粒度VQA任务中的局限性，如需要任务特定微调、低效的盲目搜索或与高效注意力实现不兼容。

Method: 通过四步实现：识别VQA提示中的目标对象，利用KV缓存计算对象相关性图，提出并排序相关图像区域，最后使用排名最高的区域执行细粒度VQA任务。

Result: 在四个细粒度VQA数据集和两种MLLM上表现优异，优于三种流行视觉裁剪方法，计算量减少3-6.5倍。

Conclusion: FOCUS通过智能搜索策略显著提升了细粒度VQA任务的效率和准确性。

Abstract: While Multimodal Large Language Models (MLLMs) offer strong perception and
reasoning capabilities for image-text input, Visual Question Answering (VQA)
focusing on small image details still remains a challenge. Although visual
cropping techniques seem promising, recent approaches have several limitations:
the need for task-specific fine-tuning, low efficiency due to uninformed
exhaustive search, or incompatibility with efficient attention implementations.
We address these shortcomings by proposing a training-free visual cropping
method, dubbed FOCUS, that leverages MLLM-internal representations to guide the
search for the most relevant image region. This is accomplished in four steps:
first, we identify the target object(s) in the VQA prompt; second, we compute
an object relevance map using the key-value (KV) cache; third, we propose and
rank relevant image regions based on the map; and finally, we perform the
fine-grained VQA task using the top-ranked region. As a result of this informed
search strategy, FOCUS achieves strong performance across four fine-grained VQA
datasets and two types of MLLMs. It outperforms three popular visual cropping
methods in both accuracy and efficiency, and matches the best-performing
baseline, ZoomEye, while requiring 3 - 6.5 x less compute.

</details>


### [6] [CAST: Cross-Attentive Spatio-Temporal feature fusion for Deepfake detection](https://arxiv.org/abs/2506.21711)
*Aryan Thakre,Omkar Nagwekar,Vedang Talekar,Aparna Santra Biswas*

Main category: cs.CV

TL;DR: 提出了一种名为CAST的统一模型，利用交叉注意力机制融合时空特征，显著提升了深度伪造视频检测的性能。


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术对数字媒体真实性构成威胁，现有CNN-Transformer模型在时空特征融合上存在局限性，需要更高效的交互方式。

Method: 提出CAST模型，通过交叉注意力机制动态融合时空特征，增强对细微时间演化伪造痕迹的检测能力。

Result: 在FaceForensics++、Celeb-DF和DeepfakeDetection数据集上表现优异，AUC达99.49%，准确率97.57%。跨数据集测试AUC为93.31%。

Conclusion: 交叉注意力机制显著提升了深度伪造检测的鲁棒性和泛化能力。

Abstract: Deepfakes have emerged as a significant threat to digital media authenticity,
increasing the need for advanced detection techniques that can identify subtle
and time-dependent manipulations. CNNs are effective at capturing spatial
artifacts, and Transformers excel at modeling temporal inconsistencies.
However, many existing CNN-Transformer models process spatial and temporal
features independently. In particular, attention-based methods often use
separate attention mechanisms for spatial and temporal features and combine
them using naive approaches like averaging, addition, or concatenation, which
limits the depth of spatio-temporal interaction. To address this challenge, we
propose a unified CAST model that leverages cross-attention to effectively fuse
spatial and temporal features in a more integrated manner. Our approach allows
temporal features to dynamically attend to relevant spatial regions, enhancing
the model's ability to detect fine-grained, time-evolving artifacts such as
flickering eyes or warped lips. This design enables more precise localization
and deeper contextual understanding, leading to improved performance across
diverse and challenging scenarios. We evaluate the performance of our model
using the FaceForensics++, Celeb-DF, and DeepfakeDetection datasets in both
intra- and cross-dataset settings to affirm the superiority of our approach.
Our model achieves strong performance with an AUC of 99.49 percent and an
accuracy of 97.57 percent in intra-dataset evaluations. In cross-dataset
testing, it demonstrates impressive generalization by achieving a 93.31 percent
AUC on the unseen DeepfakeDetection dataset. These results highlight the
effectiveness of cross-attention-based feature fusion in enhancing the
robustness of deepfake video detection.

</details>


### [7] [Elucidating and Endowing the Diffusion Training Paradigm for General Image Restoration](https://arxiv.org/abs/2506.21722)
*Xin Lu,Xueyang Fu,Jie Xiao,Zihao Fan,Yurui Zhu,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: 本文提出了一种将扩散训练范式融入普通图像修复（IR）框架的方法，通过系统分析时间步依赖、网络层次等关键原则，并引入正则化策略和增量训练范式，显著提升了单任务和多任务IR的性能。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像修复任务中表现出强大的生成能力，但其复杂架构和迭代过程限制了实际应用。现有方法主要关注网络架构优化，而忽视了扩散训练范式与普通IR框架的整合。

Method: 通过分析时间步依赖、网络层次等关键原则，提出新的IR框架，并引入正则化策略和增量训练范式，结合任务特定适配器。

Result: 实验表明，该方法显著提升了单任务IR的泛化能力，并在多任务统一IR中实现了优越性能。

Conclusion: 所提出的框架可以无缝集成到现有普通IR架构中，为扩散训练范式在IR任务中的应用提供了有效解决方案。

Abstract: While diffusion models demonstrate strong generative capabilities in image
restoration (IR) tasks, their complex architectures and iterative processes
limit their practical application compared to mainstream reconstruction-based
general ordinary IR networks. Existing approaches primarily focus on optimizing
network architecture and diffusion paths but overlook the integration of the
diffusion training paradigm within general ordinary IR frameworks. To address
these challenges, this paper elucidates key principles for adapting the
diffusion training paradigm to general IR training through systematic analysis
of time-step dependencies, network hierarchies, noise-level relationships, and
multi-restoration task correlations, proposing a new IR framework supported by
diffusion-based training. To enable IR networks to simultaneously restore
images and model generative representations, we introduce a series of
regularization strategies that align diffusion objectives with IR tasks,
improving generalization in single-task scenarios. Furthermore, recognizing
that diffusion-based generation exerts varying influences across different IR
tasks, we develop an incremental training paradigm and task-specific adaptors,
further enhancing performance in multi-task unified IR. Experiments demonstrate
that our method significantly improves the generalization of IR networks in
single-task IR and achieves superior performance in multi-task unified IR.
Notably, the proposed framework can be seamlessly integrated into existing
general IR architectures.

</details>


### [8] [Asymmetric Dual Self-Distillation for 3D Self-Supervised Representation Learning](https://arxiv.org/abs/2506.21724)
*Remco F. Leijenaar,Hamidreza Kasaei*

Main category: cs.CV

TL;DR: 提出了一种名为AsymDSD的自监督学习框架，通过潜在空间预测结合掩码建模和不变性学习，显著提升了3D点云语义表示的性能。


<details>
  <summary>Details</summary>
Motivation: 解决无标签大规模3D点云数据下语义表示学习的挑战，避免传统掩码点建模（MPM）因基于重构目标而难以捕获高层语义的问题。

Method: 采用非对称双自蒸馏框架（AsymDSD），结合潜在空间预测、多掩码采样和多裁剪点云适配等设计，避免形状泄漏并提升效率。

Result: 在ScanObjectNN上达到90.53%的准确率，预训练后提升至93.72%，优于现有方法。

Conclusion: AsymDSD通过创新设计显著提升了3D点云语义表示的性能，为自监督学习提供了新思路。

Abstract: Learning semantically meaningful representations from unstructured 3D point
clouds remains a central challenge in computer vision, especially in the
absence of large-scale labeled datasets. While masked point modeling (MPM) is
widely used in self-supervised 3D learning, its reconstruction-based objective
can limit its ability to capture high-level semantics. We propose AsymDSD, an
Asymmetric Dual Self-Distillation framework that unifies masked modeling and
invariance learning through prediction in the latent space rather than the
input space. AsymDSD builds on a joint embedding architecture and introduces
several key design choices: an efficient asymmetric setup, disabling attention
between masked queries to prevent shape leakage, multi-mask sampling, and a
point cloud adaptation of multi-crop. AsymDSD achieves state-of-the-art results
on ScanObjectNN (90.53%) and further improves to 93.72% when pretrained on 930k
shapes, surpassing prior methods.

</details>


### [9] [Exploring Image Generation via Mutually Exclusive Probability Spaces and Local Correlation Hypothesis](https://arxiv.org/abs/2506.21731)
*Chenqiu Zhao,Anup Basu*

Main category: cs.CV

TL;DR: 论文提出MESP和LCH两个理论框架，探讨概率生成模型的局限性，即全局分布学习导致记忆而非生成行为。基于MESP提出BL-AE和ARVM，实验显示ARVM性能优越但存在记忆问题，LCH假设局部相关性提升生成能力。


<details>
  <summary>Details</summary>
Motivation: 研究概率生成模型中全局分布学习导致记忆而非生成行为的潜在局限性。

Method: 提出MESP框架，重新思考VAE的潜在变量分布重叠问题，提出基于重叠系数的下界；基于MESP设计BL-AE和ARVM模型；提出LCH假设，强调局部相关性对生成能力的影响。

Result: ARVM在标准数据集上取得竞争性FID分数，但反映记忆问题；LCH假设通过实验验证局部相关性对生成能力的提升。

Conclusion: MESP和LCH框架揭示了概率生成模型的局限性，并提出改进方向，局部相关性是提升生成能力的关键。

Abstract: We propose two theoretical frameworks, the Mutually Exclusive Probability
Space (MESP) and the Local Correlation Hypothesis (LCH), to explore a potential
limitation in probabilistic generative models; namely that learning global
distributions leads to memorization rather than generative behavior. MESP
emerges from our rethinking of the Variational Autoencoder (VAE). We observe
that latent variable distributions in VAE exhibit overlap, which leads to an
optimization conflict between the reconstruction loss and KL-divergence loss. A
lower bound based on the overlap coefficient is proposed. We refer to this
phenomenon as Mutually Exclusive Probability Spaces. Based on MESP, a Binary
Latent Autoencoder (BL-AE) is proposed to encode images into binary latent
representations. These binary latents are used as the input to our
Autoregressive Random Variable Model (ARVM), a modified autoregressive model
outputting histograms. Our ARVM achieves competitive FID scores, outperforming
state-of-the-art methods on standard datasets. However, such scores reflect
memorization rather than generation. To address this issue, we propose the
Local Correlation Hypothesis (LCH), which posits that generative capability
arising from local correlations among latent variables. Comprehensive
experiments and discussions are conducted to validate our frameworks.

</details>


### [10] [Equitable Federated Learning with NCA](https://arxiv.org/abs/2506.21735)
*Nick Lemke,Mirko Konstantin,Henry John Krumb,John Kalkhof,Jonathan Stieber,Anirban Mukhopadhyay*

Main category: cs.CV

TL;DR: FedNCA是一种专为医疗图像分割设计的联邦学习系统，适用于资源有限的地区，解决了计算和网络限制问题。


<details>
  <summary>Details</summary>
Motivation: 在低收入和中等收入国家（LMICs），医疗资源有限，联邦学习（FL）可以协作训练模型而不共享敏感数据，但面临计算和网络障碍。

Method: 提出FedNCA系统，基于轻量级Med-NCA架构，支持低成本边缘设备（如智能手机）训练，并减少通信开销，同时具备加密能力。

Result: FedNCA在资源受限环境中高效运行，解决了基础设施和安全问题。

Conclusion: FedNCA为资源有限地区提供了高效、轻量级且安全的医疗影像解决方案，推动医疗公平。

Abstract: Federated Learning (FL) is enabling collaborative model training across
institutions without sharing sensitive patient data. This approach is
particularly valuable in low- and middle-income countries (LMICs), where access
to trained medical professionals is limited. However, FL adoption in LMICs
faces significant barriers, including limited high-performance computing
resources and unreliable internet connectivity. To address these challenges, we
introduce FedNCA, a novel FL system tailored for medical image segmentation
tasks. FedNCA leverages the lightweight Med-NCA architecture, enabling training
on low-cost edge devices, such as widely available smartphones, while
minimizing communication costs. Additionally, our encryption-ready FedNCA
proves to be suitable for compromised network communication. By overcoming
infrastructural and security challenges, FedNCA paves the way for inclusive,
efficient, lightweight, and encryption-ready medical imaging solutions,
fostering equitable healthcare advancements in resource-constrained regions.

</details>


### [11] [ImplicitQA: Going beyond frames towards Implicit Video Reasoning](https://arxiv.org/abs/2506.21742)
*Sirnam Swetha,Rohit Gupta,Parth Parag Kulkarni,David G Shatwell,Jeffrey A Chan Santiago,Nyle Siddiqui,Joseph Fioresi,Mubarak Shah*

Main category: cs.CV

TL;DR: 论文提出了ImplicitQA，一个专注于测试视频问答中隐式推理能力的新基准，填补了现有系统在理解复杂叙事内容上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有视频问答基准主要关注显式视觉内容，而忽略了人类擅长的隐式推理能力，如动机、因果关系等。

Method: 构建了包含1K高质量QA对的ImplicitQA基准，涵盖多种推理维度，并通过系统评估现有模型。

Result: 评估显示现有模型在隐式推理任务上表现不佳，依赖表层视觉线索。

Conclusion: ImplicitQA为社区提供了新挑战，促进视频问答系统在隐式推理方向的发展。

Abstract: Video QA has made significant strides by leveraging multimodal learning to
align visual and textual modalities. However, current benchmarks overwhelmingly
focus on questions answerable through explicit visual content - actions,
objects & events directly observable within individual frames or short clips.
In contrast, creative and cinematic videos - such as movies, TV shows, and
narrative-driven content - employ storytelling techniques that deliberately
omit certain depictions, requiring viewers to infer motives, causality, and
relationships across discontinuous frames. Humans naturally excel at such
implicit reasoning, seamlessly integrating information across time and context
to construct coherent narratives. Current VideoQA systems and benchmarks fail
to capture this essential dimension of human-like understanding. To bridge this
gap, we present ImplicitQA, a novel benchmark specifically designed to test
models on implicit reasoning. It comprises 1K meticulously annotated QA pairs
derived from 320+ high-quality creative video clips, systematically categorized
into key reasoning dimensions: lateral and vertical spatial reasoning, depth
and proximity, viewpoint and visibility, motion and trajectory, causal and
motivational reasoning, social interactions, physical context, and inferred
counting. These annotations are deliberately challenging, crafted by authors
ensuring high-quality. Our extensive evaluations on leading VideoQA models
reveals performance degradation, underscoring their reliance on surface-level
visual cues and highlighting the difficulty of implicit reasoning. Performance
variations across models further illustrate the complexity and diversity of the
challenges presented by ImplicitQA. By releasing both the dataset and our data
collection framework, we aim to stimulate further research and development in
the community. https://huggingface.co/datasets/ucf-crcv/ImplicitQA.

</details>


### [12] [Early Glaucoma Detection using Deep Learning with Multiple Datasets of Fundus Images](https://arxiv.org/abs/2506.21770)
*Rishiraj Paul Chowdhury,Nirmit Shekar Karkera*

Main category: cs.CV

TL;DR: 提出了一种基于EfficientNet-B0的深度学习流程，用于从视网膜眼底图像中检测青光眼，通过多数据集训练提升泛化能力，实验表明简单预处理效果更优。


<details>
  <summary>Details</summary>
Motivation: 青光眼是导致不可逆失明的主要原因，早期检测对治疗效果至关重要。传统方法通常具有侵入性且需要专业设备。

Method: 使用EfficientNet-B0架构，通过ACRIMA、ORIGA和RIM-ONE数据集进行顺序训练和微调，以增强泛化能力。

Result: 实验显示，简单预处理比复杂增强方法具有更高的AUC-ROC，模型在未见数据集上表现出强判别性能。

Conclusion: 该流程为青光眼早期检测提供了可重复且可扩展的方法，具有潜在临床价值。

Abstract: Glaucoma is a leading cause of irreversible blindness, but early detection
can significantly improve treatment outcomes. Traditional diagnostic methods
are often invasive and require specialized equipment. In this work, we present
a deep learning pipeline using the EfficientNet-B0 architecture for glaucoma
detection from retinal fundus images. Unlike prior studies that rely on single
datasets, we sequentially train and fine-tune our model across ACRIMA, ORIGA,
and RIM-ONE datasets to enhance generalization. Our experiments show that
minimal preprocessing yields higher AUC-ROC compared to more complex
enhancements, and our model demonstrates strong discriminative performance on
unseen datasets. The proposed pipeline offers a reproducible and scalable
approach to early glaucoma detection, supporting its potential clinical
utility.

</details>


### [13] [Comparing Learning Paradigms for Egocentric Video Summarization](https://arxiv.org/abs/2506.21785)
*Daniel Wen*

Main category: cs.CV

TL;DR: 研究比较了监督学习、无监督学习和提示微调在自我中心视频理解中的表现，发现GPT-4o优于专用模型，但现有方法在自我中心视频领域仍有局限。


<details>
  <summary>Details</summary>
Motivation: 探索计算机视觉技术在自我中心视频中的应用，推动该领域的发展。

Method: 评估了三种方法（监督学习、无监督学习和提示微调）在自我中心视频摘要任务中的表现。

Result: GPT-4o表现优于专用模型，但现有方法在自我中心视频中效果较差。

Conclusion: 需进一步改进模型以适应自我中心视频的独特挑战。

Abstract: In this study, we investigate various computer vision paradigms - supervised
learning, unsupervised learning, and prompt fine-tuning - by assessing their
ability to understand and interpret egocentric video data. Specifically, we
examine Shotluck Holmes (state-of-the-art supervised learning), TAC-SUM
(state-of-the-art unsupervised learning), and GPT-4o (a prompt fine-tuned
pre-trained model), evaluating their effectiveness in video summarization. Our
results demonstrate that current state-of-the-art models perform less
effectively on first-person videos compared to third-person videos,
highlighting the need for further advancements in the egocentric video domain.
Notably, a prompt fine-tuned general-purpose GPT-4o model outperforms these
specialized models, emphasizing the limitations of existing approaches in
adapting to the unique challenges of first-person perspectives. Although our
evaluation is conducted on a small subset of egocentric videos from the
Ego-Exo4D dataset due to resource constraints, the primary objective of this
research is to provide a comprehensive proof-of-concept analysis aimed at
advancing the application of computer vision techniques to first-person videos.
By exploring novel methodologies and evaluating their potential, we aim to
contribute to the ongoing development of models capable of effectively
processing and interpreting egocentric perspectives.

</details>


### [14] [CAT-SG: A Large Dynamic Scene Graph Dataset for Fine-Grained Understanding of Cataract Surgery](https://arxiv.org/abs/2506.21813)
*Felix Holm,Gözde Ünver,Ghazal Ghazaei,Nassir Navab*

Main category: cs.CV

TL;DR: 该论文介绍了首个白内障手术场景图数据集（CAT-SG），用于捕捉手术工具与组织间的语义关系，并提出了一种新的场景图生成模型CatSGG，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有数据集仅关注手术分析的孤立方面（如工具检测或阶段分割），缺乏对实体间语义关系的全面建模。

Method: 提出了CAT-SG数据集，包含工具-组织交互、程序变化和时间依赖的结构化标注，并开发了CatSGG模型生成结构化手术表示。

Result: CAT-SG提供了手术工作流的整体视图，CatSGG模型在生成结构化表示方面优于现有方法。

Conclusion: CAT-SG数据集和CatSGG模型为AI驱动的临床实践（如手术培训和实时决策支持）提供了更智能、上下文感知的基础。

Abstract: Understanding the intricate workflows of cataract surgery requires modeling
complex interactions between surgical tools, anatomical structures, and
procedural techniques. Existing datasets primarily address isolated aspects of
surgical analysis, such as tool detection or phase segmentation, but lack
comprehensive representations that capture the semantic relationships between
entities over time. This paper introduces the Cataract Surgery Scene Graph
(CAT-SG) dataset, the first to provide structured annotations of tool-tissue
interactions, procedural variations, and temporal dependencies. By
incorporating detailed semantic relations, CAT-SG offers a holistic view of
surgical workflows, enabling more accurate recognition of surgical phases and
techniques. Additionally, we present a novel scene graph generation model,
CatSGG, which outperforms current methods in generating structured surgical
representations. The CAT-SG dataset is designed to enhance AI-driven surgical
training, real-time decision support, and workflow analysis, paving the way for
more intelligent, context-aware systems in clinical practice.

</details>


### [15] [Few-Shot Segmentation of Historical Maps via Linear Probing of Vision Foundation Models](https://arxiv.org/abs/2506.21826)
*Rafael Sterzinger,Marco Peer,Robert Sablatnig*

Main category: cs.CV

TL;DR: 提出了一种基于大型视觉基础模型的少样本历史地图分割方法，通过参数高效微调，显著提升了分割性能。


<details>
  <summary>Details</summary>
Motivation: 历史地图的多样性视觉表示和有限标注数据对自动化处理提出了挑战。

Method: 结合大型视觉基础模型的语义嵌入与参数高效微调技术。

Result: 在Siegfried数据集上，10-shot和5-shot场景下分别实现了5%和13%的相对mIoU提升；在ICDAR 2021数据集上，平均PQ达到67.3%。

Conclusion: 该方法在极低数据需求下仍保持高性能，显著减少人工标注需求，推动了历史地图的自动化处理。

Abstract: As rich sources of history, maps provide crucial insights into historical
changes, yet their diverse visual representations and limited annotated data
pose significant challenges for automated processing. We propose a simple yet
effective approach for few-shot segmentation of historical maps, leveraging the
rich semantic embeddings of large vision foundation models combined with
parameter-efficient fine-tuning. Our method outperforms the state-of-the-art on
the Siegfried benchmark dataset in vineyard and railway segmentation, achieving
+5% and +13% relative improvements in mIoU in 10-shot scenarios and around +20%
in the more challenging 5-shot setting. Additionally, it demonstrates strong
performance on the ICDAR 2021 competition dataset, attaining a mean PQ of 67.3%
for building block segmentation, despite not being optimized for this
shape-sensitive metric, underscoring its generalizability. Notably, our
approach maintains high performance even in extremely low-data regimes (10- &
5-shot), while requiring only 689k trainable parameters - just 0.21% of the
total model size. Our approach enables precise segmentation of diverse
historical maps while drastically reducing the need for manual annotations,
advancing automated processing and analysis in the field. Our implementation is
publicly available at:
https://github.com/RafaelSterzinger/few-shot-map-segmentation.

</details>


### [16] [TaleForge: Interactive Multimodal System for Personalized Story Creation](https://arxiv.org/abs/2506.21832)
*Minh-Loi Nguyen,Quang-Khai Le,Tam V. Nguyen,Minh-Triet Tran,Trung-Nghia Le*

Main category: cs.CV

TL;DR: TaleForge是一个结合大型语言模型和文本到图像扩散技术的个性化故事生成系统，通过将用户面部图像嵌入叙事和插图中，提升沉浸感和参与度。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将用户视为被动消费者，提供有限个性化的通用情节，降低了参与度和沉浸感。

Method: TaleForge包含三个模块：故事生成（LLMs根据用户提示创建叙事和角色描述）、个性化图像生成（将用户面部和服装选择融入角色插图）、背景生成（创建包含个性化角色的场景背景）。

Result: 用户研究表明，当用户作为主角时，参与感和归属感显著提升。参与者赞赏系统的实时预览和直观控制，但希望有更精细的叙事编辑工具。

Conclusion: TaleForge通过个性化文本和图像的结合，推动了多模态故事叙述的发展，创造了沉浸式、以用户为中心的体验。

Abstract: Storytelling is a deeply personal and creative process, yet existing methods
often treat users as passive consumers, offering generic plots with limited
personalization. This undermines engagement and immersion, especially where
individual style or appearance is crucial. We introduce TaleForge, a
personalized story-generation system that integrates large language models
(LLMs) and text-to-image diffusion to embed users' facial images within both
narratives and illustrations. TaleForge features three interconnected modules:
Story Generation, where LLMs create narratives and character descriptions from
user prompts; Personalized Image Generation, merging users' faces and outfit
choices into character illustrations; and Background Generation, creating scene
backdrops that incorporate personalized characters. A user study demonstrated
heightened engagement and ownership when individuals appeared as protagonists.
Participants praised the system's real-time previews and intuitive controls,
though they requested finer narrative editing tools. TaleForge advances
multimodal storytelling by aligning personalized text and imagery to create
immersive, user-centric experiences.

</details>


### [17] [PEACE: Empowering Geologic Map Holistic Understanding with MLLMs](https://arxiv.org/abs/2501.06184)
*Yangyu Huang,Tianyi Gao,Haoran Xu,Qihao Zhao,Yang Song,Zhipeng Gui,Tengchao Lv,Hao Chen,Lei Cui,Scarlett Li,Furu Wei*

Main category: cs.CV

TL;DR: 论文提出了GeoMap-Bench基准和GeoMap-Agent模型，用于提升多模态大语言模型（MLLMs）在地质地图理解中的表现，显著优于GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 当前MLLMs在地质地图理解中存在不足，主要由于地图的高分辨率、多组件和领域知识需求等挑战。

Method: 构建GeoMap-Bench基准，并开发GeoMap-Agent模型，包含分层信息提取（HIE）、领域知识注入（DKI）和提示增强问答（PEQA）模块。

Result: GeoMap-Agent在GeoMap-Bench上的得分为0.811，显著高于GPT-4o的0.369。

Conclusion: 该研究为地质学中的AI应用铺平了道路，提升了地质调查的效率和准确性。

Abstract: Geologic map, as a fundamental diagram in geology science, provides critical
insights into the structure and composition of Earth's subsurface and surface.
These maps are indispensable in various fields, including disaster detection,
resource exploration, and civil engineering. Despite their significance,
current Multimodal Large Language Models (MLLMs) often fall short in geologic
map understanding. This gap is primarily due to the challenging nature of
cartographic generalization, which involves handling high-resolution map,
managing multiple associated components, and requiring domain-specific
knowledge. To quantify this gap, we construct GeoMap-Bench, the first-ever
benchmark for evaluating MLLMs in geologic map understanding, which assesses
the full-scale abilities in extracting, referring, grounding, reasoning, and
analyzing. To bridge this gap, we introduce GeoMap-Agent, the inaugural agent
designed for geologic map understanding, which features three modules:
Hierarchical Information Extraction (HIE), Domain Knowledge Injection (DKI),
and Prompt-enhanced Question Answering (PEQA). Inspired by the
interdisciplinary collaboration among human scientists, an AI expert group acts
as consultants, utilizing a diverse tool pool to comprehensively analyze
questions. Through comprehensive experiments, GeoMap-Agent achieves an overall
score of 0.811 on GeoMap-Bench, significantly outperforming 0.369 of GPT-4o.
Our work, emPowering gEologic mAp holistiC undErstanding (PEACE) with MLLMs,
paves the way for advanced AI applications in geology, enhancing the efficiency
and accuracy of geological investigations.

</details>


### [18] [PrefPaint: Enhancing Image Inpainting through Expert Human Feedback](https://arxiv.org/abs/2506.21834)
*Duy-Bao Bui,Hoang-Khang Nguyen,Trung-Nghia Le*

Main category: cs.CV

TL;DR: PrefPaint是一种结合人类反馈的Stable Diffusion Inpainting方法，无需昂贵奖励模型，通过交互式界面优化训练和推理，在医学图像修复中表现优异。


<details>
  <summary>Details</summary>
Motivation: 医学图像修复（如息肉成像）的准确性至关重要，现有模型可能生成不准确图像，影响诊断和治疗。需要专家标注以确保可靠性。

Method: PrefPaint将人类反馈直接整合到Stable Diffusion Inpainting训练中，开发了基于Web的交互界面，简化训练、微调和推理流程。

Result: 用户研究表明，PrefPaint在多个领域优于现有方法，减少了视觉不一致性，特别是在医学场景中生成了更真实的息肉图像。

Conclusion: PrefPaint通过人类反馈和交互界面提升了图像修复的准确性和实用性，尤其在医学领域具有显著优势。

Abstract: Inpainting, the process of filling missing or corrupted image parts, has
broad applications, including medical imaging. However, in specialized fields
like medical polyps imaging, where accuracy and reliability are critical,
inpainting models can generate inaccurate images, leading to significant errors
in medical diagnosis and treatment. To ensure reliability, medical images
should be annotated by experts like oncologists for effective model training.
We propose PrefPaint, an approach that incorporates human feedback into the
training process of Stable Diffusion Inpainting, bypassing the need for
computationally expensive reward models. In addition, we develop a web-based
interface streamlines training, fine-tuning, and inference. This interactive
interface provides a smooth and intuitive user experience, making it easier to
offer feedback and manage the fine-tuning process. User study on various
domains shows that PrefPaint outperforms existing methods, reducing visual
inconsistencies and improving image rendering, particularly in medical
contexts, where our model generates more realistic polyps images.

</details>


### [19] [LLaVA-Scissor: Token Compression with Semantic Connected Components for Video LLMs](https://arxiv.org/abs/2506.21862)
*Boyuan Sun,Jiaxing Zhao,Xihan Wei,Qibin Hou*

Main category: cs.CV

TL;DR: LLaVA-Scissor是一种无需训练的令牌压缩策略，用于视频多模态大语言模型，通过语义连通组件（SCC）实现全面的语义覆盖，显著优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于注意力得分的令牌压缩方法无法有效捕捉所有语义区域且易导致冗余，需要一种更高效的压缩策略。

Method: 提出基于语义连通组件（SCC）的两步时空令牌压缩策略，将令牌分配到不同的语义区域，确保非重叠语义令牌覆盖整个视频。

Result: 在多种视频理解基准测试中表现优异，尤其在低令牌保留率下显著优于其他方法。

Conclusion: LLaVA-Scissor通过SCC实现了高效的令牌压缩，为视频多模态模型提供了更优的解决方案。

Abstract: In this paper, we present LLaVA-Scissor, a training-free token compression
strategy designed for video multimodal large language models. Previous methods
mostly attempt to compress tokens based on attention scores, but fail to
effectively capture all semantic regions and often lead to token redundancy.
Differently, we propose to leverage the Semantic Connected Components (SCC)
approach that assigns tokens to distinct semantic regions within the token set,
ensuring comprehensive semantic coverage. The outcome is a two-step
spatio-temporal token compression strategy that utilizes SCC in both spatial
and temporal domains. This strategy can effectively compress tokens by
representing the entire video with a set of non-overlapping semantic tokens. We
conduct extensive evaluations of the token compression capabilities of
LLaVA-Scissor across diverse video understanding benchmarks, including video
question answering, long video understanding, and comprehensive multi-choices
benchmarks. Experimental results show that the proposed LLaVA-Scissor
outperforms other token compression methods, achieving superior performance in
various video understanding benchmarks, particularly at low token retention
ratios. Project page: https://github.com/HumanMLLM/LLaVA-Scissor.

</details>


### [20] [ProSAM: Enhancing the Robustness of SAM-based Visual Reference Segmentation with Probabilistic Prompts](https://arxiv.org/abs/2506.21835)
*Xiaoqi Wang,Clint Sebastian,Wenbin He,Liu Ren*

Main category: cs.CV

TL;DR: ProSAM提出了一种改进的视觉参考分割方法，通过变分提示编码器预测多变量提示分布，解决了现有SAM方法在边界生成提示导致的不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于SAM的视觉参考分割方法因提示编码器不理想，常在物体边界生成提示，导致不稳定性和鲁棒性下降。

Method: ProSAM通过学习变分提示编码器预测多变量提示分布，避免在不稳定区域生成提示。

Result: ProSAM在Pascal-5$^i$和COCO-20$^i$数据集上表现优于现有方法。

Conclusion: ProSAM为视觉参考分割提供了更鲁棒的解决方案。

Abstract: The recent advancements in large foundation models have driven the success of
open-set image segmentation, a task focused on segmenting objects beyond
predefined categories. Among various prompt types (such as points, boxes,
texts, and visual references), visual reference segmentation stands out for its
unique flexibility and strong zero-shot capabilities. Recently, several
SAM-based methods have made notable progress in this task by automatically
generating prompts to guide SAM. However, these methods often generate prompts
at object boundaries due to suboptimal prompt encoder, which results in
instability and reduced robustness. In this work, we introduce ProSAM, a simple
but effective method to address the stability challenges we identified in
existing SAM-based visual reference segmentation approaches. By learning a
variational prompt encoder to predict multivariate prompt distributions, ProSAM
avoids generating prompts that lie in unstable regions, overcoming the
instability caused by less robust prompts. Our approach consistently surpasses
state-of-the-art methods on the Pascal-5$^i$ and COCO-20$^i$ datasets,
providing a more robust solution for visual reference segmentation.

</details>


### [21] [Pedestrian Intention and Trajectory Prediction in Unstructured Traffic Using IDD-PeD](https://arxiv.org/abs/2506.22111)
*Ruthvik Bokkasam,Shankar Gangisetty,A. H. Abdul Hafez,C. V. Jawahar*

Main category: cs.CV

TL;DR: 论文介绍了一个印度驾驶行人数据集，旨在解决非结构化环境中行人行为建模的复杂性，并展示了现有预测方法在该数据集上的性能下降。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶的快速发展，准确预测行人行为对复杂交通环境中的安全至关重要，而现有数据集难以满足非结构化环境的需求。

Method: 论文提出了一个包含高水平和低水平注释的印度驾驶行人数据集，用于评估行人意图和轨迹预测方法。

Result: 在该数据集上，现有意图预测方法性能下降高达15%，轨迹预测方法的MSE增加高达1208。

Conclusion: 该数据集为行人行为研究提供了新的挑战，有助于开发更鲁棒的预测模型。

Abstract: With the rapid advancements in autonomous driving, accurately predicting
pedestrian behavior has become essential for ensuring safety in complex and
unpredictable traffic conditions. The growing interest in this challenge
highlights the need for comprehensive datasets that capture unstructured
environments, enabling the development of more robust prediction models to
enhance pedestrian safety and vehicle navigation. In this paper, we introduce
an Indian driving pedestrian dataset designed to address the complexities of
modeling pedestrian behavior in unstructured environments, such as illumination
changes, occlusion of pedestrians, unsignalized scene types and
vehicle-pedestrian interactions. The dataset provides high-level and detailed
low-level comprehensive annotations focused on pedestrians requiring the
ego-vehicle's attention. Evaluation of the state-of-the-art intention
prediction methods on our dataset shows a significant performance drop of up to
$\mathbf{15\%}$, while trajectory prediction methods underperform with an
increase of up to $\mathbf{1208}$ MSE, defeating standard pedestrian datasets.
Additionally, we present exhaustive quantitative and qualitative analysis of
intention and trajectory baselines. We believe that our dataset will open new
challenges for the pedestrian behavior research community to build robust
models. Project Page:
https://cvit.iiit.ac.in/research/projects/cvit-projects/iddped

</details>


### [22] [GenEscape: Hierarchical Multi-Agent Generation of Escape Room Puzzles](https://arxiv.org/abs/2506.21839)
*Mengyi Shan,Brian Curless,Ira Kemelmacher-Shlizerman,Steve Seitz*

Main category: cs.CV

TL;DR: 提出了一种分层多智能体框架，用于生成视觉吸引、逻辑严密且具有挑战性的逃脱房间谜题图像，解决了基础图像模型在空间关系和功能推理上的不足。


<details>
  <summary>Details</summary>
Motivation: 挑战文本到图像模型生成逃脱房间谜题图像的能力，要求其具备视觉吸引力、逻辑严密性和智力挑战性。

Method: 采用分层多智能体框架，将任务分解为功能设计、符号场景图推理、布局合成和局部图像编辑四个阶段，通过智能体协作和迭代反馈确保场景的视觉一致性和功能可解性。

Result: 实验表明，智能体协作提高了输出质量，包括可解性、避免捷径和功能清晰度，同时保持了视觉质量。

Conclusion: 分层多智能体框架有效提升了逃脱房间谜题图像的生成质量，解决了基础模型的局限性。

Abstract: We challenge text-to-image models with generating escape room puzzle images
that are visually appealing, logically solid, and intellectually stimulating.
While base image models struggle with spatial relationships and affordance
reasoning, we propose a hierarchical multi-agent framework that decomposes this
task into structured stages: functional design, symbolic scene graph reasoning,
layout synthesis, and local image editing. Specialized agents collaborate
through iterative feedback to ensure the scene is visually coherent and
functionally solvable. Experiments show that agent collaboration improves
output quality in terms of solvability, shortcut avoidance, and affordance
clarity, while maintaining visual quality.

</details>


### [23] [3D-Telepathy: Reconstructing 3D Objects from EEG Signals](https://arxiv.org/abs/2506.21843)
*Yuxiang Ge,Jionghao Cheng,Ruiquan Ge,Zhaojie Fang,Gangyong Jia,Xiang Wan,Nannan Li,Ahmed Elazab,Changmiao Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种创新的EEG编码器架构，结合双重自注意力机制和混合训练策略，成功从EEG数据中重建3D物体。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅将脑电图（EEG）数据转换为2D图像，忽略了3D空间信息的重建。由于EEG信号包含丰富的空间信息，仅重建2D图像限制了其在脑机接口（BCI）中的实际应用。

Method: 提出了一种创新的EEG编码器架构，结合双重自注意力机制，采用混合训练策略（包括交叉注意力、对比学习和自监督学习），并利用稳定扩散作为先验分布和变分分数蒸馏训练神经辐射场。

Result: 成功从EEG数据中生成了内容和结构相似的3D物体。

Conclusion: 该方法为从EEG数据重建3D物体提供了有效解决方案，扩展了BCI的应用潜力。

Abstract: Reconstructing 3D visual stimuli from Electroencephalography (EEG) data holds
significant potential for applications in Brain-Computer Interfaces (BCIs) and
aiding individuals with communication disorders. Traditionally, efforts have
focused on converting brain activity into 2D images, neglecting the translation
of EEG data into 3D objects. This limitation is noteworthy, as the human brain
inherently processes three-dimensional spatial information regardless of
whether observing 2D images or the real world. The neural activities captured
by EEG contain rich spatial information that is inevitably lost when
reconstructing only 2D images, thus limiting its practical applications in BCI.
The transition from EEG data to 3D object reconstruction faces considerable
obstacles. These include the presence of extensive noise within EEG signals and
a scarcity of datasets that include both EEG and 3D information, which
complicates the extraction process of 3D visual data. Addressing this
challenging task, we propose an innovative EEG encoder architecture that
integrates a dual self-attention mechanism. We use a hybrid training strategy
to train the EEG Encoder, which includes cross-attention, contrastive learning,
and self-supervised learning techniques. Additionally, by employing stable
diffusion as a prior distribution and utilizing Variational Score Distillation
to train a neural radiation field, we successfully generate 3D objects with
similar content and structure from EEG data.

</details>


### [24] [End-to-End RGB-IR Joint Image Compression With Channel-wise Cross-modality Entropy Model](https://arxiv.org/abs/2506.21851)
*Haofeng Wang,Fangtao Zhou,Qi Zhang,Zeyuan Chen,Enci Zhang,Zhao Wang,Xiaofeng Huang,Siwei Ma*

Main category: cs.CV

TL;DR: 提出了一种用于RGB-IR图像对的联合压缩框架，通过跨模态熵模型（CCEM）提升压缩效率。


<details>
  <summary>Details</summary>
Motivation: 随着多模态数据（如RGB-IR）应用的增加，存储和传输成本成倍增长，需要高效的压缩方法。

Method: 设计了CCEM模型，包含低频上下文提取块（LCEB）和融合块（LCFB），利用跨模态先验信息优化熵参数预测。

Result: 在LLVIP和KAIST数据集上表现优于现有方法，例如在LLVIP上比特率节省23.1%。

Conclusion: 该框架显著提升了RGB-IR图像对的压缩效率，具有实际应用价值。

Abstract: RGB-IR(RGB-Infrared) image pairs are frequently applied simultaneously in
various applications like intelligent surveillance. However, as the number of
modalities increases, the required data storage and transmission costs also
double. Therefore, efficient RGB-IR data compression is essential. This work
proposes a joint compression framework for RGB-IR image pair. Specifically, to
fully utilize cross-modality prior information for accurate context probability
modeling within and between modalities, we propose a Channel-wise
Cross-modality Entropy Model (CCEM). Among CCEM, a Low-frequency Context
Extraction Block (LCEB) and a Low-frequency Context Fusion Block (LCFB) are
designed for extracting and aggregating the global low-frequency information
from both modalities, which assist the model in predicting entropy parameters
more accurately. Experimental results demonstrate that our approach outperforms
existing RGB-IR image pair and single-modality compression methods on LLVIP and
KAIST datasets. For instance, the proposed framework achieves a 23.1% bit rate
saving on LLVIP dataset compared to the state-of-the-art RGB-IR image codec
presented at CVPR 2022.

</details>


### [25] [Periodic-MAE: Periodic Video Masked Autoencoder for rPPG Estimation](https://arxiv.org/abs/2506.21855)
*Jiho Choi,Sang Jun Lee*

Main category: cs.CV

TL;DR: 提出了一种通过自监督学习从无标记面部视频中学习周期性信号通用表示的方法，用于远程光电容积描记（rPPG）估计。


<details>
  <summary>Details</summary>
Motivation: 从面部视频中捕捉微妙的肤色变化以估计生理信号（如心率）是rPPG的核心挑战，现有方法缺乏对周期性信号的通用表示学习。

Method: 使用视频掩码自编码器（MAE）学习高维时空表示，结合帧掩码和生理带宽限制约束，以捕捉准周期性信号。

Result: 在PURE、UBFC-rPPG、MMPD和V4V数据集上验证，性能显著提升，尤其在跨数据集评估中表现优异。

Conclusion: 该方法通过自监督学习有效捕捉周期性信号，为rPPG任务提供了通用且鲁棒的表示。

Abstract: In this paper, we propose a method that learns a general representation of
periodic signals from unlabeled facial videos by capturing subtle changes in
skin tone over time. The proposed framework employs the video masked
autoencoder to learn a high-dimensional spatio-temporal representation of the
facial region through self-supervised learning. Capturing quasi-periodic
signals in the video is crucial for remote photoplethysmography (rPPG)
estimation. To account for signal periodicity, we apply frame masking in terms
of video sampling, which allows the model to capture resampled quasi-periodic
signals during the pre-training stage. Moreover, the framework incorporates
physiological bandlimit constraints, leveraging the property that physiological
signals are sparse within their frequency bandwidth to provide pulse cues to
the model. The pre-trained encoder is then transferred to the rPPG task, where
it is used to extract physiological signals from facial videos. We evaluate the
proposed method through extensive experiments on the PURE, UBFC-rPPG, MMPD, and
V4V datasets. Our results demonstrate significant performance improvements,
particularly in challenging cross-dataset evaluations. Our code is available at
https://github.com/ziiho08/Periodic-MAE.

</details>


### [26] [Integrating Multi-Modal Sensors: A Review of Fusion Techniques for Intelligent Vehicles](https://arxiv.org/abs/2506.21885)
*Chuheng Wei,Ziye Qin,Ziyan Zhang,Guoyuan Wu,Matthew J. Barth*

Main category: cs.CV

TL;DR: 本文系统综述了多传感器融合在自动驾驶中的关键作用，分类了数据级、特征级和决策级融合策略，并探讨了深度学习方法、多模态数据集及新兴趋势（如VLMs和LLMs的整合）。


<details>
  <summary>Details</summary>
Motivation: 多传感器融合能克服单一传感器的局限性，提升自动驾驶的环境感知能力，尤其在恶劣天气和复杂城市环境中。

Method: 将多传感器融合策略分为数据级、特征级和决策级，并系统回顾了基于深度学习的对应方法。

Result: 提供了关键多模态数据集的分析，并讨论了其在现实挑战中的应用，同时探索了新兴技术趋势。

Conclusion: 多传感器融合在自动驾驶中具有巨大潜力，未来方向包括整合VLMs和LLMs以增强系统适应性和鲁棒性。

Abstract: Multi-sensor fusion plays a critical role in enhancing perception for
autonomous driving, overcoming individual sensor limitations, and enabling
comprehensive environmental understanding. This paper first formalizes
multi-sensor fusion strategies into data-level, feature-level, and
decision-level categories and then provides a systematic review of deep
learning-based methods corresponding to each strategy. We present key
multi-modal datasets and discuss their applicability in addressing real-world
challenges, particularly in adverse weather conditions and complex urban
environments. Additionally, we explore emerging trends, including the
integration of Vision-Language Models (VLMs), Large Language Models (LLMs), and
the role of sensor fusion in end-to-end autonomous driving, highlighting its
potential to enhance system adaptability and robustness. Our work offers
valuable insights into current methods and future directions for multi-sensor
fusion in autonomous driving.

</details>


### [27] [SPADE: Spatial Transcriptomics and Pathology Alignment Using a Mixture of Data Experts for an Expressive Latent Space](https://arxiv.org/abs/2506.21857)
*Ekaterina Redekop,Mara Pleasure,Zichen Wang,Kimberly Flores,Anthony Sisk,William Speier,Corey W. Arnold*

Main category: cs.CV

TL;DR: SPADE是一种基础模型，整合了组织病理学和空间转录组学数据，通过对比学习生成统一的潜在空间，显著提升了少样本任务性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态方法在整合全切片图像（WSI）与空间转录组学（ST）方面存在不足，而这两者的结合对捕捉分子异质性至关重要。

Method: SPADE采用混合数据专家技术，通过两阶段特征空间聚类和对比学习，学习共配准的WSI补丁和基因表达谱的表示。

Result: 在HEST-1k数据集上预训练后，SPADE在14个下游任务中表现显著优于基线模型。

Conclusion: SPADE展示了将形态学和分子信息整合到统一潜在空间的优势。

Abstract: The rapid growth of digital pathology and advances in self-supervised deep
learning have enabled the development of foundational models for various
pathology tasks across diverse diseases. While multimodal approaches
integrating diverse data sources have emerged, a critical gap remains in the
comprehensive integration of whole-slide images (WSIs) with spatial
transcriptomics (ST), which is crucial for capturing critical molecular
heterogeneity beyond standard hematoxylin & eosin (H&E) staining. We introduce
SPADE, a foundation model that integrates histopathology with ST data to guide
image representation learning within a unified framework, in effect creating an
ST-informed latent space. SPADE leverages a mixture-of-data experts technique,
where experts, created via two-stage feature-space clustering, use contrastive
learning to learn representations of co-registered WSI patches and gene
expression profiles. Pre-trained on the comprehensive HEST-1k dataset, SPADE is
evaluated on 14 downstream tasks, demonstrating significantly superior few-shot
performance compared to baseline models, highlighting the benefits of
integrating morphological and molecular information into one latent space.

</details>


### [28] [Robust and Accurate Multi-view 2D/3D Image Registration with Differentiable X-ray Rendering and Dual Cross-view Constraints](https://arxiv.org/abs/2506.22191)
*Yuxin Cui,Rui Song,Yibin Li,Max Q. -H. Meng,Zhe Min*

Main category: cs.CV

TL;DR: 提出了一种新颖的多视角2D/3D刚性配准方法，通过两阶段设计和交叉视图约束提升配准精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决单视角术中图像视野有限的问题，提升配准的准确性和鲁棒性。

Method: 两阶段方法：第一阶段设计联合损失函数和交叉视图训练损失；第二阶段通过测试时优化细化估计姿态。

Result: 在DeepFluoro数据集上实现了0.79±2.17 mm的平均目标配准误差，优于现有方法。

Conclusion: 多视角约束显著提升了配准性能，方法在临床应用中具有潜力。

Abstract: Robust and accurate 2D/3D registration, which aligns preoperative models with
intraoperative images of the same anatomy, is crucial for successful
interventional navigation. To mitigate the challenge of a limited field of view
in single-image intraoperative scenarios, multi-view 2D/3D registration is
required by leveraging multiple intraoperative images. In this paper, we
propose a novel multi-view 2D/3D rigid registration approach comprising two
stages. In the first stage, a combined loss function is designed, incorporating
both the differences between predicted and ground-truth poses and the
dissimilarities (e.g., normalized cross-correlation) between simulated and
observed intraoperative images. More importantly, additional cross-view
training loss terms are introduced for both pose and image losses to explicitly
enforce cross-view constraints. In the second stage, test-time optimization is
performed to refine the estimated poses from the coarse stage. Our method
exploits the mutual constraints of multi-view projection poses to enhance the
robustness of the registration process. The proposed framework achieves a mean
target registration error (mTRE) of $0.79 \pm 2.17$ mm on six specimens from
the DeepFluoro dataset, demonstrating superior performance compared to
state-of-the-art registration algorithms.

</details>


### [29] [Remote Sensing Large Vision-Language Model: Semantic-augmented Multi-level Alignment and Semantic-aware Expert Modeling](https://arxiv.org/abs/2506.21863)
*Sungjune Park,Yeongyun Kim,Se Yeon Kim,Yong Man Ro*

Main category: cs.CV

TL;DR: 提出了一种针对遥感图像的新型大视觉语言模型框架，通过语义增强的多级对齐和语义感知专家建模，解决了通用模型在遥感领域的局限性。


<details>
  <summary>Details</summary>
Motivation: 通用大视觉语言模型在自然图像领域表现优异，但在遥感图像中因视觉、尺度和语义差异而表现不佳，限制了其直接应用。

Method: 设计了语义增强模块和语义感知专家模型，前者通过检索和聚合多级语义信息增强视觉特征，后者通过分层专家处理不同级别的语义表示。

Result: 在多个遥感任务（如场景分类和视觉问答）中表现优异，实现了跨语义级别的性能提升。

Conclusion: 该框架有效填补了通用模型与遥感领域需求之间的差距，展示了其在多级语义理解中的能力。

Abstract: Large Vision and Language Models (LVLMs) have shown strong performance across
various vision-language tasks in natural image domains. However, their
application to remote sensing (RS) remains underexplored due to significant
domain differences in visual appearances, object scales, and semantics. These
discrepancies hider the effective understanding of RS scenes, which contain
rich, multi-level semantic information spanning from coarse-to-fine levels.
Hence, it limits the direct adaptation of existing LVLMs to RS imagery. To
address this gap, we propose a novel LVLM framework tailored for RS
understanding, incorporating two core components: Semantic-augmented
Multi-level Alignment and Semantic-aware Expert Modeling. First, to align
multi-level visual features, we introduce the retrieval-based Semantic
Augmentation Module which enriches the visual features with relevant semantics
across fine-to-coarse levels (e.g., object- and scene-level information). It is
designed to retrieve relevant semantic cues from a RS semantic knowledge
database, followed by aggregation of semantic cues with user query and
multi-level visual features, resulting in semantically enriched representation
across multiple levels. Second, for Semantic-aware Expert Modeling, we design
semantic experts, where each expert is responsible for processing semantic
representation at different levels separately. This enables hierarchical
semantic understanding from coarse to fine levels. Evaluations across multiple
RS tasks-including scene classification and VQA, etc.-demonstrate that the
proposed framework achieves consistent improvements across multiple semantic
levels. This highlights its capability and effectiveness in bridging the gap
between general LVLMs and unique demands of RS-specific vision-language
understanding.

</details>


### [30] [Dual-Perspective United Transformer for Object Segmentation in Optical Remote Sensing Images](https://arxiv.org/abs/2506.21866)
*Yanguang Sun,Jiexi Yan,Jianjun Qian,Chunyan Xu,Jian Yang,Lei Luo*

Main category: cs.CV

TL;DR: 提出了一种新型的双视角统一Transformer（DPU-Former），用于光学遥感图像分割，结合了卷积和Transformer的优势，解决了特征异质性和模型复杂度问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常只基于卷积或Transformer特征，忽略了二者的结合及其带来的挑战，导致分割效果不佳。

Method: 设计了全局-局部混合注意力机制和傅里叶空间合并策略，并引入了门控线性前馈网络和DPU-Former解码器。

Result: 在多个数据集上优于现有最优方法。

Conclusion: DPU-Former通过结合长程依赖和空间细节，显著提升了分割性能。

Abstract: Automatically segmenting objects from optical remote sensing images (ORSIs)
is an important task. Most existing models are primarily based on either
convolutional or Transformer features, each offering distinct advantages.
Exploiting both advantages is valuable research, but it presents several
challenges, including the heterogeneity between the two types of features, high
complexity, and large parameters of the model. However, these issues are often
overlooked in existing the ORSIs methods, causing sub-optimal segmentation. For
that, we propose a novel Dual-Perspective United Transformer (DPU-Former) with
a unique structure designed to simultaneously integrate long-range dependencies
and spatial details. In particular, we design the global-local mixed attention,
which captures diverse information through two perspectives and introduces a
Fourier-space merging strategy to obviate deviations for efficient fusion.
Furthermore, we present a gated linear feed-forward network to increase the
expressive ability. Additionally, we construct a DPU-Former decoder to
aggregate and strength features at different layers. Consequently, the
DPU-Former model outperforms the state-of-the-art methods on multiple datasets.
Code: https://github.com/CSYSI/DPU-Former.

</details>


### [31] [Grounding-Aware Token Pruning: Recovering from Drastic Performance Drops in Visual Grounding Caused by Pruning](https://arxiv.org/abs/2506.21873)
*Tzu-Chun Chien,Chieh-Kai Lin,Shiang-Feng Tsai,Ruei-Chi Lai,Hung-Jen Chen,Min Sun*

Main category: cs.CV

TL;DR: 多模态大语言模型（MLLMs）在视觉定位中表现优异，但剪枝方法会削弱其定位能力。作者提出GAP方法，通过调整位置ID恢复性能。


<details>
  <summary>Details</summary>
Motivation: 解决剪枝方法导致视觉定位性能显著下降的问题。

Method: 提出Grounding-Aware Token Pruning (GAP)，调整位置ID以恢复性能。

Result: GAP将REC准确率从15.34%恢复到51.42%，接近原始性能的90%。

Conclusion: GAP方法简单有效，无需额外训练或计算开销，适用于多种模型。

Abstract: Recent Multimodal Large Language Models (MLLMs) have demonstrated strong
performance in visual grounding, establishing themselves as a general interface
for various vision-language applications. This progress has driven the
development of token pruning methods to mitigate the high computational costs
associated with processing numerous visual tokens. However, we observe that
pruning significantly weakens the model's grounding ability, leading to
incorrect predictions and drastic performance degradation. In Referring
Expression Comprehension (REC), for instance, pruning causes the accuracy of
LLaVA on the RefCOCO validation set to drop from 56.14% to 15.34%. Our analysis
identifies misaligned position IDs after pruning as the primary cause of this
degradation, as both the order and value of these IDs are crucial for
maintaining performance in grounding tasks. To address this issue, we propose
Grounding-Aware Token Pruning (GAP), a simple yet effective adjustment to
position IDs that recovers REC accuracy back to 51.42%, which is 90% of the
original performance in the without pruning setting, all while requiring no
additional training, memory, or computational overhead. Applied to models such
as Shikra, MiniGPTv2, and the LLaVA series, our method consistently improves
performance across various token pruning strategies.

</details>


### [32] [GRASP-PsONet: Gradient-based Removal of Spurious Patterns for PsOriasis Severity Classification](https://arxiv.org/abs/2506.21883)
*Basudha Pal,Sharif Amit Kamran,Brendon Lutnick,Molly Lucas,Chaitanya Parmar,Asha Patel Shah,David Apfel,Steven Fakharzadeh,Lloyd Miller,Gabriela Cula,Kristopher Standish*

Main category: cs.CV

TL;DR: 提出了一种基于梯度解释性的框架，用于自动标记训练图像中的问题样本，以提高银屑病严重程度分类模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 银屑病严重程度评分在临床试验中很重要，但受限于评估者间的差异和临床评估的负担。远程成像虽具扩展性，但存在光照、背景和设备质量等问题，影响模型性能。

Method: 使用基于梯度的解释性方法，追踪误分类验证图像的梯度，检测引入虚假相关性的训练样本。应用于ConvNeXT弱监督模型。

Result: 移除8.2%的问题图像后，模型AUC-ROC提升5%（85%至90%）。方法能检测90%以上的评估者不一致案例。

Conclusion: 该方法提高了远程评估的自动化评分鲁棒性，减少了对人工审查的需求。

Abstract: Psoriasis (PsO) severity scoring is important for clinical trials but is
hindered by inter-rater variability and the burden of in person clinical
evaluation. Remote imaging using patient captured mobile photos offers
scalability but introduces challenges, such as variation in lighting,
background, and device quality that are often imperceptible to humans but can
impact model performance. These factors, along with inconsistencies in
dermatologist annotations, reduce the reliability of automated severity
scoring. We propose a framework to automatically flag problematic training
images that introduce spurious correlations which degrade model generalization,
using a gradient based interpretability approach. By tracing the gradients of
misclassified validation images, we detect training samples where model errors
align with inconsistently rated examples or are affected by subtle, nonclinical
artifacts. We apply this method to a ConvNeXT based weakly supervised model
designed to classify PsO severity from phone images. Removing 8.2% of flagged
images improves model AUC-ROC by 5% (85% to 90%) on a held out test set.
Commonly, multiple annotators and an adjudication process ensure annotation
accuracy, which is expensive and time consuming. Our method detects training
images with annotation inconsistencies, potentially removing the need for
manual review. When applied to a subset of training data rated by two
dermatologists, the method identifies over 90% of cases with inter-rater
disagreement by reviewing only the top 30% of samples. This improves automated
scoring for remote assessments, ensuring robustness despite data collection
variability.

</details>


### [33] [DIVE: Deep-search Iterative Video Exploration A Technical Report for the CVRR Challenge at CVPR 2025](https://arxiv.org/abs/2506.21891)
*Umihiro Kamoto,Tatsuya Ishibashi,Noriyuki Kugo*

Main category: cs.CV

TL;DR: DIVE方法通过迭代推理在视频问答挑战赛中取得第一名，准确率达81.44%。


<details>
  <summary>Details</summary>
Motivation: 解决复杂视频问答问题，提升对多样化视频内容的理解和推理能力。

Method: 采用DIVE（深度搜索迭代视频探索）方法，通过语义分解和逐步推理解决问题。

Result: 在CVRR-ES基准测试中达到81.44%的准确率，排名第一。

Conclusion: DIVE的迭代推理框架在视频问答中表现出色，具有鲁棒性。

Abstract: In this report, we present the winning solution that achieved the 1st place
in the Complex Video Reasoning & Robustness Evaluation Challenge 2025. This
challenge evaluates the ability to generate accurate natural language answers
to questions about diverse, real-world video clips. It uses the Complex Video
Reasoning and Robustness Evaluation Suite (CVRR-ES) benchmark, which consists
of 214 unique videos and 2,400 question-answer pairs spanning 11 categories.
Our method, DIVE (Deep-search Iterative Video Exploration), adopts an iterative
reasoning approach, in which each input question is semantically decomposed and
solved through stepwise reasoning and progressive inference. This enables our
system to provide highly accurate and contextually appropriate answers to even
the most complex queries. Applied to the CVRR-ES benchmark, our approach
achieves 81.44% accuracy on the test set, securing the top position among all
participants. This report details our methodology and provides a comprehensive
analysis of the experimental results, demonstrating the effectiveness of our
iterative reasoning framework in achieving robust video question answering. The
code is available at https://github.com/PanasonicConnect/DIVE

</details>


### [34] [SODA: Out-of-Distribution Detection in Domain-Shifted Point Clouds via Neighborhood Propagation](https://arxiv.org/abs/2506.21892)
*Adam Goodge,Xun Xu,Bryan Hooi,Wee Siong Ng,Jingyi Liao,Yongyi Su,Xulei Yang*

Main category: cs.CV

TL;DR: 论文提出了一种名为SODA的新方法，利用3D视觉语言模型（3D VLMs）检测点云数据中的分布外（OOD）对象，解决了合成数据到真实数据的域偏移问题。


<details>
  <summary>Details</summary>
Motivation: 随着点云数据应用的普及，检测OOD点云对象对模型安全性和可靠性至关重要，但现有研究对此问题关注不足。

Method: 提出SODA方法，通过基于邻域的分数传播方案改进OOD检测，无需额外训练模型。

Result: SODA在多种数据集和问题设置中表现优于现有方法，达到最先进性能。

Conclusion: SODA有效解决了合成数据到真实数据的域偏移问题，提升了OOD点云检测的性能。

Abstract: As point cloud data increases in prevalence in a variety of applications, the
ability to detect out-of-distribution (OOD) point cloud objects becomes
critical for ensuring model safety and reliability. However, this problem
remains under-explored in existing research. Inspired by success in the image
domain, we propose to exploit advances in 3D vision-language models (3D VLMs)
for OOD detection in point cloud objects. However, a major challenge is that
point cloud datasets used to pre-train 3D VLMs are drastically smaller in size
and object diversity than their image-based counterparts. Critically, they
often contain exclusively computer-designed synthetic objects. This leads to a
substantial domain shift when the model is transferred to practical tasks
involving real objects scanned from the physical environment. In this paper,
our empirical experiments show that synthetic-to-real domain shift
significantly degrades the alignment of point cloud with their associated text
embeddings in the 3D VLM latent space, hindering downstream performance. To
address this, we propose a novel methodology called SODA which improves the
detection of OOD point clouds through a neighborhood-based score propagation
scheme. SODA is inference-based, requires no additional model training, and
achieves state-of-the-art performance over existing approaches across datasets
and problem settings.

</details>


### [35] [Exploring Task-Solving Paradigm for Generalized Cross-Domain Face Anti-Spoofing via Reinforcement Fine-Tuning](https://arxiv.org/abs/2506.21895)
*Fangling Jiang,Qi Li,Weining Wang,Gang Wang,Bing Liu,Zhenan Sun*

Main category: cs.CV

TL;DR: 本文提出了一种基于强化微调的人脸反欺骗方法，通过多模态大语言模型自主学习和推理，而非依赖数据记忆，解决了跨域泛化和可解释性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法容易记住训练集的数据模式，导致对未知攻击类型的泛化能力差且缺乏可解释性。

Method: 设计了可验证的类别一致奖励和推理一致奖励，采用GRPO优化策略，引导模型从多角度探索推理策略。

Result: 实验表明，该方法在跨域泛化性能上达到最优，能有效应对未见目标域中的多种未知攻击类型，并提供可解释的决策。

Conclusion: 该方法通过强化学习提炼出高度泛化的决策规则，解决了人脸反欺骗中的跨域和可解释性问题。

Abstract: Recently the emergence of novel presentation attacks has drawn increasing
attention to face anti-spoofing. However, existing methods tend to memorize
data patterns from the training set, resulting in poor generalization to
unknown attack types across different scenarios and limited interpretability.
To address these challenges, this paper presents a reinforcement
fine-tuning-based face anti-spoofing method that stimulates the capabilities of
multimodal large language models to think and learn how to solve the
anti-spoofing task itself, rather than relying on the memorization of
authenticity patterns. We design verifiable class consistent reward and
reasoning consistent reward, and employ a GRPO-based optimization strategy to
guide the model in exploring reasoning policies from multiple perspectives to
maximize expected rewards. As a result, through iterative trial-and-error
learning while retaining only high-reward trajectories, the model distills
highly generalizable decision-making rules from the extensive solution space to
effectively address cross-domain face anti-spoofing tasks. Extensive
experimental results demonstrate that our method achieves state-of-the-art
cross-domain generalization performance. It generalizes well to diverse unknown
attack types in unseen target domains while providing interpretable reasoning
for its authenticity decisions without requiring labor-intensive textual
annotations for training.

</details>


### [36] [Visual Content Detection in Educational Videos with Transfer Learning and Dataset Enrichment](https://arxiv.org/abs/2506.21903)
*Dipayan Biswas,Shishir Shah,Jaspal Subhlok*

Main category: cs.CV

TL;DR: 论文提出了一种基于迁移学习的方法，用于检测教学视频中的视觉元素，优化了YOLO模型，并公开了标注数据集和源代码。


<details>
  <summary>Details</summary>
Motivation: 教学视频中的视觉元素（如图表、表格）对理解和检索至关重要，但自动检测这些元素存在挑战，缺乏标准结构和标注数据。

Method: 采用迁移学习方法，评估并优化YOLO模型，结合半监督自动标注策略。

Result: YOLO表现最佳，优化后模型在检测教学视频中的视觉元素上取得了成功。

Conclusion: 该方法为教学视频中的目标检测提供了通用解决方案，并公开了数据集和代码以促进未来研究。

Abstract: Video is transforming education with online courses and recorded lectures
supplementing and replacing classroom teaching. Recent research has focused on
enhancing information retrieval for video lectures with advanced navigation,
searchability, summarization, as well as question answering chatbots. Visual
elements like tables, charts, and illustrations are central to comprehension,
retention, and data presentation in lecture videos, yet their full potential
for improving access to video content remains underutilized. A major factor is
that accurate automatic detection of visual elements in a lecture video is
challenging; reasons include i) most visual elements, such as charts, graphs,
tables, and illustrations, are artificially created and lack any standard
structure, and ii) coherent visual objects may lack clear boundaries and may be
composed of connected text and visual components. Despite advancements in deep
learning based object detection, current models do not yield satisfactory
performance due to the unique nature of visual content in lectures and scarcity
of annotated datasets. This paper reports on a transfer learning approach for
detecting visual elements in lecture video frames. A suite of state of the art
object detection models were evaluated for their performance on lecture video
datasets. YOLO emerged as the most promising model for this task. Subsequently
YOLO was optimized for lecture video object detection with training on multiple
benchmark datasets and deploying a semi-supervised auto labeling strategy.
Results evaluate the success of this approach, also in developing a general
solution to the problem of object detection in lecture videos. Paper
contributions include a publicly released benchmark of annotated lecture video
frames, along with the source code to facilitate future research.

</details>


### [37] [RAUM-Net: Regional Attention and Uncertainty-aware Mamba Network](https://arxiv.org/abs/2506.21905)
*Mingquan Liu*

Main category: cs.CV

TL;DR: 提出了一种结合Mamba特征建模、区域注意力和贝叶斯不确定性的半监督方法，用于解决细粒度视觉分类（FGVC）中数据稀缺和特征脆弱的问题。


<details>
  <summary>Details</summary>
Motivation: 细粒度视觉分类（FGVC）因类间差异细微和特征表示脆弱而具有挑战性，现有方法在数据稀缺时表现不佳。

Method: 结合Mamba特征建模、区域注意力和贝叶斯不确定性，增强局部到全局特征建模，并选择高质量伪标签。

Result: 在FGVC基准测试中表现出色，尤其在遮挡情况下，且对标记数据有限的情况具有鲁棒性。

Conclusion: 该方法在数据稀缺的FGVC任务中表现优异，代码已开源。

Abstract: Fine Grained Visual Categorization (FGVC) remains a challenging task in
computer vision due to subtle inter class differences and fragile feature
representations. Existing methods struggle in fine grained scenarios,
especially when labeled data is scarce. We propose a semi supervised method
combining Mamba based feature modeling, region attention, and Bayesian
uncertainty. Our approach enhances local to global feature modeling while
focusing on key areas during learning. Bayesian inference selects high quality
pseudo labels for stability. Experiments show strong performance on FGVC
benchmarks with occlusions, demonstrating robustness when labeled data is
limited. Code is available at https://github.com/wxqnl/RAUM Net.

</details>


### [38] [CERBERUS: Crack Evaluation & Recognition Benchmark for Engineering Reliability & Urban Stability](https://arxiv.org/abs/2506.21909)
*Justin Reinman,Sunwoong Choi*

Main category: cs.CV

TL;DR: CERBERUS是一个合成基准，用于训练和评估AI模型检测基础设施中的裂缝和其他缺陷，结合合成与真实数据可提升性能。


<details>
  <summary>Details</summary>
Motivation: 为自动化基础设施检测提供灵活、可重复的测试方法，支持未来研究。

Method: 包括裂缝图像生成器和Unity构建的3D检查场景，测试了YOLO模型在不同数据组合下的表现。

Result: 结合合成与真实数据能提高模型在真实图像上的性能。

Conclusion: CERBERUS为缺陷检测系统提供了有效工具，并公开可用。

Abstract: CERBERUS is a synthetic benchmark designed to help train and evaluate AI
models for detecting cracks and other defects in infrastructure. It includes a
crack image generator and realistic 3D inspection scenarios built in Unity. The
benchmark features two types of setups: a simple Fly-By wall inspection and a
more complex Underpass scene with lighting and geometry challenges. We tested a
popular object detection model (YOLO) using different combinations of synthetic
and real crack data. Results show that combining synthetic and real data
improves performance on real-world images. CERBERUS provides a flexible,
repeatable way to test defect detection systems and supports future research in
automated infrastructure inspection. CERBERUS is publicly available at
https://github.com/justinreinman/Cerberus-Defect-Generator.

</details>


### [39] [Generating Attribute-Aware Human Motions from Textual Prompt](https://arxiv.org/abs/2506.21912)
*Xinghan Wang,Kun Xu,Fei Li,Cao Sheng,Jiazhong Yu,Yadong Mu*

Main category: cs.CV

TL;DR: 本文提出了一种基于文本和人体属性的运动生成框架，通过解耦动作语义和属性信息，实现了属性控制的运动生成。


<details>
  <summary>Details</summary>
Motivation: 现有文本驱动的人体运动生成方法忽略了人体属性（如年龄、性别、体重和身高）对运动模式的影响，本文旨在填补这一空白。

Method: 提出了一种受结构因果模型启发的框架，将动作语义与人体属性解耦，支持文本到语义的预测和属性控制的生成。

Result: 模型能够生成与用户文本和属性输入一致的逼真运动，并通过新数据集HumanAttr验证了其有效性。

Conclusion: 本文为属性感知的文本到运动生成设定了首个基准，展示了模型在解耦和生成方面的潜力。

Abstract: Text-driven human motion generation has recently attracted considerable
attention, allowing models to generate human motions based on textual
descriptions. However, current methods neglect the influence of human
attributes (such as age, gender, weight, and height) which are key factors
shaping human motion patterns. This work represents a pilot exploration for
bridging this gap. We conceptualize each motion as comprising both attribute
information and action semantics, where textual descriptions align exclusively
with action semantics. To achieve this, a new framework inspired by Structural
Causal Models is proposed to decouple action semantics from human attributes,
enabling text-to-semantics prediction and attribute-controlled generation. The
resulting model is capable of generating realistic, attribute-aware motion
aligned with the user's text and attribute inputs. For evaluation, we introduce
HumanAttr, a comprehensive dataset containing attribute annotations for
text-motion pairs, setting the first benchmark for attribute-aware
text-to-motion generation. Extensive experiments on the new dataset validate
our model's effectiveness.

</details>


### [40] [SepFormer: Coarse-to-fine Separator Regression Network for Table Structure Recognition](https://arxiv.org/abs/2506.21920)
*Nam Quan Nguyen,Xuan Phong Pham,Tuan-Anh Tran*

Main category: cs.CV

TL;DR: SepFormer是一种基于DETR架构的表格结构识别方法，通过单步分割与合并范式提升速度和鲁棒性，在多个基准数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 表格结构识别（TSR）是语义数据提取的基础，现有方法需进一步优化速度和鲁棒性。

Method: SepFormer采用粗到细的两阶段方法，通过两个Transformer解码器预测表格分隔线，结合角度损失逐步优化。

Result: SepFormer在SciTSR等数据集上达到25.6 FPS，性能与最先进方法相当。

Conclusion: SepFormer通过创新架构和优化策略，实现了高效的表格结构识别。

Abstract: The automated reconstruction of the logical arrangement of tables from image
data, termed Table Structure Recognition (TSR), is fundamental for semantic
data extraction. Recently, researchers have explored a wide range of techniques
to tackle this problem, demonstrating significant progress. Each table is a set
of vertical and horizontal separators. Following this realization, we present
SepFormer, which integrates the split-and-merge paradigm into a single step
through separator regression with a DETR-style architecture, improving speed
and robustness. SepFormer is a coarse-to-fine approach that predicts table
separators from single-line to line-strip separators with a stack of two
transformer decoders. In the coarse-grained stage, the model learns to
gradually refine single-line segments through decoder layers with additional
angle loss. At the end of the fine-grained stage, the model predicts line-strip
separators by refining sampled points from each single-line segment. Our
SepFormer can run on average at 25.6 FPS while achieving comparable performance
with state-of-the-art methods on several benchmark datasets, including SciTSR,
PubTabNet, WTW, and iFLYTAB.

</details>


### [41] [ZeroReg3D: A Zero-shot Registration Pipeline for 3D Consecutive Histopathology Image Reconstruction](https://arxiv.org/abs/2506.21923)
*Juming Xiong,Ruining Deng,Jialin Yue,Siqi Lu,Junlin Guo,Marilyn Lionts,Tianyuan Yao,Can Cui,Junchao Zhu,Chongyu Qu,Mengmeng Yin,Haichun Yang,Yuankai Huo*

Main category: cs.CV

TL;DR: ZeroReg3D是一种新型零样本配准方法，用于从连续组织切片中精确重建3D模型，解决了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有2D组织学分析方法难以保留3D空间关系，且深度学习方法泛化性差，非深度学习方法精度不足。

Method: 结合零样本深度学习关键点匹配与优化仿射和非刚性配准技术。

Result: 有效解决组织变形、切片伪影、染色差异和光照不一致等问题，无需重新训练。

Conclusion: ZeroReg3D在3D重建中表现出色，代码已开源。

Abstract: Histological analysis plays a crucial role in understanding tissue structure
and pathology. While recent advancements in registration methods have improved
2D histological analysis, they often struggle to preserve critical 3D spatial
relationships, limiting their utility in both clinical and research
applications. Specifically, constructing accurate 3D models from 2D slices
remains challenging due to tissue deformation, sectioning artifacts,
variability in imaging techniques, and inconsistent illumination. Deep
learning-based registration methods have demonstrated improved performance but
suffer from limited generalizability and require large-scale training data. In
contrast, non-deep-learning approaches offer better generalizability but often
compromise on accuracy. In this study, we introduced ZeroReg3D, a novel
zero-shot registration pipeline tailored for accurate 3D reconstruction from
serial histological sections. By combining zero-shot deep learning-based
keypoint matching with optimization-based affine and non-rigid registration
techniques, ZeroReg3D effectively addresses critical challenges such as tissue
deformation, sectioning artifacts, staining variability, and inconsistent
illumination without requiring retraining or fine-tuning. The code has been
made publicly available at https://github.com/hrlblab/ZeroReg3D

</details>


### [42] [SPAZER: Spatial-Semantic Progressive Reasoning Agent for Zero-shot 3D Visual Grounding](https://arxiv.org/abs/2506.21924)
*Zhao Jin,Rong-Cheng Tu,Jingyi Liao,Wenhao Sun,Xiao Luo,Shunyu Liu,Dacheng Tao*

Main category: cs.CV

TL;DR: SPAZER结合3D和2D模态进行渐进式推理，显著提升零样本3D视觉定位性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在复杂场景中仅依赖空间或语义理解的局限性。

Method: 通过渐进式框架结合3D渲染和2D图像，进行候选筛选和联合决策。

Result: 在ScanRefer和Nr3D基准上准确率分别提升9.0%和10.9%。

Conclusion: SPAZER无需3D标注数据即可实现鲁棒的零样本定位。

Abstract: 3D Visual Grounding (3DVG) aims to localize target objects within a 3D scene
based on natural language queries. To alleviate the reliance on costly 3D
training data, recent studies have explored zero-shot 3DVG by leveraging the
extensive knowledge and powerful reasoning capabilities of pre-trained LLMs and
VLMs. However, existing paradigms tend to emphasize either spatial (3D-based)
or semantic (2D-based) understanding, limiting their effectiveness in complex
real-world applications. In this work, we introduce SPAZER - a VLM-driven agent
that combines both modalities in a progressive reasoning framework. It first
holistically analyzes the scene and produces a 3D rendering from the optimal
viewpoint. Based on this, anchor-guided candidate screening is conducted to
perform a coarse-level localization of potential objects. Furthermore,
leveraging retrieved relevant 2D camera images, 3D-2D joint decision-making is
efficiently performed to determine the best-matching object. By bridging
spatial and semantic reasoning neural streams, SPAZER achieves robust zero-shot
grounding without training on 3D-labeled data. Extensive experiments on
ScanRefer and Nr3D benchmarks demonstrate that SPAZER significantly outperforms
previous state-of-the-art zero-shot methods, achieving notable gains of 9.0%
and 10.9% in accuracy.

</details>


### [43] [Quality Assessment and Distortion-aware Saliency Prediction for AI-Generated Omnidirectional Images](https://arxiv.org/abs/2506.21925)
*Liu Yang,Huiyu Duan,Jiarui Wang,Jing Liu,Menghan Hu,Xiongkuo Min,Guangtao Zhai,Patrick Le Callet*

Main category: cs.CV

TL;DR: 该论文研究了AI生成的全景图像（AIGODIs）的质量评估与优化问题，提出了基于BLIP-2模型的BLIP2OIQA和BLIP2OISal方法，并建立了OHF2024数据库。实验表明这些方法在视觉体验评估和失真显著性预测任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着AIGC技术的发展，AI生成的全景图像在VR/AR应用中潜力巨大，但其质量评估与优化研究尚不充分。

Method: 建立了OHF2024数据库，并基于BLIP-2模型提出了BLIP2OIQA和BLIP2OISal模型，用于质量评估和失真显著性预测，进一步设计了自动优化流程。

Result: BLIP2OIQA和BLIP2OISal在视觉体验评估和失真显著性预测任务中达到SOTA效果，优化流程有效提升了图像质量。

Conclusion: 该研究为AIGODIs的质量评估与优化提供了有效工具，数据库和代码将开源以促进未来研究。

Abstract: With the rapid advancement of Artificial Intelligence Generated Content
(AIGC) techniques, AI generated images (AIGIs) have attracted widespread
attention, among which AI generated omnidirectional images (AIGODIs) hold
significant potential for Virtual Reality (VR) and Augmented Reality (AR)
applications. AI generated omnidirectional images exhibit unique quality
issues, however, research on the quality assessment and optimization of
AI-generated omnidirectional images is still lacking. To this end, this work
first studies the quality assessment and distortion-aware saliency prediction
problems for AIGODIs, and further presents a corresponding optimization
process. Specifically, we first establish a comprehensive database to reflect
human feedback for AI-generated omnidirectionals, termed OHF2024, which
includes both subjective quality ratings evaluated from three perspectives and
distortion-aware salient regions. Based on the constructed OHF2024 database, we
propose two models with shared encoders based on the BLIP-2 model to evaluate
the human visual experience and predict distortion-aware saliency for
AI-generated omnidirectional images, which are named as BLIP2OIQA and
BLIP2OISal, respectively. Finally, based on the proposed models, we present an
automatic optimization process that utilizes the predicted visual experience
scores and distortion regions to further enhance the visual quality of an
AI-generated omnidirectional image. Extensive experiments show that our
BLIP2OIQA model and BLIP2OISal model achieve state-of-the-art (SOTA) results in
the human visual experience evaluation task and the distortion-aware saliency
prediction task for AI generated omnidirectional images, and can be effectively
used in the optimization process. The database and codes will be released on
https://github.com/IntMeGroup/AIGCOIQA to facilitate future research.

</details>


### [44] [SDRNET: Stacked Deep Residual Network for Accurate Semantic Segmentation of Fine-Resolution Remotely Sensed Images](https://arxiv.org/abs/2506.21945)
*Naftaly Wambugu,Ruisheng Wang,Bo Guo,Tianshu Yu,Sheng Xu,Mohammed Elhassan*

Main category: cs.CV

TL;DR: 论文提出了一种堆叠深度残差网络（SDRNet），用于高分辨率遥感图像的语义分割，解决了类别差异、遮挡和物体尺寸变化等问题。


<details>
  <summary>Details</summary>
Motivation: 高分辨率遥感图像的语义分割面临类别差异、遮挡和物体尺寸变化的挑战，现有深度卷积神经网络难以提取足够特征。

Method: 采用双堆叠编码器-解码器网络和扩张残差块（DRB），以捕获长距离语义并保留空间信息。

Result: 在ISPRS Vaihingen和Potsdam数据集上的实验表明，SDRNet性能优于现有深度卷积神经网络。

Conclusion: SDRNet能有效解决高分辨率遥感图像语义分割的挑战，具有竞争力。

Abstract: Land cover maps generated from semantic segmentation of high-resolution
remotely sensed images have drawn mucon in the photogrammetry and remote
sensing research community. Currently, massive fine-resolution remotely sensed
(FRRS) images acquired by improving sensing and imaging technologies become
available. However, accurate semantic segmentation of such FRRS images is
greatly affected by substantial class disparities, the invisibility of key
ground objects due to occlusion, and object size variation. Despite the
extraordinary potential in deep convolutional neural networks (DCNNs) in image
feature learning and representation, extracting sufficient features from FRRS
images for accurate semantic segmentation is still challenging. These
challenges demand the deep learning models to learn robust features and
generate sufficient feature descriptors. Specifically, learning
multi-contextual features to guarantee adequate coverage of varied object sizes
from the ground scene and harnessing global-local contexts to overcome class
disparities challenge even profound networks. Deeper networks significantly
lose spatial details due to gradual downsampling processes resulting in poor
segmentation results and coarse boundaries. This article presents a stacked
deep residual network (SDRNet) for semantic segmentation from FRRS images. The
proposed framework utilizes two stacked encoder-decoder networks to harness
long-range semantics yet preserve spatial information and dilated residual
blocks (DRB) between each encoder and decoder network to capture sufficient
global dependencies thus improving segmentation performance. Our experimental
results obtained using the ISPRS Vaihingen and Potsdam datasets demonstrate
that the SDRNet performs effectively and competitively against current DCNNs in
semantic segmentation.

</details>


### [45] [Exploring Semantic Masked Autoencoder for Self-supervised Point Cloud Understanding](https://arxiv.org/abs/2506.21957)
*Yixin Zha,Chuxin Wang,Wenfei Yang,Tianzhu Zhang*

Main category: cs.CV

TL;DR: 提出了一种基于语义掩码自编码器的方法，通过原型语义建模和增强掩码策略，解决了随机掩码在点云理解中的语义关系捕捉不足问题。


<details>
  <summary>Details</summary>
Motivation: 随机掩码策略在点云预训练中难以捕捉合理的语义关系，限制了自监督模型的性能。

Method: 设计了原型语义建模模块和语义增强掩码策略，结合组件语义增强提示调优策略。

Result: 在ScanObjectNN、ModelNet40和ShapeNetPart等数据集上验证了方法的有效性。

Conclusion: 提出的方法显著提升了点云理解的性能，尤其在捕捉语义关系方面表现突出。

Abstract: Point cloud understanding aims to acquire robust and general feature
representations from unlabeled data. Masked point modeling-based methods have
recently shown significant performance across various downstream tasks. These
pre-training methods rely on random masking strategies to establish the
perception of point clouds by restoring corrupted point cloud inputs, which
leads to the failure of capturing reasonable semantic relationships by the
self-supervised models. To address this issue, we propose Semantic Masked
Autoencoder, which comprises two main components: a prototype-based component
semantic modeling module and a component semantic-enhanced masking strategy.
Specifically, in the component semantic modeling module, we design a component
semantic guidance mechanism to direct a set of learnable prototypes in
capturing the semantics of different components from objects. Leveraging these
prototypes, we develop a component semantic-enhanced masking strategy that
addresses the limitations of random masking in effectively covering complete
component structures. Furthermore, we introduce a component semantic-enhanced
prompt-tuning strategy, which further leverages these prototypes to improve the
performance of pre-trained models in downstream tasks. Extensive experiments
conducted on datasets such as ScanObjectNN, ModelNet40, and ShapeNetPart
demonstrate the effectiveness of our proposed modules.

</details>


### [46] [TASeg: Text-aware RGB-T Semantic Segmentation based on Fine-tuning Vision Foundation Models](https://arxiv.org/abs/2506.21975)
*Meng Yu,Te Cui,Qitong Chu,Wenjie Song,Yi Yang,Yufeng Yue*

Main category: cs.CV

TL;DR: TASeg是一个基于LoRA微调技术的文本感知RGB-T分割框架，通过动态特征融合模块和多模态特征融合提升语义分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-T语义分割模型依赖低层视觉特征，缺乏高层文本信息，导致类别视觉相似时分割不准确；同时，SAM在实例级分割中表现优异，但与热图像和文本的整合存在模态异质性和计算效率问题。

Method: 提出TASeg框架，利用LoRA微调技术适配视觉基础模型，设计动态特征融合模块（DFFM）融合多模态视觉特征，并引入CLIP生成的文本嵌入以提升语义对齐。

Result: 在多样化数据集上的实验表明，TASeg在挑战性场景中表现优异，且训练参数较少。

Conclusion: TASeg通过结合文本信息和多模态特征，显著提升了语义分割的准确性和效率。

Abstract: Reliable semantic segmentation of open environments is essential for
intelligent systems, yet significant problems remain: 1) Existing RGB-T
semantic segmentation models mainly rely on low-level visual features and lack
high-level textual information, which struggle with accurate segmentation when
categories share similar visual characteristics. 2) While SAM excels in
instance-level segmentation, integrating it with thermal images and text is
hindered by modality heterogeneity and computational inefficiency. To address
these, we propose TASeg, a text-aware RGB-T segmentation framework by using
Low-Rank Adaptation (LoRA) fine-tuning technology to adapt vision foundation
models. Specifically, we propose a Dynamic Feature Fusion Module (DFFM) in the
image encoder, which effectively merges features from multiple visual
modalities while freezing SAM's original transformer blocks. Additionally, we
incorporate CLIP-generated text embeddings in the mask decoder to enable
semantic alignment, which further rectifies the classification error and
improves the semantic understanding accuracy. Experimental results across
diverse datasets demonstrate that our method achieves superior performance in
challenging scenarios with fewer trainable parameters.

</details>


### [47] [R1-Track: Direct Application of MLLMs to Visual Object Tracking via Reinforcement Learning](https://arxiv.org/abs/2506.21980)
*Biao Wang,Wenwen Li*

Main category: cs.CV

TL;DR: 论文提出了一种基于多模态大语言模型（MLLMs）的视觉单目标跟踪方法R1-Track，通过强化学习微调Qwen2.5-VL模型，解决了传统跟踪方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统视觉单目标跟踪方法依赖大规模监督训练，缺乏灵活性。多模态大语言模型的快速发展为直接应用于跟踪任务提供了可能。

Method: 使用基于规则的奖励函数和小规模数据集，通过GRPO强化学习方法微调Qwen2.5-VL模型，得到R1-Track。

Result: R1-Track在GOT-10k基准测试中表现优异，支持通过边界框或文本描述灵活初始化。

Conclusion: R1-Track展示了MLLMs在视觉跟踪任务中的潜力，并提出了进一步改进的方向。

Abstract: Visual single object tracking aims to continuously localize and estimate the
scale of a target in subsequent video frames, given only its initial state in
the first frame. This task has traditionally been framed as a template matching
problem, evolving through major phases including correlation filters,
two-stream networks, and one-stream networks with significant progress
achieved. However, these methods typically require explicit classification and
regression modeling, depend on supervised training with large-scale datasets,
and are limited to the single task of tracking, lacking flexibility. In recent
years, multi-modal large language models (MLLMs) have advanced rapidly.
Open-source models like Qwen2.5-VL, a flagship MLLMs with strong foundational
capabilities, demonstrate excellent performance in grounding tasks. This has
spurred interest in applying such models directly to visual tracking. However,
experiments reveal that Qwen2.5-VL struggles with template matching between
image pairs (i.e., tracking tasks). Inspired by deepseek-R1, we fine-tuned
Qwen2.5-VL using the group relative policy optimization (GRPO) reinforcement
learning method on a small-scale dataset with a rule-based reward function. The
resulting model, R1-Track, achieved notable performance on the GOT-10k
benchmark. R1-Track supports flexible initialization via bounding boxes or text
descriptions while retaining most of the original model's general capabilities.
And we further discuss potential improvements for R1-Track. This rough
technical report summarizes our findings as of May 2025.

</details>


### [48] [RoboEnvision: A Long-Horizon Video Generation Model for Multi-Task Robot Manipulation](https://arxiv.org/abs/2506.22007)
*Liudi Yang,Yang Bai,George Eskandar,Fengyi Shen,Mohammad Altillawi,Dong Chen,Soumajit Majumder,Ziyuan Liu,Gitta Kutyniok,Abhinav Valada*

Main category: cs.CV

TL;DR: 提出了一种新方法，通过分解任务和关键帧生成，避免自回归生成，提高了长时程机器人任务视频的质量和一致性。


<details>
  <summary>Details</summary>
Motivation: 解决文本到视频扩散模型在长时程机器人任务中因自回归生成导致的错误累积问题。

Method: 1) 分解任务并生成关键帧；2) 使用扩散模型插值关键帧；3) 引入语义保持注意力模块和轻量级策略模型。

Result: 在两个基准测试中取得了视频质量和一致性的最佳结果，并在长时程任务中优于之前的策略模型。

Conclusion: 提出的方法有效解决了长时程视频生成中的错误累积问题，显著提升了性能。

Abstract: We address the problem of generating long-horizon videos for robotic
manipulation tasks. Text-to-video diffusion models have made significant
progress in photorealism, language understanding, and motion generation but
struggle with long-horizon robotic tasks. Recent works use video diffusion
models for high-quality simulation data and predictive rollouts in robot
planning. However, these works predict short sequences of the robot achieving
one task and employ an autoregressive paradigm to extend to the long horizon,
leading to error accumulations in the generated video and in the execution. To
overcome these limitations, we propose a novel pipeline that bypasses the need
for autoregressive generation. We achieve this through a threefold
contribution: 1) we first decompose the high-level goals into smaller atomic
tasks and generate keyframes aligned with these instructions. A second
diffusion model then interpolates between each of the two generated frames,
achieving the long-horizon video. 2) We propose a semantics preserving
attention module to maintain consistency between the keyframes. 3) We design a
lightweight policy model to regress the robot joint states from generated
videos. Our approach achieves state-of-the-art results on two benchmarks in
video quality and consistency while outperforming previous policy models on
long-horizon tasks.

</details>


### [49] [Towards Universal & Efficient Model Compression via Exponential Torque Pruning](https://arxiv.org/abs/2506.22015)
*Sarthak Ketanbhai Modi,Lim Zi Pong,Shourya Kuchhal,Yoshi Cao,Yupeng Cheng,Teo Yon Shin,Lin Shang-Wei,Zhiming Li*

Main category: cs.CV

TL;DR: 论文提出了一种名为指数扭矩剪枝（ETP）的新方法，通过指数力应用方案改进现有剪枝技术，显著提高压缩率且几乎不影响准确性。


<details>
  <summary>Details</summary>
Motivation: 现代深度神经网络（DNNs）的复杂性和规模快速增长，导致计算成本和内存使用问题，需要高效的模型压缩技术。现有基于扭矩正则化的方法剪枝效果不佳，网络仍密集且准确性下降明显。

Method: 提出指数扭矩剪枝（ETP），采用指数力应用方案进行正则化，有效剪除冗余模块并保留必要模块。

Result: 实验表明，ETP在多个领域显著提高了压缩率，且准确性下降可忽略不计。

Conclusion: ETP是一种简单高效的剪枝方法，优于现有技术。

Abstract: The rapid growth in complexity and size of modern deep neural networks (DNNs)
has increased challenges related to computational costs and memory usage,
spurring a growing interest in efficient model compression techniques. Previous
state-of-the-art approach proposes using a Torque-inspired regularization which
forces the weights of neural modules around a selected pivot point. Whereas, we
observe that the pruning effect of this approach is far from perfect, as the
post-trained network is still dense and also suffers from high accuracy drop.
In this work, we attribute such ineffectiveness to the default linear force
application scheme, which imposes inappropriate force on neural module of
different distances. To efficiently prune the redundant and distant modules
while retaining those that are close and necessary for effective inference, in
this work, we propose Exponential Torque Pruning (ETP), which adopts an
exponential force application scheme for regularization. Experimental results
on a broad range of domains demonstrate that, though being extremely simple,
ETP manages to achieve significantly higher compression rate than the previous
state-of-the-art pruning strategies with negligible accuracy drop.

</details>


### [50] [Advancing Facial Stylization through Semantic Preservation Constraint and Pseudo-Paired Supervision](https://arxiv.org/abs/2506.22022)
*Zhanyi Lu,Yue Zhou*

Main category: cs.CV

TL;DR: 提出了一种结合语义保留约束和伪配对监督的面部风格化方法，解决了生成结果中的伪影和内容一致性问题，并实现了多模态和参考引导的风格化。


<details>
  <summary>Details</summary>
Motivation: 现有基于StyleGAN的方法在面部风格化中存在伪影和内容一致性不足的问题，作者认为这是由于忽略了生成器在风格化过程中的语义偏移。

Method: 提出了一种结合语义保留约束和伪配对监督的方法，并开发了多级伪配对数据集以实施监督约束。

Result: 实验结果表明，该方法生成了高保真且美观的面部风格化效果，优于先前方法。

Conclusion: 该方法不仅提升了风格化效果，还实现了更灵活的多模态和参考引导风格化，无需复杂网络设计或额外训练。

Abstract: Facial stylization aims to transform facial images into appealing,
high-quality stylized portraits, with the critical challenge of accurately
learning the target style while maintaining content consistency with the
original image. Although previous StyleGAN-based methods have made significant
advancements, the generated results still suffer from artifacts or insufficient
fidelity to the source image. We argue that these issues stem from neglecting
semantic shift of the generator during stylization. Therefore, we propose a
facial stylization method that integrates semantic preservation constraint and
pseudo-paired supervision to enhance the content correspondence and improve the
stylization effect. Additionally, we develop a methodology for creating
multi-level pseudo-paired datasets to implement supervisory constraint.
Furthermore, building upon our facial stylization framework, we achieve more
flexible multimodal and reference-guided stylization without complex network
architecture designs or additional training. Experimental results demonstrate
that our approach produces high-fidelity, aesthetically pleasing facial style
transfer that surpasses previous methods.

</details>


### [51] [Cross-modal Ship Re-Identification via Optical and SAR Imagery: A Novel Dataset and Method](https://arxiv.org/abs/2506.22027)
*Han Wang,Shengyang Li,Jian Yang,Yuxuan Liu,Yixuan Lv,Zhuang Zhou*

Main category: cs.CV

TL;DR: 论文提出了一种混合光学和合成孔径雷达（SAR）的船舶再识别数据集（HOSS ReID），用于评估低地球轨道星座的光学和SAR传感器在船舶跟踪中的有效性，并提出了基于Vision Transformer的跨模态船舶再识别方法TransOSS。


<details>
  <summary>Details</summary>
Motivation: 当前船舶跟踪方法主要依赖地球静止卫星或视频卫星，前者分辨率低且易受天气影响，后者拍摄时间短且覆盖范围有限，难以满足实际需求。

Method: 提出HOSS ReID数据集，包含多模态卫星在不同时间和角度下拍摄的船舶图像；提出TransOSS方法，改进Vision Transformer的嵌入结构，引入对比学习预训练。

Result: HOSS ReID数据集支持多模态船舶跟踪，TransOSS方法能有效提取模态不变特征。

Conclusion: 该研究为船舶跟踪提供了新的数据集和方法，支持全天候和多模态的船舶再识别。

Abstract: Detecting and tracking ground objects using earth observation imagery remains
a significant challenge in the field of remote sensing. Continuous maritime
ship tracking is crucial for applications such as maritime search and rescue,
law enforcement, and shipping analysis. However, most current ship tracking
methods rely on geostationary satellites or video satellites. The former offer
low resolution and are susceptible to weather conditions, while the latter have
short filming durations and limited coverage areas, making them less suitable
for the real-world requirements of ship tracking. To address these limitations,
we present the Hybrid Optical and Synthetic Aperture Radar (SAR) Ship
Re-Identification Dataset (HOSS ReID dataset), designed to evaluate the
effectiveness of ship tracking using low-Earth orbit constellations of optical
and SAR sensors. This approach ensures shorter re-imaging cycles and enables
all-weather tracking. HOSS ReID dataset includes images of the same ship
captured over extended periods under diverse conditions, using different
satellites of different modalities at varying times and angles. Furthermore, we
propose a baseline method for cross-modal ship re-identification, TransOSS,
which is built on the Vision Transformer architecture. It refines the patch
embedding structure to better accommodate cross-modal tasks, incorporates
additional embeddings to introduce more reference information, and employs
contrastive learning to pre-train on large-scale optical-SAR image pairs,
ensuring the model's ability to extract modality-invariant features. Our
dataset and baseline method are publicly available on
https://github.com/Alioth2000/Hoss-ReID.

</details>


### [52] [Partial CLIP is Enough: Chimera-Seg for Zero-shot Semantic Segmentation](https://arxiv.org/abs/2506.22032)
*Jialei Chen,Xu Zheng,Danda Pani Paudel,Luc Van Gool,Hiroshi Murase,Daisuke Deguchi*

Main category: cs.CV

TL;DR: Chimera-Seg和SGD方法解决了零样本语义分割中视觉语言对齐和特征粒度差异的挑战，提升了分割性能。


<details>
  <summary>Details</summary>
Motivation: 零样本语义分割需要同时处理已见和未见类别，但现有方法在视觉语言对齐和特征粒度上存在挑战。

Method: 提出Chimera-Seg结合分割主干和CLIP语义头，以及SGD选择性蒸馏高相似度特征。

Result: 在两个基准测试中，hIoU分别提升了0.9%和1.2%。

Conclusion: Chimera-Seg和SGD有效解决了对齐和粒度问题，提升了零样本分割性能。

Abstract: Zero-shot Semantic Segmentation (ZSS) aims to segment both seen and unseen
classes using supervision from only seen classes. Beyond adaptation-based
methods, distillation-based approaches transfer vision-language alignment of
vision-language model, e.g., CLIP, to segmentation models. However, such
knowledge transfer remains challenging due to: (1) the difficulty of aligning
vision-based features with the textual space, which requires combining spatial
precision with vision-language alignment; and (2) the semantic gap between
CLIP's global representations and the local, fine-grained features of
segmentation models. To address challenge (1), we propose Chimera-Seg, which
integrates a segmentation backbone as the body and a CLIP-based semantic head
as the head, like the Chimera in Greek mythology, combining spatial precision
with vision-language alignment. Specifically, Chimera-Seg comprises a trainable
segmentation model and a CLIP Semantic Head (CSH), which maps dense features
into the CLIP-aligned space. The CSH incorporates a frozen subnetwork and fixed
projection layers from the CLIP visual encoder, along with lightweight
trainable components. The partial module from CLIP visual encoder, paired with
the segmentation model, retains segmentation capability while easing the
mapping to CLIP's semantic space. To address challenge (2), we propose
Selective Global Distillation (SGD), which distills knowledge from dense
features exhibiting high similarity to the CLIP CLS token, while gradually
reducing the number of features used for alignment as training progresses.
Besides, we also use a Semantic Alignment Module (SAM) to further align dense
visual features with semantic embeddings extracted from the frozen CLIP text
encoder. Experiments on two benchmarks show improvements of 0.9% and 1.2% in
hIoU.

</details>


### [53] [Few-Shot Identity Adaptation for 3D Talking Heads via Global Gaussian Field](https://arxiv.org/abs/2506.22044)
*Hong Nie,Fuyuan Cao,Lu Chen,Fengxin Chen,Yuefeng Zou,Jun Yu*

Main category: cs.CV

TL;DR: FIAG是一种新型的3D说话头部合成框架，通过共享的全局高斯场和通用运动场，实现高效的身份特定适应，仅需少量训练数据即可生成高质量结果。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于重建和渲染的说话头部合成方法对身份特定模型的依赖问题，提高计算效率和可扩展性。

Method: 提出FIAG框架，结合全局高斯场（支持多身份共享表示）和通用运动场（捕捉跨身份的运动动态），实现快速身份适应。

Result: 实验表明FIAG在质量和通用性上优于现有方法，验证了其有效性。

Conclusion: FIAG通过共享结构和运动信息，显著提升了说话头部合成的效率和适应性。

Abstract: Reconstruction and rendering-based talking head synthesis methods achieve
high-quality results with strong identity preservation but are limited by their
dependence on identity-specific models. Each new identity requires training
from scratch, incurring high computational costs and reduced scalability
compared to generative model-based approaches. To overcome this limitation, we
propose FIAG, a novel 3D speaking head synthesis framework that enables
efficient identity-specific adaptation using only a few training footage. FIAG
incorporates Global Gaussian Field, which supports the representation of
multiple identities within a shared field, and Universal Motion Field, which
captures the common motion dynamics across diverse identities. Benefiting from
the shared facial structure information encoded in the Global Gaussian Field
and the general motion priors learned in the motion field, our framework
enables rapid adaptation from canonical identity representations to specific
ones with minimal data. Extensive comparative and ablation experiments
demonstrate that our method outperforms existing state-of-the-art approaches,
validating both the effectiveness and generalizability of the proposed
framework. Code is available at: \textit{https://github.com/gme-hong/FIAG}.

</details>


### [54] [EnLVAM: Enhanced Left Ventricle Linear Measurements Utilizing Anatomical Motion Mode](https://arxiv.org/abs/2506.22063)
*Durgesh K. Singh,Ahcene Boubekki,Qing Cao,Svein Arne Aase,Robert Jenssen,Michael Kampffmeyer*

Main category: cs.CV

TL;DR: 提出了一种通过强制直线约束提高左心室测量准确性的新框架，利用解剖M模式图像训练标志点检测器，并在B模式空间中转换，减少误差。


<details>
  <summary>Details</summary>
Motivation: 手动放置标志点耗时且易出错，现有深度学习方法常导致标志点错位，影响测量准确性。

Method: 训练标志点检测器于解剖M模式图像，实时从B模式视频计算并转换回B模式空间，结合半自动设计和用户交互。

Result: 实验显示相比标准B模式方法，准确性提高，且框架适用于不同网络架构。

Conclusion: 该框架通过直线约束和半自动设计，显著提高了左心室测量的准确性和临床实用性。

Abstract: Linear measurements of the left ventricle (LV) in the Parasternal Long Axis
(PLAX) view using B-mode echocardiography are crucial for cardiac assessment.
These involve placing 4-6 landmarks along a virtual scanline (SL) perpendicular
to the LV axis near the mitral valve tips. Manual placement is time-consuming
and error-prone, while existing deep learning methods often misalign landmarks,
causing inaccurate measurements. We propose a novel framework that enhances LV
measurement accuracy by enforcing straight-line constraints. A landmark
detector is trained on Anatomical M-Mode (AMM) images, computed in real time
from B-mode videos, then transformed back to B-mode space. This approach
addresses misalignment and reduces measurement errors. Experiments show
improved accuracy over standard B-mode methods, and the framework generalizes
well across network architectures. Our semi-automatic design includes a
human-in-the-loop step where the user only places the SL, simplifying
interaction while preserving alignment flexibility and clinical relevance.

</details>


### [55] [MirrorMe: Towards Realtime and High Fidelity Audio-Driven Halfbody Animation](https://arxiv.org/abs/2506.22065)
*Dechao Meng,Steven Xiao,Xindi Zhang,Guangyuan Wang,Peng Zhang,Qi Wang,Bang Zhang,Liefeng Bo*

Main category: cs.CV

TL;DR: MirrorMe是一个基于LTX视频模型的实时音频驱动肖像动画框架，通过空间和时间压缩实现高效潜在空间去噪，解决了现有方法的高延迟和时间一致性问题。


<details>
  <summary>Details</summary>
Motivation: 音频驱动肖像动画在实时生成高保真、时间连贯的视频方面面临挑战，现有扩散方法因逐帧UNet架构导致高延迟和时间不一致。

Method: 提出MirrorMe框架，基于LTX视频模型，引入参考身份注入机制、因果音频编码器和适配器，以及渐进式训练策略。

Result: 在EMTD Benchmark上，MirrorMe在保真度、唇同步准确性和时间稳定性方面表现优异。

Conclusion: MirrorMe通过创新方法实现了实时、可控的高质量肖像动画生成，显著提升了性能。

Abstract: Audio-driven portrait animation, which synthesizes realistic videos from
reference images using audio signals, faces significant challenges in real-time
generation of high-fidelity, temporally coherent animations. While recent
diffusion-based methods improve generation quality by integrating audio into
denoising processes, their reliance on frame-by-frame UNet architectures
introduces prohibitive latency and struggles with temporal consistency. This
paper introduces MirrorMe, a real-time, controllable framework built on the LTX
video model, a diffusion transformer that compresses video spatially and
temporally for efficient latent space denoising. To address LTX's trade-offs
between compression and semantic fidelity, we propose three innovations: 1. A
reference identity injection mechanism via VAE-encoded image concatenation and
self-attention, ensuring identity consistency; 2. A causal audio encoder and
adapter tailored to LTX's temporal structure, enabling precise audio-expression
synchronization; and 3. A progressive training strategy combining close-up
facial training, half-body synthesis with facial masking, and hand pose
integration for enhanced gesture control. Extensive experiments on the EMTD
Benchmark demonstrate MirrorMe's state-of-the-art performance in fidelity,
lip-sync accuracy, and temporal stability.

</details>


### [56] [Single-Scanline Relative Pose Estimation for Rolling Shutter Cameras](https://arxiv.org/abs/2506.22069)
*Petr Hruby,Marc Pollefeys*

Main category: cs.CV

TL;DR: 提出了一种新颖的方法，通过滚动快门相机中单条扫描线的线投影交点估计相对位姿，无需显式建模相机运动。


<details>
  <summary>Details</summary>
Motivation: 解决滚动快门相机在结构从运动（SfM）中的位姿估计问题，避免复杂的运动建模需求。

Method: 利用线投影与单条扫描线的交点进行位姿估计，支持单视图或多视图场景，并开发了最小求解器处理平行线和已知重力方向的情况。

Result: 在Fastec数据集上的实验验证了该方法用于滚动快门SfM初始化的可行性。

Conclusion: 该方法为滚动快门SfM提供了基础模块，具有进一步开发的潜力。

Abstract: We propose a novel approach for estimating the relative pose between rolling
shutter cameras using the intersections of line projections with a single
scanline per image. This allows pose estimation without explicitly modeling
camera motion. Alternatively, scanlines can be selected within a single image,
enabling single-view relative pose estimation for scanlines of rolling shutter
cameras. Our approach is designed as a foundational building block for rolling
shutter structure-from-motion (SfM), where no motion model is required, and
each scanline's pose can be computed independently. % We classify minimal
solvers for this problem in both generic and specialized settings, including
cases with parallel lines and known gravity direction, assuming known
intrinsics and no lens distortion. Furthermore, we develop minimal solvers for
the parallel-lines scenario, both with and without gravity priors, by
leveraging connections between this problem and the estimation of 2D structure
from 1D cameras. % Experiments on rolling shutter images from the Fastec
dataset demonstrate the feasibility of our approach for initializing rolling
shutter SfM, highlighting its potential for further development. % The code
will be made publicly available.

</details>


### [57] [Reasoning in machine vision: learning to think fast and slow](https://arxiv.org/abs/2506.22075)
*Shaheer U. Saeed,Yipei Wang,Veeru Kasivisvanathan,Brian R. Davidson,Matthew J. Clarkson,Yipeng Hu,Daniel C. Alexander*

Main category: cs.CV

TL;DR: 论文提出了一种新的学习范式，通过增加推理时间（计算资源）来提升机器在视觉任务中的推理能力，尤其在数据稀缺的情况下。该方法结合了快速思考的System I和慢速思考的System II模块，模仿人类推理过程。


<details>
  <summary>Details</summary>
Motivation: 人类推理能力在复杂场景中表现出色，而机器推理仍受限于训练数据，无法在推理时动态优化。现有研究多集中于基于规则的语言推理，非语言推理（如视觉任务）仍具挑战性。

Method: 受心理学双过程理论启发，结合快速反应的System I模块和通过自玩强化学习迭代优化的System II模块，模拟人类推理过程。

Result: 在视觉任务（包括计算机视觉基准和医学图像癌症定位）中，该方法通过延长推理时间，表现优于大规模监督学习、基础模型甚至人类专家。

Conclusion: 该范式为非语言机器推理提供了潜在变革性解决方案，尤其在数据稀缺的视觉任务中表现卓越。

Abstract: Reasoning is a hallmark of human intelligence, enabling adaptive
decision-making in complex and unfamiliar scenarios. In contrast, machine
intelligence remains bound to training data, lacking the ability to dynamically
refine solutions at inference time. While some recent advances have explored
reasoning in machines, these efforts are largely limited to verbal domains such
as mathematical problem-solving, where explicit rules govern step-by-step
reasoning. Other critical real-world tasks - including visual perception,
spatial reasoning, and radiological diagnosis - require non-verbal reasoning,
which remains an open challenge. Here we present a novel learning paradigm that
enables machine reasoning in vision by allowing performance improvement with
increasing thinking time (inference-time compute), even under conditions where
labelled data is very limited. Inspired by dual-process theories of human
cognition in psychology, our approach integrates a fast-thinking System I
module for familiar tasks, with a slow-thinking System II module that
iteratively refines solutions using self-play reinforcement learning. This
paradigm mimics human reasoning by proposing, competing over, and refining
solutions in data-scarce scenarios. We demonstrate superior performance through
extended thinking time, compared not only to large-scale supervised learning
but also foundation models and even human experts, in real-world vision tasks.
These tasks include computer-vision benchmarks and cancer localisation on
medical images across five organs, showcasing transformative potential for
non-verbal machine reasoning.

</details>


### [58] [Towards Accurate Heart Rate Measurement from Ultra-Short Video Clips via Periodicity-Guided rPPG Estimation and Signal Reconstruction](https://arxiv.org/abs/2506.22078)
*Pei-Kai Huanga,Ya-Ting Chan,Kuan-Wen Chen,Yen-Chun Chou,Shih-Yu Yang,Chiou-Ting Hsu*

Main category: cs.CV

TL;DR: 提出一种新方法，通过周期性引导和信号生成器，从2秒超短视频中准确测量心率，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有远程心率测量方法忽视超短视频的需求，本文旨在解决这一挑战。

Method: 提出周期性引导的rPPG估计方法和信号生成器，以克服超短视频中心跳周期少和频谱泄漏问题。

Result: 在四个基准数据集上验证，新方法在超短视频中心率测量准确且性能领先。

Conclusion: 该方法不仅解决了超短视频中心率测量的难题，还实现了最先进的性能。

Abstract: Many remote Heart Rate (HR) measurement methods focus on estimating remote
photoplethysmography (rPPG) signals from video clips lasting around 10 seconds
but often overlook the need for HR estimation from ultra-short video clips. In
this paper, we aim to accurately measure HR from ultra-short 2-second video
clips by specifically addressing two key challenges. First, to overcome the
limited number of heartbeat cycles in ultra-short video clips, we propose an
effective periodicity-guided rPPG estimation method that enforces consistent
periodicity between rPPG signals estimated from ultra-short clips and their
much longer ground truth signals. Next, to mitigate estimation inaccuracies due
to spectral leakage, we propose including a generator to reconstruct longer
rPPG signals from ultra-short ones while preserving their periodic consistency
to enable more accurate HR measurement. Extensive experiments on four rPPG
estimation benchmark datasets demonstrate that our proposed method not only
accurately measures HR from ultra-short video clips but also outperform
previous rPPG estimation techniques to achieve state-of-the-art performance.

</details>


### [59] [BézierGS: Dynamic Urban Scene Reconstruction with Bézier Curve Gaussian Splatting](https://arxiv.org/abs/2506.22099)
*Zipei Ma,Junzhe Jiang,Yurui Chen,Li Zhang*

Main category: cs.CV

TL;DR: 提出BézierGS方法，通过可学习的Bézier曲线建模动态物体运动轨迹，减少对高精度标注的依赖，提升街景重建效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖高精度物体姿态标注，限制了大规模场景重建。

Method: 使用Bézier曲线表示动态物体运动轨迹，结合动态物体渲染和曲线一致性约束。

Result: 在Waymo和nuPlan数据集上表现优于现有方法。

Conclusion: BézierGS能有效提升动态和静态场景的重建质量。

Abstract: The realistic reconstruction of street scenes is critical for developing
real-world simulators in autonomous driving. Most existing methods rely on
object pose annotations, using these poses to reconstruct dynamic objects and
move them during the rendering process. This dependence on high-precision
object annotations limits large-scale and extensive scene reconstruction. To
address this challenge, we propose B\'ezier curve Gaussian splatting
(B\'ezierGS), which represents the motion trajectories of dynamic objects using
learnable B\'ezier curves. This approach fully leverages the temporal
information of dynamic objects and, through learnable curve modeling,
automatically corrects pose errors. By introducing additional supervision on
dynamic object rendering and inter-curve consistency constraints, we achieve
reasonable and accurate separation and reconstruction of scene elements.
Extensive experiments on the Waymo Open Dataset and the nuPlan benchmark
demonstrate that B\'ezierGS outperforms state-of-the-art alternatives in both
dynamic and static scene components reconstruction and novel view synthesis.

</details>


### [60] [Tied Prototype Model for Few-Shot Medical Image Segmentation](https://arxiv.org/abs/2506.22101)
*Hyeongji Kim,Stine Hansen,Michael Kampffmeyer*

Main category: cs.CV

TL;DR: TPM改进ADNet，通过绑定原型位置和多原型扩展，提升医学图像少样本分割性能。


<details>
  <summary>Details</summary>
Motivation: 解决ADNet在单原型、二分类和固定阈值上的局限性。

Method: 提出TPM，绑定前景和背景原型，支持多原型和多类分割，自适应阈值。

Result: TPM显著提升分割精度。

Conclusion: TPM为医学图像少样本分割提供了新视角。

Abstract: Common prototype-based medical image few-shot segmentation (FSS) methods
model foreground and background classes using class-specific prototypes.
However, given the high variability of the background, a more promising
direction is to focus solely on foreground modeling, treating the background as
an anomaly -- an approach introduced by ADNet. Yet, ADNet faces three key
limitations: dependence on a single prototype per class, a focus on binary
classification, and fixed thresholds that fail to adapt to patient and organ
variability. To address these shortcomings, we propose the Tied Prototype Model
(TPM), a principled reformulation of ADNet with tied prototype locations for
foreground and background distributions. Building on its probabilistic
foundation, TPM naturally extends to multiple prototypes and multi-class
segmentation while effectively separating non-typical background features.
Notably, both extensions lead to improved segmentation accuracy. Finally, we
leverage naturally occurring class priors to define an ideal target for
adaptive thresholds, boosting segmentation performance. Taken together, TPM
provides a fresh perspective on prototype-based FSS for medical image
segmentation. The code can be found at https://github.com/hjk92g/TPM-FSS.

</details>


### [61] [Pipe Reconstruction from Point Cloud Data](https://arxiv.org/abs/2506.22118)
*Antje Alex,Jannis Stoppe*

Main category: cs.CV

TL;DR: 提出一种自动化管道重建方法，从激光扫描数据中生成数字孪生工业资产的精确模型。


<details>
  <summary>Details</summary>
Motivation: 手动建模管道耗时耗力，需自动化方法提高效率和精度。

Method: 采用拉普拉斯收缩估计骨架曲线，结合滚动球技术和2D圆拟合重新居中，并通过3D平滑细化。

Result: 能够准确确定管道属性（半径、长度、方向），生成复杂管道网络的详细3D模型。

Conclusion: 自动化管道重建支持数字孪生开发，降低成本并提高建模速度和准确性。

Abstract: Accurate digital twins of industrial assets, such as ships and offshore
platforms, rely on the precise reconstruction of complex pipe networks.
However, manual modelling of pipes from laser scan data is a time-consuming and
labor-intensive process. This paper presents a pipeline for automated pipe
reconstruction from incomplete laser scan data. The approach estimates a
skeleton curve using Laplacian-based contraction, followed by curve elongation.
The skeleton axis is then recentred using a rolling sphere technique combined
with 2D circle fitting, and refined with a 3D smoothing step. This enables the
determination of pipe properties, including radius, length and orientation, and
facilitates the creation of detailed 3D models of complex pipe networks. By
automating pipe reconstruction, this approach supports the development of
digital twins, allowing for rapid and accurate modeling while reducing costs.

</details>


### [62] [Low-Rank Implicit Neural Representation via Schatten-p Quasi-Norm and Jacobian Regularization](https://arxiv.org/abs/2506.22134)
*Zhengyun Cheng,Changhao Wang,Guanwen Zhang,Yi Xu,Wei Zhou,Xiangyang Ji*

Main category: cs.CV

TL;DR: 提出了一种基于CP分解的低秩张量函数（CP-INR），通过神经网络参数化实现连续数据表示，并引入稀疏性和平滑性正则化方法，在多维数据恢复任务中表现优越。


<details>
  <summary>Details</summary>
Motivation: 现有张量分解方法（如Tucker和CP）在灵活性和可解释性之间存在权衡，且稀疏解难以获取。CP-INR旨在结合CP分解的天然结构优势，同时解决稀疏性和平滑性问题。

Method: 1. 提出CP-INR，利用神经网络参数化低秩张量函数；2. 引入Schatten-p拟范数的变分形式实现稀疏CP分解；3. 提出基于谱范数的平滑正则化方法，避免显式链式求导。

Result: 在图像修复、去噪和点云上采样等任务中，CP-INR表现优于现有方法，验证了其优越性和通用性。

Conclusion: CP-INR结合了CP分解的可解释性和神经网络的非线性能力，通过稀疏和平滑正则化，在多维数据恢复任务中实现了高效和通用的表现。

Abstract: Higher-order tensors are well-suited for representing multi-dimensional data,
such as color images and videos. Low-rank tensor representation has become
essential in machine learning and computer vision, but existing methods like
Tucker decomposition offer flexibility at the expense of interpretability. In
contrast, while the CANDECOMP/PARAFAC (CP) decomposition provides a more
natural and interpretable tensor structure, obtaining sparse solutions remains
challenging. Leveraging the rich properties of CP decomposition, we propose a
CP-based low-rank tensor function parameterized by neural networks for implicit
neural representation (CP-INR). This approach enables continuous data
representation beyond structured grids, fully exploiting the non-linearity of
tensor data with theoretical guarantees on excess risk bounds. To achieve a
sparse CP decomposition, we introduce a variational form of the Schatten-p
quasi-norm and prove its relationship to multilinear rank minimization. For
smoothness, we propose a regularization term based on the spectral norm of the
Jacobian and Hutchinson's trace estimator. Our proposed smoothness
regularization is SVD-free and avoids explicit chain rule derivations. It can
serve as an alternative to Total Variation (TV) regularization in image
denoising tasks and is naturally applicable to continuous data. Extensive
experiments on multi-dimensional data recovery tasks, including image
inpainting, denoising, and point cloud upsampling, demonstrate the superiority
and versatility of our method compared to state-of-the-art approaches.

</details>


### [63] [Q-Frame: Query-aware Frame Selection and Multi-Resolution Adaptation for Video-LLMs](https://arxiv.org/abs/2506.22139)
*Shaojie Zhang,Jiahui Yang,Jianqin Yin,Zhenbo Luo,Jian Luan*

Main category: cs.CV

TL;DR: Q-Frame是一种自适应帧选择和多分辨率缩放方法，用于提升视频理解任务中的多模态大语言模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频-LLM采用均匀帧采样，难以有效捕捉查询相关的关键时空线索，需要一种更高效的方法。

Method: Q-Frame通过无训练、即插即用的策略，利用CLIP等文本-图像匹配网络和Gumbel-Max技巧进行帧选择。

Result: 在MLVU、LongVideoBench和Video-MME等基准数据集上，Q-Frame表现优于现有方法。

Conclusion: Q-Frame能高效处理更多帧，保留关键时空信息，适用于多种视频理解任务。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated significant
success in visual understanding tasks. However, challenges persist in adapting
these models for video comprehension due to the large volume of data and
temporal complexity. Existing Video-LLMs using uniform frame sampling often
struggle to capture the query-related crucial spatiotemporal clues of videos
effectively. In this paper, we introduce Q-Frame, a novel approach for adaptive
frame selection and multi-resolution scaling tailored to the video's content
and the specific query. Q-Frame employs a training-free, plug-and-play strategy
generated by a text-image matching network like CLIP, utilizing the Gumbel-Max
trick for efficient frame selection. Q-Frame allows Video-LLMs to process more
frames without exceeding computational limits, thereby preserving critical
temporal and spatial information. We demonstrate Q-Frame's effectiveness
through extensive experiments on benchmark datasets, including MLVU,
LongVideoBench, and Video-MME, illustrating its superiority over existing
methods and its applicability across various video understanding tasks.

</details>


### [64] [Visual Structures Helps Visual Reasoning: Addressing the Binding Problem in VLMs](https://arxiv.org/abs/2506.22146)
*Amirmohammad Izadi,Mohammad Ali Banayeeanzade,Fatemeh Askari,Ali Rahimiakbar,Mohammad Mahdi Vahedi,Hosein Hasani,Mahdieh Soleymani Baghshah*

Main category: cs.CV

TL;DR: 论文提出通过增强视觉输入的低级空间结构（如水平线）并结合文本提示，显著提升了视觉语言模型在视觉推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在视觉推理中存在绑定问题，即难以可靠地将感知特征与正确的视觉对象关联，导致在计数、视觉搜索等任务中表现不佳。

Method: 通过为视觉输入添加低级空间结构（如水平线），并配合鼓励序列化、空间感知解析的文本提示，改进模型的视觉推理能力。

Result: 实验显示，该方法在视觉搜索、计数、场景描述和空间关系任务中分别提升了25.00%、26.83%、0.32（编辑距离误差减少）和9.50%的性能。

Conclusion: 低级视觉结构调整是提升视觉语言模型在空间任务中表现的有效策略，且优于纯文本方法。

Abstract: Despite progress in Vision-Language Models (VLMs), their capacity for visual
reasoning is often limited by the \textit{binding problem}: the failure to
reliably associate perceptual features with their correct visual referents.
This limitation underlies persistent errors in tasks such as counting, visual
search, scene description, and spatial relationship understanding. A key factor
is that current VLMs process visual features largely in parallel, lacking
mechanisms for spatially grounded, serial attention. This paper introduces a
simple yet effective intervention: augmenting visual inputs with low-level
spatial structures (e.g., horizontal lines) and pairing this with a textual
prompt that encourages sequential, spatially-aware parsing. We empirically
demonstrate substantial performance improvements across core visual reasoning
tasks. Specifically, our method improves GPT-4o visual search accuracy by
25.00%, increases counting accuracy by 26.83%, reduces edit distance error in
scene description by 0.32, and enhances performance on spatial relationship
tasks by 9.50% on a a 2D synthetic dataset. Furthermore, we find that the
visual modification is essential for these gains; purely textual strategies,
including Chain-of-Thought prompting, are insufficient and can even degrade
performance. Our method enhances binding only with a single-query inference,
underscoring the importance of visual input design over purely
linguistically-based approaches. These findings suggest that low-level visual
structuring is a powerful and underexplored direction for improving
compositional visual reasoning and could serve as a general strategy for
enhancing VLM performance on spatially grounded tasks.

</details>


### [65] [RetFiner: A Vision-Language Refinement Scheme for Retinal Foundation Models](https://arxiv.org/abs/2506.22149)
*Ronald Fecso,José Morano,Ursula Schmidt-Erfurth,Hrvoje Bogunović*

Main category: cs.CV

TL;DR: RetFiner是一种自监督视觉语言优化方案，通过利用文本数据的丰富监督信号，提升现有基础模型的表示能力，并在下游任务中显著提高性能。


<details>
  <summary>Details</summary>
Motivation: 现有OCT基础模型仅基于图像数据训练，缺乏全面的语义理解，导致下游任务性能不足，尤其是复杂任务。RetFiner旨在通过视觉语言优化解决这一问题。

Method: RetFiner采用多样化的训练目标，利用文本数据的监督信号优化基础模型的表示能力，并直接适应特定人群。

Result: 在七种OCT分类任务中，RetFiner显著提升了RETFound、UrFound和VisionFM的线性探测性能，平均分别提高了5.8、3.9和2.1个百分点。

Conclusion: RetFiner通过视觉语言优化有效提升了基础模型的下游任务性能，为OCT图像分析提供了更高效的解决方案。

Abstract: The rise of imaging techniques such as optical coherence tomography (OCT) and
advances in deep learning (DL) have enabled clinicians and researchers to
streamline retinal disease staging. A popular DL approach is self-supervised
learning (SSL), where models learn from vast amounts of unlabeled data,
avoiding costly annotation. SSL has allowed the development of foundation
models (FMs), large models that can be used for a variety of downstream tasks.
However, existing FMs for OCT, trained solely on image data, lack a
comprehensive and robust semantic understanding of images, as evidenced by
their downstream performance (especially for complex tasks), and thus require
supervised fine-tuning (which may be unfeasible) to better adapt to specific
applications and populations. To address this, we propose RetFiner, an SSL
vision-language refinement scheme that improves the representations of existing
FMs and enables their efficient and direct adaptation to specific populations
for improved downstream performance. Our method uses a diverse set of training
objectives which take advantage of the rich supervisory signal found in textual
data. We tested RetFiner on the retinal FMs RETFound, UrFound, and VisionFM,
showing significant improvements in linear probing performance on seven highly
diverse OCT classification tasks, with an average increase of 5.8, 3.9, and 2.1
percentage points over their baselines, respectively. Our code and model
weights are publicly available at https://github.com/ronnief1/RetFiner.

</details>


### [66] [Attention-disentangled Uniform Orthogonal Feature Space Optimization for Few-shot Object Detection](https://arxiv.org/abs/2506.22161)
*Taijin Zhao,Heqian Qiu,Yu Dai,Lanxiao Wang,Fanman Meng,Qingbo Wu,Hongliang Li*

Main category: cs.CV

TL;DR: 论文提出了一种统一正交特征空间（UOFS）优化框架，用于解决少样本目标检测（FSOD）中特征空间耦合的问题，通过解耦特征空间和混合背景优化（HBO）策略提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有FSOD方法在共享特征空间中耦合目标识别和前景分类，导致类特定目标性标准和样本不具代表性。

Method: 提出UOFS框架，解耦特征空间为幅度（目标性）和角度（分类），并采用HBO策略解决未标记实例和角度优化问题。

Result: 实验表明，该方法显著优于基于耦合特征空间的现有方法。

Conclusion: UOFS和HBO策略有效解决了FSOD中的特征空间耦合问题，提升了检测性能。

Abstract: Few-shot object detection (FSOD) aims to detect objects with limited samples
for novel classes, while relying on abundant data for base classes. Existing
FSOD approaches, predominantly built on the Faster R-CNN detector, entangle
objectness recognition and foreground classification within shared feature
spaces. This paradigm inherently establishes class-specific objectness criteria
and suffers from unrepresentative novel class samples. To resolve this
limitation, we propose a Uniform Orthogonal Feature Space (UOFS) optimization
framework. First, UOFS decouples the feature space into two orthogonal
components, where magnitude encodes objectness and angle encodes
classification. This decoupling enables transferring class-agnostic objectness
knowledge from base classes to novel classes. Moreover, implementing the
disentanglement requires careful attention to two challenges: (1) Base set
images contain unlabeled foreground instances, causing confusion between
potential novel class instances and backgrounds. (2) Angular optimization
depends exclusively on base class foreground instances, inducing overfitting of
angular distributions to base classes. To address these challenges, we propose
a Hybrid Background Optimization (HBO) strategy: (1) Constructing a pure
background base set by removing unlabeled instances in original images to
provide unbiased magnitude-based objectness supervision. (2) Incorporating
unlabeled foreground instances in the original base set into angular
optimization to enhance distribution uniformity. Additionally, we propose a
Spatial-wise Attention Disentanglement and Association (SADA) module to address
task conflicts between class-agnostic and class-specific tasks. Experiments
demonstrate that our method significantly outperforms existing approaches based
on entangled feature spaces.

</details>


### [67] [Frequency-Semantic Enhanced Variational Autoencoder for Zero-Shot Skeleton-based Action Recognition](https://arxiv.org/abs/2506.22179)
*Wenhan Wu,Zhishuai Guo,Chen Chen,Hongfei Xue,Aidong Lu*

Main category: cs.CV

TL;DR: 论文提出了一种基于频率分解的FS-VAE模型，用于零样本骨架动作识别，通过频率增强和语义对齐提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在语义空间中忽略细粒度动作模式的问题，如手部动作的差异。

Method: FS-VAE包含三个关键模块：频率增强、多级语义对齐和校准交叉对齐损失。

Result: 在基准测试中验证了频率增强语义特征能有效区分视觉和语义相似的动作簇。

Conclusion: FS-VAE通过频率和语义的联合优化，显著提升了零样本动作识别的鲁棒性。

Abstract: Zero-shot skeleton-based action recognition aims to develop models capable of
identifying actions beyond the categories encountered during training. Previous
approaches have primarily focused on aligning visual and semantic
representations but often overlooked the importance of fine-grained action
patterns in the semantic space (e.g., the hand movements in drinking water and
brushing teeth). To address these limitations, we propose a Frequency-Semantic
Enhanced Variational Autoencoder (FS-VAE) to explore the skeleton semantic
representation learning with frequency decomposition. FS-VAE consists of three
key components: 1) a frequency-based enhancement module with high- and
low-frequency adjustments to enrich the skeletal semantics learning and improve
the robustness of zero-shot action recognition; 2) a semantic-based action
description with multilevel alignment to capture both local details and global
correspondence, effectively bridging the semantic gap and compensating for the
inherent loss of information in skeleton sequences; 3) a calibrated
cross-alignment loss that enables valid skeleton-text pairs to counterbalance
ambiguous ones, mitigating discrepancies and ambiguities in skeleton and text
features, thereby ensuring robust alignment. Evaluations on the benchmarks
demonstrate the effectiveness of our approach, validating that
frequency-enhanced semantic features enable robust differentiation of visually
and semantically similar action clusters, improving zero-shot action
recognition.

</details>


### [68] [ReF-LLE: Personalized Low-Light Enhancement via Reference-Guided Deep Reinforcement Learning](https://arxiv.org/abs/2506.22216)
*Ming Zhao,Pingping Liu,Tongshun Zhang,Zhe Zhang*

Main category: cs.CV

TL;DR: ReF-LLE是一种基于傅里叶频域和深度强化学习的个性化低光图像增强方法，通过零参考图像评估策略和自适应迭代策略，显著提升了增强效果。


<details>
  <summary>Details</summary>
Motivation: 解决低光图像增强中因条件差异和主观偏好带来的挑战。

Method: 在傅里叶频域中结合深度强化学习，引入零参考图像评估策略和个性化自适应迭代策略。

Result: 在基准数据集上表现优于现有方法，具有更高的感知质量和个性化适应性。

Conclusion: ReF-LLE为低光图像增强提供了一种高效且个性化的解决方案。

Abstract: Low-light image enhancement presents two primary challenges: 1) Significant
variations in low-light images across different conditions, and 2) Enhancement
levels influenced by subjective preferences and user intent. To address these
issues, we propose ReF-LLE, a novel personalized low-light image enhancement
method that operates in the Fourier frequency domain and incorporates deep
reinforcement learning. ReF-LLE is the first to integrate deep reinforcement
learning into this domain. During training, a zero-reference image evaluation
strategy is introduced to score enhanced images, providing reward signals that
guide the model to handle varying degrees of low-light conditions effectively.
In the inference phase, ReF-LLE employs a personalized adaptive iterative
strategy, guided by the zero-frequency component in the Fourier domain, which
represents the overall illumination level. This strategy enables the model to
adaptively adjust low-light images to align with the illumination distribution
of a user-provided reference image, ensuring personalized enhancement results.
Extensive experiments on benchmark datasets demonstrate that ReF-LLE
outperforms state-of-the-art methods, achieving superior perceptual quality and
adaptability in personalized low-light image enhancement.

</details>


### [69] [Boosting Classification with Quantum-Inspired Augmentations](https://arxiv.org/abs/2506.22241)
*Matthias Tschöpe,Vitor Fortes Rey,Sogo Pierre Sanon,Paul Lukowicz,Nikolaos Palaiodimopoulos,Maximilian Kiefer-Emmanouilidis*

Main category: cs.CV

TL;DR: 量子门扰动作为数据增强技术提升经典机器学习性能，但隐私保护效果有限。


<details>
  <summary>Details</summary>
Motivation: 研究量子门扰动在量子机器学习中的潜在优势，探索其作为数据增强技术的效果及其对经典机器学习的改进。

Method: 使用随机Bloch球旋转作为量子启发的数据增强技术，应用于ImageNet数据集，并与传统增强方法对比。

Result: 量子增强方法显著提升图像分类性能（Top-1准确率提高3%，Top-5提高2.5%，F1分数从8%增至12%），但隐私保护效果不佳。

Conclusion: 量子扰动可作为有效的数据增强手段，但对隐私保护无显著贡献。

Abstract: Understanding the impact of small quantum gate perturbations, which are
common in quantum digital devices but absent in classical computers, is crucial
for identifying potential advantages in quantum machine learning. While these
perturbations are typically seen as detrimental to quantum computation, they
can actually enhance performance by serving as a natural source of data
augmentation. Additionally, they can often be efficiently simulated on
classical hardware, enabling quantum-inspired approaches to improve classical
machine learning methods. In this paper, we investigate random Bloch sphere
rotations, which are fundamental SU(2) transformations, as a simple yet
effective quantum-inspired data augmentation technique. Unlike conventional
augmentations such as flipping, rotating, or cropping, quantum transformations
lack intuitive spatial interpretations, making their application to tasks like
image classification less straightforward. While common quantum augmentation
methods rely on applying quantum models or trainable quanvolutional layers to
classical datasets, we focus on the direct application of small-angle Bloch
rotations and their effect on classical data. Using the large-scale ImageNet
dataset, we demonstrate that our quantum-inspired augmentation method improves
image classification performance, increasing Top-1 accuracy by 3%, Top-5
accuracy by 2.5%, and the F$_1$ score from 8% to 12% compared to standard
classical augmentation methods. Finally, we examine the use of stronger unitary
augmentations. Although these transformations preserve information in
principle, they result in visually unrecognizable images with potential
applications for privacy computations. However, we show that our augmentation
approach and simple SU(2) transformations do not enhance differential privacy
and discuss the implications of this limitation.

</details>


### [70] [4D-VLA: Spatiotemporal Vision-Language-Action Pretraining with Cross-Scene Calibration](https://arxiv.org/abs/2506.22242)
*Jiahui Zhang,Yurui Chen,Yueming Xu,Ze Huang,Yanpeng Zhou,Yu-Jie Yuan,Xinyue Cai,Guowei Huang,Xingyue Quan,Hang Xu,Li Zhang*

Main category: cs.CV

TL;DR: 论文提出了一种名为4D-VLA的新方法，通过整合4D信息（深度和时序）来解决机器人数据预训练中的坐标系和状态混乱问题，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常使用简单观察作为输入来建模动作分布，但这些输入往往不完整，导致条件动作分布分散，即坐标系混乱和状态混乱，从而影响预训练效率。

Method: 4D-VLA通过引入深度和时序信息到视觉特征中，对齐机器人与场景的坐标系，同时提出记忆库采样策略以提取历史图像中的关键帧。

Result: 实验表明，该方法在模拟和真实环境中均显著提升了成功率，并在多视图基准测试中表现出更强的空间理解和适应性。

Conclusion: 4D-VLA通过整合4D信息和优化采样策略，有效解决了预训练中的混乱问题，显著提升了模型性能。

Abstract: Leveraging diverse robotic data for pretraining remains a critical challenge.
Existing methods typically model the dataset's action distribution using simple
observations as inputs. However, these inputs are often incomplete, resulting
in a dispersed conditional action distribution-an issue we refer to as
coordinate system chaos and state chaos. This inconsistency significantly
hampers pretraining efficiency. To address this, we propose 4D-VLA, a novel
approach that effectively integrates 4D information into the input to mitigate
these sources of chaos. Our model introduces depth and temporal information
into visual features with sequential RGB-D inputs, aligning the coordinate
systems of the robot and the scene. This alignment endows the model with strong
spatiotemporal reasoning capabilities while minimizing training overhead.
Additionally, we introduce memory bank sampling, a frame sampling strategy
designed to extract informative frames from historical images, further
improving effectiveness and efficiency. Experimental results demonstrate that
our pretraining method and architectural components substantially enhance model
performance. In both simulated and real-world experiments, our model achieves a
significant increase in success rate over OpenVLA. To further assess spatial
perception and generalization to novel views, we introduce MV-Bench, a
multi-view simulation benchmark. Our model consistently outperforms existing
methods, demonstrating stronger spatial understanding and adaptability.

</details>


### [71] [From Ground to Air: Noise Robustness in Vision Transformers and CNNs for Event-Based Vehicle Classification with Potential UAV Applications](https://arxiv.org/abs/2506.22360)
*Nouf Almesafri,Hector Figueiredo,Miguel Arana-Catania*

Main category: cs.CV

TL;DR: 研究比较了CNN（ResNet34）和ViT（ViT B16）在事件相机上的性能，发现ResNet34在分类准确率上略优，但ViT B16在噪声环境下表现更稳健。


<details>
  <summary>Details</summary>
Motivation: 事件相机适用于动态环境（如无人机和自动驾驶车辆），但现有深度学习模型在其上的性能尚不明确。

Method: 使用ResNet34和ViT B16在GEN1事件数据集上进行微调，并在标准条件和模拟噪声下评估。

Result: ResNet34和ViT B16在干净数据上的准确率分别为88%和86%，但ViT B16在噪声下表现更稳健。

Conclusion: 研究结果对无人机等动态环境中的事件视觉系统具有潜在应用价值。

Abstract: This study investigates the performance of the two most relevant computer
vision deep learning architectures, Convolutional Neural Network and Vision
Transformer, for event-based cameras. These cameras capture scene changes,
unlike traditional frame-based cameras with capture static images, and are
particularly suited for dynamic environments such as UAVs and autonomous
vehicles. The deep learning models studied in this work are ResNet34 and ViT
B16, fine-tuned on the GEN1 event-based dataset. The research evaluates and
compares these models under both standard conditions and in the presence of
simulated noise. Initial evaluations on the clean GEN1 dataset reveal that
ResNet34 and ViT B16 achieve accuracies of 88% and 86%, respectively, with
ResNet34 showing a slight advantage in classification accuracy. However, the
ViT B16 model demonstrates notable robustness, particularly given its
pre-training on a smaller dataset. Although this study focuses on ground-based
vehicle classification, the methodologies and findings hold significant promise
for adaptation to UAV contexts, including aerial object classification and
event-based vision systems for aviation-related tasks.

</details>


### [72] [EAMamba: Efficient All-Around Vision State Space Model for Image Restoration](https://arxiv.org/abs/2506.22246)
*Yu-Cheng Lin,Yu-Syuan Xu,Hao-Wei Chen,Hsien-Kai Kuo,Chun-Yi Lee*

Main category: cs.CV

TL;DR: 论文提出EAMamba框架，通过多头选择性扫描模块（MHSSM）和全方位扫描机制，解决了Vision Mamba在图像修复任务中的计算复杂性和局部像素遗忘问题，显著降低了计算量。


<details>
  <summary>Details</summary>
Motivation: Vision Mamba在图像修复任务中表现出色，但仍面临计算复杂度高和局部像素遗忘的挑战，因此需要改进。

Method: 引入EAMamba框架，结合MHSSM模块和全方位扫描策略，高效聚合扫描序列并捕获全局信息。

Result: 实验表明，EAMamba在多种修复任务中显著降低FLOPs（31-89%），同时保持良好性能。

Conclusion: EAMamba有效解决了Vision Mamba的局限性，为图像修复任务提供了高效且性能优越的解决方案。

Abstract: Image restoration is a key task in low-level computer vision that aims to
reconstruct high-quality images from degraded inputs. The emergence of Vision
Mamba, which draws inspiration from the advanced state space model Mamba, marks
a significant advancement in this field. Vision Mamba demonstrates excellence
in modeling long-range dependencies with linear complexity, a crucial advantage
for image restoration tasks. Despite its strengths, Vision Mamba encounters
challenges in low-level vision tasks, including computational complexity that
scales with the number of scanning sequences and local pixel forgetting. To
address these limitations, this study introduces Efficient All-Around Mamba
(EAMamba), an enhanced framework that incorporates a Multi-Head Selective Scan
Module (MHSSM) with an all-around scanning mechanism. MHSSM efficiently
aggregates multiple scanning sequences, which avoids increases in computational
complexity and parameter count. The all-around scanning strategy implements
multiple patterns to capture holistic information and resolves the local pixel
forgetting issue. Our experimental evaluations validate these innovations
across several restoration tasks, including super resolution, denoising,
deblurring, and dehazing. The results validate that EAMamba achieves a
significant 31-89% reduction in FLOPs while maintaining favorable performance
compared to existing low-level Vision Mamba methods.

</details>


### [73] [COOCO -- Common Objects Out-of-Context -- Semantic Violation in Scenes: Investigating Multimodal Context in Referential Communication](https://arxiv.org/abs/2506.22274)
*Filippo Merlo,Ece Takmaz,Wenkai Chen,Albert Gatt*

Main category: cs.CV

TL;DR: 研究探讨了视觉语言模型（VLMs）是否依赖场景上下文生成对象引用，并引入COOCO数据集测试模型在不同场景-对象一致性和噪声下的表现。


<details>
  <summary>Details</summary>
Motivation: 探究VLMs是否像人类一样利用场景上下文进行对象识别和引用。

Method: 引入COOCO数据集，测试模型在不同场景-对象一致性和噪声下的表现，并进行注意力分析。

Result: 模型会根据场景-对象语义相关性和噪声水平动态调整对上下文的依赖，中层次注意力在目标分类中起关键作用。

Conclusion: VLMs能动态平衡局部和上下文信息，尤其在场景-对象高度一致或对象受损时更依赖上下文。

Abstract: Natural scenes provide us with rich contexts for object recognition and
reference. In particular, knowing what type of scene one is looking at
generates expectations about which objects will occur, and what their spatial
configuration should be. Do Vision-Language Models (VLMs) learn to rely on
scene contexts in a similar way, when generating references to objects? To
address this question, we introduce the \textit{Common Objects Out-of-Context
(COOCO)} dataset and test to what extent VLMs rely on scene context to refer to
objects under different degrees of scene-object congruency, and different
perturbations. Our findings show that models leverage scene context adaptively,
depending on both the semantic relatedness between object and scene and the
level of noise. In particular, models rely more on context under high
target-scene congruence or when objects are degraded. Attention analysis
reveals that successful object categorisation involves increased focus on the
target in mid-level layers, especially under moderate noise, suggesting that
VLMs dynamically balance local and contextual information for reference
generation. We make our dataset, code and models available at
\href{https://github.com/cs-nlp-uu/scenereg}{https://github.com/cs-nlp-uu/scenereg}.

</details>


### [74] [Rethinking Visual Token Reduction in LVLMs under Cross-modal Misalignment](https://arxiv.org/abs/2506.22283)
*Rui Xu,Yunke Wang,Yong Luo,Bo Du*

Main category: cs.CV

TL;DR: VisionDrop是一种无需训练的视觉令牌修剪框架，通过视觉内注意力选择信息丰富的视觉令牌，解决了跨模态不对齐问题，提升了LVLMs的效率。


<details>
  <summary>Details</summary>
Motivation: 现有视觉令牌减少方法依赖文本条件交互，但存在跨模态不对齐问题，限制了LVLMs的扩展性和效率。

Method: 提出VisionDrop框架，基于视觉内注意力选择令牌，设计渐进式修剪流程，在多个阶段进行令牌选择和合并。

Result: 实验表明，VisionDrop在多种基准测试中优于现有方法，无需额外训练或复杂修改。

Conclusion: VisionDrop通过简单有效的设计，实现了高效推理并保持了任务性能。

Abstract: Large Vision-Language Models (LVLMs) encode visual inputs as dense sequences
of patch-level tokens to capture fine-grained semantics. These visual tokens
often outnumber their textual counterparts by a large margin, leading to
substantial computational overhead and limiting the scalability of LVLMs in
practice. Previous efforts have explored visual token reduction either prior to
or within the large language models (LLM). However, most in-LLM reduction
approaches rely on text-conditioned interactions, implicitly assuming that
textual tokens can reliably capture the importance of visual tokens. In this
work, we revisit this assumption and reveal causal, semantic, and spatial forms
of cross-modal misalignment. These misalignments undermine the effectiveness of
text-guided visual token reduction. To address this, we introduce VisionDrop, a
training-free, visual-only pruning framework that selects informative visual
tokens based on intra-modal (visual-to-visual) attention, without relying on
textual signals. To further suppress redundancy throughout the model hierarchy,
we treat the visual encoder and the LLM as a unified system and design a
progressive pruning pipeline. Our method performs dominant token selection and
lightweight contextual merging at multiple stages, enabling fine-grained visual
information to be retained even under aggressive token budgets. Extensive
experiments across diverse benchmarks show that VisionDrop achieves consistent
improvements over existing methods, despite requiring no additional training or
complex modifications. Its simple yet effective design enables efficient
inference while preserving strong performance across tasks.

</details>


### [75] [RoomCraft: Controllable and Complete 3D Indoor Scene Generation](https://arxiv.org/abs/2506.22291)
*Mengqi Zhou,Xipeng Wang,Yuxi Wang,Zhaoxiang Zhang*

Main category: cs.CV

TL;DR: RoomCraft是一个多阶段管道，将真实图像、草图或文本描述转换为连贯的3D室内场景，解决了现有方法在几何一致性、空间关系和视觉真实性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有神经生成方法因全局空间推理有限导致重复元素，而程序化方法在多约束场景下难以处理家具碰撞和布局完整性。

Method: 结合场景生成管道和约束驱动优化框架，使用结构化格式提取场景信息，构建空间关系网络，并通过HDFS算法生成优化放置序列。引入统一约束表示和CAPS策略处理多约束和碰撞问题。

Result: RoomCraft在生成真实、语义连贯且视觉吸引人的房间布局方面显著优于现有方法。

Conclusion: RoomCraft通过多阶段优化和动态调整策略，有效解决了3D室内场景生成的复杂性和约束问题。

Abstract: Generating realistic 3D indoor scenes from user inputs remains a challenging
problem in computer vision and graphics, requiring careful balance of geometric
consistency, spatial relationships, and visual realism. While neural generation
methods often produce repetitive elements due to limited global spatial
reasoning, procedural approaches can leverage constraints for controllable
generation but struggle with multi-constraint scenarios. When constraints
become numerous, object collisions frequently occur, forcing the removal of
furniture items and compromising layout completeness.
  To address these limitations, we propose RoomCraft, a multi-stage pipeline
that converts real images, sketches, or text descriptions into coherent 3D
indoor scenes. Our approach combines a scene generation pipeline with a
constraint-driven optimization framework. The pipeline first extracts
high-level scene information from user inputs and organizes it into a
structured format containing room type, furniture items, and spatial relations.
It then constructs a spatial relationship network to represent furniture
arrangements and generates an optimized placement sequence using a
heuristic-based depth-first search (HDFS) algorithm to ensure layout coherence.
To handle complex multi-constraint scenarios, we introduce a unified constraint
representation that processes both formal specifications and natural language
inputs, enabling flexible constraint-oriented adjustments through a
comprehensive action space design. Additionally, we propose a Conflict-Aware
Positioning Strategy (CAPS) that dynamically adjusts placement weights to
minimize furniture collisions and ensure layout completeness.
  Extensive experiments demonstrate that RoomCraft significantly outperforms
existing methods in generating realistic, semantically coherent, and visually
appealing room layouts across diverse input modalities.

</details>


### [76] [OutDreamer: Video Outpainting with a Diffusion Transformer](https://arxiv.org/abs/2506.22298)
*Linhao Zhong,Fan Li,Yi Huang,Jianzhuang Liu,Renjing Pei,Fenglong Song*

Main category: cs.CV

TL;DR: OutDreamer是一个基于扩散变换器（DiT）的视频外绘框架，通过高效视频控制分支和条件外绘分支，结合掩码驱动自注意力层和潜在对齐损失，显著提升了视频外绘的质量和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在视频外绘任务中难以同时保证时空一致性和生成内容的高质量，扩散变换器（DiT）因其优越性能成为潜在解决方案。

Method: 提出OutDreamer框架，包含高效视频控制分支和条件外绘分支，引入掩码驱动自注意力层和潜在对齐损失，并采用跨视频片段细化器处理长视频。

Result: 在广泛认可的基准测试中，OutDreamer在零样本设置下优于现有最优方法。

Conclusion: OutDreamer通过创新的架构设计和损失函数，显著提升了视频外绘的性能和适应性。

Abstract: Video outpainting is a challenging task that generates new video content by
extending beyond the boundaries of an original input video, requiring both
temporal and spatial consistency. Many state-of-the-art methods utilize latent
diffusion models with U-Net backbones but still struggle to achieve high
quality and adaptability in generated content. Diffusion transformers (DiTs)
have emerged as a promising alternative because of their superior performance.
We introduce OutDreamer, a DiT-based video outpainting framework comprising two
main components: an efficient video control branch and a conditional
outpainting branch. The efficient video control branch effectively extracts
masked video information, while the conditional outpainting branch generates
missing content based on these extracted conditions. Additionally, we propose a
mask-driven self-attention layer that dynamically integrates the given mask
information, further enhancing the model's adaptability to outpainting tasks.
Furthermore, we introduce a latent alignment loss to maintain overall
consistency both within and between frames. For long video outpainting, we
employ a cross-video-clip refiner to iteratively generate missing content,
ensuring temporal consistency across video clips. Extensive evaluations
demonstrate that our zero-shot OutDreamer outperforms state-of-the-art
zero-shot methods on widely recognized benchmarks.

</details>


### [77] [MatChA: Cross-Algorithm Matching with Feature Augmentation](https://arxiv.org/abs/2506.22336)
*Paula Carbó Cubero,Alberto Jaenal Gálvez,André Mateus,José Araújo,Patric Jensfelt*

Main category: cs.CV

TL;DR: 提出了一种针对跨检测器特征匹配的方法，通过特征描述符增强和潜在空间转换，显著提升了图像匹配和视觉定位的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在跨设备、跨特征检测器的视觉定位中表现不佳，主要因为假设使用相同检测器，而实际中不同描述符通常对应不同检测器，导致关键点重复率低和描述符区分度不足。

Method: 通过特征描述符增强和潜在空间转换，解决跨检测器特征匹配问题。

Result: 在多个基准测试中，该方法显著提升了图像匹配和视觉定位的性能。

Conclusion: 该方法首次解决了跨检测器特征匹配问题，为实际应用中的视觉定位提供了有效解决方案。

Abstract: State-of-the-art methods fail to solve visual localization in scenarios where
different devices use different sparse feature extraction algorithms to obtain
keypoints and their corresponding descriptors. Translating feature descriptors
is enough to enable matching. However, performance is drastically reduced in
cross-feature detector cases, because current solutions assume common
keypoints. This means that the same detector has to be used, which is rarely
the case in practice when different descriptors are used. The low repeatability
of keypoints, in addition to non-discriminatory and non-distinctive
descriptors, make the identification of true correspondences extremely
challenging. We present the first method tackling this problem, which performs
feature descriptor augmentation targeting cross-detector feature matching, and
then feature translation to a latent space. We show that our method
significantly improves image matching and visual localization in the
cross-feature scenario and evaluate the proposed method on several benchmarks.

</details>


### [78] [A Deep Learning framework for building damage assessment using VHR SAR and geospatial data: demonstration on the 2023 Turkiye Earthquake](https://arxiv.org/abs/2506.22338)
*Luigi Russo,Deodato Tapete,Silvia Liberata Ullo,Paolo Gamba*

Main category: cs.CV

TL;DR: 提出了一种基于单日期高分辨率SAR图像和多源地理空间数据的深度学习框架，用于快速检测建筑物损坏，无需依赖灾前数据。


<details>
  <summary>Details</summary>
Motivation: 解决光学卫星图像在灾害后因云层覆盖或缺乏灾前数据而失效的问题，提供快速、准确的建筑物损坏评估。

Method: 整合SAR图像、OSM建筑轮廓、DSM数据和GEM的结构与暴露属性，构建多模态深度学习模型。

Result: 在土耳其2023年地震数据集中验证，模型通过结合地理空间特征显著提升了检测性能和泛化能力。

Conclusion: 该方法为灾害管理提供了快速、可靠的建筑物损坏评估工具，具有广泛适用性和自动化潜力。

Abstract: Building damage identification shortly after a disaster is crucial for
guiding emergency response and recovery efforts. Although optical satellite
imagery is commonly used for disaster mapping, its effectiveness is often
hampered by cloud cover or the absence of pre-event acquisitions. To overcome
these challenges, we introduce a novel multimodal deep learning (DL) framework
for detecting building damage using single-date very high resolution (VHR)
Synthetic Aperture Radar (SAR) imagery from the Italian Space Agency (ASI)
COSMO SkyMed (CSK) constellation, complemented by auxiliary geospatial data.
Our method integrates SAR image patches, OpenStreetMap (OSM) building
footprints, digital surface model (DSM) data, and structural and exposure
attributes from the Global Earthquake Model (GEM) to improve detection accuracy
and contextual interpretation. Unlike existing approaches that depend on pre
and post event imagery, our model utilizes only post event data, facilitating
rapid deployment in critical scenarios. The framework effectiveness is
demonstrated using a new dataset from the 2023 earthquake in Turkey, covering
multiple cities with diverse urban settings. Results highlight that
incorporating geospatial features significantly enhances detection performance
and generalizability to previously unseen areas. By combining SAR imagery with
detailed vulnerability and exposure information, our approach provides reliable
and rapid building damage assessments without the dependency from available
pre-event data. Moreover, the automated and scalable data generation process
ensures the framework's applicability across diverse disaster-affected regions,
underscoring its potential to support effective disaster management and
recovery efforts. Code and data will be made available upon acceptance of the
paper.

</details>


### [79] [Closing the Performance Gap in Biometric Cryptosystems: A Deeper Analysis on Unlinkable Fuzzy Vaults](https://arxiv.org/abs/2506.22347)
*Hans Geißner,Christian Rathgeb*

Main category: cs.CV

TL;DR: 本文提出了一种基于等频区间的特征量化方法，解决了模糊保险库生物识别系统中的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 模糊保险库生物识别系统（BCS）因特征集大小不稳定和特征类型转换导致的信息丢失而性能下降，亟需解决。

Method: 提出了一种基于等频区间的特征量化方法，确保固定特征集大小，并支持无训练适应任意区间数。

Result: 实验表明，该方法显著减少了模板保护引入的性能差距，并在多种生物识别模态上表现优异。

Conclusion: 该方法有效解决了性能下降问题，且与现有系统无缝集成，适用于多种生物识别系统。

Abstract: This paper analyses and addresses the performance gap in the fuzzy
vault-based \ac{BCS}. We identify unstable error correction capabilities, which
are caused by variable feature set sizes and their influence on similarity
thresholds, as a key source of performance degradation. This issue is further
compounded by information loss introduced through feature type transformations.
To address both problems, we propose a novel feature quantization method based
on \it{equal frequent intervals}. This method guarantees fixed feature set
sizes and supports training-free adaptation to any number of intervals. The
proposed approach significantly reduces the performance gap introduced by
template protection. Additionally, it integrates seamlessly with existing
systems to minimize the negative effects of feature transformation. Experiments
on state-of-the-art face, fingerprint, and iris recognition systems confirm
that only minimal performance degradation remains, demonstrating the
effectiveness of the method across major biometric modalities.

</details>


### [80] [Exploiting Vision Language Model for Training-Free 3D Point Cloud OOD Detection via Graph Score Propagation](https://arxiv.org/abs/2506.22375)
*Tiankai Chen,Yushu Li,Adam Goodge,Fei Teng,Xulei Yang,Tianrui Li,Xun Xu*

Main category: cs.CV

TL;DR: 本文提出了一种基于视觉语言模型（VLM）的无训练框架，用于3D点云数据的分布外（OOD）检测，通过图分数传播（GSP）方法提升检测效果。


<details>
  <summary>Details</summary>
Motivation: 3D点云数据的OOD检测在安全感知应用中至关重要，但现有方法主要针对2D图像，难以直接扩展到3D环境。

Method: 提出了一种基于类原型和测试数据构建图的框架，结合GSP方法，利用提示聚类和自训练负提示优化OOD评分。

Result: GSP方法在合成和真实数据集上均优于现有技术。

Conclusion: 该方法为3D点云OOD检测提供了一种高效且适应性强的新框架。

Abstract: Out-of-distribution (OOD) detection in 3D point cloud data remains a
challenge, particularly in applications where safe and robust perception is
critical. While existing OOD detection methods have shown progress for 2D image
data, extending these to 3D environments involves unique obstacles. This paper
introduces a training-free framework that leverages Vision-Language Models
(VLMs) for effective OOD detection in 3D point clouds. By constructing a graph
based on class prototypes and testing data, we exploit the data manifold
structure to enhancing the effectiveness of VLMs for 3D OOD detection. We
propose a novel Graph Score Propagation (GSP) method that incorporates prompt
clustering and self-training negative prompting to improve OOD scoring with
VLM. Our method is also adaptable to few-shot scenarios, providing options for
practical applications. We demonstrate that GSP consistently outperforms
state-of-the-art methods across synthetic and real-world datasets 3D point
cloud OOD detection.

</details>


### [81] [Can Video Large Multimodal Models Think Like Doubters-or Double-Down: A Study on Defeasible Video Entailment](https://arxiv.org/abs/2506.22385)
*Yue Zhang,Jilei Sun,Yunhui Guo,Vibhav Gogate*

Main category: cs.CV

TL;DR: 论文提出Defeasible Video Entailment (DVidE)任务，旨在提升视频大型多模态模型(VLMMs)的动态推理能力，通过分类和生成任务解决抽象和自适应推理问题。


<details>
  <summary>Details</summary>
Motivation: 现有VLMMs在抽象和自适应推理方面表现不足，无法根据新信息动态调整推理结论。

Method: 提出Chain of Counterfactual Thought框架用于分类任务，结合反事实推理和ASR增强视频内容；生成任务则结合ASR输出和LLM生成连贯更新。

Result: 实验结果显示方法显著提升了VLMMs的动态推理能力。

Conclusion: DVidE任务及相关框架有效增强了VLMMs的动态推理能力，为未来研究提供了新方向。

Abstract: Video Large Multimodal Models (VLMMs) have made impressive strides in
understanding video content, but they often struggle with abstract and adaptive
reasoning-the ability to revise their interpretations when new information
emerges. In reality, conclusions are rarely set in stone; additional context
can strengthen or weaken an initial inference. To address this, we introduce
Defeasible Video Entailment (DVidE), a new task that challenges models to think
like doubters, constantly updating their reasoning based on evolving evidence.
In DVidE, given a video premise and a textual hypothesis, models must determine
whether a new update strengthens or weakens the hypothesis (classification
version) or generate a coherent update that modifies the entailment
relationship (generation version). For solving the classification task, we
propose the Chain of Counterfactual Thought framework, utilizing counterfactual
reasoning, ASR-enhanced video content, and rationale refinement to reduce
inference bias. For the generation task, we develop a framework that combines
ASR output with a Large Language Model (LLM) to produce coherent, contextually
relevant updates aligned with the intended strengthener or weakener goals.
Additionally, we introduce a novel benchmark dataset, with
strengthener/weakener annotations and an LLM-based evaluation metric
specifically designed for assessing generative performance. Experimental
results demonstrate significant improvements, highlighting our proposed method
in enhancing dynamic reasoning capabilities of VLMMs.

</details>


### [82] [Test-Time Consistency in Vision Language Models](https://arxiv.org/abs/2506.22395)
*Shih-Han Chou,Shivam Chandhok,James J. Little,Leonid Sigal*

Main category: cs.CV

TL;DR: 提出了一种无需监督再训练的测试时一致性框架，通过交叉熵一致性损失和伪标签一致性损失提升视觉语言模型的语义一致性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在语义等效输入下表现不一致，影响可靠性和鲁棒性。

Method: 提出后处理方法，利用交叉熵一致性损失和伪标签一致性损失，无需模型架构修改或大规模微调。

Result: 在MM-R3基准测试中显著提升模型一致性。

Conclusion: 为多模态学习的推理时适应提供了新方向。

Abstract: Vision-Language Models (VLMs) have achieved impressive performance across a
wide range of multimodal tasks, yet they often exhibit inconsistent behavior
when faced with semantically equivalent inputs, undermining their reliability
and robustness. Recent benchmarks, such as MM-R3, highlight that even
state-of-the-art VLMs can produce divergent predictions across semantically
equivalent inputs, despite maintaining high average accuracy. Prior work
addresses this issue by modifying model architectures or conducting large-scale
fine-tuning on curated datasets. In contrast, we propose a simple and effective
test-time consistency framework that enhances semantic consistency without
supervised re-training. Our method is entirely post-hoc, model-agnostic, and
applicable to any VLM with access to its weights. Given a single test point, we
enforce consistent predictions via two complementary objectives: (i) a
Cross-Entropy Agreement Loss that aligns predictive distributions across
semantically equivalent inputs, and (ii) a Pseudo-Label Consistency Loss that
draws outputs toward a self-averaged consensus. Our method is plug-and-play and
leverages information from a single test input itself to improve consistency.
Experiments on the MM-R3 benchmark show that our framework yields substantial
gains in consistency across state-of-the-art models, establishing a new
direction for inference-time adaptation in multimodal learning.

</details>


### [83] [Shape-for-Motion: Precise and Consistent Video Editing with 3D Proxy](https://arxiv.org/abs/2506.22432)
*Yuhao Liu,Tengfei Wang,Fang Liu,Zhenwei Wang,Rynson W. H. Lau*

Main category: cs.CV

TL;DR: Shape-for-Motion是一种新颖的视频编辑框架，通过3D代理实现精确且一致的视频编辑，支持多种操作如姿态编辑、旋转和纹理修改。


<details>
  <summary>Details</summary>
Motivation: 现有方法在确保用户意图的细粒度对齐方面仍存在挑战，需要一种更精确和一致的控制工具。

Method: 利用3D代理（时间一致的网格）进行编辑，设计双传播策略简化编辑过程，并通过视频扩散模型生成结果。

Result: 支持多种精确且物理一致的操作，实验证明了方法的优越性和有效性。

Conclusion: Shape-for-Motion为高质量、可控的视频编辑工作流程迈出了关键一步。

Abstract: Recent advances in deep generative modeling have unlocked unprecedented
opportunities for video synthesis. In real-world applications, however, users
often seek tools to faithfully realize their creative editing intentions with
precise and consistent control. Despite the progress achieved by existing
methods, ensuring fine-grained alignment with user intentions remains an open
and challenging problem. In this work, we present Shape-for-Motion, a novel
framework that incorporates a 3D proxy for precise and consistent video
editing. Shape-for-Motion achieves this by converting the target object in the
input video to a time-consistent mesh, i.e., a 3D proxy, allowing edits to be
performed directly on the proxy and then inferred back to the video frames. To
simplify the editing process, we design a novel Dual-Propagation Strategy that
allows users to perform edits on the 3D mesh of a single frame, and the edits
are then automatically propagated to the 3D meshes of the other frames. The 3D
meshes for different frames are further projected onto the 2D space to produce
the edited geometry and texture renderings, which serve as inputs to a
decoupled video diffusion model for generating edited results. Our framework
supports various precise and physically-consistent manipulations across the
video frames, including pose editing, rotation, scaling, translation, texture
modification, and object composition. Our approach marks a key step toward
high-quality, controllable video editing workflows. Extensive experiments
demonstrate the superiority and effectiveness of our approach. Project page:
https://shapeformotion.github.io/

</details>


### [84] [WarpRF: Multi-View Consistency for Training-Free Uncertainty Quantification and Applications in Radiance Fields](https://arxiv.org/abs/2506.22433)
*Sadra Safadoust,Fabio Tosi,Fatma Güney,Matteo Poggi*

Main category: cs.CV

TL;DR: WarpRF是一种无需训练的通用框架，用于量化辐射场的不确定性，通过反向变形和一致性测量实现，适用于任何辐射场实现。


<details>
  <summary>Details</summary>
Motivation: 量化辐射场的不确定性，以支持下游任务如主动视图选择和主动映射。

Method: 利用反向变形将可靠渲染投影到未见视点，并测量与渲染图像的一致性。

Result: WarpRF在不确定性量化和下游任务中表现优异，超越现有方法。

Conclusion: WarpRF是一种简单、低成本且通用的不确定性量化框架，适用于任何辐射场实现。

Abstract: We introduce WarpRF, a training-free general-purpose framework for
quantifying the uncertainty of radiance fields. Built upon the assumption that
photometric and geometric consistency should hold among images rendered by an
accurate model, WarpRF quantifies its underlying uncertainty from an unseen
point of view by leveraging backward warping across viewpoints, projecting
reliable renderings to the unseen viewpoint and measuring the consistency with
images rendered there. WarpRF is simple and inexpensive, does not require any
training, and can be applied to any radiance field implementation for free.
WarpRF excels at both uncertainty quantification and downstream tasks, e.g.,
active view selection and active mapping, outperforming any existing method
tailored to specific frameworks.

</details>


### [85] [MiCo: Multi-image Contrast for Reinforcement Visual Reasoning](https://arxiv.org/abs/2506.22434)
*Xi Chen,Mingkang Zhu,Shaoteng Liu,Xiaoyang Wu,Xiaogang Xu,Yu Liu,Xiang Bai,Hengshuang Zhao*

Main category: cs.CV

TL;DR: 论文提出了一种通过自监督视觉表示学习实现多图像链式思维推理的方法，无需人工标注数据。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法依赖人工标注的局限性，利用图像内在约束作为监督信号。

Method: 构建图像三元组，通过强化学习优化模型推理能力。

Result: 在视觉比较任务上训练后，模型能泛化到多种问题，显著提升多图像推理性能。

Conclusion: 自监督方法有效提升视觉推理能力，且无需人工标注。

Abstract: This work explores enabling Chain-of-Thought (CoT) reasoning to link visual
cues across multiple images. A straightforward solution is to adapt rule-based
reinforcement learning for Vision-Language Models (VLMs). However, such methods
typically rely on manually curated question-answer pairs, which can be
particularly challenging when dealing with fine grained visual details and
complex logic across images. Inspired by self-supervised visual representation
learning, we observe that images contain inherent constraints that can serve as
supervision. Based on this insight, we construct image triplets comprising two
augmented views of the same image and a third, similar but distinct image.
During training, the model is prompted to generate a reasoning process to
compare these images (i.e., determine same or different). Then we optimize the
model with rule-based reinforcement learning. Due to the high visual similarity
and the presence of augmentations, the model must attend to subtle visual
changes and perform logical reasoning to succeed. Experiments show that,
although trained solely on visual comparison tasks, the learned reasoning
ability generalizes effectively to a wide range of questions. Without relying
on any human-annotated question-answer pairs, our method achieves significant
improvements on multi-image reasoning benchmarks and shows strong performance
on general vision tasks.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [86] [Simultaneously Fair Allocation of Indivisible Items Across Multiple Dimensions](https://arxiv.org/abs/2506.21727)
*Yasushi Kawase,Bodhayan Roy,Mohammad Azharuddin Sanpui*

Main category: cs.GT

TL;DR: 论文研究了多维环境下不可分割物品的公平分配问题，提出了两种松弛的嫉妒自由概念（weak sEFc和strong sEFc），并给出了存在性边界和算法。


<details>
  <summary>Details</summary>
Motivation: 现实应用中，如云计算资源分配，传统的一维公平概念无法满足多维需求，因此需要研究多维公平分配。

Method: 提出了weak sEFc和strong sEFc两种松弛的嫉妒自由概念，并分析了其存在性边界和算法。

Result: 给出了weak和strong sEFc分配的存在性边界，证明了检查weak sEF1和strong sEF1分配存在性的NP难问题。

Conclusion: 多维公平分配问题在理论和实践中具有重要意义，提出的松弛概念为解决复杂环境下的公平分配提供了新思路。

Abstract: This paper explores the fair allocation of indivisible items in a
multidimensional setting, motivated by the need to address fairness in complex
environments where agents assess bundles according to multiple criteria. Such
multidimensional settings are not merely of theoretical interest but are
central to many real-world applications. For example, cloud computing resources
are evaluated based on multiple criteria such as CPU cores, memory, and network
bandwidth. In such cases, traditional one dimensional fairness notions fail to
capture fairness across multiple attributes. To address these challenges, we
study two relaxed variants of envy-freeness: weak simultaneously envy-free up
to c goods (weak sEFc) and strong simultaneously envy-free up to c goods
(strong sEFc), which accommodate the multidimensionality of agents'
preferences. Under the weak notion, for every pair of agents and for each
dimension, any perceived envy can be eliminated by removing, if necessary, a
different set of goods from the envied agent's allocation. In contrast, the
strong version requires selecting a single set of goods whose removal from the
envied bundle simultaneously eliminates envy in every dimension. We provide
upper and lower bounds on the relaxation parameter c that guarantee the
existence of weak or strong sEFc allocations, where these bounds are
independent of the total number of items. In addition, we present algorithms
for checking whether a weak or strong sEFc allocation exists. Moreover, we
establish NP-hardness results for checking the existence of weak sEF1 and
strong sEF1 allocations.

</details>


### [87] [Pseudo-Equilibria, or: How to Stop Worrying About Crypto and Just Analyze the Game](https://arxiv.org/abs/2506.22089)
*Alexandros Psomas,Athina Terzoglou,Yu Wei,Vassilis Zikas*

Main category: cs.GT

TL;DR: 论文提出了一种新的解决方案概念——伪纳什均衡，用于解决密码学协议在博弈论分析中的理想世界与现实世界之间的不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 随着分布式账本的兴起，密码学与博弈论之间需要一种共享语言。博弈论学者通常将密码学协议抽象为理想化的、独立于实现的基元，但现有的标准解决方案（如纳什均衡）在从理想世界转移到现实世界时并不稳健。

Method: 作者提出伪纳什均衡的概念，即任何玩家的效用偏离在计算上无法区分。通过证明理想密码学中的纳什均衡对应于现实协议中的伪纳什均衡，实现了更简单和通用的转换。

Result: 伪纳什均衡简化了博弈论学者对密码学协议的分析，避免了为适应密码学实现的特殊性而调整理想博弈中的效用函数。

Conclusion: 伪纳什均衡允许独立且无缝地研究博弈论和密码学方面的问题，为两者之间的桥梁提供了更简洁的解决方案。

Abstract: We consider the problem of a game theorist analyzing a game that uses
cryptographic protocols. Ideally, a theorist abstracts protocols as ideal,
implementation-independent primitives, letting conclusions in the "ideal world"
carry over to the "real world." This is crucial, since the game theorist
cannot--and should not be expected to--handle full cryptographic complexity. In
today's landscape, the rise of distributed ledgers makes a shared language
between cryptography and game theory increasingly necessary.
  The security of cryptographic protocols hinges on two types of assumptions:
state-of-the-world (e.g., "factoring is hard") and behavioral (e.g., "honest
majority"). We observe that for protocols relying on behavioral assumptions
(e.g., ledgers), our goal is unattainable in full generality. For
state-of-the-world assumptions, we show that standard solution concepts, e.g.,
($\epsilon$-)Nash equilibria, are not robust to transfer from the ideal to the
real world.
  We propose a new solution concept: the pseudo-Nash equilibrium. Informally, a
profile $s=(s_1,\dots,s_n)$ is a pseudo-Nash equilibrium if, for any player $i$
and deviation $s'_i$ with higher expected utility, $i$'s utility from $s_i$ is
(computationally) indistinguishable from that of $s'_i$. Pseudo-Nash is simpler
and more accessible to game theorists than prior notions addressing the
mismatch between (asymptotic) cryptography and game theory. We prove that Nash
equilibria in games with ideal, unbreakable cryptography correspond to
pseudo-Nash equilibria when ideal cryptography is instantiated with real
protocols (under state-of-the-world assumptions). Our translation is
conceptually simpler and more general: it avoids tuning or restricting utility
functions in the ideal game to fit quirks of cryptographic implementations.
Thus, pseudo-Nash lets us study game-theoretic and cryptographic aspects
separately and seamlessly.

</details>


### [88] [A few good choices](https://arxiv.org/abs/2506.22133)
*Thanh Nguyen,Haoyu Song,Young-San Lin*

Main category: cs.GT

TL;DR: 论文提出了一种更灵活的$(t, \alpha)$-undominated sets概念，扩展了Condorcet winning sets和$\alpha$-undominated sets，证明了其存在性和最优性，并改进了已有结果。


<details>
  <summary>Details</summary>
Motivation: 解决Condorcet paradox中单一候选人的限制，提出更灵活的选择集概念以适应实际应用需求。

Method: 引入$(t, \alpha)$-undominated sets，允许选民将外部候选人与集合中的第$t$偏好成员比较，确保不超过$\alpha$比例的选民更偏好外部候选人。

Result: 证明了$(t, \alpha)$-undominated sets的存在性和最优性，改进了$\alpha$-undominated sets的大小界限，并展示了Condorcet winning sets的候选人数可从六降至五。

Conclusion: $(t, \alpha)$-undominated sets提供了一种灵活且理论保证的选择集框架，适用于更广泛的应用场景。

Abstract: A Condorcet winning set addresses the Condorcet paradox by selecting a few
candidates--rather than a single winner--such that no unselected alternative is
preferred to all of them by a majority of voters. This idea extends to
$\alpha$-undominated sets, which ensure the same property for any
$\alpha$-fraction of voters and are guaranteed to exist in constant size for
any $\alpha$. However, the requirement that an outsider be preferred to every
member of the set can be overly restrictive and difficult to justify in many
applications. Motivated by this, we introduce a more flexible notion: $(t,
\alpha)$-undominated sets. Here, each voter compares an outsider to their
$t$-th most preferred member of the set, and the set is undominated if no
outsider is preferred by more than an $\alpha$-fraction of voters. This
framework subsumes prior definitions, recovering Condorcet winning sets when
$(t = 1, \alpha = 1/2)$ and $\alpha$-undominated sets when $t = 1$, and
introduces a new, tunable notion of collective acceptability for $t > 1$. We
establish three main results:
  1. We prove that a $(t, \alpha)$-undominated set of size $O(t/\alpha)$ exists
for all values of $t$ and $\alpha$.
  2. We show that as $t$ becomes large, the minimum size of such a set
approaches $t/\alpha$, which is asymptotically optimal.
  3. In the special case $t = 1$, we improve the bound on the size of an
$\alpha$-undominated set given by Charikar, Lassota, Ramakrishnan, Vetta, and
Wang (STOC 2025). As a consequence, we show that a Condorcet winning set of
five candidates exists, improving their bound of six.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [89] [ViStruct: Simulating Expert-Like Reasoning Through Task Decomposition and Visual Attention Cues](https://arxiv.org/abs/2506.21762)
*Oliver Huang,Carolina Nobre*

Main category: cs.HC

TL;DR: ViStruct是一个自动化管道，模拟专家行为，将高级视觉问题分解为结构化分析步骤，并通过视觉注意力提示展示专家推理流程。


<details>
  <summary>Details</summary>
Motivation: 数据可视化任务通常需要多步推理，但专家的解释策略（如分解复杂目标和选择性关注关键图表区域）很少明确化。ViStruct旨在模拟这些专家行为。

Method: ViStruct利用大型语言和视觉语言模型，识别图表组件，将子任务映射到空间区域，并通过视觉注意力提示展示推理流程。

Result: 在12种图表类型的45个任务上评估ViStruct，验证其能够生成可解释且与专家一致的推理序列。

Conclusion: ViStruct为未来视觉素养工具的开发提供了可复制的专家解释模型。

Abstract: Data visualization tasks often require multi-step reasoning, and the
interpretive strategies experts use, such as decomposing complex goals into
smaller subtasks and selectively attending to key chart regions are rarely made
explicit. ViStruct is an automated pipeline that simulates these expert
behaviours by breaking high-level visual questions into structured analytic
steps and highlighting semantically relevant chart areas. Leveraging large
language and vision-language models, ViStruct identifies chart components, maps
subtasks to spatial regions, and presents visual attention cues to externalize
expert-like reasoning flows. While not designed for direct novice instruction,
ViStruct provides a replicable model of expert interpretation that can inform
the development of future visual literacy tools. We evaluate the system on 45
tasks across 12 chart types and validate its outputs with trained visualization
users, confirming its ability to produce interpretable and expert-aligned
reasoning sequences.

</details>


### [90] [3Description: An Intuitive Human-AI Collaborative 3D Modeling Approach](https://arxiv.org/abs/2506.21845)
*Zhuodi Cai*

Main category: cs.HC

TL;DR: 3Description是一种实验性的人机协作3D建模方法，通过语言和手势描述，让非专业人士也能参与3D建模。


<details>
  <summary>Details</summary>
Motivation: 解决传统3D建模在可访问性和易用性上的挑战，让更多人参与3D世界的构建。

Method: 结合定性研究、产品分析和用户测试，整合自然语言处理和计算机视觉技术，基于Web平台实现。

Result: 通过语言和手势输入，用户能够描述并调整3D模型组件。

Conclusion: 3Description不仅提升了3D建模的包容性和用户友好性，还增强了人与AI的协作，避免了技术过度主导，保留了人类创造力。

Abstract: This paper presents 3Description, an experimental human-AI collaborative
approach for intuitive 3D modeling. 3Description aims to address accessibility
and usability challenges in traditional 3D modeling by enabling
non-professional individuals to co-create 3D models using verbal and gesture
descriptions. Through a combination of qualitative research, product analysis,
and user testing, 3Description integrates AI technologies such as Natural
Language Processing and Computer Vision, powered by OpenAI and MediaPipe.
Recognizing the web has wide cross-platform capabilities, 3Description is
web-based, allowing users to describe the desired model and subsequently adjust
its components using verbal and gestural inputs. In the era of AI and emerging
media, 3Description not only contributes to a more inclusive and user-friendly
design process, empowering more people to participate in the construction of
the future 3D world, but also strives to increase human engagement in
co-creation with AI, thereby avoiding undue surrender to technology and
preserving human creativity.

</details>


### [91] [Avatars and Environments for Meetings in Social VR: What Styles and Choices Matter to People in Group Creativity Tasks?](https://arxiv.org/abs/2506.21780)
*Anya Osborne,Sabrina Fielder,Lee Taber,Tara Lamb,Joshua McVeigh-Schultz,Katherine Isbister*

Main category: cs.HC

TL;DR: 研究探讨了社交虚拟现实（VR）平台作为视频会议替代方案的效果，分析了不同虚拟环境和头像风格对团队创造力的影响。


<details>
  <summary>Details</summary>
Motivation: 由于COVID-19疫情，远程协作需求增加，社交VR平台可能增强会议中的共在感，减少面对面会议的高碳排放。

Method: 通过两项研究：研究一调查头像和虚拟环境偏好（N=87）；研究二在VR环境中测试不同设置对创造力任务的影响（N=40）。

Result: 研究发现头像外观和虚拟环境设置对团队协作有显著影响。

Conclusion: 社交VR平台可作为视频会议的有效替代，优化头像和环境设计可提升团队创造力。

Abstract: Due to the COVID-19 pandemic, many professional entities shifted toward
remote collaboration and video conferencing (VC) tools. Social virtual reality
(VR) platforms present an alternative to VC for meetings and collaborative
activities. Well-crafted social VR environments could enhance feelings of
co-presence and togetherness at meetings, helping reduce the need for
carbon-intensive travel to face-to-face meetings. This research contributes to
creating meeting tools in VR by exploring the effects of avatar styles and
virtual environments on groups creative performance using the Mozilla Hubs
platform. We present the results of two sequential studies. Study One surveys
avatar and environment preferences in various VR meeting contexts (N=87). Study
Two applies these findings to the design of a between-subjects and
within-subjects research where participants (N=40) perform creativity tasks in
pairs as embodied avatars in different virtual settings using VR headsets. We
discuss the design implications of avatar appearances and meeting settings on
teamwork.

</details>


### [92] [Validation of the MySurgeryRisk Algorithm for Predicting Complications and Death after Major Surgery: A Retrospective Multicenter Study Using OneFlorida Data Trust](https://arxiv.org/abs/2506.21814)
*Yuanfang Ren,Esra Adiyeke,Ziyuan Guan,Zhenhong Hu,Mackenzie J Meni,Benjamin Shickel,Parisa Rashidi,Tezcan Ozrazgat-Baslanti,Azra Bihorac*

Main category: cs.HC

TL;DR: 研究开发并验证了基于XGBoost的模型，用于预测大手术后并发症和死亡风险，模型性能与现有MySurgeryRisk算法相当，具有更高的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 尽管手术技术和护理有所进步，但术后并发症仍普遍存在，影响高达15%的患者。研究旨在开发并验证预测模型，以改善术后风险管理。

Method: 采用回顾性、纵向和多中心队列分析，基于508,097例手术数据，应用XGBoost模型预测术后急性肾损伤、ICU需求、机械通气需求和院内死亡率。

Result: 模型在验证集上表现优异，AUC值在0.92至0.95之间，PR曲线AUC值在0.26至0.63之间，性能与MySurgeryRisk模型相当。

Conclusion: 模型具有较高的预测能力和泛化性，手术代码和医生专业是影响手术结果的关键因素。

Abstract: Despite advances in surgical techniques and care, postoperative complications
are prevalent and effects up to 15% of the patients who underwent a major
surgery. The objective of this study is to develop and validate models for
predicting postoperative complications and death after major surgery on a large
and multicenter dataset, following the previously validated MySurgeryRisk
algorithm. This retrospective, longitudinal and multicenter cohort analysis
included 508,097 encounters from 366,875 adult inpatients who underwent major
surgeries and were admitted to healthcare institutions within the OneFlorida+
network between 01/01/2012 and 04/29/2023. We applied the validated feature
selection and transformation approach in MySurgeryRisk models and redeveloped
eXtreme Gradient Boosting (XGBoost) models for predicting risk of postoperative
acute kidney injury (AKI), need for intensive care unit (ICU) admission, need
for mechanical ventilation (MV) therapy and in-hospital mortality on a
development set and evaluated the model performance on a validation set. Area
under the receiver operating characteristics curve values were obtained for
need for ICU admission, 0.93 (95% Confidence Interval [CI], 0.93-0.93); need
for MV, 0.94 (95% CI, 0.94-0.94); AKI, 0.92 (95% CI, 0.92-0.92); and
in-hospital mortality, 0.95 (95% CI, 0.94-0.95). Area under the
precision-recall curve values were computed for need for ICU admission, 0.62
(95% CI, 0.62-0.63); need for MV, 0.51 (95% CI, 0.49-0.52); AKI, 0.53 (95% CI,
0.53-0.54); and in-hospital mortality, 0.26 (95% CI, 0.24-0.29). The
performance of these models is comparable to that of the previously validated
MySurgeryRisk models, suggesting the enhanced generalizability of the models.
Primary procedure code and provider specialty consistently appeared as the top
influential variables, providing valuable insights into the factors influencing
surgical outcomes.

</details>


### [93] [Focus on the Experts: Co-designing an Augmented Reality Eye-Gaze Tracking System with Surgical Trainees to Improve Endoscopic Instruction](https://arxiv.org/abs/2506.21896)
*Jumanh Atoum,Jinkyung Park,Mamtaj Akter,Nicholas Kavoussi,Pamela Wisniewski,Jie Ying Wu*

Main category: cs.HC

TL;DR: 研究探讨了增强现实（AR）在手术培训中的应用潜力，通过与18名外科实习生合作，设计了一个基于眼动追踪的AR系统，以提高内窥镜手术培训的效率。


<details>
  <summary>Details</summary>
Motivation: 传统手术培训模式依赖高强度的监督，难以满足日益增长的外科医生需求，且患者护理优先限制了实习生的实践机会。AR技术有望提升培训效率。

Method: 与18名外科实习生合作，了解当前培训环境的优缺点，并共同设计了一个基于眼动追踪的AR系统。

Result: 实习生认为AR眼动追踪系统能有效补充传统培训，帮助他们练习2D到3D的解剖映射，且不影响患者护理。

Conclusion: 研究结果为设计未来协作式AR眼动追踪系统提供了用户导向的指南，有助于优化内窥镜手术培训模块。

Abstract: The current apprenticeship model for surgical training requires a high level
of supervision, which does not scale well to meet the growing need for more
surgeons. Many endoscopic procedures are directly taught in the operating room
(OR) while the attending surgeon and trainee operate on patients. The need to
prioritize patient care limits the trainees' opportunities to experiment and
receive feedback on their performance. Augmented reality (AR) has the potential
to increase efficiency in endoscopic surgical training, but additional research
is critical to understanding the needs of surgical trainees to inform the
design of AR training systems. Therefore, we worked with 18 surgical trainees
to understand the strengths, limitations, and unmet needs of their current
training environment and to co-design an AR eye-gaze tracking system based on
their preferences. Trainees emphasized the need to practice the 2D to 3D
mapping needed to properly familiarize oneself with the anatomy of patients to
prepare for real surgery. The trainees felt that an AR-based eye gaze tracking
system would be a useful supplemental training method that would improve their
learning in OR cases without detracting from patient care. To tailor the AR
system to their needs, they co-designed features to improve their ability to
track the attending surgeon's eye gaze and to provide a real-time, interactive
system. Our results are valuable in shaping the endoscopic training modules by
generating user-informed guidelines to design future collaborative AR-based
eye-gaze tracking systems.

</details>


### [94] [Bias, Accuracy, and Trust: Gender-Diverse Perspectives on Large Language Models](https://arxiv.org/abs/2506.21898)
*Aimen Gaba,Emily Wall,Tejas Ramkumar Babu,Yuriy Brun,Kyle Hall,Cindy Xiong Bearfield*

Main category: cs.HC

TL;DR: 研究探讨了不同性别群体对ChatGPT的偏见、准确性和可信度的感知，发现性别化提示会引发更多身份特定回应，非二元性别参与者易受刻板印象影响。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs（如ChatGPT）中的性别偏见及其对不同性别群体的影响，以促进更包容和可信的AI系统。

Method: 通过25次深度访谈，分析性别化和中性提示对模型回应的影响及用户评价。

Result: 性别化提示引发身份特定回应，非二元性别参与者易受刻板印象影响；准确性感知一致，可信度因性别而异。

Conclusion: 研究强调在LLM开发中纳入性别多样性视角，以提升包容性和可信度。

Abstract: Large language models (LLMs) are becoming increasingly ubiquitous in our
daily lives, but numerous concerns about bias in LLMs exist. This study
examines how gender-diverse populations perceive bias, accuracy, and
trustworthiness in LLMs, specifically ChatGPT. Through 25 in-depth interviews
with non-binary/transgender, male, and female participants, we investigate how
gendered and neutral prompts influence model responses and how users evaluate
these responses. Our findings reveal that gendered prompts elicit more
identity-specific responses, with non-binary participants particularly
susceptible to condescending and stereotypical portrayals. Perceived accuracy
was consistent across gender groups, with errors most noted in technical topics
and creative tasks. Trustworthiness varied by gender, with men showing higher
trust, especially in performance, and non-binary participants demonstrating
higher performance-based trust. Additionally, participants suggested improving
the LLMs by diversifying training data, ensuring equal depth in gendered
responses, and incorporating clarifying questions. This research contributes to
the CSCW/HCI field by highlighting the need for gender-diverse perspectives in
LLM development in particular and AI in general, to foster more inclusive and
trustworthy systems.

</details>


### [95] [AnyAni: An Interactive System with Generative AI for Animation Effect Creation and Code Understanding in Web Development](https://arxiv.org/abs/2506.21962)
*Tianrun Qiu,Yuxin Ma*

Main category: cs.HC

TL;DR: AnyAni是一个支持前端开发者通过人机协作系统生成动画效果的工具，结合生成式AI和非线性工作流，帮助开发者解决动画设计中的描述、设计和实现问题。


<details>
  <summary>Details</summary>
Motivation: 前端开发者在没有专业设计师帮助时，常面临动画设计困难，需要工具支持。

Method: 通过形成性研究（N=6）识别问题，开发AnyAni系统，结合生成式AI和非线性工作流，支持动画的构思、操作和实现。

Result: 用户研究（N=9）验证了AnyAni在动画效果创作中的可用性。

Conclusion: AnyAni有效支持开发者解决动画设计问题，提升开发效率。

Abstract: Generative AI assistants have been widely used in front-end programming.
However, besides code writing, developers often encounter the need to generate
animation effects. As novices in creative design without the assistance of
professional designers, developers typically face difficulties in describing,
designing, and implementing desired animations. To address this issue, we
conducted a formative study (N=6) to identify the challenges that code
developers face when dealing with animation design issues. Then, we introduce
AnyAni, a human-AI collaborative system that supports front-end developers in
the ideation, manipulation, and implementation of animation effects. The system
combines the assistance of generative AI in creative design by adopting a
nonlinear workflow for iterative animation development. In addition, developers
can understand and learn the code generated for implementing animations through
various interactive methods. A user study (N=9) demonstrated the usability of
AnyAni in animation effect creation support for developers.

</details>


### [96] [Building Trustworthy Cognitive Monitoring for Safety-Critical Human Tasks: A Phased Methodological Approach](https://arxiv.org/abs/2506.22066)
*Maciej Grzeszczuk,Grzegorz Pochwatko,Barbara Karpowicz,Stanisław Knapiński,Wiesław Kopeć*

Main category: cs.HC

TL;DR: 提出了一种分阶段构建认知监控系统的方法，用于高风险任务环境，旨在提升情境感知并减少人为错误。


<details>
  <summary>Details</summary>
Motivation: 高风险任务操作员（如空中交通管制员、外科医生等）需在压力下保持高效认知表现，需开发非侵入式实时监控系统以支持其工作。

Method: 整合人因研究、模拟训练、传感器技术和心理学原理，从简化模拟逐步过渡到实际场景，实现自适应监控。

Result: 框架支持实时性能评估，适应工作负荷变化、疲劳和压力影响，提供早期预警机制。

Conclusion: 该方法有助于开发透明且具有韧性的系统，提升安全关键领域的人类表现。

Abstract: Operators performing high-stakes, safety-critical tasks - such as air traffic
controllers, surgeons, or mission control personnel - must maintain exceptional
cognitive performance under variable and often stressful conditions. This paper
presents a phased methodological approach to building cognitive monitoring
systems for such environments. By integrating insights from human factors
research, simulation-based training, sensor technologies, and fundamental
psychological principles, the proposed framework supports real-time performance
assessment with minimum intrusion. The approach begins with simplified
simulations and evolves towards operational contexts. Key challenges addressed
include variability in workload, the effects of fatigue and stress, thus the
need for adaptive monitoring for early warning support mechanisms. The
methodology aims to improve situational awareness, reduce human error, and
support decision-making without undermining operator autonomy. Ultimately, the
work contributes to the development of resilient and transparent systems in
domains where human performance is critical to safety.

</details>


### [97] [NoticeLight: Embracing Socio-Technical Asymmetry through Tangible Peripheral Robotic Embodiment in Hybrid Collaboration](https://arxiv.org/abs/2506.22125)
*Marie Altmann,Kimberly Hegemann,Ali Askari,Vineetha Rallabandi,Max Pascher,Jens Gerken*

Main category: cs.HC

TL;DR: NoticeLight是一种有形、外围的机器人装置，旨在通过物理信号增强混合会议中的远程参与者存在感。


<details>
  <summary>Details</summary>
Motivation: 混合协作中存在社会技术不对称性，远程参与者面临存在感差距、可见性降低和非语言沟通受限的问题。传统方法试图消除这些不对称性，而本研究提出将其作为设计约束。

Method: 引入NoticeLight，将远程参与者的数字存在转化为物理信号（如情绪动态、语言贡献拼图和注意力提示），通过抽象群体状态为微妙的光模式，增强外围意识。

Result: NoticeLight在不干扰会议流程或增加认知负荷的情况下，促进了平衡参与和外围意识。

Conclusion: 该研究展示了机器人作为调解者的潜力，重塑而非复制人类存在，推动了工作场所中机器人如何促进公平、动态协作的讨论。

Abstract: Hybrid collaboration has become a fixture in modern workplaces, yet it
introduces persistent socio-technical asymmetries-especially disadvantaging
remote participants, who struggle with presence disparity, reduced visibility,
and limited non-verbal communication. Traditional solutions often seek to erase
these asymmetries, but recent research suggests embracing them as productive
design constraints. In this context, we introduce NoticeLight: a tangible,
peripheral robotic embodiment designed to augment hybrid meetings. NoticeLight
transforms remote participants' digital presence into ambient, physical signals
-- such as mood dynamics, verbal contribution mosaics, and attention cues --
within the co-located space. By abstracting group states into subtle light
patterns, NoticeLight fosters peripheral awareness and balanced participation
without disrupting meeting flow or demanding cognitive overload. This approach
aligns with emerging perspectives in human-robot synergy, positioning robots as
mediators that reshape, rather than replicate, human presence. Our work thereby
advances the discourse on how robotic embodiments can empower equitable,
dynamic collaboration in the workplace.

</details>


### [98] [Adapting University Policies for Generative AI: Opportunities, Challenges, and Policy Solutions in Higher Education](https://arxiv.org/abs/2506.22231)
*Russell Beale*

Main category: cs.HC

TL;DR: 生成式AI（如ChatGPT）在高等教育中带来机遇与挑战，需制定政策平衡其潜力与学术诚信。


<details>
  <summary>Details</summary>
Motivation: 探讨生成式AI在高等教育中的快速应用及其对学术研究、教学和评估的影响，同时关注其引发的伦理和公平问题。

Method: 通过分析实证研究和案例，评估生成式AI的使用现状及检测工具的准确性，并提出政策建议。

Result: 47%的学生在课程中使用生成式AI，检测工具准确率为88%。需重新设计评估方式、加强培训并制定使用规范。

Conclusion: 主动调整政策是必要的，以利用AI潜力同时维护学术诚信与公平。

Abstract: The rapid proliferation of generative artificial intelligence (AI) tools -
especially large language models (LLMs) such as ChatGPT - has ushered in a
transformative era in higher education. Universities in developed regions are
increasingly integrating these technologies into research, teaching, and
assessment. On one hand, LLMs can enhance productivity by streamlining
literature reviews, facilitating idea generation, assisting with coding and
data analysis, and even supporting grant proposal drafting. On the other hand,
their use raises significant concerns regarding academic integrity, ethical
boundaries, and equitable access. Recent empirical studies indicate that nearly
47% of students use LLMs in their coursework - with 39% using them for exam
questions and 7% for entire assignments - while detection tools currently
achieve around 88% accuracy, leaving a 12% error margin. This article
critically examines the opportunities offered by generative AI, explores the
multifaceted challenges it poses, and outlines robust policy solutions.
Emphasis is placed on redesigning assessments to be AI-resilient, enhancing
staff and student training, implementing multi-layered enforcement mechanisms,
and defining acceptable use. By synthesizing data from recent research and case
studies, the article argues that proactive policy adaptation is imperative to
harness AI's potential while safeguarding the core values of academic integrity
and equity.

</details>


### [99] [How to Evaluate the Accuracy of Online and AI-Based Symptom Checkers: A Standardized Methodological Framework](https://arxiv.org/abs/2506.22379)
*Marvin Kopka,Markus A. Feufel*

Main category: cs.HC

TL;DR: 本文提出了一种标准化评估在线和AI症状检查工具的方法框架，以解决过去十年缺乏高质量评估方法的问题。


<details>
  <summary>Details</summary>
Motivation: 过去的研究方法缺乏质量控制，导致评估结果不可靠，亟需一种标准化的评估框架。

Method: 通过综合实证研究，提出了基于代表性案例选择、内外效度评估设计和可比性指标的框架。

Result: 该框架提供了开放资源支持实施，旨在提高未来评估的质量和可比性。

Conclusion: 该框架有望促进元分析和帮助利益相关者做出更明智的决策。

Abstract: Online and AI-based symptom checkers are applications that assist medical
laypeople in diagnosing their symptoms and determining which course of action
to take. When evaluating these tools, previous studies primarily used an
approach introduced a decade ago that lacked any type of quality control.
Numerous studies have criticized this approach, and several empirical studies
have sought to improve specific aspects of evaluations. However, even after a
decade, a high-quality methodological framework for standardizing the
evaluation of symptom checkers remains missing. This article synthesizes
empirical studies to outline a framework for standardized evaluations based on
representative case selection, an externally and internally valid evaluation
design, and metrics that increase cross-study comparability. This approach is
backed up by several open-access resources to facilitate implementation.
Ultimately, this approach should enhance the quality and comparability of
future evaluations of online and AI-based symptom checkers to enable
meta-analyses and help stakeholders make more informed decisions.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [100] [Robust and Efficient Autoregressive Speech Synthesis with Dynamic Chunk-wise Prediction Policy](https://arxiv.org/abs/2506.22023)
*Bohan Li,Zhihan Li,Haoran Wang,Hanglei Zhang,Yiwei Guo,Hankun Wang,Xie Chen,Kai Yu*

Main category: cs.SD

TL;DR: 论文提出了一种动态分块自回归（DCAR）框架，解决了传统自回归语音合成模型在长序列处理中的效率和质量问题，显著提升了合成质量和推理速度。


<details>
  <summary>Details</summary>
Motivation: 传统自回归语音合成模型在处理长语音序列时存在帧间注意力不稳定、延迟高和合成质量下降的问题，限制了实时应用的可行性。

Method: DCAR通过引入动态分块到帧的注意力机制，结合多令牌预测训练，动态调整令牌预测范围，减少序列长度依赖。

Result: 实验表明，DCAR在测试集上实现了72.27%的可懂度提升和2.61倍的推理加速。

Conclusion: DCAR为下一代语音合成系统提供了高效且鲁棒的基础框架。

Abstract: Recently, autoregressive (AR) language models have emerged as a dominant
approach in speech synthesis, offering expressive generation and scalable
training. However, conventional AR speech synthesis models relying on the
next-token prediction paradigm often encounter significant challenges when
handling long speech sequences. These models often struggle to construct stable
frame-to-frame attention, leading to increased latency and degraded synthesis
quality, thereby limiting their feasibility for real-time applications. To
address these limitations, we introduce a novel dynamic chunk-wise
autoregressive synthesis framework, termed DCAR, designed to enhance both
efficiency and intelligibility robustness in AR speech generation. DCAR
introduces a chunk-to-frame attention mechanism through training with
multi-token prediction, enabling dynamic chunk prediction in variable speech
contexts using a lightweight module trained on-policy. DCAR dynamically adjusts
the token prediction span, significantly reducing the sequence length
dependency while obtaining high synthesis quality. Comprehensive empirical
evaluations demonstrate that DCAR substantially outperforms traditional
next-token prediction models, achieving up to 72.27% intelligibility
improvement and 2.61x inference speedup simultaneously on the test set.
Furthermore, we conduct comprehensive analysis to support it as a versatile
foundation for next-generation speech synthesis systems.

</details>


### [101] [Fine-Tuning MIDI-to-Audio Alignment using a Neural Network on Piano Roll and CQT Representations](https://arxiv.org/abs/2506.22237)
*Sebastian Murgul,Moritz Reiser,Michael Heizmann,Christoph Seibert*

Main category: cs.SD

TL;DR: 提出一种基于卷积循环神经网络（CRNN）的方法，用于同步钢琴演奏音频与未严格对齐的MIDI文件，比传统DTW方法准确率提升20%。


<details>
  <summary>Details</summary>
Motivation: 解决钢琴演奏音频与MIDI文件对齐的挑战，传统方法（如DTW）在精度和鲁棒性上存在不足。

Method: 使用CRNN架构，输入未对齐的钢琴卷和频谱图，输出对齐的钢琴卷；通过模拟人类演奏时序误差的数据集训练模型。

Result: 模型比DTW方法对齐准确率提升20%，结合DTW后进一步提高了鲁棒性和一致性。

Conclusion: 神经网络在MIDI与音频对齐任务中展现出潜力，可推动该领域的技术进步。

Abstract: In this paper, we present a neural network approach for synchronizing audio
recordings of human piano performances with their corresponding loosely aligned
MIDI files. The task is addressed using a Convolutional Recurrent Neural
Network (CRNN) architecture, which effectively captures spectral and temporal
features by processing an unaligned piano roll and a spectrogram as inputs to
estimate the aligned piano roll. To train the network, we create a dataset of
piano pieces with augmented MIDI files that simulate common human timing
errors. The proposed model achieves up to 20% higher alignment accuracy than
the industry-standard Dynamic Time Warping (DTW) method across various
tolerance windows. Furthermore, integrating DTW with the CRNN yields additional
improvements, offering enhanced robustness and consistency. These findings
demonstrate the potential of neural networks in advancing state-of-the-art
MIDI-to-audio alignment.

</details>


### [102] [Reconstructing Intelligible Speech from the Pressure Sensor Data in HVACs](https://arxiv.org/abs/2506.22311)
*Tarikul Islam Tamiti,Biraj Joshi,Rida Hasan,Anomadarshi Barua*

Main category: cs.SD

TL;DR: WaLi利用压力传感器数据重构可理解的语音，通过复杂值Conformer和CGAB技术，解决了低分辨率和高噪声问题，对隐私构成新威胁。


<details>
  <summary>Details</summary>
Motivation: 压力传感器在HVAC系统中广泛使用，其数据可能被用于窃听，但现有技术只能检测关键词。WaLi旨在从低分辨率数据中重构完整语音。

Method: 使用复杂值Conformer和CGAB捕捉音素依赖关系，并处理HVAC噪声，重构缺失频率的幅度和相位。

Result: 实验显示，WaLi在0.5 kHz至8 kHz上采样中达到LSD 1.24和NISQA-MOS 1.78的精度。

Conclusion: WaLi的高精度重构能力揭示了压力传感器在隐私保护方面的新威胁。

Abstract: Pressure sensors are an integrated component of modern Heating, Ventilation,
and Air Conditioning (HVAC) systems. As these pressure sensors operate within
the 0-10 Pa range, support high sampling frequencies of 0.5-2 kHz, and are
often placed close to human proximity, they can be used to eavesdrop on
confidential conversation, since human speech has a similar audible range of
0-10 Pa and a bandwidth of 4 kHz for intelligible quality. This paper presents
WaLi, which reconstructs intelligible speech from the low-resolution and noisy
pressure sensor data by providing the following technical contributions: (i)
WaLi reconstructs intelligible speech from a minimum of 0.5 kHz sampling
frequency of pressure sensors, whereas previous work can only detect hot
words/phrases. WaLi uses complex-valued conformer and Complex Global Attention
Block (CGAB) to capture inter-phoneme and intra-phoneme dependencies that exist
in the low-resolution pressure sensor data. (ii) WaLi handles the transient
noise injected from HVAC fans and duct vibrations, by reconstructing both the
clean magnitude and phase of the missing frequencies of the low-frequency
aliased components. Extensive measurement studies on real-world pressure
sensors show an LSD of 1.24 and NISQA-MOS of 1.78 for 0.5 kHz to 8 kHz
upsampling. We believe that such levels of accuracy pose a significant threat
when viewed from a privacy perspective that has not been addressed before for
pressure sensors.

</details>


### [103] [A Practical Approach to Power Saving in Hearables Using Sub-Nyquist Sampling with Bandwidth Extension](https://arxiv.org/abs/2506.22321)
*Tarikul Islam Tamiti,Anomadarshi Barua*

Main category: cs.SD

TL;DR: SUBARU提出了一种低功耗的音频增强方法，通过子奈奎斯特采样和虚拟判别器实现高效能处理。


<details>
  <summary>Details</summary>
Motivation: 现有方法未考虑低功耗实现中的采样频率和比特分辨率降低对语音质量和智能性的影响，且缺乏宽频重建方法。

Method: SUBARU采用子奈奎斯特采样和低比特分辨率ADC，引入多尺度虚拟判别器，实现流式操作。

Result: 功耗降低3.31倍，推理时间1.74ms，内存占用小于13.77MB。

Conclusion: SUBARU在低功耗和高效能音频增强方面表现优异。

Abstract: Hearables are wearable computers that are worn on the ear. Bone conduction
microphones (BCMs) are used with air conduction microphones (ACMs) in hearables
as a supporting modality for multimodal speech enhancement (SE) in noisy
conditions. However, existing works don't consider the following practical
aspects for low-power implementations on hearables: (i) They do not explore how
lowering the sampling frequencies and bit resolutions in analog-to-digital
converters (ADCs) of hearables jointly impact low-power processing and
multimodal SE in terms of speech quality and intelligibility. (ii) They don't
discuss how GAN-like audio quality can be achieved without using actual GAN
discriminators. And (iii) They don't process signals from ACMs/BCMs at
sub-Nyquist sampling rate because, in their frameworks, they lack a wideband
reconstruction methodology from their narrowband parts. We propose SUBARU
(\textbf{Sub}-Nyquist \textbf{A}udio \textbf{R}esolution \textbf{U}psampling),
which achieves the following: SUBARU (i) intentionally uses sub-Nyquist
sampling and low bit resolution in ADCs, achieving a 3.31x reduction in power
consumption; (ii) introduces novel multi-scale and multi-period virtual
discriminators, which achieve GAN-like audio quality without using GANs'
adversarial training; and (iii) achieves streaming operations on mobile
platforms and SE in in-the-wild noisy conditions with an inference time of
1.74ms and a memory footprint of less than 13.77MB.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [104] [FrankenBot: Brain-Morphic Modular Orchestration for Robotic Manipulation with Vision-Language Models](https://arxiv.org/abs/2506.21627)
*Shiyi Wang,Wenbo Li,Yiteng Chen,Qingyao Wu,Huiping Zhuang*

Main category: cs.RO

TL;DR: 论文提出了一种基于视觉语言模型（VLM）的机器人操纵框架FrankenBot，通过模拟人脑结构实现多功能集成与高效操作。


<details>
  <summary>Details</summary>
Motivation: 开发一个能在复杂动态环境中高效完成多种任务的通用机器人操纵系统，需整合任务规划、策略生成等功能，但现有方法通常仅关注单一功能。

Method: 采用分治策略和人脑结构启发，设计FrankenBot框架，将关键功能映射到不同脑区并优化协调机制。

Result: 实验表明，FrankenBot在异常处理、长期记忆和操作效率等方面表现优异，且无需微调或再训练。

Conclusion: FrankenBot通过多功能集成与高效协调，显著提升了机器人操纵系统的性能与稳定性。

Abstract: Developing a general robot manipulation system capable of performing a wide
range of tasks in complex, dynamic, and unstructured real-world environments
has long been a challenging task. It is widely recognized that achieving
human-like efficiency and robustness manipulation requires the robotic brain to
integrate a comprehensive set of functions, such as task planning, policy
generation, anomaly monitoring and handling, and long-term memory, achieving
high-efficiency operation across all functions. Vision-Language Models (VLMs),
pretrained on massive multimodal data, have acquired rich world knowledge,
exhibiting exceptional scene understanding and multimodal reasoning
capabilities. However, existing methods typically focus on realizing only a
single function or a subset of functions within the robotic brain, without
integrating them into a unified cognitive architecture. Inspired by a
divide-and-conquer strategy and the architecture of the human brain, we propose
FrankenBot, a VLM-driven, brain-morphic robotic manipulation framework that
achieves both comprehensive functionality and high operational efficiency. Our
framework includes a suite of components, decoupling a part of key functions
from frequent VLM calls, striking an optimal balance between functional
completeness and system efficiency. Specifically, we map task planning, policy
generation, memory management, and low-level interfacing to the cortex,
cerebellum, temporal lobe-hippocampus complex, and brainstem, respectively, and
design efficient coordination mechanisms for the modules. We conducted
comprehensive experiments in both simulation and real-world robotic
environments, demonstrating that our method offers significant advantages in
anomaly detection and handling, long-term memory, operational efficiency, and
stability -- all without requiring any fine-tuning or retraining.

</details>


### [105] [Ark: An Open-source Python-based Framework for Robot Learning](https://arxiv.org/abs/2506.21628)
*Magnus Dierking,Christopher E. Mower,Sarthak Das,Huang Helong,Jiacheng Qiu,Cody Reading,Wei Chen,Huidong Liang,Huang Guowei,Jan Peters,Quan Xingyue,Jun Wang,Haitham Bou-Ammar*

Main category: cs.RO

TL;DR: ARK是一个开源的、以Python为中心的机器人框架，旨在简化机器人软件开发，降低学习门槛，并加速自主机器人的研究和商业部署。


<details>
  <summary>Details</summary>
Motivation: 当前机器人软件开发的复杂性（如低级的C/C++需求、分散的工具链和硬件集成）阻碍了商业自主性的进展，而ARK希望通过提供类似现代AI的Python生态系统来解决这一问题。

Method: ARK提供了一个Gym风格的环境接口，支持数据收集、预处理和策略训练，同时无缝切换模拟与物理机器人。其轻量级客户端-服务器架构和可选的C/C++绑定确保了实时性能。

Result: ARK展示了从操作到移动导航的快速原型设计、轻松硬件交换和端到端流程，其文档和案例研究证明了其高效性。

Conclusion: ARK通过统一的Python生态系统降低了机器人开发的入门门槛，加速了自主机器人的研究和商业应用。

Abstract: Robotics has made remarkable hardware strides-from DARPA's Urban and Robotics
Challenges to the first humanoid-robot kickboxing tournament-yet commercial
autonomy still lags behind progress in machine learning. A major bottleneck is
software: current robot stacks demand steep learning curves, low-level C/C++
expertise, fragmented tooling, and intricate hardware integration, in stark
contrast to the Python-centric, well-documented ecosystems that propelled
modern AI. We introduce ARK, an open-source, Python-first robotics framework
designed to close that gap. ARK presents a Gym-style environment interface that
allows users to collect data, preprocess it, and train policies using
state-of-the-art imitation-learning algorithms (e.g., ACT, Diffusion Policy)
while seamlessly toggling between high-fidelity simulation and physical robots.
A lightweight client-server architecture provides networked
publisher-subscriber communication, and optional C/C++ bindings ensure
real-time performance when needed. ARK ships with reusable modules for control,
SLAM, motion planning, system identification, and visualization, along with
native ROS interoperability. Comprehensive documentation and case studies-from
manipulation to mobile navigation-demonstrate rapid prototyping, effortless
hardware swapping, and end-to-end pipelines that rival the convenience of
mainstream machine-learning workflows. By unifying robotics and AI practices
under a common Python umbrella, ARK lowers entry barriers and accelerates
research and commercial deployment of autonomous robots.

</details>


### [106] [TOMD: A Trail-based Off-road Multimodal Dataset for Traversable Pathway Segmentation under Challenging Illumination Conditions](https://arxiv.org/abs/2506.21630)
*Yixin Sun,Li Li,Wenke E,Amir Atapour-Abarghouei,Toby P. Breckon*

Main category: cs.RO

TL;DR: 论文提出了一个针对狭窄、小径类越野环境的综合数据集TOMD，并开发了一种动态多尺度数据融合模型，用于准确预测可通行路径。


<details>
  <summary>Details</summary>
Motivation: 解决自主机器人在非结构化户外环境中检测可通行路径的挑战，特别是在搜索救援和森林火灾等关键应用中。

Method: 引入TOMD数据集，包含多模态传感器数据，并提出动态多尺度数据融合模型，分析不同光照条件下的融合策略。

Result: 结果表明该方法有效，且光照对分割性能有显著影响。

Conclusion: TOMD数据集和提出的模型为未来越野导航研究提供了支持。

Abstract: Detecting traversable pathways in unstructured outdoor environments remains a
significant challenge for autonomous robots, especially in critical
applications such as wide-area search and rescue, as well as incident
management scenarios like forest fires. Existing datasets and models primarily
target urban settings or wide, vehicle-traversable off-road tracks, leaving a
substantial gap in addressing the complexity of narrow, trail-like off-road
scenarios. To address this, we introduce the Trail-based Off-road Multimodal
Dataset (TOMD), a comprehensive dataset specifically designed for such
environments. TOMD features high-fidelity multimodal sensor data -- including
128-channel LiDAR, stereo imagery, GNSS, IMU, and illumination measurements --
collected through repeated traversals under diverse conditions. We also propose
a dynamic multiscale data fusion model for accurate traversable pathway
prediction. The study analyzes the performance of early, cross, and mixed
fusion strategies under varying illumination levels. Results demonstrate the
effectiveness of our approach and the relevance of illumination in segmentation
performance. We publicly release TOMD at https://github.com/yyyxs1125/TMOD to
support future research in trail-based off-road navigation.

</details>


### [107] [Real-Time 3D Guidewire Reconstruction from Intraoperative DSA Images for Robot-Assisted Endovascular Interventions](https://arxiv.org/abs/2506.21631)
*Tianliang Yao,Bingrui Li,Bo Lu,Zhiqiang Pei,Yixuan Yuan,Peng Qi*

Main category: cs.RO

TL;DR: 提出了一种结合术前3D CTA和术中2D DSA的多模态框架，用于实时3D导丝重建，显著提升了机器人辅助血管内手术的空间感知能力。


<details>
  <summary>Details</summary>
Motivation: 传统2D DSA缺乏深度信息，导致空间模糊性，限制了导丝形状的精确感知。

Method: 通过鲁棒特征提取处理2D DSA噪声，结合可变形图像配准和逆投影算法，实现3D导丝形状的实时重建。

Result: 系统实现了1.76±0.08像素的投影误差和2.93±0.15%的长度偏差，处理速度为39.3±1.5 FPS。

Conclusion: 该方法优化了机器人性能，提高了复杂血管内手术的精确性，有望改善临床效果。

Abstract: Accurate three-dimensional (3D) reconstruction of guidewire shapes is crucial
for precise navigation in robot-assisted endovascular interventions.
Conventional 2D Digital Subtraction Angiography (DSA) is limited by the absence
of depth information, leading to spatial ambiguities that hinder reliable
guidewire shape sensing. This paper introduces a novel multimodal framework for
real-time 3D guidewire reconstruction, combining preoperative 3D Computed
Tomography Angiography (CTA) with intraoperative 2D DSA images. The method
utilizes robust feature extraction to address noise and distortion in 2D DSA
data, followed by deformable image registration to align the 2D projections
with the 3D CTA model. Subsequently, the inverse projection algorithm
reconstructs the 3D guidewire shape, providing real-time, accurate spatial
information. This framework significantly enhances spatial awareness for
robotic-assisted endovascular procedures, effectively bridging the gap between
preoperative planning and intraoperative execution. The system demonstrates
notable improvements in real-time processing speed, reconstruction accuracy,
and computational efficiency. The proposed method achieves a projection error
of 1.76$\pm$0.08 pixels and a length deviation of 2.93$\pm$0.15\%, with a frame
rate of 39.3$\pm$1.5 frames per second (FPS). These advancements have the
potential to optimize robotic performance and increase the precision of complex
endovascular interventions, ultimately contributing to better clinical
outcomes.

</details>


### [108] [AeroLite-MDNet: Lightweight Multi-task Deviation Detection Network for UAV Landing](https://arxiv.org/abs/2506.21635)
*Haiping Yang,Huaxing Liu,Wei Wu,Zuohui Chen,Ning Wu*

Main category: cs.RO

TL;DR: 论文提出了一种基于视觉的无人机着陆偏差预警系统AeroLite-MDNet，通过多尺度融合模块和分割分支提高检测精度，并引入新评价指标AWD和新数据集UAVLandData，实验显示系统性能优越。


<details>
  <summary>Details</summary>
Motivation: 无人机着陆时因GPS信号干扰等问题难以精准着陆，影响操作连续性，需一种可靠方法提升着陆安全性。

Method: 提出AeroLite-MDNet模型，结合多尺度融合模块和分割分支，用于检测着陆偏差和估计方向；引入AWD指标和新数据集UAVLandData。

Result: 系统AWD为0.7秒，偏差检测准确率达98.6%，显著提升着陆可靠性。

Conclusion: AeroLite-MDNet系统有效解决了无人机着陆偏差问题，实验验证了其优越性能。

Abstract: Unmanned aerial vehicles (UAVs) are increasingly employed in diverse
applications such as land surveying, material transport, and environmental
monitoring. Following missions like data collection or inspection, UAVs must
land safely at docking stations for storage or recharging, which is an
essential requirement for ensuring operational continuity. However, accurate
landing remains challenging due to factors like GPS signal interference. To
address this issue, we propose a deviation warning system for UAV landings,
powered by a novel vision-based model called AeroLite-MDNet. This model
integrates a multiscale fusion module for robust cross-scale object detection
and incorporates a segmentation branch for efficient orientation estimation. We
introduce a new evaluation metric, Average Warning Delay (AWD), to quantify the
system's sensitivity to landing deviations. Furthermore, we contribute a new
dataset, UAVLandData, which captures real-world landing deviation scenarios to
support training and evaluation. Experimental results show that our system
achieves an AWD of 0.7 seconds with a deviation detection accuracy of 98.6\%,
demonstrating its effectiveness in enhancing UAV landing reliability. Code will
be available at https://github.com/ITTTTTI/Maskyolo.git

</details>


### [109] [Optimal Motion Scaling for Delayed Telesurgery](https://arxiv.org/abs/2506.21689)
*Jason Lim,Florian Richter,Zih-Yun Chiu,Jaeyon Lee,Ethan Quist,Nathan Fisher,Jonathan Chambers,Steven Hong,Michael C. Yip*

Main category: cs.RO

TL;DR: 研究探讨了在长距离通信延迟下机器人远程操作的最佳运动缩放比例，发现个性化模型能显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决因网络延迟导致的机器人远程操作性能下降问题，尤其是医疗领域的远程手术。

Method: 通过用户研究分析延迟、缩放比例和操作性能的关系，并开发个性化模型。

Result: 研究发现不同用户和缩放比例在特定延迟下性能差异显著，需个性化优化。

Conclusion: 个性化模型能有效优化远程操作性能，尤其在长延迟环境下。

Abstract: Robotic teleoperation over long communication distances poses challenges due
to delays in commands and feedback from network latency. One simple yet
effective strategy to reduce errors and increase performance under delay is to
downscale the relative motion between the operating surgeon and the robot. The
question remains as to what is the optimal scaling factor, and how this value
changes depending on the level of latency as well as operator tendencies. We
present user studies investigating the relationship between latency, scaling
factor, and performance. The results of our studies demonstrate a statistically
significant difference in performance between users and across scaling factors
for certain levels of delay. These findings indicate that the optimal scaling
factor for a given level of delay is specific to each user, motivating the need
for personalized models for optimal performance. We present techniques to model
the user-specific mapping of latency level to scaling factor for optimal
performance, leading to an efficient and effective solution to optimizing
performance of robotic teleoperation and specifically telesurgery under large
communication delay.

</details>


### [110] [Experimental investigation of pose informed reinforcement learning for skid-steered visual navigation](https://arxiv.org/abs/2506.21732)
*Ameya Salvi,Venkat Krovi*

Main category: cs.RO

TL;DR: 提出了一种基于学习的视觉导航方法，解决了滑移转向车辆在动态操作中的建模和验证问题，性能显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 滑移转向车辆在自动化部署中因缺乏准确的解析模型而受限，尤其是在动态操作中。

Method: 采用端到端学习方法（如模仿学习和深度强化学习），提出了一种结构化的视觉导航框架。

Result: 通过软件模拟、硬件评估和消融研究，验证了该方法在性能上的显著提升。

Conclusion: 该方法为滑移转向车辆的视觉导航提供了一种有效的解决方案，尤其在动态操作中表现优异。

Abstract: Vision-based lane keeping is a topic of significant interest in the robotics
and autonomous ground vehicles communities in various on-road and off-road
applications. The skid-steered vehicle architecture has served as a useful
vehicle platform for human controlled operations. However, systematic modeling,
especially of the skid-slip wheel terrain interactions (primarily in off-road
settings) has created bottlenecks for automation deployment. End-to-end
learning based methods such as imitation learning and deep reinforcement
learning, have gained prominence as a viable deployment option to counter the
lack of accurate analytical models. However, the systematic formulation and
subsequent verification/validation in dynamic operation regimes (particularly
for skid-steered vehicles) remains a work in progress. To this end, a novel
approach for structured formulation for learning visual navigation is proposed
and investigated in this work. Extensive software simulations, hardware
evaluations and ablation studies now highlight the significantly improved
performance of the proposed approach against contemporary literature.

</details>


### [111] [Skill-Nav: Enhanced Navigation with Versatile Quadrupedal Locomotion via Waypoint Interface](https://arxiv.org/abs/2506.21853)
*Dewei Wang,Chenjia Ba,Chenhui Li,Jiyuan Shi,Yan Ding,Chi Zhang,Bin Zhao*

Main category: cs.RO

TL;DR: Skill-Nav是一种将四足机器人运动技能与导航结合的分层方法，通过路径点作为接口，利用深度强化学习训练运动策略，实现复杂地形导航。


<details>
  <summary>Details</summary>
Motivation: 四足机器人虽具备卓越的运动能力，但运动技能与导航的结合尚未充分研究，这有望提升其长距离移动能力。

Method: 提出Skill-Nav方法，通过路径点作为接口，训练基于深度强化学习的运动策略，使机器人能自主调整运动技能以到达目标位置并避开障碍。

Result: 实验表明，Skill-Nav能在模拟和现实场景中有效穿越复杂地形并完成导航任务。

Conclusion: Skill-Nav通过路径点接口实现了运动技能与导航的高效结合，为复杂地形导航提供了灵活解决方案。

Abstract: Quadrupedal robots have demonstrated exceptional locomotion capabilities
through Reinforcement Learning (RL), including extreme parkour maneuvers.
However, integrating locomotion skills with navigation in quadrupedal robots
has not been fully investigated, which holds promise for enhancing
long-distance movement capabilities. In this paper, we propose Skill-Nav, a
method that incorporates quadrupedal locomotion skills into a hierarchical
navigation framework using waypoints as an interface. Specifically, we train a
waypoint-guided locomotion policy using deep RL, enabling the robot to
autonomously adjust its locomotion skills to reach targeted positions while
avoiding obstacles. Compared with direct velocity commands, waypoints offer a
simpler yet more flexible interface for high-level planning and low-level
control. Utilizing waypoints as the interface allows for the application of
various general planning tools, such as large language models (LLMs) and path
planning algorithms, to guide our locomotion policy in traversing terrains with
diverse obstacles. Extensive experiments conducted in both simulated and
real-world scenarios demonstrate that Skill-Nav can effectively traverse
complex terrains and complete challenging navigation tasks.

</details>


### [112] [Embodied Domain Adaptation for Object Detection](https://arxiv.org/abs/2506.21860)
*Xiangyu Shi,Yanyuan Qiao,Lingqiao Liu,Feras Dayoub*

Main category: cs.RO

TL;DR: 论文提出了一种无需源数据的领域自适应方法（SFDA），通过时间聚类和多尺度阈值融合改进伪标签，结合对比学习的Mean Teacher框架，显著提升了室内动态环境下的零样本检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决标准闭集方法和开放词汇对象检测（OVOD）在室内环境中因领域偏移和动态条件导致的性能不足问题。

Method: 采用源自由领域自适应（SFDA）方法，通过时间聚类优化伪标签，结合多尺度阈值融合和Mean Teacher框架，利用对比学习进行模型适应。

Result: 在EDAOD基准测试中，零样本检测性能显著提升，能够灵活适应动态室内条件。

Conclusion: 提出的方法有效解决了室内环境中对象检测的领域适应问题，为动态条件下的机器人感知提供了实用解决方案。

Abstract: Mobile robots rely on object detectors for perception and object localization
in indoor environments. However, standard closed-set methods struggle to handle
the diverse objects and dynamic conditions encountered in real homes and labs.
Open-vocabulary object detection (OVOD), driven by Vision Language Models
(VLMs), extends beyond fixed labels but still struggles with domain shifts in
indoor environments. We introduce a Source-Free Domain Adaptation (SFDA)
approach that adapts a pre-trained model without accessing source data. We
refine pseudo labels via temporal clustering, employ multi-scale threshold
fusion, and apply a Mean Teacher framework with contrastive learning. Our
Embodied Domain Adaptation for Object Detection (EDAOD) benchmark evaluates
adaptation under sequential changes in lighting, layout, and object diversity.
Our experiments show significant gains in zero-shot detection performance and
flexible adaptation to dynamic indoor conditions.

</details>


### [113] [A MILP-Based Solution to Multi-Agent Motion Planning and Collision Avoidance in Constrained Environments](https://arxiv.org/abs/2506.21982)
*Akshay Jaitly,Jack Cline,Siavash Farzan*

Main category: cs.RO

TL;DR: 提出一种混合整数线性规划（MILP）方法，用于多智能体运动规划，通过序列化解决流程嵌入PAAMP，显著减少变量数量并提高求解速度。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体运动规划中传统MILP方法变量多、求解慢的问题，提出更高效的优化框架。

Method: 结合PAAMP和序列化解决流程，使用区域序列限制智能体运动，并通过大M超平面模型确保智能体间分离，减少碰撞约束的变量数量。

Result: 在代表性多智能体场景中，该方法比传统MILP快一个数量级，且能生成无碰撞的平滑轨迹。

Conclusion: 提出的MILP框架在多智能体运动规划中显著提升了效率和性能，适用于复杂场景。

Abstract: We propose a mixed-integer linear program (MILP) for multi-agent motion
planning that embeds Polytopic Action-based Motion Planning (PAAMP) into a
sequence-then-solve pipeline. Region sequences confine each agent to adjacent
convex polytopes, while a big-M hyperplane model enforces inter-agent
separation. Collision constraints are applied only to agents sharing or
neighboring a region, which reduces binary variables exponentially compared
with naive formulations. An L1 path-length-plus-acceleration cost yields smooth
trajectories. We prove finite-time convergence and demonstrate on
representative multi-agent scenarios with obstacles that our formulation
produces collision-free trajectories an order of magnitude faster than an
unstructured MILP baseline.

</details>


### [114] [LMPVC and Policy Bank: Adaptive voice control for industrial robots with code generating LLMs and reusable Pythonic policies](https://arxiv.org/abs/2506.22028)
*Ossi Parikka,Roel Pieters*

Main category: cs.RO

TL;DR: 论文提出了一种基于大语言模型（LLM）的语音控制架构LMPVC，用于人机协作（HRC），通过集成策略编程和教学功能，解决了LLM的局限性。


<details>
  <summary>Details</summary>
Motivation: 现代制造业趋向个性化和复杂化，需要更先进的人机协作方法，尤其是语音控制。LLM的发展为此提供了潜力。

Method: 提出LMPVC架构，结合代码生成和策略银行（Policy Bank）系统，实现语音控制、编程和教学功能。

Result: LMPVC能适应不同任务，无需耗时训练，弥补了LLM的不足。

Conclusion: LMPVC为HRC提供了一种高效灵活的语音控制解决方案，代码已开源。

Abstract: Modern industry is increasingly moving away from mass manufacturing, towards
more specialized and personalized products. As manufacturing tasks become more
complex, full automation is not always an option, human involvement may be
required. This has increased the need for advanced human robot collaboration
(HRC), and with it, improved methods for interaction, such as voice control.
Recent advances in natural language processing, driven by artificial
intelligence (AI), have the potential to answer this demand. Large language
models (LLMs) have rapidly developed very impressive general reasoning
capabilities, and many methods of applying this to robotics have been proposed,
including through the use of code generation. This paper presents Language
Model Program Voice Control (LMPVC), an LLM-based prototype voice control
architecture with integrated policy programming and teaching capabilities,
built for use with Robot Operating System 2 (ROS2) compatible robots. The
architecture builds on prior works using code generation for voice control by
implementing an additional programming and teaching system, the Policy Bank. We
find this system can compensate for the limitations of the underlying LLM, and
allow LMPVC to adapt to different downstream tasks without a slow and costly
training process. The architecture and additional results are released on
GitHub (https://github.com/ozzyuni/LMPVC).

</details>


### [115] [Multi-Robot Assembly of Deformable Linear Objects Using Multi-Modal Perception](https://arxiv.org/abs/2506.22034)
*Kejia Chen,Celina Dettmering,Florian Pachler,Zhuo Liu,Yue Zhang,Tailai Cheng,Jonas Dirr,Zhenshan Bing,Alois Knoll,Rüdiger Daub*

Main category: cs.RO

TL;DR: 提出了一种基于对象感知和规划的框架，用于实现工业价值链中全面的可变形线性物体（DLO）装配过程。


<details>
  <summary>Details</summary>
Motivation: 工业中DLO（如电缆）的装配具有潜力，但因其变形复杂且行为难以预测，机器人自动化面临挑战。现有研究仅解决孤立子问题，缺乏集成工作流。

Method: 利用视觉和触觉信息跟踪DLO形状及接触状态，结合机器人动作规划，实现从杂乱环境中分拣到多机器人协同装配的完整流程。

Result: 真实多机器人实验验证了方法的有效性及其工业适用性。

Conclusion: 提出的框架为DLO装配提供了集成解决方案，展示了工业应用的潜力。

Abstract: Industrial assembly of deformable linear objects (DLOs) such as cables offers
great potential for many industries. However, DLOs pose several challenges for
robot-based automation due to the inherent complexity of deformation and,
consequentially, the difficulties in anticipating the behavior of DLOs in
dynamic situations. Although existing studies have addressed isolated
subproblems like shape tracking, grasping, and shape control, there has been
limited exploration of integrated workflows that combine these individual
processes. To address this gap, we propose an object-centric perception and
planning framework to achieve a comprehensive DLO assembly process throughout
the industrial value chain. The framework utilizes visual and tactile
information to track the DLO's shape as well as contact state across different
stages, which facilitates effective planning of robot actions. Our approach
encompasses robot-based bin picking of DLOs from cluttered environments,
followed by a coordinated handover to two additional robots that mount the DLOs
onto designated fixtures. Real-world experiments employing a setup with
multiple robots demonstrate the effectiveness of the approach and its relevance
to industrial scenarios.

</details>


### [116] [An Introduction to Zero-Order Optimization Techniques for Robotics](https://arxiv.org/abs/2506.22087)
*Armand Jordana,Jianghan Zhang,Joseph Amigo,Ludovic Righetti*

Main category: cs.RO

TL;DR: 本文为零阶优化技术提供数学教程，统一视角理解机器人学中的算法，并推导新RL算法。


<details>
  <summary>Details</summary>
Motivation: 零阶优化技术在机器人学中因处理非可微函数和逃离局部极小值的优势而流行，适用于轨迹优化和策略优化。

Method: 提出随机搜索的数学教程，提供统一视角分类轨迹优化方法，并推导新RL算法。

Result: 通过统一视角，将多种轨迹优化方法归类，并开发出有竞争力的新RL算法。

Conclusion: 零阶优化技术的统一视角为机器人学中的算法理解和创新提供了有效工具。

Abstract: Zero-order optimization techniques are becoming increasingly popular in
robotics due to their ability to handle non-differentiable functions and escape
local minima. These advantages make them particularly useful for trajectory
optimization and policy optimization. In this work, we propose a mathematical
tutorial on random search. It offers a simple and unifying perspective for
understanding a wide range of algorithms commonly used in robotics. Leveraging
this viewpoint, we classify many trajectory optimization methods under a common
framework and derive novel competitive RL algorithms.

</details>


### [117] [Evaluating Pointing Gestures for Target Selection in Human-Robot Collaboration](https://arxiv.org/abs/2506.22116)
*Noora Sassali,Roel Pieters*

Main category: cs.RO

TL;DR: 该研究提出了一种基于姿态估计和几何模型的方法，用于在平面工作空间中定位指向目标，并评估其在机器人任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 指向手势在人机协作中广泛应用，但缺乏一种系统的方法来定位指向目标并评估其准确性。

Method: 采用姿态估计和基于肩-腕伸展的几何模型，从RGB-D流中提取手势数据，并结合多模态技术（如物体检测和语音处理）进行验证。

Result: 开发了一个概念验证机器人系统，展示了多模态协作应用的可行性，并提供了工具的性能和局限性分析。

Conclusion: 该方法为多模态机器人系统中的指向手势定位提供了可行解决方案，但仍需进一步优化以适应更复杂场景。

Abstract: Pointing gestures are a common interaction method used in Human-Robot
Collaboration for various tasks, ranging from selecting targets to guiding
industrial processes. This study introduces a method for localizing pointed
targets within a planar workspace. The approach employs pose estimation, and a
simple geometric model based on shoulder-wrist extension to extract gesturing
data from an RGB-D stream. The study proposes a rigorous methodology and
comprehensive analysis for evaluating pointing gestures and target selection in
typical robotic tasks. In addition to evaluating tool accuracy, the tool is
integrated into a proof-of-concept robotic system, which includes object
detection, speech transcription, and speech synthesis to demonstrate the
integration of multiple modalities in a collaborative application. Finally, a
discussion over tool limitations and performance is provided to understand its
role in multimodal robotic systems. All developments are available at:
https://github.com/NMKsas/gesture_pointer.git.

</details>


### [118] [RM-Dijkstra: A surface optimal path planning algorithm based on Riemannian metric](https://arxiv.org/abs/2506.22170)
*Yu Zhang,Xiao-Song Yang*

Main category: cs.RO

TL;DR: 提出了基于黎曼度量的RM-Dijkstra算法，用于解决移动机器人表面路径规划问题，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: Dijkstra算法在离散图空间中表现优异，但在移动机器人表面路径规划中应用较少，需要改进。

Method: 通过构建新的黎曼度量，将表面路径规划问题转化为2D平面上的几何问题，并确保投影映射为等距浸入。

Result: 仿真测试表明，RM-Dijkstra算法在路径精度和平滑度上优于传统算法，尤其在复杂场景中。

Conclusion: RM-Dijkstra算法有效解决了表面最优路径规划问题，具有实际应用潜力。

Abstract: The Dijkstra algorithm is a classic path planning method, which operates in a
discrete graph space to determine the shortest path from a specified source
point to a target node or all other nodes based on non-negative edge weights.
Numerous studies have focused on the Dijkstra algorithm due to its potential
application. However, its application in surface path planning for mobile
robots remains largely unexplored. In this letter, a surface optimal path
planning algorithm called RM-Dijkstra is proposed, which is based on Riemannian
metric model. By constructing a new Riemannian metric on the 2D projection
plane, the surface optimal path planning problem is therefore transformed into
a geometric problem on the 2D plane with new Riemannian metric. Induced by the
standard Euclidean metric on surface, the constructed new metric reflects
environmental information of the robot and ensures that the projection map is
an isometric immersion. By conducting a series of simulation tests, the
experimental results demonstrate that the RM-Dijkstra algorithm not only
effectively solves the optimal path planning problem on surfaces, but also
outperforms traditional path planning algorithms in terms of path accuracy and
smoothness, particularly in complex scenarios.

</details>


### [119] [ASVSim (AirSim for Surface Vehicles): A High-Fidelity Simulation Framework for Autonomous Surface Vehicle Research](https://arxiv.org/abs/2506.22174)
*Bavo Lesy,Siemen Herremans,Robin Kerstens,Jan Steckel,Walter Daems,Siegfried Mercelis,Ali Anwar*

Main category: cs.RO

TL;DR: ASVSim是一个开源仿真框架，专为内河和港口环境中的自主航运研究设计，结合了船舶动力学和海洋传感器模拟功能。


<details>
  <summary>Details</summary>
Motivation: 运输行业对无人水面车辆（USVs）的需求增加，但缺乏开源高保真仿真框架和数据集。

Method: 基于Cosys-AirSim开发，支持船舶动力学和传感器模拟，生成合成数据集用于训练计算机视觉和强化学习模型。

Result: 通过实验展示了ASVSim在自主导航算法研究和数据集生成方面的潜力。

Conclusion: ASVSim作为开源项目，为海洋工程社区提供了自主导航研究的平台。

Abstract: The transport industry has recently shown significant interest in unmanned
surface vehicles (USVs), specifically for port and inland waterway transport.
These systems can improve operational efficiency and safety, which is
especially relevant in the European Union, where initiatives such as the Green
Deal are driving a shift towards increased use of inland waterways. At the same
time, a shortage of qualified personnel is accelerating the adoption of
autonomous solutions. However, there is a notable lack of open-source,
high-fidelity simulation frameworks and datasets for developing and evaluating
such solutions. To address these challenges, we introduce AirSim For Surface
Vehicles (ASVSim), an open-source simulation framework specifically designed
for autonomous shipping research in inland and port environments. The framework
combines simulated vessel dynamics with marine sensor simulation capabilities,
including radar and camera systems and supports the generation of synthetic
datasets for training computer vision models and reinforcement learning agents.
Built upon Cosys-AirSim, ASVSim provides a comprehensive platform for
developing autonomous navigation algorithms and generating synthetic datasets.
The simulator supports research of both traditional control methods and deep
learning-based approaches. Through limited experiments, we demonstrate the
potential of the simulator in these research areas. ASVSim is provided as an
open-source project under the MIT license, making autonomous navigation
research accessible to a larger part of the ocean engineering community.

</details>


### [120] [KnotDLO: Toward Interpretable Knot Tying](https://arxiv.org/abs/2506.22176)
*Holly Dinkel,Raghavendra Navaratna,Jingyi Xiang,Brian Coltin,Trey Smith,Timothy Bretl*

Main category: cs.RO

TL;DR: KnotDLO是一种无需人工演示或训练的单手可变形线性物体（DLO）打结方法，具有抗遮挡性、可重复性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决DLO打结任务中的遮挡问题、初始配置差异以及需要人工干预的局限性。

Method: 通过当前DLO形状规划抓取和目标路径点，利用分段线性曲线跟踪和几何计算生成中间路径点，实现视觉与控制的解耦。

Result: 在16次实验中，KnotDLO在从未见过的配置下成功打结的成功率为50%。

Conclusion: KnotDLO展示了无需训练和人工干预的DLO打结能力，但成功率有待提升。

Abstract: This work presents KnotDLO, a method for one-handed Deformable Linear Object
(DLO) knot tying that is robust to occlusion, repeatable for varying rope
initial configurations, interpretable for generating motion policies, and
requires no human demonstrations or training. Grasp and target waypoints for
future DLO states are planned from the current DLO shape. Grasp poses are
computed from indexing the tracked piecewise linear curve representing the DLO
state based on the current curve shape and are piecewise continuous. KnotDLO
computes intermediate waypoints from the geometry of the current DLO state and
the desired next state. The system decouples visual reasoning from control. In
16 trials of knot tying, KnotDLO achieves a 50% success rate in tying an
overhand knot from previously unseen configurations.

</details>


### [121] [Robotic Multimodal Data Acquisition for In-Field Deep Learning Estimation of Cover Crop Biomass](https://arxiv.org/abs/2506.22364)
*Joe Johnson,Phanender Chalasani,Arnav Shah,Ram L. Ray,Muthukumar Bagavathiannan*

Main category: cs.RO

TL;DR: 研究提出了一种基于多模态传感器和机器学习的系统，用于精准估计覆盖作物生物量，以优化杂草管理策略。


<details>
  <summary>Details</summary>
Motivation: 精准杂草管理对减少作物产量损失至关重要，但传统方法（如人工检查）效率低下，需要更高效的技术。

Method: 结合光学和LiDAR数据，利用机器学习方法进行数据融合，提高生物量预测精度。

Result: 最佳模型在干生物量估计中达到0.88的决定系数，表现优异。

Conclusion: 该系统为精准农业提供了有效工具，支持可持续杂草管理和耕作实践。

Abstract: Accurate weed management is essential for mitigating significant crop yield
losses, necessitating effective weed suppression strategies in agricultural
systems. Integrating cover crops (CC) offers multiple benefits, including soil
erosion reduction, weed suppression, decreased nitrogen requirements, and
enhanced carbon sequestration, all of which are closely tied to the aboveground
biomass (AGB) they produce. However, biomass production varies significantly
due to microsite variability, making accurate estimation and mapping essential
for identifying zones of poor weed suppression and optimizing targeted
management strategies. To address this challenge, developing a comprehensive CC
map, including its AGB distribution, will enable informed decision-making
regarding weed control methods and optimal application rates. Manual visual
inspection is impractical and labor-intensive, especially given the extensive
field size and the wide diversity and variation of weed species and sizes. In
this context, optical imagery and Light Detection and Ranging (LiDAR) data are
two prominent sources with unique characteristics that enhance AGB estimation.
This study introduces a ground robot-mounted multimodal sensor system designed
for agricultural field mapping. The system integrates optical and LiDAR data,
leveraging machine learning (ML) methods for data fusion to improve biomass
predictions. The best ML-based model for dry AGB estimation achieved a
coefficient of determination value of 0.88, demonstrating robust performance in
diverse field conditions. This approach offers valuable insights for
site-specific management, enabling precise weed suppression strategies and
promoting sustainable farming practices.

</details>


### [122] [FrankenBot: Brain-Morphic Modular Orchestration for Robotic Manipulation with Vision-Language Models](https://arxiv.org/abs/2506.21627)
*Shiyi Wang,Wenbo Li,Yiteng Chen,Qingyao Wu,Huiping Zhuang*

Main category: cs.RO

TL;DR: 论文提出了一种名为FrankenBot的VLM驱动的机器人操作框架，通过模仿人脑结构实现多功能集成与高效操作。


<details>
  <summary>Details</summary>
Motivation: 开发一个能在复杂动态环境中执行多种任务的通用机器人系统，需要整合多种功能，但现有方法通常只关注单一功能。

Method: 采用分治策略和人脑结构，将任务规划、策略生成等功能映射到不同脑区，设计高效协调机制。

Result: 实验表明，该方法在异常检测、长期记忆和操作效率等方面具有显著优势，且无需微调或重新训练。

Conclusion: FrankenBot框架成功实现了功能全面性与操作效率的平衡，为通用机器人系统提供了新思路。

Abstract: Developing a general robot manipulation system capable of performing a wide
range of tasks in complex, dynamic, and unstructured real-world environments
has long been a challenging task. It is widely recognized that achieving
human-like efficiency and robustness manipulation requires the robotic brain to
integrate a comprehensive set of functions, such as task planning, policy
generation, anomaly monitoring and handling, and long-term memory, achieving
high-efficiency operation across all functions. Vision-Language Models (VLMs),
pretrained on massive multimodal data, have acquired rich world knowledge,
exhibiting exceptional scene understanding and multimodal reasoning
capabilities. However, existing methods typically focus on realizing only a
single function or a subset of functions within the robotic brain, without
integrating them into a unified cognitive architecture. Inspired by a
divide-and-conquer strategy and the architecture of the human brain, we propose
FrankenBot, a VLM-driven, brain-morphic robotic manipulation framework that
achieves both comprehensive functionality and high operational efficiency. Our
framework includes a suite of components, decoupling a part of key functions
from frequent VLM calls, striking an optimal balance between functional
completeness and system efficiency. Specifically, we map task planning, policy
generation, memory management, and low-level interfacing to the cortex,
cerebellum, temporal lobe-hippocampus complex, and brainstem, respectively, and
design efficient coordination mechanisms for the modules. We conducted
comprehensive experiments in both simulation and real-world robotic
environments, demonstrating that our method offers significant advantages in
anomaly detection and handling, long-term memory, operational efficiency, and
stability -- all without requiring any fine-tuning or retraining.

</details>


### [123] [Ark: An Open-source Python-based Framework for Robot Learning](https://arxiv.org/abs/2506.21628)
*Magnus Dierking,Christopher E. Mower,Sarthak Das,Huang Helong,Jiacheng Qiu,Cody Reading,Wei Chen,Huidong Liang,Huang Guowei,Jan Peters,Quan Xingyue,Jun Wang,Haitham Bou-Ammar*

Main category: cs.RO

TL;DR: ARK是一个开源的、以Python为中心的机器人框架，旨在简化机器人软件开发，降低学习曲线，并提供与AI生态系统类似的便利性。


<details>
  <summary>Details</summary>
Motivation: 当前机器人软件栈需要复杂的硬件集成和低级的C/C++专业知识，与Python主导的现代AI生态系统形成鲜明对比，ARK旨在弥合这一差距。

Method: ARK提供了一个Gym风格的环境接口，支持数据收集、预处理和策略训练，同时支持高保真仿真和物理机器人之间的无缝切换。它还提供轻量级客户端-服务器架构和可选的C/C++绑定。

Result: ARK展示了快速原型设计、轻松硬件交换和端到端流水线的能力，其模块化和文档化使其在研究和商业部署中具有竞争力。

Conclusion: ARK通过统一机器人技术和AI实践，降低了入门门槛，加速了自主机器人的研究和商业应用。

Abstract: Robotics has made remarkable hardware strides-from DARPA's Urban and Robotics
Challenges to the first humanoid-robot kickboxing tournament-yet commercial
autonomy still lags behind progress in machine learning. A major bottleneck is
software: current robot stacks demand steep learning curves, low-level C/C++
expertise, fragmented tooling, and intricate hardware integration, in stark
contrast to the Python-centric, well-documented ecosystems that propelled
modern AI. We introduce ARK, an open-source, Python-first robotics framework
designed to close that gap. ARK presents a Gym-style environment interface that
allows users to collect data, preprocess it, and train policies using
state-of-the-art imitation-learning algorithms (e.g., ACT, Diffusion Policy)
while seamlessly toggling between high-fidelity simulation and physical robots.
A lightweight client-server architecture provides networked
publisher-subscriber communication, and optional C/C++ bindings ensure
real-time performance when needed. ARK ships with reusable modules for control,
SLAM, motion planning, system identification, and visualization, along with
native ROS interoperability. Comprehensive documentation and case studies-from
manipulation to mobile navigation-demonstrate rapid prototyping, effortless
hardware swapping, and end-to-end pipelines that rival the convenience of
mainstream machine-learning workflows. By unifying robotics and AI practices
under a common Python umbrella, ARK lowers entry barriers and accelerates
research and commercial deployment of autonomous robots.

</details>


### [124] [TOMD: A Trail-based Off-road Multimodal Dataset for Traversable Pathway Segmentation under Challenging Illumination Conditions](https://arxiv.org/abs/2506.21630)
*Yixin Sun,Li Li,Wenke E,Amir Atapour-Abarghouei,Toby P. Breckon*

Main category: cs.RO

TL;DR: 论文提出了一个针对非结构化户外环境中可通行路径检测的数据集TOMD和动态多尺度数据融合模型，填补了现有数据集的不足，并验证了光照对分割性能的影响。


<details>
  <summary>Details</summary>
Motivation: 解决非结构化户外环境中可通行路径检测的挑战，特别是在搜索救援和森林火灾等关键应用中，现有数据集和模型主要针对城市环境或宽阔的越野路径，无法满足狭窄小径的需求。

Method: 引入TOMD数据集，包含多模态传感器数据，并提出动态多尺度数据融合模型，比较了不同融合策略在不同光照条件下的性能。

Result: 结果表明，该方法有效，且光照对分割性能有显著影响。

Conclusion: TOMD数据集和动态多尺度数据融合模型为非结构化户外环境中的可通行路径检测提供了有效解决方案，并公开数据集以支持未来研究。

Abstract: Detecting traversable pathways in unstructured outdoor environments remains a
significant challenge for autonomous robots, especially in critical
applications such as wide-area search and rescue, as well as incident
management scenarios like forest fires. Existing datasets and models primarily
target urban settings or wide, vehicle-traversable off-road tracks, leaving a
substantial gap in addressing the complexity of narrow, trail-like off-road
scenarios. To address this, we introduce the Trail-based Off-road Multimodal
Dataset (TOMD), a comprehensive dataset specifically designed for such
environments. TOMD features high-fidelity multimodal sensor data -- including
128-channel LiDAR, stereo imagery, GNSS, IMU, and illumination measurements --
collected through repeated traversals under diverse conditions. We also propose
a dynamic multiscale data fusion model for accurate traversable pathway
prediction. The study analyzes the performance of early, cross, and mixed
fusion strategies under varying illumination levels. Results demonstrate the
effectiveness of our approach and the relevance of illumination in segmentation
performance. We publicly release TOMD at https://github.com/yyyxs1125/TMOD to
support future research in trail-based off-road navigation.

</details>


### [125] [Real-Time 3D Guidewire Reconstruction from Intraoperative DSA Images for Robot-Assisted Endovascular Interventions](https://arxiv.org/abs/2506.21631)
*Tianliang Yao,Bingrui Li,Bo Lu,Zhiqiang Pei,Yixuan Yuan,Peng Qi*

Main category: cs.RO

TL;DR: 提出一种结合术前3D CTA和术中2D DSA的多模态框架，实现实时3D导丝重建，提升机器人辅助血管内手术的空间感知。


<details>
  <summary>Details</summary>
Motivation: 传统2D DSA缺乏深度信息，导致空间模糊，阻碍导丝形状的可靠感知。

Method: 通过鲁棒特征提取处理2D DSA噪声和畸变，结合可变形图像配准将2D投影与3D CTA对齐，再通过逆投影算法重建3D导丝形状。

Result: 系统在实时处理速度、重建精度和计算效率上显著提升，投影误差为1.76±0.08像素，长度偏差为2.93±0.15%，帧率为39.3±1.5 FPS。

Conclusion: 该方法优化了机器人性能，提高了复杂血管内手术的精度，有望改善临床效果。

Abstract: Accurate three-dimensional (3D) reconstruction of guidewire shapes is crucial
for precise navigation in robot-assisted endovascular interventions.
Conventional 2D Digital Subtraction Angiography (DSA) is limited by the absence
of depth information, leading to spatial ambiguities that hinder reliable
guidewire shape sensing. This paper introduces a novel multimodal framework for
real-time 3D guidewire reconstruction, combining preoperative 3D Computed
Tomography Angiography (CTA) with intraoperative 2D DSA images. The method
utilizes robust feature extraction to address noise and distortion in 2D DSA
data, followed by deformable image registration to align the 2D projections
with the 3D CTA model. Subsequently, the inverse projection algorithm
reconstructs the 3D guidewire shape, providing real-time, accurate spatial
information. This framework significantly enhances spatial awareness for
robotic-assisted endovascular procedures, effectively bridging the gap between
preoperative planning and intraoperative execution. The system demonstrates
notable improvements in real-time processing speed, reconstruction accuracy,
and computational efficiency. The proposed method achieves a projection error
of 1.76$\pm$0.08 pixels and a length deviation of 2.93$\pm$0.15\%, with a frame
rate of 39.3$\pm$1.5 frames per second (FPS). These advancements have the
potential to optimize robotic performance and increase the precision of complex
endovascular interventions, ultimately contributing to better clinical
outcomes.

</details>


### [126] [AeroLite-MDNet: Lightweight Multi-task Deviation Detection Network for UAV Landing](https://arxiv.org/abs/2506.21635)
*Haiping Yang,Huaxing Liu,Wei Wu,Zuohui Chen,Ning Wu*

Main category: cs.RO

TL;DR: 论文提出了一种基于视觉的无人机着陆偏差预警系统AeroLite-MDNet，通过多尺度融合模块和分割分支提高检测和方向估计能力，并引入新评价指标AWD和新数据集UAVLandData，实验显示系统性能优越。


<details>
  <summary>Details</summary>
Motivation: 无人机着陆时因GPS信号干扰等问题难以精准降落，需提高着陆可靠性。

Method: 提出AeroLite-MDNet模型，结合多尺度融合模块和分割分支，用于检测着陆偏差和估计方向；引入AWD指标和新数据集UAVLandData。

Result: 系统AWD为0.7秒，偏差检测准确率达98.6%。

Conclusion: AeroLite-MDNet系统显著提升了无人机着陆的可靠性。

Abstract: Unmanned aerial vehicles (UAVs) are increasingly employed in diverse
applications such as land surveying, material transport, and environmental
monitoring. Following missions like data collection or inspection, UAVs must
land safely at docking stations for storage or recharging, which is an
essential requirement for ensuring operational continuity. However, accurate
landing remains challenging due to factors like GPS signal interference. To
address this issue, we propose a deviation warning system for UAV landings,
powered by a novel vision-based model called AeroLite-MDNet. This model
integrates a multiscale fusion module for robust cross-scale object detection
and incorporates a segmentation branch for efficient orientation estimation. We
introduce a new evaluation metric, Average Warning Delay (AWD), to quantify the
system's sensitivity to landing deviations. Furthermore, we contribute a new
dataset, UAVLandData, which captures real-world landing deviation scenarios to
support training and evaluation. Experimental results show that our system
achieves an AWD of 0.7 seconds with a deviation detection accuracy of 98.6\%,
demonstrating its effectiveness in enhancing UAV landing reliability. Code will
be available at https://github.com/ITTTTTI/Maskyolo.git

</details>


### [127] [Optimal Motion Scaling for Delayed Telesurgery](https://arxiv.org/abs/2506.21689)
*Jason Lim,Florian Richter,Zih-Yun Chiu,Jaeyon Lee,Ethan Quist,Nathan Fisher,Jonathan Chambers,Steven Hong,Michael C. Yip*

Main category: cs.RO

TL;DR: 研究探讨了远程机器人操作中延迟对性能的影响，提出通过个性化缩放因子优化性能。


<details>
  <summary>Details</summary>
Motivation: 解决远程机器人操作中因网络延迟导致的命令和反馈延迟问题，提升性能。

Method: 通过用户研究分析延迟、缩放因子与性能的关系，并开发个性化模型。

Result: 研究发现缩放因子的最优值因用户和延迟水平而异，个性化模型显著提升性能。

Conclusion: 个性化缩放因子模型是优化远程机器人操作（如远程手术）性能的有效解决方案。

Abstract: Robotic teleoperation over long communication distances poses challenges due
to delays in commands and feedback from network latency. One simple yet
effective strategy to reduce errors and increase performance under delay is to
downscale the relative motion between the operating surgeon and the robot. The
question remains as to what is the optimal scaling factor, and how this value
changes depending on the level of latency as well as operator tendencies. We
present user studies investigating the relationship between latency, scaling
factor, and performance. The results of our studies demonstrate a statistically
significant difference in performance between users and across scaling factors
for certain levels of delay. These findings indicate that the optimal scaling
factor for a given level of delay is specific to each user, motivating the need
for personalized models for optimal performance. We present techniques to model
the user-specific mapping of latency level to scaling factor for optimal
performance, leading to an efficient and effective solution to optimizing
performance of robotic teleoperation and specifically telesurgery under large
communication delay.

</details>


### [128] [Experimental investigation of pose informed reinforcement learning for skid-steered visual navigation](https://arxiv.org/abs/2506.21732)
*Ameya Salvi,Venkat Krovi*

Main category: cs.RO

TL;DR: 论文提出了一种基于学习的视觉导航方法，解决了滑移转向车辆在动态操作中的建模和验证问题，并通过实验验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 滑移转向车辆在自动化部署中因缺乏准确的解析模型而受限，尤其是滑移-滑动轮地交互的建模问题。

Method: 采用端到端学习方法（如模仿学习和深度强化学习），提出了一种结构化的视觉导航框架。

Result: 通过软件仿真、硬件评估和消融研究，证明了该方法在性能上显著优于现有文献。

Conclusion: 该方法为滑移转向车辆的自动化部署提供了一种有效的解决方案，尤其在动态操作环境中表现优异。

Abstract: Vision-based lane keeping is a topic of significant interest in the robotics
and autonomous ground vehicles communities in various on-road and off-road
applications. The skid-steered vehicle architecture has served as a useful
vehicle platform for human controlled operations. However, systematic modeling,
especially of the skid-slip wheel terrain interactions (primarily in off-road
settings) has created bottlenecks for automation deployment. End-to-end
learning based methods such as imitation learning and deep reinforcement
learning, have gained prominence as a viable deployment option to counter the
lack of accurate analytical models. However, the systematic formulation and
subsequent verification/validation in dynamic operation regimes (particularly
for skid-steered vehicles) remains a work in progress. To this end, a novel
approach for structured formulation for learning visual navigation is proposed
and investigated in this work. Extensive software simulations, hardware
evaluations and ablation studies now highlight the significantly improved
performance of the proposed approach against contemporary literature.

</details>


### [129] [Skill-Nav: Enhanced Navigation with Versatile Quadrupedal Locomotion via Waypoint Interface](https://arxiv.org/abs/2506.21853)
*Dewei Wang,Chenjia Ba,Chenhui Li,Jiyuan Shi,Yan Ding,Chi Zhang,Bin Zhao*

Main category: cs.RO

TL;DR: Skill-Nav通过将四足机器人的运动技能与导航结合，利用路径点作为接口，实现了复杂地形的高效导航。


<details>
  <summary>Details</summary>
Motivation: 探索如何将四足机器人的运动技能与导航能力结合，以提升长距离移动能力。

Method: 提出Skill-Nav方法，使用深度强化学习训练路径点引导的运动策略，结合高级规划和低级控制。

Result: 在仿真和实际场景中，Skill-Nav能有效穿越复杂地形并完成导航任务。

Conclusion: Skill-Nav为四足机器人导航提供了一种灵活且高效的解决方案。

Abstract: Quadrupedal robots have demonstrated exceptional locomotion capabilities
through Reinforcement Learning (RL), including extreme parkour maneuvers.
However, integrating locomotion skills with navigation in quadrupedal robots
has not been fully investigated, which holds promise for enhancing
long-distance movement capabilities. In this paper, we propose Skill-Nav, a
method that incorporates quadrupedal locomotion skills into a hierarchical
navigation framework using waypoints as an interface. Specifically, we train a
waypoint-guided locomotion policy using deep RL, enabling the robot to
autonomously adjust its locomotion skills to reach targeted positions while
avoiding obstacles. Compared with direct velocity commands, waypoints offer a
simpler yet more flexible interface for high-level planning and low-level
control. Utilizing waypoints as the interface allows for the application of
various general planning tools, such as large language models (LLMs) and path
planning algorithms, to guide our locomotion policy in traversing terrains with
diverse obstacles. Extensive experiments conducted in both simulated and
real-world scenarios demonstrate that Skill-Nav can effectively traverse
complex terrains and complete challenging navigation tasks.

</details>


### [130] [Embodied Domain Adaptation for Object Detection](https://arxiv.org/abs/2506.21860)
*Xiangyu Shi,Yanyuan Qiao,Lingqiao Liu,Feras Dayoub*

Main category: cs.RO

TL;DR: 论文提出了一种无需源数据的领域自适应方法（SFDA），通过时间聚类和多尺度阈值融合改进伪标签，结合对比学习的Mean Teacher框架，显著提升了室内动态环境下的零样本检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决室内环境中标准闭集方法和开放词汇对象检测（OVOD）在动态条件下的局限性，尤其是领域偏移问题。

Method: 采用无需源数据的领域自适应（SFDA），结合时间聚类、多尺度阈值融合和Mean Teacher框架，利用对比学习优化模型。

Result: 在EDAOD基准测试中，零样本检测性能显著提升，能够灵活适应动态室内条件。

Conclusion: 提出的方法有效解决了室内环境中的领域偏移问题，提升了对象检测的适应性和性能。

Abstract: Mobile robots rely on object detectors for perception and object localization
in indoor environments. However, standard closed-set methods struggle to handle
the diverse objects and dynamic conditions encountered in real homes and labs.
Open-vocabulary object detection (OVOD), driven by Vision Language Models
(VLMs), extends beyond fixed labels but still struggles with domain shifts in
indoor environments. We introduce a Source-Free Domain Adaptation (SFDA)
approach that adapts a pre-trained model without accessing source data. We
refine pseudo labels via temporal clustering, employ multi-scale threshold
fusion, and apply a Mean Teacher framework with contrastive learning. Our
Embodied Domain Adaptation for Object Detection (EDAOD) benchmark evaluates
adaptation under sequential changes in lighting, layout, and object diversity.
Our experiments show significant gains in zero-shot detection performance and
flexible adaptation to dynamic indoor conditions.

</details>


### [131] [A MILP-Based Solution to Multi-Agent Motion Planning and Collision Avoidance in Constrained Environments](https://arxiv.org/abs/2506.21982)
*Akshay Jaitly,Jack Cline,Siavash Farzan*

Main category: cs.RO

TL;DR: 提出一种混合整数线性规划（MILP）方法，用于多智能体运动规划，通过PAAMP嵌入序列-求解流程，显著减少计算量并提升效率。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体运动规划中计算复杂度高的问题，通过优化约束和减少变量，提高求解速度。

Method: 采用PAAMP和序列-求解流程，结合大M超平面模型确保智能体分离，仅对相邻区域智能体施加碰撞约束。

Result: 在代表性多智能体场景中，比非结构化MILP基线快一个数量级，生成无碰撞轨迹。

Conclusion: 该方法显著提升了多智能体运动规划的效率和实用性。

Abstract: We propose a mixed-integer linear program (MILP) for multi-agent motion
planning that embeds Polytopic Action-based Motion Planning (PAAMP) into a
sequence-then-solve pipeline. Region sequences confine each agent to adjacent
convex polytopes, while a big-M hyperplane model enforces inter-agent
separation. Collision constraints are applied only to agents sharing or
neighboring a region, which reduces binary variables exponentially compared
with naive formulations. An L1 path-length-plus-acceleration cost yields smooth
trajectories. We prove finite-time convergence and demonstrate on
representative multi-agent scenarios with obstacles that our formulation
produces collision-free trajectories an order of magnitude faster than an
unstructured MILP baseline.

</details>


### [132] [LMPVC and Policy Bank: Adaptive voice control for industrial robots with code generating LLMs and reusable Pythonic policies](https://arxiv.org/abs/2506.22028)
*Ossi Parikka,Roel Pieters*

Main category: cs.RO

TL;DR: 论文提出了一种基于大型语言模型（LLM）的语音控制架构LMPVC，用于ROS2兼容机器人，通过集成策略编程和教学功能（Policy Bank）来弥补LLM的局限性，并实现任务适应。


<details>
  <summary>Details</summary>
Motivation: 现代制造业向个性化和专业化发展，复杂任务需要人机协作（HRC），语音控制成为重要交互方式。AI驱动的自然语言处理技术（如LLM）为此提供了潜力。

Method: 提出LMPVC架构，结合代码生成和策略编程（Policy Bank），用于ROS2兼容机器人，实现语音控制与任务适应。

Result: LMPVC通过Policy Bank弥补LLM的局限性，无需耗时训练即可适应不同任务。

Conclusion: LMPVC为HRC提供了高效的语音控制解决方案，适应性强，成果已开源。

Abstract: Modern industry is increasingly moving away from mass manufacturing, towards
more specialized and personalized products. As manufacturing tasks become more
complex, full automation is not always an option, human involvement may be
required. This has increased the need for advanced human robot collaboration
(HRC), and with it, improved methods for interaction, such as voice control.
Recent advances in natural language processing, driven by artificial
intelligence (AI), have the potential to answer this demand. Large language
models (LLMs) have rapidly developed very impressive general reasoning
capabilities, and many methods of applying this to robotics have been proposed,
including through the use of code generation. This paper presents Language
Model Program Voice Control (LMPVC), an LLM-based prototype voice control
architecture with integrated policy programming and teaching capabilities,
built for use with Robot Operating System 2 (ROS2) compatible robots. The
architecture builds on prior works using code generation for voice control by
implementing an additional programming and teaching system, the Policy Bank. We
find this system can compensate for the limitations of the underlying LLM, and
allow LMPVC to adapt to different downstream tasks without a slow and costly
training process. The architecture and additional results are released on
GitHub (https://github.com/ozzyuni/LMPVC).

</details>


### [133] [Multi-Robot Assembly of Deformable Linear Objects Using Multi-Modal Perception](https://arxiv.org/abs/2506.22034)
*Kejia Chen,Celina Dettmering,Florian Pachler,Zhuo Liu,Yue Zhang,Tailai Cheng,Jonas Dirr,Zhenshan Bing,Alois Knoll,Rüdiger Daub*

Main category: cs.RO

TL;DR: 提出了一种基于对象感知和规划的框架，用于实现全面的可变形线性物体（DLO）工业组装流程。


<details>
  <summary>Details</summary>
Motivation: 解决DLO在动态情况下行为预测的复杂性，以及现有研究中缺乏集成工作流程的问题。

Method: 利用视觉和触觉信息跟踪DLO的形状和接触状态，结合机器人动作规划，实现从杂乱环境中抓取到装配的完整流程。

Result: 通过多机器人实验验证了方法的有效性，并展示了其在工业场景中的适用性。

Conclusion: 该框架为DLO的工业组装提供了一种集成化的解决方案，具有实际应用潜力。

Abstract: Industrial assembly of deformable linear objects (DLOs) such as cables offers
great potential for many industries. However, DLOs pose several challenges for
robot-based automation due to the inherent complexity of deformation and,
consequentially, the difficulties in anticipating the behavior of DLOs in
dynamic situations. Although existing studies have addressed isolated
subproblems like shape tracking, grasping, and shape control, there has been
limited exploration of integrated workflows that combine these individual
processes. To address this gap, we propose an object-centric perception and
planning framework to achieve a comprehensive DLO assembly process throughout
the industrial value chain. The framework utilizes visual and tactile
information to track the DLO's shape as well as contact state across different
stages, which facilitates effective planning of robot actions. Our approach
encompasses robot-based bin picking of DLOs from cluttered environments,
followed by a coordinated handover to two additional robots that mount the DLOs
onto designated fixtures. Real-world experiments employing a setup with
multiple robots demonstrate the effectiveness of the approach and its relevance
to industrial scenarios.

</details>


### [134] [An Introduction to Zero-Order Optimization Techniques for Robotics](https://arxiv.org/abs/2506.22087)
*Armand Jordana,Jianghan Zhang,Joseph Amigo,Ludovic Righetti*

Main category: cs.RO

TL;DR: 本文提出了一种关于随机搜索的数学教程，为理解机器人学中常用算法提供了统一视角，并基于此分类了轨迹优化方法，推导出新的强化学习算法。


<details>
  <summary>Details</summary>
Motivation: 零阶优化技术在机器人学中日益流行，因其能处理不可微函数和逃离局部极小值，适用于轨迹优化和策略优化。

Method: 提出随机搜索的数学教程，提供统一视角，分类轨迹优化方法。

Result: 基于统一视角，推导出新的竞争性强化学习算法。

Conclusion: 随机搜索的数学教程为机器人学中的算法提供了简单且统一的理解框架，并推动了新算法的开发。

Abstract: Zero-order optimization techniques are becoming increasingly popular in
robotics due to their ability to handle non-differentiable functions and escape
local minima. These advantages make them particularly useful for trajectory
optimization and policy optimization. In this work, we propose a mathematical
tutorial on random search. It offers a simple and unifying perspective for
understanding a wide range of algorithms commonly used in robotics. Leveraging
this viewpoint, we classify many trajectory optimization methods under a common
framework and derive novel competitive RL algorithms.

</details>


### [135] [Evaluating Pointing Gestures for Target Selection in Human-Robot Collaboration](https://arxiv.org/abs/2506.22116)
*Noora Sassali,Roel Pieters*

Main category: cs.RO

TL;DR: 该研究提出了一种基于姿态估计和几何模型的方法，用于在平面工作空间中定位指向手势的目标，并评估其在机器人任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 指向手势是人机协作中常用的交互方式，但需要一种准确的方法来定位目标。

Method: 采用姿态估计和基于肩-腕伸展的几何模型，从RGB-D流中提取手势数据。

Result: 开发了一个原型机器人系统，整合了目标检测、语音转录和语音合成，验证了多模态协作应用的可行性。

Conclusion: 研究提供了指向手势工具的局限性分析，并探讨了其在多模态机器人系统中的作用。

Abstract: Pointing gestures are a common interaction method used in Human-Robot
Collaboration for various tasks, ranging from selecting targets to guiding
industrial processes. This study introduces a method for localizing pointed
targets within a planar workspace. The approach employs pose estimation, and a
simple geometric model based on shoulder-wrist extension to extract gesturing
data from an RGB-D stream. The study proposes a rigorous methodology and
comprehensive analysis for evaluating pointing gestures and target selection in
typical robotic tasks. In addition to evaluating tool accuracy, the tool is
integrated into a proof-of-concept robotic system, which includes object
detection, speech transcription, and speech synthesis to demonstrate the
integration of multiple modalities in a collaborative application. Finally, a
discussion over tool limitations and performance is provided to understand its
role in multimodal robotic systems. All developments are available at:
https://github.com/NMKsas/gesture_pointer.git.

</details>


### [136] [RM-Dijkstra: A surface optimal path planning algorithm based on Riemannian metric](https://arxiv.org/abs/2506.22170)
*Yu Zhang,Xiao-Song Yang*

Main category: cs.RO

TL;DR: 提出了一种基于黎曼度量的RM-Dijkstra算法，用于解决移动机器人表面最优路径规划问题，优于传统算法。


<details>
  <summary>Details</summary>
Motivation: Dijkstra算法在离散图空间中表现优异，但其在移动机器人表面路径规划中的应用尚未充分探索。

Method: 通过构建新的黎曼度量，将表面路径规划问题转化为2D平面上的几何问题，并确保投影映射是等距浸入。

Result: 仿真测试表明，RM-Dijkstra算法在路径精度和平滑度上优于传统算法，尤其在复杂场景中。

Conclusion: RM-Dijkstra算法为表面路径规划提供了一种高效且准确的解决方案。

Abstract: The Dijkstra algorithm is a classic path planning method, which operates in a
discrete graph space to determine the shortest path from a specified source
point to a target node or all other nodes based on non-negative edge weights.
Numerous studies have focused on the Dijkstra algorithm due to its potential
application. However, its application in surface path planning for mobile
robots remains largely unexplored. In this letter, a surface optimal path
planning algorithm called RM-Dijkstra is proposed, which is based on Riemannian
metric model. By constructing a new Riemannian metric on the 2D projection
plane, the surface optimal path planning problem is therefore transformed into
a geometric problem on the 2D plane with new Riemannian metric. Induced by the
standard Euclidean metric on surface, the constructed new metric reflects
environmental information of the robot and ensures that the projection map is
an isometric immersion. By conducting a series of simulation tests, the
experimental results demonstrate that the RM-Dijkstra algorithm not only
effectively solves the optimal path planning problem on surfaces, but also
outperforms traditional path planning algorithms in terms of path accuracy and
smoothness, particularly in complex scenarios.

</details>


### [137] [ASVSim (AirSim for Surface Vehicles): A High-Fidelity Simulation Framework for Autonomous Surface Vehicle Research](https://arxiv.org/abs/2506.22174)
*Bavo Lesy,Siemen Herremans,Robin Kerstens,Jan Steckel,Walter Daems,Siegfried Mercelis,Ali Anwar*

Main category: cs.RO

TL;DR: 本文介绍了ASVSim，一个专为内河和港口环境设计的开源仿真框架，用于自主航运研究。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏开源、高保真的仿真框架和数据集，开发自主航运解决方案面临挑战。

Method: ASVSim结合了模拟船舶动力学和海洋传感器仿真能力，支持生成合成数据集。

Result: 实验展示了ASVSim在自主导航算法研究和合成数据集生成方面的潜力。

Conclusion: ASVSim作为开源项目，为海洋工程社区提供了自主导航研究的平台。

Abstract: The transport industry has recently shown significant interest in unmanned
surface vehicles (USVs), specifically for port and inland waterway transport.
These systems can improve operational efficiency and safety, which is
especially relevant in the European Union, where initiatives such as the Green
Deal are driving a shift towards increased use of inland waterways. At the same
time, a shortage of qualified personnel is accelerating the adoption of
autonomous solutions. However, there is a notable lack of open-source,
high-fidelity simulation frameworks and datasets for developing and evaluating
such solutions. To address these challenges, we introduce AirSim For Surface
Vehicles (ASVSim), an open-source simulation framework specifically designed
for autonomous shipping research in inland and port environments. The framework
combines simulated vessel dynamics with marine sensor simulation capabilities,
including radar and camera systems and supports the generation of synthetic
datasets for training computer vision models and reinforcement learning agents.
Built upon Cosys-AirSim, ASVSim provides a comprehensive platform for
developing autonomous navigation algorithms and generating synthetic datasets.
The simulator supports research of both traditional control methods and deep
learning-based approaches. Through limited experiments, we demonstrate the
potential of the simulator in these research areas. ASVSim is provided as an
open-source project under the MIT license, making autonomous navigation
research accessible to a larger part of the ocean engineering community.

</details>


### [138] [KnotDLO: Toward Interpretable Knot Tying](https://arxiv.org/abs/2506.22176)
*Holly Dinkel,Raghavendra Navaratna,Jingyi Xiang,Brian Coltin,Trey Smith,Timothy Bretl*

Main category: cs.RO

TL;DR: KnotDLO是一种无需人类演示或训练、能处理遮挡且可重复的单手可变形线性物体（DLO）打结方法。


<details>
  <summary>Details</summary>
Motivation: 解决DLO打结中的遮挡问题，提高方法的可重复性和可解释性，同时避免依赖人类演示或训练数据。

Method: 通过当前DLO形状规划抓取和目标路径点，基于分段线性曲线计算抓取位姿，并利用几何信息生成中间路径点。

Result: 在16次打结试验中，KnotDLO在从未见过的配置下实现了50%的成功率。

Conclusion: KnotDLO展示了在复杂DLO操作中的潜力，尤其在无需人类干预的情况下实现打结任务。

Abstract: This work presents KnotDLO, a method for one-handed Deformable Linear Object
(DLO) knot tying that is robust to occlusion, repeatable for varying rope
initial configurations, interpretable for generating motion policies, and
requires no human demonstrations or training. Grasp and target waypoints for
future DLO states are planned from the current DLO shape. Grasp poses are
computed from indexing the tracked piecewise linear curve representing the DLO
state based on the current curve shape and are piecewise continuous. KnotDLO
computes intermediate waypoints from the geometry of the current DLO state and
the desired next state. The system decouples visual reasoning from control. In
16 trials of knot tying, KnotDLO achieves a 50% success rate in tying an
overhand knot from previously unseen configurations.

</details>


### [139] [Robotic Multimodal Data Acquisition for In-Field Deep Learning Estimation of Cover Crop Biomass](https://arxiv.org/abs/2506.22364)
*Joe Johnson,Phanender Chalasani,Arnav Shah,Ram L. Ray,Muthukumar Bagavathiannan*

Main category: cs.RO

TL;DR: 研究提出了一种基于多模态传感器和机器学习的覆盖作物生物量估计方法，以优化杂草管理策略。


<details>
  <summary>Details</summary>
Motivation: 覆盖作物（CC）在农业系统中具有多重效益，但其生物量因微环境差异变化显著，需准确估计以优化杂草管理。

Method: 开发了一种地面机器人搭载的多模态传感器系统，结合光学和LiDAR数据，利用机器学习方法进行数据融合和生物量预测。

Result: 最佳机器学习模型对干燥生物量的预测决定系数为0.88，表现稳健。

Conclusion: 该方法为精准杂草管理和可持续农业提供了有效工具。

Abstract: Accurate weed management is essential for mitigating significant crop yield
losses, necessitating effective weed suppression strategies in agricultural
systems. Integrating cover crops (CC) offers multiple benefits, including soil
erosion reduction, weed suppression, decreased nitrogen requirements, and
enhanced carbon sequestration, all of which are closely tied to the aboveground
biomass (AGB) they produce. However, biomass production varies significantly
due to microsite variability, making accurate estimation and mapping essential
for identifying zones of poor weed suppression and optimizing targeted
management strategies. To address this challenge, developing a comprehensive CC
map, including its AGB distribution, will enable informed decision-making
regarding weed control methods and optimal application rates. Manual visual
inspection is impractical and labor-intensive, especially given the extensive
field size and the wide diversity and variation of weed species and sizes. In
this context, optical imagery and Light Detection and Ranging (LiDAR) data are
two prominent sources with unique characteristics that enhance AGB estimation.
This study introduces a ground robot-mounted multimodal sensor system designed
for agricultural field mapping. The system integrates optical and LiDAR data,
leveraging machine learning (ML) methods for data fusion to improve biomass
predictions. The best ML-based model for dry AGB estimation achieved a
coefficient of determination value of 0.88, demonstrating robust performance in
diverse field conditions. This approach offers valuable insights for
site-specific management, enabling precise weed suppression strategies and
promoting sustainable farming practices.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [140] [An Effective Two-Phase Genetic Algorithm for Solving the Resource Constrained Project Scheduling Problem (RCPSP)](https://arxiv.org/abs/2506.21915)
*D. Sun,S. Zhou*

Main category: cs.NE

TL;DR: 本文提出了一种名为2-Phase Genetic Algorithm (2PGA)的简单有效变体，用于解决RCPSP问题。2PGA通过交替执行两阶段选择策略（集中优化与多样化探索）提升算法性能，并在标准测试集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决资源受限项目调度问题（RCPSP）时，传统遗传算法容易陷入局部最优。2PGA通过两阶段选择策略平衡集中优化与多样化探索，以提升解的质量。

Method: 2PGA将遗传算法的父代选择分为两阶段：第一阶段包含当前最优解以集中优化，第二阶段排除当前最优解以促进多样化。两阶段交替迭代进行。

Result: 在PSPLIB标准测试集上，2PGA表现优异，改进了部分启发式算法的最优解。

Conclusion: 2PGA通过两阶段策略有效平衡了集中优化与多样化探索，为RCPSP问题提供了一种高效的解决方案。

Abstract: This note presents a simple and effective variation of genetic algorithm (GA)
for solving RCPSP, denoted as 2-Phase Genetic Algorithm (2PGA). The 2PGA
implements GA parent selection in two phases: Phase-1 includes the best current
solutions in the parent pool, and Phase-2 excludes the best current solutions
from the parent pool. The 2PGA carries out the GA evolution by alternating the
two phases iteratively. In exploring a solution space, the Phase-1 emphasizes
intensification in current neighborhood, while the Phase-2 emphasizes
diversification to escape local traps. The 2PGA was tested on the standard
benchmark problems in PSPLIB, the results have shown that the algorithm is
effective and has improved some of the best heuristic solutions.

</details>


### [141] [In situ fine-tuning of in silico trained Optical Neural Networks](https://arxiv.org/abs/2506.22122)
*Gianluca Kosmella,Ripalta Stabile,Jaron Sanders*

Main category: cs.NE

TL;DR: 论文提出了一种轻量级算法GIFT，用于解决光学神经网络（ONN）训练中因噪声误配导致的性能下降问题，并通过实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 光学神经网络具有超快计算、高带宽和低能耗等优势，但训练过程中因噪声和硬件不完美导致模拟与实际性能存在差距，需要一种高效解决方案。

Method: 引入Gradient-Informed Fine-Tuning (GIFT)算法，利用噪声结构的梯度信息对预训练参数进行现场微调，无需复杂实验或昂贵重训练。

Result: 在MNIST数字分类任务中，GIFT将相对准确率提升高达28%，显著优于基线性能。

Conclusion: GIFT为简化数字模型与实际ONN实现之间的差距提供了实用解决方案。

Abstract: Optical Neural Networks (ONNs) promise significant advantages over
traditional electronic neural networks, including ultrafast computation, high
bandwidth, and low energy consumption, by leveraging the intrinsic capabilities
of photonics. However, training ONNs poses unique challenges, notably the
reliance on simplified in silico models whose trained parameters must
subsequently be mapped to physical hardware. This process often introduces
inaccuracies due to discrepancies between the idealized digital model and the
physical ONN implementation, particularly stemming from noise and fabrication
imperfections.
  In this paper, we analyze how noise misspecification during in silico
training impacts ONN performance and we introduce Gradient-Informed Fine-Tuning
(GIFT), a lightweight algorithm designed to mitigate this performance
degradation. GIFT uses gradient information derived from the noise structure of
the ONN to adapt pretrained parameters directly in situ, without requiring
expensive retraining or complex experimental setups. GIFT comes with formal
conditions under which it improves ONN performance.
  We also demonstrate the effectiveness of GIFT via simulation on a five-layer
feed forward ONN trained on the MNIST digit classification task. GIFT achieves
up to $28\%$ relative accuracy improvement compared to the baseline performance
under noise misspecification, without resorting to costly retraining. Overall,
GIFT provides a practical solution for bridging the gap between simplified
digital models and real-world ONN implementations.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [142] [APO: Enhancing Reasoning Ability of MLLMs via Asymmetric Policy Optimization](https://arxiv.org/abs/2506.21655)
*Minjie Hong,Zirun Guo,Yan Xia,Zehan Wang,Ziang Zhang,Tao Jin,Zhou Zhao*

Main category: cs.LG

TL;DR: 论文提出了一种名为Asymmetric Policy Optimization (APO)的方法，通过Difficulty-Adaptive Divergence Shaping (DADS)和Suboptimal Trajectory Complexity Regularization (STCR)技术，解决了MLLMs在强化学习中性能下降和过度推理的问题，显著提升了推理能力。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在复杂推理任务中表现不佳，而强化学习（RL）虽然能提升推理能力，但在MLLMs中应用时存在性能下降和过度推理的问题。

Method: 提出APO方法，将样本分为正负两组：对正样本使用DADS动态调整KL散度权重；对负样本使用STCR惩罚过长响应。

Result: 在Qwen2.5-VL-3B上应用该方法得到的View-R1-3B模型，推理能力平均提升7%，并在多个基准测试中优于更大的MLLMs。

Conclusion: DADS和STCR技术有效提升了MLLMs的复杂推理能力，同时保持了模型的泛化性能。

Abstract: Multimodal Large Language Models (MLLMs) are powerful at integrating diverse
data, but they often struggle with complex reasoning. While Reinforcement
learning (RL) can boost reasoning in LLMs, applying it to MLLMs is tricky.
Common issues include a drop in performance on general tasks and the generation
of overly detailed or "overthinking" reasoning. Our work investigates how the
KL penalty and overthinking affect RL training in MLLMs. We propose Asymmetric
Policy Optimization (APO) to address these issues, which divides the sampled
responses into positive and negative groups. For positive samples,
Difficulty-Adaptive Divergence Shaping (DADS) is introduced to dynamically
adjust the KL divergence weight based on their difficulty. This method prevents
policy entropy from dropping sharply, improves training stability, utilizes
samples better, and preserves the model's existing knowledge. For negative
samples, Suboptimal Trajectory Complexity Regularization (STCR) is proposed to
penalize overly long responses. This helps mitigate overthinking and encourages
more concise reasoning while preserving the model's explorative capacity. We
apply our method to Qwen2.5-VL-3B, creating View-R1-3B. View-R1-3B
significantly enhances reasoning capabilities, showing an average 7\% gain over
the base model and outperforming larger MLLMs (7-11B) on various reasoning
benchmarks. Importantly, unlike other reasoning-tuned MLLMs that often degrade
on general tasks, View-R1-3B maintains consistent improvement, demonstrating
superior generalization. These results highlight the effectiveness and broad
applicability of our DADS and STCR techniques for advancing complex multimodal
reasoning in MLLMs. The code will be made available at
https://github.com/Indolent-Kawhi/View-R1.

</details>


### [143] [SceneDiffuser++: City-Scale Traffic Simulation via a Generative World Model](https://arxiv.org/abs/2506.21976)
*Shuhan Tan,John Lambert,Hong Jeon,Sakshum Kulshrestha,Yijing Bai,Jing Luo,Dragomir Anguelov,Mingxing Tan,Chiyu Max Jiang*

Main category: cs.LG

TL;DR: CitySim提出了一种生成式城市交通模拟框架SceneDiffuser++，通过端到端生成模型实现从A点到B点的城市规模模拟。


<details>
  <summary>Details</summary>
Motivation: 弥补手动驾驶测试里程的不足，通过模拟生成更多测试场景，提升自动驾驶验证效率。

Method: 提出SceneDiffuser++，一种基于单一损失函数的端到端生成模型，整合场景生成、动态代理行为建模等技术。

Result: 在扩展版Waymo数据集上验证了其城市规模模拟能力，并展示了长期模拟的优越真实性。

Conclusion: SceneDiffuser++为城市交通模拟提供了高效、真实的解决方案，填补了动态场景生成等技术的空白。

Abstract: The goal of traffic simulation is to augment a potentially limited amount of
manually-driven miles that is available for testing and validation, with a much
larger amount of simulated synthetic miles. The culmination of this vision
would be a generative simulated city, where given a map of the city and an
autonomous vehicle (AV) software stack, the simulator can seamlessly simulate
the trip from point A to point B by populating the city around the AV and
controlling all aspects of the scene, from animating the dynamic agents (e.g.,
vehicles, pedestrians) to controlling the traffic light states. We refer to
this vision as CitySim, which requires an agglomeration of simulation
technologies: scene generation to populate the initial scene, agent behavior
modeling to animate the scene, occlusion reasoning, dynamic scene generation to
seamlessly spawn and remove agents, and environment simulation for factors such
as traffic lights. While some key technologies have been separately studied in
various works, others such as dynamic scene generation and environment
simulation have received less attention in the research community. We propose
SceneDiffuser++, the first end-to-end generative world model trained on a
single loss function capable of point A-to-B simulation on a city scale
integrating all the requirements above. We demonstrate the city-scale traffic
simulation capability of SceneDiffuser++ and study its superior realism under
long simulation conditions. We evaluate the simulation quality on an augmented
version of the Waymo Open Motion Dataset (WOMD) with larger map regions to
support trip-level simulation.

</details>


### [144] [Risk-Averse Total-Reward Reinforcement Learning](https://arxiv.org/abs/2506.21683)
*Xihong Su,Jia Lin Hau,Gersi Doko,Kishan Panaganti,Marek Petrik*

Main category: cs.LG

TL;DR: 提出一种Q-learning算法，用于求解总奖励风险厌恶MDP问题，具有强收敛性和性能保证。


<details>
  <summary>Details</summary>
Motivation: 现有基于模型的算法在小规模问题上有效，但需要完全访问转移概率，限制了其应用范围。

Method: 利用ERM的动态一致性和可引出性，设计Q-learning算法求解总奖励ERM和EVaR目标。

Result: 数值实验表明，算法在表格领域快速可靠地收敛到最优风险厌恶值函数。

Conclusion: 该算法为风险厌恶MDP提供了一种高效的无模型解决方案。

Abstract: Risk-averse total-reward Markov Decision Processes (MDPs) offer a promising
framework for modeling and solving undiscounted infinite-horizon objectives.
Existing model-based algorithms for risk measures like the entropic risk
measure (ERM) and entropic value-at-risk (EVaR) are effective in small
problems, but require full access to transition probabilities. We propose a
Q-learning algorithm to compute the optimal stationary policy for total-reward
ERM and EVaR objectives with strong convergence and performance guarantees. The
algorithm and its optimality are made possible by ERM's dynamic consistency and
elicitability. Our numerical results on tabular domains demonstrate quick and
reliable convergence of the proposed Q-learning algorithm to the optimal
risk-averse value function.

</details>


### [145] [Exploring Modularity of Agentic Systems for Drug Discovery](https://arxiv.org/abs/2506.22189)
*Laura van Weesep,Samuel Genheden,Ola Engkvist,Jens Sjölund*

Main category: cs.LG

TL;DR: 研究探讨了基于LLM的代理系统在药物发现中的模块化问题，比较了不同LLM和代理类型的性能，发现Claude-3.5-Sonnet等模型表现更优，且代码生成代理通常优于工具调用代理，但结果因问题和模型而异。


<details>
  <summary>Details</summary>
Motivation: 探索LLM和代理系统在药物发现中的模块化潜力，填补该领域的研究空白。

Method: 比较不同LLM和代理类型（工具调用与代码生成）的性能，使用LLM-as-a-judge评分进行案例研究。

Result: Claude-3.5-Sonnet等模型表现更优，代码生成代理通常更有效，但结果高度依赖问题和模型。系统提示的替换效果也因问题和模型而异。

Conclusion: 强调了进一步研究代理系统模块化的必要性，以开发稳定且可扩展的解决方案。

Abstract: Large-language models (LLMs) and agentic systems present exciting
opportunities to accelerate drug discovery and design. In this study, we
critically examine the modularity of LLM-based agentic systems for drug
discovery, i.e., whether parts of the agentic system such as the LLM are
interchangeable, a topic that has received limited attention in drug discovery
applications. We compare the performance of different large language models
(LLMs) and the effectiveness of tool-calling agents versus code-generating
agents in this domain. Our case study, comparing performance in orchestrating
tools for chemistry and drug discovery using an LLM-as-a-judge score, shows
that Claude-3.5-Sonnet, Claude-3.7-Sonnet and GPT-4o outperform alternative
language models such as Llama-3.1-8B, Llama-3.1-70B, GPT-3.5-Turbo, and
Nova-Micro. Although we confirm that code-generating agents outperform the
tool-calling ones on average, we show that this is highly question and model
dependent. Furthermore, the impact of replacing system prompts is dependent on
the specific question asked and the model used, underscoring that -- even in
this particular domain -- one cannot just replace language models without
considering prompt re-engineering. Our study highlights the necessity of
further research into the modularity of agentic systems to enable the
development of stable and scalable solutions for real-world problems.

</details>


### [146] [Unimodal Strategies in Density-Based Clustering](https://arxiv.org/abs/2506.21695)
*Oron Nir,Jay Tenenbaum,Ariel Shamir*

Main category: cs.LG

TL;DR: 本文揭示了密度聚类方法中核心点邻域半径与簇数目的单峰关系，并基于此提出了一种高效的参数调优策略。


<details>
  <summary>Details</summary>
Motivation: 密度聚类方法在处理噪声或复杂分布数据时优于基于质心的方法，但参数调优计算成本高。

Method: 利用Ternary Search算法，基于核心点邻域半径与簇数目的单峰关系，高效确定半径参数。

Result: 在多个高维大规模任务（NLP、音频、计算机视觉）中验证了方法的有效性和鲁棒性。

Conclusion: 本研究不仅改进了密度聚类的参数控制，还深化了对参数间关系的理解。

Abstract: Density-based clustering methods often surpass centroid-based counterparts,
when addressing data with noise or arbitrary data distributions common in
real-world problems. In this study, we reveal a key property intrinsic to
density-based clustering methods regarding the relation between the number of
clusters and the neighborhood radius of core points - we empirically show that
it is nearly unimodal, and support this claim theoretically in a specific
setting. We leverage this property to devise new strategies for finding
appropriate values for the radius more efficiently based on the Ternary Search
algorithm. This is especially important for large scale data that is
high-dimensional, where parameter tuning is computationally intensive. We
validate our methodology through extensive applications across a range of
high-dimensional, large-scale NLP, Audio, and Computer Vision tasks,
demonstrating its practical effectiveness and robustness. This work not only
offers a significant advancement in parameter control for density-based
clustering but also broadens the understanding regarding the relations between
their guiding parameters. Our code is available at
https://github.com/oronnir/UnimodalStrategies.

</details>


### [147] [$\textrm{ODE}_t \left(\textrm{ODE}_l \right)$: Shortcutting the Time and Length in Diffusion and Flow Models for Faster Sampling](https://arxiv.org/abs/2506.21714)
*Denis Gudovskiy,Wenzhao Zheng,Tomoyuki Okuno,Yohei Nakata,Kurt Keutzer*

Main category: cs.LG

TL;DR: 论文提出了一种动态控制质量-复杂度权衡的方法，通过重连Transformer架构中的块来解决ODE问题，并在采样时实现任意时间步和块数的灵活性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注减少采样时间步以提高效率，但忽略了在神经网络长度上的动态调整。本文探索了在时间步和网络长度上动态控制质量-复杂度权衡的互补方向。

Method: 通过重连Transformer架构中的块来解决内部离散化的ODE问题，并在流匹配训练中引入时间和长度一致性项，从而实现采样时时间步和块数的灵活性。

Result: 在CelebA-HQ和ImageNet上的实验表明，最高效采样模式下延迟降低3倍，高质量采样模式下FID得分提升3.5分。

Conclusion: 提出的方法在时间维度上不依赖特定求解器，同时降低了延迟和内存使用，显著提升了采样效率和质量。

Abstract: Recently, continuous normalizing flows (CNFs) and diffusion models (DMs) have
been studied using the unified theoretical framework. Although such models can
generate high-quality data points from a noise distribution, the sampling
demands multiple iterations to solve an ordinary differential equation (ODE)
with high computational complexity. Most existing methods focus on reducing the
number of time steps during the sampling process to improve efficiency. In this
work, we explore a complementary direction in which the quality-complexity
tradeoff can be dynamically controlled in terms of time steps and in the length
of the neural network. We achieve this by rewiring the blocks in the
transformer-based architecture to solve an inner discretized ODE w.r.t. its
length. Then, we employ time- and length-wise consistency terms during flow
matching training, and as a result, the sampling can be performed with an
arbitrary number of time steps and transformer blocks. Unlike others, our
$\textrm{ODE}_t \left(\textrm{ODE}_l \right)$ approach is solver-agnostic in
time dimension and decreases both latency and memory usage. Compared to the
previous state of the art, image generation experiments on CelebA-HQ and
ImageNet show a latency reduction of up to $3\times$ in the most efficient
sampling mode, and a FID score improvement of up to $3.5$ points for
high-quality sampling. We release our code and model weights with fully
reproducible experiments.

</details>


### [148] [Performance Prediction for Large Systems via Text-to-Text Regression](https://arxiv.org/abs/2506.21718)
*Yash Akhauri,Bryan Lewandowski,Cheng-Hsi Lin,Adrian N. Reyes,Grant C. Forbes,Arissa Wongpanich,Bangding Yang,Mohamed S. Abdelfattah,Sagi Perel,Xingyou Song*

Main category: cs.LG

TL;DR: 论文提出了一种基于文本到文本回归的通用方法，用于预测复杂系统数据中的指标结果，相比传统表格回归方法表现更优。


<details>
  <summary>Details</summary>
Motivation: 传统表格回归方法在处理复杂系统数据（如配置文件或系统日志）时效果不佳，需要一种更通用且可扩展的替代方案。

Method: 采用60M参数的编码器-解码器模型，从随机初始化开始训练，用于预测资源效率。

Result: 模型在Google的Borg调度系统上实现了接近完美的0.99等级相关性（平均0.9），MSE比表格方法低100倍，并能轻松适应新任务。

Conclusion: 文本到文本回归方法为复杂系统数据的预测提供了通用解决方案，并为现实世界结果的通用模拟器奠定了基础。

Abstract: In many industries, predicting metric outcomes of large systems is a
fundamental problem, driven largely by traditional tabular regression. However,
such methods struggle on complex systems data in the wild such as configuration
files or system logs, where feature engineering is often infeasible. We propose
text-to-text regression as a general, scalable alternative. For predicting
resource efficiency on Borg, Google's massive compute cluster scheduling
system, a 60M parameter encoder-decoder, trained from random initialization,
achieves up to a near perfect 0.99 (0.9 average) rank correlation across the
entire fleet, and 100x lower MSE than tabular approaches. The model also easily
adapts to new tasks in only 500 few-shot examples and captures the densities of
complex outcome distributions. Ablation studies highlight the importance of
using encoders, increasing sequence length, and the model's inherent
uncertainty quantification. These findings pave the way for universal
simulators of real-world outcomes.

</details>


### [149] [Federated Item Response Theory Models](https://arxiv.org/abs/2506.21744)
*Biying Zhou,Nanyu Luo,Feng Ji*

Main category: cs.LG

TL;DR: 提出了一种结合联邦学习的隐私保护分布式IRT估计框架FedIRT，验证了其与传统IRT相当的统计准确性，并提供了开源R包支持。


<details>
  <summary>Details</summary>
Motivation: 传统IRT估计需要集中所有个体原始数据，存在隐私问题，联邦学习提供了隐私保护和分布式计算的可能。

Method: 提出FedIRT框架，结合联邦学习实现分布式IRT估计，支持2PL和PCM模型。

Result: 数值实验表明FedIRT统计准确性与传统IRT相当，同时保护隐私并降低通信成本；真实考试数据集验证了其实用性。

Conclusion: FedIRT扩展了IRT在分布式场景（如多校评估）的应用，不牺牲准确性或安全性，并提供开源工具支持。

Abstract: Item Response Theory (IRT) models have been widely used to estimate
respondents' latent abilities and calibrate items' difficulty. Traditional IRT
estimation requires all individual raw response data to be centralized in one
place, thus potentially causing privacy issues. Federated learning is an
emerging field in computer science and machine learning with added features of
privacy protection and distributed computing. To integrate the advances from
federated learning with modern psychometrics, we propose a novel framework,
Federated Item Response Theory (IRT), to enable estimating traditional IRT
models with additional privacy, allowing estimation in a distributed manner
without losing estimation accuracy.
  Our numerical experiments confirm that FedIRT achieves statistical accuracy
similar to standard IRT estimation using popular R packages, while offering
critical advantages: privacy protection and reduced communication costs. We
also validate FedIRT's utility through a real-world exam dataset, demonstrating
its effectiveness in realistic educational contexts. This new framework extends
IRT's applicability to distributed settings, such as multi-school assessments,
without sacrificing accuracy or security. To support practical adoption, we
provide an open-ource R package, FedIRT, implementing the framework for the
two-parameter logistic (2PL) and partial credit models (PCM).

</details>


### [150] [Gradient-Based Neuroplastic Adaptation for Concurrent Optimization of Neuro-Fuzzy Networks](https://arxiv.org/abs/2506.21771)
*John Wesley Hostetter,Min Chi*

Main category: cs.LG

TL;DR: 提出了一种基于梯度的神经可塑性适应方法，用于同时优化神经模糊网络的参数和结构，解决了现有方法中参数与结构分离优化的问题，并在视觉任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 神经模糊网络（NFNs）具有透明性和符号化表达的优势，但其系统化设计过程仍具挑战性。现有方法通常将参数和结构优化分离，导致架构脆弱且性能不佳。

Method: 提出了一种独立于应用的梯度基神经可塑性适应方法，同时优化NFNs的参数和结构。

Result: 该方法使得NFNs能够应用于之前难以处理的场景，如基于视觉的在线强化学习任务，并在DOOM游戏中表现出色。

Conclusion: 同时优化参数和结构的方法显著提升了NFNs的性能，拓展了其应用范围。

Abstract: Neuro-fuzzy networks (NFNs) are transparent, symbolic, and universal function
approximations that perform as well as conventional neural architectures, but
their knowledge is expressed as linguistic IF-THEN rules. Despite these
advantages, their systematic design process remains a challenge. Existing work
will often sequentially build NFNs by inefficiently isolating parametric and
structural identification, leading to a premature commitment to brittle and
subpar architecture. We propose a novel application-independent approach called
gradient-based neuroplastic adaptation for the concurrent optimization of NFNs'
parameters and structure. By recognizing that NFNs' parameters and structure
should be optimized simultaneously as they are deeply conjoined, settings
previously unapproachable for NFNs are now accessible, such as the online
reinforcement learning of NFNs for vision-based tasks. The effectiveness of
concurrently optimizing NFNs is empirically shown as it is trained by online
reinforcement learning to proficiently play challenging scenarios from a
vision-based video game called DOOM.

</details>


### [151] [M3PO: Massively Multi-Task Model-Based Policy Optimization](https://arxiv.org/abs/2506.21782)
*Aditya Narendra,Dmitry Makarov,Aleksandr Panov*

Main category: cs.LG

TL;DR: M3PO是一种基于模型的强化学习框架，旨在解决单任务样本效率低和多任务泛化差的问题，通过结合隐式世界模型和混合探索策略，实现了高效且鲁棒的策略优化。


<details>
  <summary>Details</summary>
Motivation: 现有基于模型的方法（如DreamerV3）忽略了控制中心表示，而基于无模型的方法（如PPO）样本复杂度高且探索能力弱。M3PO旨在解决这些问题。

Method: M3PO整合了隐式世界模型（预测任务结果而非观测重建）和混合探索策略（结合基于模型的规划和基于无模型的不确定性奖励），并通过信任区域优化器稳定策略更新。

Result: M3PO在多个基准测试中实现了最先进的性能。

Conclusion: M3PO为现有基于模型的策略优化方法提供了高效且鲁棒的替代方案。

Abstract: We introduce Massively Multi-Task Model-Based Policy Optimization (M3PO), a
scalable model-based reinforcement learning (MBRL) framework designed to
address sample inefficiency in single-task settings and poor generalization in
multi-task domains. Existing model-based approaches like DreamerV3 rely on
pixel-level generative models that neglect control-centric representations,
while model-free methods such as PPO suffer from high sample complexity and
weak exploration. M3PO integrates an implicit world model, trained to predict
task outcomes without observation reconstruction, with a hybrid exploration
strategy that combines model-based planning and model-free uncertainty-driven
bonuses. This eliminates the bias-variance trade-off in prior methods by using
discrepancies between model-based and model-free value estimates to guide
exploration, while maintaining stable policy updates through a trust-region
optimizer. M3PO provides an efficient and robust alternative to existing
model-based policy optimization approaches and achieves state-of-the-art
performance across multiple benchmarks.

</details>


### [152] [Multi-task parallelism for robust pre-training of graph foundation models on multi-source, multi-fidelity atomistic modeling data](https://arxiv.org/abs/2506.21788)
*Massimiliano Lupo Pasini,Jong Youl Choi,Pei Zhang,Kshitij Mehta,Rylie Weaver,Ashwin M. Aji,Karl W. Schulz,Jorda Polo,Prasanna Balaprakash*

Main category: cs.LG

TL;DR: 论文提出了一种基于图神经网络的多任务并行方法，用于高效处理多源、多保真度的原子结构数据，并在超级计算机上验证了其扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决多源、多保真度原子结构数据预训练中的挑战，提升模型的通用性和可扩展性。

Method: 采用多任务学习方法，共享消息传递层处理输入，然后通过多个解码头预测特定数据输出，并利用GPU加速实现多任务并行。

Result: 在2400万个结构上训练，并在三种异构超级计算机上验证了高效扩展性。

Conclusion: 提出的方法在多源数据预训练中表现稳定，且具备良好的超级计算机扩展性。

Abstract: Graph foundation models using graph neural networks promise sustainable,
efficient atomistic modeling. To tackle challenges of processing multi-source,
multi-fidelity data during pre-training, recent studies employ multi-task
learning, in which shared message passing layers initially process input
atomistic structures regardless of source, then route them to multiple decoding
heads that predict data-specific outputs. This approach stabilizes pre-training
and enhances a model's transferability to unexplored chemical regions.
Preliminary results on approximately four million structures are encouraging,
yet questions remain about generalizability to larger, more diverse datasets
and scalability on supercomputers. We propose a multi-task parallelism method
that distributes each head across computing resources with GPU acceleration.
Implemented in the open-source HydraGNN architecture, our method was trained on
over 24 million structures from five datasets and tested on the Perlmutter,
Aurora, and Frontier supercomputers, demonstrating efficient scaling on all
three highly heterogeneous super-computing architectures.

</details>


### [153] [Why Neural Network Can Discover Symbolic Structures with Gradient-based Training: An Algebraic and Geometric Foundation for Neurosymbolic Reasoning](https://arxiv.org/abs/2506.21797)
*Peihao Wang,Zhangyang Wang*

Main category: cs.LG

TL;DR: 论文提出了一种理论框架，解释离散符号结构如何从连续神经网络训练动态中自然涌现。通过将神经参数提升到测度空间并建模训练为Wasserstein梯度流，研究发现几何约束下参数测度经历两种现象：梯度流解耦和自由度收缩。


<details>
  <summary>Details</summary>
Motivation: 探索连续神经网络训练如何自然形成离散符号结构，为理解神经符号系统提供理论基础。

Method: 将神经参数提升到测度空间，建模训练为Wasserstein梯度流，分析几何约束下的参数测度变化。

Result: 发现梯度流解耦和自由度收缩现象，网络从高维探索过渡到符合代数运算的低维表示。

Conclusion: 框架为神经符号系统的设计和理解提供了理论基础，连接了连续学习与离散代数推理。

Abstract: We develop a theoretical framework that explains how discrete symbolic
structures can emerge naturally from continuous neural network training
dynamics. By lifting neural parameters to a measure space and modeling training
as Wasserstein gradient flow, we show that under geometric constraints, such as
group invariance, the parameter measure $\mu_t$ undergoes two concurrent
phenomena: (1) a decoupling of the gradient flow into independent optimization
trajectories over some potential functions, and (2) a progressive contraction
on the degree of freedom. These potentials encode algebraic constraints
relevant to the task and act as ring homomorphisms under a commutative
semi-ring structure on the measure space. As training progresses, the network
transitions from a high-dimensional exploration to compositional
representations that comply with algebraic operations and exhibit a lower
degree of freedom. We further establish data scaling laws for realizing
symbolic tasks, linking representational capacity to the group invariance that
facilitates symbolic solutions. This framework charts a principled foundation
for understanding and designing neurosymbolic systems that integrate continuous
learning with discrete algebraic reasoning.

</details>


### [154] [The Cost of Avoiding Backpropagation](https://arxiv.org/abs/2506.21833)
*Kunjal Panchal,Sunav Choudhary,Yuriy Brun,Hui Guan*

Main category: cs.LG

TL;DR: 该论文比较了前向模式自动微分（FmAD）和零阶（ZO）优化与反向传播（BP）在内存效率上的表现，发现BP结合检查点技术优于FmAD和ZO。


<details>
  <summary>Details</summary>
Motivation: 探讨FmAD和ZO作为BP的替代方案在低资源环境中的实际效果，填补与内存高效BP变体的比较和统一理论分析的空白。

Method: 通过理论和实验对比BP、FmAD和ZO方法，分析内存使用、准确性、收敛速度和计算成本。

Result: BP结合检查点技术表现最佳，比FmAD和ZO高出31.1%的准确性、34.8%的收敛速度和3.8倍的计算效率。

Conclusion: FmAD和ZO在内存效率上虽有优势，但在其他关键指标上表现不佳，BP结合检查点技术仍是内存受限场景下的最佳选择。

Abstract: Forward-mode automatic differentiation (FmAD) and zero-order (ZO)
optimization have been proposed as memory-efficient alternatives to
backpropagation (BP) for gradient computation, especially in low-resource
settings. However, their practical benefits remain unclear due to two key gaps:
a lack of comparison against memory-efficient BP variants, such as activation
checkpointing, and a lack of a unified theoretical analysis. This work presents
a comprehensive theoretical and empirical comparison of BP, FmAD, and ZO
methods. Our theoretical analysis shows that while FmAD, and ZO can reduce
memory usage, they incur significant costs in accuracy, convergence speed, and
computation compared to BP with checkpointing. These drawbacks worsen with
larger models or constrained perturbation budgets. Empirical experiments on
large language and vision-language models show that BP with checkpointing
outperforms FmAD and ZO variants, including those enhanced with variance
reduction, achieving up to 31.1% higher accuracy, 34.8% faster convergence, and
3.8x fewer computations at comparable memory usage. Our results highlight
fundamental limitations of FmAD and ZO, and reaffirm BP with checkpointing as
the most effective strategy for model training under memory-constrained
settings. Our code is available at
https://github.com/Astuary/The_Cost_of_Avoiding_Backpropagation.

</details>


### [155] [Koopman operator-based discussion on partial observation in stochastic systems](https://arxiv.org/abs/2506.21844)
*Jun Ohkubo*

Main category: cs.LG

TL;DR: 论文探讨了在随机系统中部分观测的影响，利用Koopman算子理论，强调了状态空间与函数空间的区分重要性，并通过数值实验展示了加性噪声幅度的精度幂律行为。


<details>
  <summary>Details</summary>
Motivation: 在确定性系统中，Mori-Zwanzig形式为部分观测提供了理论框架，但随机系统中的部分观测问题尚未充分研究。本文旨在填补这一空白。

Method: 采用Koopman算子理论，结合延迟嵌入技术，分析随机系统中的部分观测效应，并通过数值实验验证。

Result: 数值实验表明，加性噪声幅度的精度呈现幂律行为，并探讨了幂律指数与部分观测效应的关系。

Conclusion: 在随机系统中，状态空间与函数空间的区分至关重要，延迟嵌入技术对部分观测有益，且噪声幅度的精度遵循幂律行为。

Abstract: It is sometimes difficult to achieve a complete observation for a full set of
observables, and partial observations are necessary. For deterministic systems,
the Mori-Zwanzig formalism provides a theoretical framework for handling
partial observations. Recently, data-driven algorithms based on the Koopman
operator theory have made significant progress, and there is a discussion to
connect the Mori-Zwanzig formalism with the Koopman operator theory. In this
work, we discuss the effects of partial observation in stochastic systems using
the Koopman operator theory. The discussion clarifies the importance of
distinguishing the state space and the function space in stochastic systems.
Even in stochastic systems, the delay embedding technique is beneficial for
partial observation, and several numerical experiments showed a power-law
behavior of the accuracy for the amplitude of the additive noise. We also
discuss the relation between the exponent of the power-law behavior and the
effects of partial observation.

</details>


### [156] [A Survey of Continual Reinforcement Learning](https://arxiv.org/abs/2506.21872)
*Chaofan Pan,Xin Yang,Yanhua Li,Wei Wei,Tianrui Li,Bo An,Jiye Liang*

Main category: cs.LG

TL;DR: 该论文综述了持续强化学习（CRL）的核心概念、挑战和方法，提出了新的分类法，并探讨了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习（RL）在数据需求、计算资源和泛化能力方面的局限性，通过持续学习（CL）提升RL的适应性和知识保留能力。

Method: 详细回顾现有工作，提出基于知识存储和转移的四类CRL方法分类法。

Result: 分析了CRL的独特挑战，并为未来研究提供了实用见解。

Conclusion: CRL是一个有前景的研究方向，能够提升RL在动态和真实环境中的适用性。

Abstract: Reinforcement Learning (RL) is an important machine learning paradigm for
solving sequential decision-making problems. Recent years have witnessed
remarkable progress in this field due to the rapid development of deep neural
networks. However, the success of RL currently relies on extensive training
data and computational resources. In addition, RL's limited ability to
generalize across tasks restricts its applicability in dynamic and real-world
environments. With the arisen of Continual Learning (CL), Continual
Reinforcement Learning (CRL) has emerged as a promising research direction to
address these limitations by enabling agents to learn continuously, adapt to
new tasks, and retain previously acquired knowledge. In this survey, we provide
a comprehensive examination of CRL, focusing on its core concepts, challenges,
and methodologies. Firstly, we conduct a detailed review of existing works,
organizing and analyzing their metrics, tasks, benchmarks, and scenario
settings. Secondly, we propose a new taxonomy of CRL methods, categorizing them
into four types from the perspective of knowledge storage and/or transfer.
Finally, our analysis highlights the unique challenges of CRL and provides
practical insights into future directions.

</details>


### [157] [Advancements and Challenges in Continual Reinforcement Learning: A Comprehensive Review](https://arxiv.org/abs/2506.21899)
*Amara Zuffer,Michael Burke,Mehrtash Harandi*

Main category: cs.LG

TL;DR: 该论文综述了持续强化学习（CRL）的关键概念、挑战和方法，特别关注机器人领域的进展，并总结了评估环境和未来方向。


<details>
  <summary>Details</summary>
Motivation: 研究持续强化学习的动机是解决RL任务多样性和动态性带来的挑战，使智能体能够持续学习和保留知识。

Method: 论文通过综述方式探讨了CRL的基本概念、挑战和新兴方法，并重点分析了机器人领域的应用。

Result: 综述总结了CRL的最新进展、评估环境，并指出了当前研究的局限性。

Conclusion: 论文为研究人员提供了CRL领域的全面视角，并提出了未来研究方向。

Abstract: The diversity of tasks and dynamic nature of reinforcement learning (RL)
require RL agents to be able to learn sequentially and continuously, a learning
paradigm known as continuous reinforcement learning. This survey reviews how
continual learning transforms RL agents into dynamic continual learners. This
enables RL agents to acquire and retain useful and reusable knowledge
seamlessly. The paper delves into fundamental aspects of continual
reinforcement learning, exploring key concepts, significant challenges, and
novel methodologies. Special emphasis is placed on recent advancements in
continual reinforcement learning within robotics, along with a succinct
overview of evaluation environments utilized in prominent research,
facilitating accessibility for newcomers to the field. The review concludes
with a discussion on limitations and promising future directions, providing
valuable insights for researchers and practitioners alike.

</details>


### [158] [TOAST: Task-Oriented Adaptive Semantic Transmission over Dynamic Wireless Environments](https://arxiv.org/abs/2506.21900)
*Sheng Yun,Jianhua Pei,Ping Wang*

Main category: cs.LG

TL;DR: TOAST是一个面向6G网络的语义感知通信框架，通过动态任务平衡、参数高效调整和噪声恢复机制，显著提升了分类准确性和重建质量。


<details>
  <summary>Details</summary>
Motivation: 6G网络需要从比特传输转向语义感知通信，TOAST旨在解决动态无线环境中多任务优化的核心挑战。

Method: TOAST结合了深度强化学习的任务平衡、基于Swin Transformer的低秩适应机制和潜在空间扩散模型，以应对不同信道损伤。

Result: 实验表明，TOAST在低信噪比条件下显著优于基线方法，分类准确性和重建质量均有显著提升。

Conclusion: TOAST为6G语义通信提供了一个高效、鲁棒的解决方案，适用于多种信道条件。

Abstract: The evolution toward 6G networks demands a fundamental shift from bit-centric
transmission to semantic-aware communication that emphasizes task-relevant
information. This work introduces TOAST (Task-Oriented Adaptive Semantic
Transmission), a unified framework designed to address the core challenge of
multi-task optimization in dynamic wireless environments through three
complementary components. First, we formulate adaptive task balancing as a
Markov decision process, employing deep reinforcement learning to dynamically
adjust the trade-off between image reconstruction fidelity and semantic
classification accuracy based on real-time channel conditions. Second, we
integrate module-specific Low-Rank Adaptation (LoRA) mechanisms throughout our
Swin Transformer-based joint source-channel coding architecture, enabling
parameter-efficient fine-tuning that dramatically reduces adaptation overhead
while maintaining full performance across diverse channel impairments including
Additive White Gaussian Noise (AWGN), fading, phase noise, and impulse
interference. Third, we incorporate an Elucidating diffusion model that
operates in the latent space to restore features corrupted by channel noises,
providing substantial quality improvements compared to baseline approaches.
Extensive experiments across multiple datasets demonstrate that TOAST achieves
superior performance compared to baseline approaches, with significant
improvements in both classification accuracy and reconstruction quality at low
Signal-to-Noise Ratio (SNR) conditions while maintaining robust performance
across all tested scenarios.

</details>


### [159] [HQCM-EBTC: A Hybrid Quantum-Classical Model for Explainable Brain Tumor Classification](https://arxiv.org/abs/2506.21937)
*Marwan Ait Haddou,Mohamed Bennai*

Main category: cs.LG

TL;DR: HQCM-EBTC是一种混合量子-经典模型，用于MRI图像的自动脑肿瘤分类，在7,576张扫描图像上训练，准确率达96.48%，显著优于经典基线模型。


<details>
  <summary>Details</summary>
Motivation: 提高脑肿瘤分类的准确性和可解释性，探索量子增强模型在医学影像中的潜力。

Method: 结合5量子比特、深度2的量子层与5个并行电路，使用AdamW优化器和混合损失函数（交叉熵和注意力一致性）。

Result: 准确率96.48%，优于经典模型（86.72%），尤其在胶质瘤检测中表现突出，特征可分性和肿瘤定位更优。

Conclusion: 量子增强模型在医学影像中具有潜力，可提升诊断准确性和临床解释性。

Abstract: We propose HQCM-EBTC, a hybrid quantum-classical model for automated brain
tumor classification using MRI images. Trained on a dataset of 7,576 scans
covering normal, meningioma, glioma, and pituitary classes, HQCM-EBTC
integrates a 5-qubit, depth-2 quantum layer with 5 parallel circuits, optimized
via AdamW and a composite loss blending cross-entropy and attention
consistency.
  HQCM-EBTC achieves 96.48% accuracy, substantially outperforming the classical
baseline (86.72%). It delivers higher precision and F1-scores, especially for
glioma detection. t-SNE projections reveal enhanced feature separability in
quantum space, and confusion matrices show lower misclassification. Attention
map analysis (Jaccard Index) confirms more accurate and focused tumor
localization at high-confidence thresholds.
  These results highlight the promise of quantum-enhanced models in medical
imaging, advancing both diagnostic accuracy and interpretability for clinical
brain tumor assessment.

</details>


### [160] [GuiderNet: A Meta-Learning Framework for Optimizing Quantum Circuit Geometry and Mitigating Barren Plateaus](https://arxiv.org/abs/2506.21940)
*Marwan Ait Haddou,Mohamed Bennai*

Main category: cs.LG

TL;DR: GuiderNet是一个元学习框架，通过数据依赖的参数调整优化量子电路的几何条件，显著提升训练效果和测试精度。


<details>
  <summary>Details</summary>
Motivation: 解决变分量子算法中梯度消失和优化条件差的问题。

Method: 使用经典神经网络GuiderNet对参数化量子电路进行几何优化，嵌入量子-经典混合流程中指导训练。

Result: 在糖尿病分类任务中，训练损失降低5倍，测试精度从75.3%提升至98.6%，少数类F1分数从0.67增至0.95。

Conclusion: 几何元条件化可缓解梯度消失和优化问题，提升量子机器学习的可训练性和泛化能力。

Abstract: Variational Quantum Algorithms (VQAs) offer potential for near-term quantum
advantage but face challenges from barren plateaus, where gradients vanish, and
poorly conditioned optimization landscapes. We introduce GuiderNet, a
meta-learning framework that conditions Parameterized Quantum Circuits (PQCs)
using data-dependent parameter shifts aimed at minimizing the log condition
number of the Fubini-Study metric tensor. Implemented as a classical neural
network, GuiderNet is meta-trained to guide PQC parameters into geometrically
favorable regions and is embedded within hybrid quantum-classical pipelines to
steer both initialization and adaptive modulation during training.
  Applied to the Kaggle Diabetes classification task, GuiderNet reduces
cumulative training loss by over 5x, improves test accuracy from 75.3% to
98.6%, and increases the minority-class F1 score from 0.67 to 0.95. It also
suppresses gradient explosion and stabilizes parameter updates, enabling
smoother and more robust optimization. These results demonstrate that geometric
meta-conditioning can mitigate barren plateaus and ill-conditioning, providing
a scalable approach to enhance trainability and generalization in quantum
machine learning.

</details>


### [161] [Physics-informed network paradigm with data generation and background noise removal for diverse distributed acoustic sensing applications](https://arxiv.org/abs/2506.21952)
*Yangyang Wan,Haotian Wang,Xuhui Yu,Jiageng Chen,Xinyu Fan,Zuyuan He*

Main category: cs.LG

TL;DR: 提出了一种基于物理信息的DAS神经网络范式，无需真实事件数据训练，通过物理建模生成数据，并在去噪和事件识别中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决DAS应用中真实事件数据有限的问题，同时提升去噪和事件识别的性能。

Method: 通过物理建模生成DAS事件数据，训练生成网络和去背景噪声网络，应用于事件识别和故障监测。

Result: 在公开数据集和实际场景中表现优于数据驱动网络，故障诊断准确率达91.8%。

Conclusion: 该范式为DAS应用中的数据获取和噪声问题提供了有效解决方案，具有广泛潜力。

Abstract: Distributed acoustic sensing (DAS) has attracted considerable attention
across various fields and artificial intelligence (AI) technology plays an
important role in DAS applications to realize event recognition and denoising.
Existing AI models require real-world data (RWD), whether labeled or not, for
training, which is contradictory to the fact of limited available event data in
real-world scenarios. Here, a physics-informed DAS neural network paradigm is
proposed, which does not need real-world events data for training. By
physically modeling target events and the constraints of real world and DAS
system, physical functions are derived to train a generative network for
generation of DAS events data. DAS debackground net is trained by using the
generated DAS events data to eliminate background noise in DAS data. The
effectiveness of the proposed paradigm is verified in event identification
application based on a public dataset of DAS spatiotemporal data and in belt
conveyor fault monitoring application based on DAS time-frequency data, and
achieved comparable or better performance than data-driven networks trained
with RWD. Owing to the introduction of physical information and capability of
background noise removal, the paradigm demonstrates generalization in same
application on different sites. A fault diagnosis accuracy of 91.8% is achieved
in belt conveyor field with networks which transferred from simulation test
site without any fault events data of test site and field for training. The
proposed paradigm is a prospective solution to address significant obstacles of
data acquisition and intense noise in practical DAS applications and explore
more potential fields for DAS.

</details>


### [162] [Optimal Return-to-Go Guided Decision Transformer for Auto-Bidding in Advertisement](https://arxiv.org/abs/2506.21956)
*Hao Jiang,Yongxiang Tang,Yanxiang Zeng,Pengjia Yuan,Yanhua Cheng,Teng Sha,Xialong Liu,Peng Jiang*

Main category: cs.LG

TL;DR: 论文提出R* Decision Transformer (R* DT)改进自动竞价系统，通过三步方法解决传统DT的预设RTG值和数据质量限制问题，实验验证其优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 在线广告竞价中，传统Decision Transformer (DT)存在预设RTG值和数据质量限制的问题，需要改进以实现更优的自动竞价。

Method: 提出R* DT，分三步：R DT存储状态和RTG值；R^ DT预测最高RTG值；R* DT通过生成高奖励轨迹增强训练数据。

Result: 在公开竞价数据集上验证，R* DT优于传统DT，尤其在处理混合质量轨迹时表现更佳。

Conclusion: R* DT通过数据增强和逐步优化，显著提升了自动竞价系统的性能。

Abstract: In the realm of online advertising, advertisers partake in ad auctions to
obtain advertising slots, frequently taking advantage of auto-bidding tools
provided by demand-side platforms. To improve the automation of these bidding
systems, we adopt generative models, namely the Decision Transformer (DT), to
tackle the difficulties inherent in automated bidding. Applying the Decision
Transformer to the auto-bidding task enables a unified approach to sequential
modeling, which efficiently overcomes short-sightedness by capturing long-term
dependencies between past bidding actions and user behavior. Nevertheless,
conventional DT has certain drawbacks: (1) DT necessitates a preset
return-to-go (RTG) value before generating actions, which is not inherently
produced; (2) The policy learned by DT is restricted by its training data,
which is consists of mixed-quality trajectories. To address these challenges,
we introduce the R* Decision Transformer (R* DT), developed in a three-step
process: (1) R DT: Similar to traditional DT, R DT stores actions based on
state and RTG value, as well as memorizing the RTG for a given state using the
training set; (2) R^ DT: We forecast the highest value (within the training
set) of RTG for a given state, deriving a suboptimal policy based on the
current state and the forecasted supreme RTG value; (3) R* DT: Based on R^ DT,
we generate trajectories and select those with high rewards (using a simulator)
to augment our training dataset. This data enhancement has been shown to
improve the RTG of trajectories in the training data and gradually leads the
suboptimal policy towards optimality. Comprehensive tests on a publicly
available bidding dataset validate the R* DT's efficacy and highlight its
superiority when dealing with mixed-quality trajectories.

</details>


### [163] [Binned semiparametric Bayesian networks](https://arxiv.org/abs/2506.21997)
*Rafael Sojo,Javier Díaz-Rozo,Concha Bielza,Pedro Larrañaga*

Main category: cs.LG

TL;DR: 提出了一种新的概率半参数模型，通过数据分箱降低核密度估计的计算成本，解决了维度灾难问题。


<details>
  <summary>Details</summary>
Motivation: 解决非参数分布中核密度估计的高计算成本问题，并应对维度灾难。

Method: 开发了两种新的条件概率分布（稀疏分箱核密度估计和傅里叶核密度估计），利用稀疏张量和限制父节点数量。

Result: 实验表明，分箱半参数贝叶斯网络在速度和性能上与未分箱版本相当。

Conclusion: 分箱半参数贝叶斯网络是一种更高效且可靠的替代方案。

Abstract: This paper introduces a new type of probabilistic semiparametric model that
takes advantage of data binning to reduce the computational cost of kernel
density estimation in nonparametric distributions. Two new conditional
probability distributions are developed for the new binned semiparametric
Bayesian networks, the sparse binned kernel density estimation and the Fourier
kernel density estimation. These two probability distributions address the
curse of dimensionality, which typically impacts binned models, by using sparse
tensors and restricting the number of parent nodes in conditional probability
calculations. To evaluate the proposal, we perform a complexity analysis and
conduct several comparative experiments using synthetic data and datasets from
the UCI Machine Learning repository. The experiments include different binning
rules, parent restrictions, grid sizes, and number of instances to get a
holistic view of the model's behavior. As a result, our binned semiparametric
Bayesian networks achieve structural learning and log-likelihood estimations
with no statistically significant differences compared to the semiparametric
Bayesian networks, but at a much higher speed. Thus, the new binned
semiparametric Bayesian networks prove to be a reliable and more efficient
alternative to their non-binned counterparts.

</details>


### [164] [GKNet: Graph Kalman Filtering and Model Inference via Model-based Deep Learning](https://arxiv.org/abs/2506.22004)
*Mohammad Sabbaqi,Riccardo Taormina,Elvin Isufi*

Main category: cs.LG

TL;DR: 提出了一种基于图的状态空间模型，用于图时间序列的推理任务，结合最大似然和深度学习进行参数学习与状态跟踪。


<details>
  <summary>Details</summary>
Motivation: 解决图时间序列推理任务中计算高效且能捕捉图-时间模式的需求。

Method: 使用图诱导的隐状态和观测方程模型，结合最大似然和深度学习进行参数学习。

Result: 模型能够处理部分观测数据，适用于预测和填补等下游任务。

Conclusion: 提出的方法在理论可解释性和深度学习扩展性之间取得了平衡。

Abstract: Inference tasks with time series over graphs are of importance in
applications such as urban water networks, economics, and networked
neuroscience. Addressing these tasks typically relies on identifying a
computationally affordable model that jointly captures the graph-temporal
patterns of the data. In this work, we propose a graph-aware state space model
for graph time series, where both the latent state and the observation equation
are parametric graph-induced models with a limited number of parameters that
need to be learned. More specifically, we consider the state equation to follow
a stochastic partial differential equation driven by noise over the graphs
edges accounting not only for potential edge uncertainties but also for
increasing the degrees of freedom in the latter in a tractable manner. The
graph structure conditioning of the noise dispersion allows the state variable
to deviate from the stochastic process in certain neighborhoods. The
observation model is a sampled and graph-filtered version of the state
capturing multi-hop neighboring influence. The goal is to learn the parameters
in both state and observation models from the partially observed data for
downstream tasks such as prediction and imputation. The model is inferred first
through a maximum likelihood approach that provides theoretical tractability
but is limited in expressivity and scalability. To improve on the latter, we
use the state-space formulation to build a principled deep learning
architecture that jointly learns the parameters and tracks the state in an
end-to-end manner in the spirit of Kalman neural networks.

</details>


### [165] [TROFI: Trajectory-Ranked Offline Inverse Reinforcement Learning](https://arxiv.org/abs/2506.22008)
*Alessandro Sestini,Joakim Bergdahl,Konrad Tollmar,Andrew D. Bagdanov,Linus Gisslén*

Main category: cs.LG

TL;DR: TROFI是一种离线强化学习方法，通过从人类偏好中学习奖励函数来训练策略，无需预定义奖励函数或最优轨迹。


<details>
  <summary>Details</summary>
Motivation: 在离线强化学习中，数据集通常需要预定义的奖励函数标记，但在实际应用中（如游戏开发）奖励函数可能不可用。本文旨在解决这一问题。

Method: 提出TROFI方法，首先从人类偏好中学习奖励函数，然后用其标记数据集以训练策略。该方法无需最优轨迹。

Result: 在D4RL基准测试中，TROFI表现优于基线方法，并与使用真实奖励函数的方法相当。在3D游戏环境中也验证了其有效性。

Conclusion: 研究表明，奖励函数的设计对值函数与未来折扣奖励的对齐至关重要，需确保其易于学习和优化。

Abstract: In offline reinforcement learning, agents are trained using only a fixed set
of stored transitions derived from a source policy. However, this requires that
the dataset be labeled by a reward function. In applied settings such as video
game development, the availability of the reward function is not always
guaranteed. This paper proposes Trajectory-Ranked OFfline Inverse reinforcement
learning (TROFI), a novel approach to effectively learn a policy offline
without a pre-defined reward function. TROFI first learns a reward function
from human preferences, which it then uses to label the original dataset making
it usable for training the policy. In contrast to other approaches, our method
does not require optimal trajectories. Through experiments on the D4RL
benchmark we demonstrate that TROFI consistently outperforms baselines and
performs comparably to using the ground truth reward to learn policies.
Additionally, we validate the efficacy of our method in a 3D game environment.
Our studies of the reward model highlight the importance of the reward function
in this setting: we show that to ensure the alignment of a value function to
the actual future discounted reward, it is fundamental to have a
well-engineered and easy-to-learn reward function.

</details>


### [166] [Reinforcement Learning with Physics-Informed Symbolic Program Priors for Zero-Shot Wireless Indoor Navigation](https://arxiv.org/abs/2506.22365)
*Tao Li,Haozhe Lei,Mingsheng Yin,Yaqi Hu*

Main category: cs.LG

TL;DR: 论文提出了一种符号化方法PiPRL，将物理先验知识融入强化学习，通过分层模块化设计提升训练效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前将物理先验知识融入强化学习的方法需要大量人工和领域知识，限制了其通用性。

Method: 采用分层模块化的神经符号集成框架PiPRL，通过可读的领域特定语言（DSL）表达物理先验，并指导低层神经控制器。

Result: PiPRL在室内导航任务中表现优于纯符号或神经策略，训练时间减少26%。

Conclusion: PiPRL框架有效结合了符号化先验和神经网络，提升了强化学习的效率和性能。

Abstract: When using reinforcement learning (RL) to tackle physical control tasks,
inductive biases that encode physics priors can help improve sample efficiency
during training and enhance generalization in testing. However, the current
practice of incorporating these helpful physics-informed inductive biases
inevitably runs into significant manual labor and domain expertise, making them
prohibitive for general users. This work explores a symbolic approach to
distill physics-informed inductive biases into RL agents, where the physics
priors are expressed in a domain-specific language (DSL) that is human-readable
and naturally explainable. Yet, the DSL priors do not translate directly into
an implementable policy due to partial and noisy observations and additional
physical constraints in navigation tasks. To address this gap, we develop a
physics-informed program-guided RL (PiPRL) framework with applications to
indoor navigation. PiPRL adopts a hierarchical and modularized neuro-symbolic
integration, where a meta symbolic program receives semantically meaningful
features from a neural perception module, which form the bases for symbolic
programming that encodes physics priors and guides the RL process of a
low-level neural controller. Extensive experiments demonstrate that PiPRL
consistently outperforms purely symbolic or neural policies and reduces
training time by over 26% with the help of the program-based inductive biases.

</details>


### [167] [Hyper-modal Imputation Diffusion Embedding with Dual-Distillation for Federated Multimodal Knowledge Graph Completion](https://arxiv.org/abs/2506.22036)
*Ying Zhang,Yu Zhao,Xuhui Sui,Baohang Zhou,Xiangrui Cai,Li Shen,Xiaojie Yuan,Dacheng Tao*

Main category: cs.LG

TL;DR: 本文提出了一种联邦多模态知识图谱补全（FedMKGC）任务，并设计了MMFeD3-HidE框架，以解决多模态不确定性和客户端异质性挑战。实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 多模态知识图谱在机构间分散，缺乏协作系统，需要更强的推理能力和传输安全保障。

Method: 提出HidE模型恢复完整多模态分布，MMFeD3通过双蒸馏在客户端和服务器间传递知识。

Result: 实验验证了MMFeD3-HidE的有效性、语义一致性和收敛鲁棒性。

Conclusion: MMFeD3-HidE为联邦多模态知识图谱补全提供了有效解决方案。

Abstract: With the increasing multimodal knowledge privatization requirements,
multimodal knowledge graphs in different institutes are usually decentralized,
lacking of effective collaboration system with both stronger reasoning ability
and transmission safety guarantees. In this paper, we propose the Federated
Multimodal Knowledge Graph Completion (FedMKGC) task, aiming at training over
federated MKGs for better predicting the missing links in clients without
sharing sensitive knowledge. We propose a framework named MMFeD3-HidE for
addressing multimodal uncertain unavailability and multimodal client
heterogeneity challenges of FedMKGC. (1) Inside the clients, our proposed
Hyper-modal Imputation Diffusion Embedding model (HidE) recovers the complete
multimodal distributions from incomplete entity embeddings constrained by
available modalities. (2) Among clients, our proposed Multimodal FeDerated Dual
Distillation (MMFeD3) transfers knowledge mutually between clients and the
server with logit and feature distillation to improve both global convergence
and semantic consistency. We propose a FedMKGC benchmark for a comprehensive
evaluation, consisting of a general FedMKGC backbone named MMFedE, datasets
with heterogeneous multimodal information, and three groups of constructed
baselines. Experiments conducted on our benchmark validate the effectiveness,
semantic consistency, and convergence robustness of MMFeD3-HidE.

</details>


### [168] [ARMOR: Robust Reinforcement Learning-based Control for UAVs under Physical Attacks](https://arxiv.org/abs/2506.22423)
*Pritam Dash,Ethan Chan,Nathan P. Lawrence,Karthik Pattabiraman*

Main category: cs.LG

TL;DR: ARMOR是一种基于强化学习的攻击弹性控制器，通过两阶段训练框架学习无人机物理状态的鲁棒潜在表示，有效应对传感器攻击。


<details>
  <summary>Details</summary>
Motivation: 无人机传感器易受物理攻击（如GPS欺骗），传统安全强化学习方法对此无效，需开发更鲁棒的控制方案。

Method: ARMOR采用两阶段训练：第一阶段利用特权攻击信息训练教师编码器生成攻击感知潜在状态；第二阶段通过监督学习训练学生编码器，仅用历史传感器数据近似教师潜在状态。

Result: 实验表明ARMOR优于传统方法，确保无人机安全，提升对未知攻击的泛化能力，并降低训练成本。

Conclusion: ARMOR为无人机在对抗性传感器攻击下的鲁棒操作提供了有效解决方案。

Abstract: Unmanned Aerial Vehicles (UAVs) depend on onboard sensors for perception,
navigation, and control. However, these sensors are susceptible to physical
attacks, such as GPS spoofing, that can corrupt state estimates and lead to
unsafe behavior. While reinforcement learning (RL) offers adaptive control
capabilities, existing safe RL methods are ineffective against such attacks. We
present ARMOR (Adaptive Robust Manipulation-Optimized State Representations),
an attack-resilient, model-free RL controller that enables robust UAV operation
under adversarial sensor manipulation. Instead of relying on raw sensor
observations, ARMOR learns a robust latent representation of the UAV's physical
state via a two-stage training framework. In the first stage, a teacher
encoder, trained with privileged attack information, generates attack-aware
latent states for RL policy training. In the second stage, a student encoder is
trained via supervised learning to approximate the teacher's latent states
using only historical sensor data, enabling real-world deployment without
privileged information. Our experiments show that ARMOR outperforms
conventional methods, ensuring UAV safety. Additionally, ARMOR improves
generalization to unseen attacks and reduces training cost by eliminating the
need for iterative adversarial training.

</details>


### [169] [UniCA: Adapting Time Series Foundation Model to General Covariate-Aware Forecasting](https://arxiv.org/abs/2506.22039)
*Lu Han,Yu Liu,Qiwen Deng,Jian Jiang,Yinbo Sun,Zhe Yu,Binfeng Wang,Xingyu Lu,Lintao Ma,Han-Jia Ye,De-Chuan Zhan*

Main category: cs.LG

TL;DR: UniCA框架通过将异构协变量转化为同质序列表示，并通过注意力机制融合，解决了时间序列基础模型（TSFMs）在处理多样化协变量时的局限性。


<details>
  <summary>Details</summary>
Motivation: TSFMs主要针对实值序列设计，难以处理包含异构协变量（如分类变量和多模态数据）的通用预测任务。

Method: UniCA框架包括协变量同质化和基于注意力的统一融合机制。

Result: 在单模态和多模态协变量预测基准测试中，UniCA表现出优越性。

Conclusion: UniCA展示了协变量感知的TSFM适应在现实预测场景中的潜力。

Abstract: Time Series Foundation Models (TSFMs) have achieved remarkable success
through large-scale pretraining. However, their design primarily targets
real-valued series, limiting their ability to handle general forecasting tasks
involving diverse and often heterogeneous covariates--such as categorical
variables and multimodal data (e.g., images, text)--which are typically
task-specific and difficult to leverage during pretraining. To address this
gap, we propose Unified Covariate Adaptation (UniCA), a framework to bridge
TSFMs with general covariate-aware forecasting. UniCA first performs covariate
homogenization to transform heterogeneous covariates into high-level
homogeneous series representations and then fuses them via a unified
attention-based fusion mechanism. UniCA is compatible and universal for
adaptation with both homogeneous and heterogeneous covariates, incorporating
extra covariate information while preserving the generalization ability of
TSFMs.Extensive experiments on multiple unimodal and multimodal covariate-aware
forecasting benchmarks demonstrate the superiority of UniCA, highlighting the
promise of covariate-aware TSFM adaptation in real-world forecasting scenarios.
Codes are released on https://github.com/hanlu-nju/UniCA.

</details>


### [170] [GPAS: Accelerating Convergence of LLM Pretraining via Gradient-Preserving Activation Scaling](https://arxiv.org/abs/2506.22049)
*Tianhao Chen,Xin Xu,Zijing Liu,Pengxiang Li,Xinyuan Song,Ajay Kumar Jaiswal,Fan Zhang,Jishan Hu,Yang Wang,Hao Chen,Shizhe Diao,Shiwei Liu,Yu Li,Yin Lu,Can Yang*

Main category: cs.LG

TL;DR: 论文提出了一种名为GPAS的技术，用于解决Pre-LN Transformer中激活方差指数增长的问题，通过缩放中间激活值但不改变梯度，提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: Pre-LN Transformer在预训练中稳定且可扩展，但存在激活方差指数增长的问题，导致残差路径主导子层输出，限制了深层学习能力。

Method: 提出Gradient-Preserving Activation Scaling (GPAS)，通过缩放中间激活值但不改变梯度，保留信息并避免梯度消失问题。

Result: 在71M到1B的不同模型规模上，GPAS均实现了性能提升，并在Sandwich-LN和DeepNorm等其他架构中表现出潜力。

Conclusion: GPAS是一种简单有效的技术，能够提升Pre-LN Transformer及其他架构的训练动态和性能。

Abstract: Modern Large Language Models, such as the LLaMA, Qwen and DeepSeek series,
predominantly adopt the Pre-LayerNorm (Pre-LN) Transformer architecture. While
being stable during pretraining and scalable to large model sizes, Pre-LN
suffers from an exponential growth in activation variance across layers,
causing the residual path to dominate over sub-layer outputs and limiting the
learning capacity of deeper layers. To mitigate this issue, we propose
Gradient-Preserving Activation Scaling (GPAS), a simple technique that can be
used in combination with existing approaches. GPAS works by scaling down the
intermediate activations while keeping their gradients unchanged. This leaves
information in the activations intact, and avoids the gradient vanishing
problem associated with gradient downscaling. Extensive experiments across
various model sizes from 71M to 1B show that GPAS achieves consistent
performance gains. Beyond enhancing Pre-LN Transformers, GPAS also shows
promise in improving alternative architectures such as Sandwich-LN and
DeepNorm, demonstrating its versatility and potential for improving training
dynamics in a wide range of settings.

</details>


### [171] [crypto price prediction using lstm+xgboost](https://arxiv.org/abs/2506.22055)
*Mehul Gautam*

Main category: cs.LG

TL;DR: 提出了一种结合LSTM和XGBoost的混合模型，用于加密货币价格预测，表现优于单一模型和传统方法。


<details>
  <summary>Details</summary>
Motivation: 加密货币市场的波动性和复杂性对价格预测提出了挑战，需要更精确的预测方法。

Method: 结合LSTM（捕捉时间依赖性）和XGBoost（建模非线性关系），并整合辅助特征如情感分数和宏观经济指标。

Result: 在比特币、以太坊等数据集上验证，混合模型的MAPE和MinMax RMSE表现优于其他方法。

Conclusion: 混合架构在金融预测中潜力显著，且适用于不同加密货币和市场环境。

Abstract: The volatility and complex dynamics of cryptocurrency markets present unique
challenges for accurate price forecasting. This research proposes a hybrid deep
learning and machine learning model that integrates Long Short-Term Memory
(LSTM) networks and Extreme Gradient Boosting (XGBoost) for cryptocurrency
price prediction. The LSTM component captures temporal dependencies in
historical price data, while XGBoost enhances prediction by modeling nonlinear
relationships with auxiliary features such as sentiment scores and
macroeconomic indicators. The model is evaluated on historical datasets of
Bitcoin, Ethereum, Dogecoin, and Litecoin, incorporating both global and
localized exchange data. Comparative analysis using Mean Absolute Percentage
Error (MAPE) and Min-Max Normalized Root Mean Square Error (MinMax RMSE)
demonstrates that the LSTM+XGBoost hybrid consistently outperforms standalone
models and traditional forecasting methods. This study underscores the
potential of hybrid architectures in financial forecasting and provides
insights into model adaptability across different cryptocurrencies and market
contexts.

</details>


### [172] [Transformers are Graph Neural Networks](https://arxiv.org/abs/2506.22084)
*Chaitanya K. Joshi*

Main category: cs.LG

TL;DR: 将Transformer架构与图神经网络（GNNs）联系起来，展示其作为消息传递GNN在完全连接图上的表现，并指出其在硬件效率上的优势。


<details>
  <summary>Details</summary>
Motivation: 探索Transformer与GNNs之间的数学联系，揭示其作为高效表达集合处理网络的潜力。

Method: 将Transformer视为在完全连接图上操作的消息传递GNN，利用自注意力机制捕捉令牌间关系，位置编码提供顺序信息。

Result: Transformer是表达力强的集合处理网络，无需依赖先验图结构，且在硬件上比稀疏消息传递更高效。

Conclusion: Transformer是当前硬件条件下更高效的GNN实现，展现了其在图表示学习中的潜力。

Abstract: We establish connections between the Transformer architecture, originally
introduced for natural language processing, and Graph Neural Networks (GNNs)
for representation learning on graphs. We show how Transformers can be viewed
as message passing GNNs operating on fully connected graphs of tokens, where
the self-attention mechanism capture the relative importance of all tokens
w.r.t. each-other, and positional encodings provide hints about sequential
ordering or structure. Thus, Transformers are expressive set processing
networks that learn relationships among input elements without being
constrained by apriori graphs. Despite this mathematical connection to GNNs,
Transformers are implemented via dense matrix operations that are significantly
more efficient on modern hardware than sparse message passing. This leads to
the perspective that Transformers are GNNs currently winning the hardware
lottery.

</details>


### [173] [Learning to Solve Multi-Objective Routing Problems on Multigraphs](https://arxiv.org/abs/2506.22095)
*Filip Rydin,Attila Lischka,Jiaming Wu,Morteza Haghir Chehreghani,Balázs Kulcsár*

Main category: cs.LG

TL;DR: 该论文提出了两种基于神经网络的路径规划方法，用于解决多目标多图路由问题，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管多图（multigraph）在实际应用中具有高度相关性，但现有的基于学习的路由方法大多忽略了这一场景。

Method: 第一种方法直接在多图上通过自回归选择边完成路径规划；第二种方法先将多图简化为简单图，再构建路径。

Result: 实验表明，两种方法在多种问题（如TSP和CVRP）中表现优异。

Conclusion: 论文提出的两种神经网络方法在多目标多图路由问题上具有实用性和高效性。

Abstract: Learning-based methods for routing have gained significant attention in
recent years, both in single-objective and multi-objective contexts. However,
the multigraph setting, where multiple paths with distinct attributes can exist
between destinations, has largely been overlooked, despite its high practical
relevancy. In this paper, we introduce two neural approaches to address
multi-objective routing on multigraphs. Our first approach works directly on
the multigraph, by autoregressively selecting edges until a tour is completed.
On the other hand, our second model first prunes the multigraph into a simple
graph and then builds routes. We validate both models experimentally and find
that they demonstrate strong performance across a variety of problems,
including the Traveling Salesman Problem (TSP) and Capacitated Vehicle Routing
Problem (CVRP).

</details>


### [174] [Transfer Learning for Assessing Heavy Metal Pollution in Seaports Sediments](https://arxiv.org/abs/2506.22096)
*Tin Lai,Farnaz Farid,Yueyang Kuan,Xintian Zhang*

Main category: cs.LG

TL;DR: 提出了一种基于深度学习的模型，用于简化重金属污染评估过程，解决了传统方法中数据稀缺和标准不一的问题。


<details>
  <summary>Details</summary>
Motivation: 传统PLI评估方法繁琐且数据收集困难，需要一种更高效、准确的替代方案。

Method: 利用迁移学习开发了一种定量评估方法，能够跨域转移学习特征。

Result: 在澳大利亚六个主要港口的数据测试中，模型的MAE和MAPE显著低于其他模型，性能提升了两个数量级。

Conclusion: 该模型为水质预测提供了一种创新、易用且经济的方法，有助于海洋生态保护和工业污染监测。

Abstract: Detecting heavy metal pollution in soils and seaports is vital for regional
environmental monitoring. The Pollution Load Index (PLI), an international
standard, is commonly used to assess heavy metal containment. However, the
conventional PLI assessment involves laborious procedures and data analysis of
sediment samples. To address this challenge, we propose a deep-learning-based
model that simplifies the heavy metal assessment process. Our model tackles the
issue of data scarcity in the water-sediment domain, which is traditionally
plagued by challenges in data collection and varying standards across nations.
By leveraging transfer learning, we develop an accurate quantitative assessment
method for predicting PLI. Our approach allows the transfer of learned features
across domains with different sets of features. We evaluate our model using
data from six major ports in New South Wales, Australia: Port Yamba, Port
Newcastle, Port Jackson, Port Botany, Port Kembla, and Port Eden. The results
demonstrate significantly lower Mean Absolute Error (MAE) and Mean Absolute
Percentage Error (MAPE) of approximately 0.5 and 0.03, respectively, compared
to other models. Our model performance is up to 2 orders of magnitude than
other baseline models. Our proposed model offers an innovative, accessible, and
cost-effective approach to predicting water quality, benefiting marine life
conservation, aquaculture, and industrial pollution monitoring.

</details>


### [175] [Earthquake Damage Grades Prediction using An Ensemble Approach Integrating Advanced Machine and Deep Learning Models](https://arxiv.org/abs/2506.22129)
*Anurag Panda,Gaurav Kumar Yadav*

Main category: cs.LG

TL;DR: 论文探讨了利用机器学习（如XGBoost）和深度学习方法，结合SMOTE技术解决类别不平衡问题，以预测地震后建筑结构损坏等级。


<details>
  <summary>Details</summary>
Motivation: 地震后快速准确评估建筑损坏等级对救援和资源分配至关重要，但现有方法存在类别不平衡问题。

Method: 采用多类分类模型（包括XGBoost、深度学习及集成方法），结合SMOTE技术处理类别不平衡，并通过特征实验和训练方法优化性能。

Result: 研究揭示了影响模型性能的关键因素，并通过混淆矩阵等方法评估了预测效果。

Conclusion: SMOTE和多种机器学习方法的结合能有效预测地震损坏等级，为灾后响应提供支持。

Abstract: In the aftermath of major earthquakes, evaluating structural and
infrastructural damage is vital for coordinating post-disaster response
efforts. This includes assessing damage's extent and spatial distribution to
prioritize rescue operations and resource allocation. Accurately estimating
damage grades to buildings post-earthquake is paramount for effective response
and recovery, given the significant impact on lives and properties,
underscoring the urgency of streamlining relief fund allocation processes.
Previous studies have shown the effectiveness of multi-class classification,
especially XGBoost, along with other machine learning models and ensembling
methods, incorporating regularization to address class imbalance. One
consequence of class imbalance is that it may give rise to skewed models that
undervalue minority classes and give preference to the majority class. This
research deals with the problem of class imbalance with the help of the
synthetic minority oversampling technique (SMOTE). We delve into multiple
multi-class classification machine learning, deep learning models, and
ensembling methods to forecast structural damage grades. The study elucidates
performance determinants through comprehensive feature manipulation experiments
and diverse training approaches. It identifies key factors contributing to
seismic vulnerability while evaluating model performance using techniques like
the confusion matrix further to enhance understanding of the effectiveness of
earthquake damage prediction.

</details>


### [176] [Thompson Sampling-Based Learning and Control for Unknown Dynamic Systems](https://arxiv.org/abs/2506.22186)
*Kaikai Zheng,Dawei Shi,Yang Shi,Long Wang*

Main category: cs.LG

TL;DR: 提出一种基于再生核希尔伯特空间的参数化方法，用于主动学习控制设计，扩展了Thompson采样的适用性。


<details>
  <summary>Details</summary>
Motivation: Thompson采样依赖于有限参数表示，限制了其在一般空间中的应用，特别是在控制系统设计中。

Method: 将控制律视为函数空间中的元素，利用再生核希尔伯特空间进行参数化，设计数据驱动的主动学习控制方法。

Result: 理论分析表明，该方法以指数速率学习控制律与闭环性能指标的关系，并推导了控制遗憾的上界。数值实验验证了其有效性。

Conclusion: 该方法扩展了Thompson采样的适用范围，为控制律学习提供了高效且通用的框架。

Abstract: Thompson sampling (TS) is an effective method to explore parametric
uncertainties and can therefore be used for active learning-based controller
design. However, TS relies on finite parametric representations, which limits
its applicability to more general spaces, which are more commonly encountered
in control system design. To address this issue, this work pro poses a
parameterization method for control law learning using reproducing kernel
Hilbert spaces and designs a data-driven active learning control approach.
Specifically, the proposed method treats the control law as an element in a
function space, allowing the design of control laws without imposing
restrictions on the system structure or the form of the controller. A TS
framework is proposed in this work to explore potential optimal control laws,
and the convergence guarantees are further provided for the learning process.
Theoretical analysis shows that the proposed method learns the relationship
between control laws and closed-loop performance metrics at an exponential
rate, and the upper bound of control regret is also derived. Numerical
experiments on controlling unknown nonlinear systems validate the effectiveness
of the proposed method.

</details>


### [177] [dreaMLearning: Data Compression Assisted Machine Learning](https://arxiv.org/abs/2506.22190)
*Xiaobo Zhao,Aaron Hurst,Panagiotis Karras,Daniel E. Lucani*

Main category: cs.LG

TL;DR: dreaMLearning框架通过压缩数据直接学习，提升效率，减少资源需求。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习对大量标注数据和计算资源的高需求问题。

Method: 基于EntroGeDe的压缩方法，支持多种数据类型和任务。

Result: 训练加速8.8倍，内存减少10倍，存储节省42%，性能影响小。

Conclusion: dreaMLearning为资源受限场景下的高效学习提供新可能。

Abstract: Despite rapid advancements, machine learning, particularly deep learning, is
hindered by the need for large amounts of labeled data to learn meaningful
patterns without overfitting and immense demands for computation and storage,
which motivate research into architectures that can achieve good performance
with fewer resources. This paper introduces dreaMLearning, a novel framework
that enables learning from compressed data without decompression, built upon
Entropy-based Generalized Deduplication (EntroGeDe), an entropy-driven lossless
compression method that consolidates information into a compact set of
representative samples. DreaMLearning accommodates a wide range of data types,
tasks, and model architectures. Extensive experiments on regression and
classification tasks with tabular and image data demonstrate that dreaMLearning
accelerates training by up to 8.8x, reduces memory usage by 10x, and cuts
storage by 42%, with a minimal impact on model performance. These advancements
enhance diverse ML applications, including distributed and federated learning,
and tinyML on resource-constrained edge devices, unlocking new possibilities
for efficient and scalable learning.

</details>


### [178] [REDELEX: A Framework for Relational Deep Learning Exploration](https://arxiv.org/abs/2506.22199)
*Jakub Peleška,Gustav Šír*

Main category: cs.LG

TL;DR: REDELEX是一个评估不同复杂度RDL模型的框架，分析了70多个RDBs，发现RDL性能优于传统方法，并探讨了影响性能的关键因素。


<details>
  <summary>Details</summary>
Motivation: 研究RDL模型性能与底层RDB特性之间的关系，填补了这一新兴领域的空白。

Method: 提出REDELEX框架，评估不同复杂度的RDL模型在70多个RDBs上的表现，并与传统方法对比。

Result: RDL性能普遍优于传统方法，模型复杂度、数据库大小和结构特性是主要影响因素。

Conclusion: REDELEX为RDL模型评估提供了全面框架，揭示了性能影响因素，推动了该领域的发展。

Abstract: Relational databases (RDBs) are widely regarded as the gold standard for
storing structured information. Consequently, predictive tasks leveraging this
data format hold significant application promise. Recently, Relational Deep
Learning (RDL) has emerged as a novel paradigm wherein RDBs are conceptualized
as graph structures, enabling the application of various graph neural
architectures to effectively address these tasks. However, given its novelty,
there is a lack of analysis into the relationships between the performance of
various RDL models and the characteristics of the underlying RDBs.
  In this study, we present REDELEX$-$a comprehensive exploration framework for
evaluating RDL models of varying complexity on the most diverse collection of
over 70 RDBs, which we make available to the community. Benchmarked alongside
key representatives of classic methods, we confirm the generally superior
performance of RDL while providing insights into the main factors shaping
performance, including model complexity, database sizes and their structural
properties.

</details>


### [179] [EFRame: Deeper Reasoning via Exploration-Filtering-Replay Reinforcement Learning Framework](https://arxiv.org/abs/2506.22200)
*Chen Wang,Lai Wei,Yanzhi Zhang,Chenyang Shao,Zedong Dan,Weiran Huang,Yue Wang,Yuzhi Zhang*

Main category: cs.LG

TL;DR: EFRame框架通过探索、过滤和回放机制增强GRPO，提升强化学习在复杂推理任务中的性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: GRPO在探索、样本效率和稳定性方面存在局限，限制了其在复杂推理任务中的表现。

Method: EFRame通过额外探索、在线过滤低质量样本和利用经验回放，构建完整稳定的学习循环。

Result: 实验表明EFRame提升了训练效率和稳健性，并解锁了GRPO无法实现的更深层次推理能力。

Conclusion: EFRame为强化学习提供了更精细的样本分类和分析方法，显著提升了复杂推理任务的性能。

Abstract: Recent advances in reinforcement learning (RL) have significantly enhanced
the reasoning capabilities of large language models (LLMs). Group Relative
Policy Optimization (GRPO), an efficient variant of PPO that lowers RL's
computational cost, still faces limited exploration, low sample efficiency and
instability, constraining its performance on complex reasoning tasks. To
address these limitations, we introduce EFRame, an Exploration-Filtering-Replay
framework that systematically augments GRPO along three critical dimensions.
EFRame performs additional rollouts to explore high-quality trajectories,
applies online filtering to eliminate low-quality samples that introduce noise
and variance, and leverages experience replay to repeatedly exploit rare but
informative samples. EFRame establishes a complete and stable learning cycle,
guiding the model through a structured transition from exploration to
convergence. Our experiments across a variety of reasoning benchmarks
demonstrate that EFRame not only improves the robustness and efficiency of
training, but also enables access to deeper reasoning capabilities that remain
unattainable under vanilla GRPO. Furthermore, EFRame enables a more
fine-grained categorization of training samples, allowing for a deeper analysis
of how different types of samples contribute to the learning process in RL. Our
code is available at https://github.com/597358816/EFRame.

</details>


### [180] [Risk-Averse Best Arm Set Identification with Fixed Budget and Fixed Confidence](https://arxiv.org/abs/2506.22253)
*Shunta Nonaga,Koji Tabata,Yuta Mizuno,Tamiki Komatsuzaki*

Main category: cs.LG

TL;DR: 论文提出了一种新的随机多臂老虎机优化问题设置，旨在同时最大化期望奖励和最小化风险（通过均值-方差准则）。提出了一种统一的元算法框架，适用于固定置信度和固定预算两种场景，并通过理论保证和实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 解决在不确定环境中决策时同时优化期望奖励和风险的问题，弥补传统方法仅关注期望回报的不足。

Method: 提出了一种统一的元算法框架，通过自适应设计置信区间，适用于固定置信度和固定预算两种场景。

Result: 理论分析证明了算法的正确性，实验表明其在准确性和样本效率上优于现有方法。

Conclusion: 该方法在风险感知决策任务中具有广泛适用性，能高效地找到帕累托最优解。

Abstract: Decision making under uncertain environments in the maximization of expected
reward while minimizing its risk is one of the ubiquitous problems in many
subjects. Here, we introduce a novel problem setting in stochastic bandit
optimization that jointly addresses two critical aspects of decision-making:
maximizing expected reward and minimizing associated uncertainty, quantified
via the mean-variance(MV) criterion. Unlike traditional bandit formulations
that focus solely on expected returns, our objective is to efficiently and
accurately identify the Pareto-optimal set of arms that strikes the best
trade-off between expected performance and risk. We propose a unified
meta-algorithmic framework capable of operating under both fixed-confidence and
fixed-budget regimes, achieved through adaptive design of confidence intervals
tailored to each scenario using the same sample exploration strategy. We
provide theoretical guarantees on the correctness of the returned solutions in
both settings. To complement this theoretical analysis, we conduct extensive
empirical evaluations across synthetic benchmarks, demonstrating that our
approach outperforms existing methods in terms of both accuracy and sample
efficiency, highlighting its broad applicability to risk-aware decision-making
tasks in uncertain environments.

</details>


### [181] [Projected Compression: Trainable Projection for Efficient Transformer Compression](https://arxiv.org/abs/2506.22255)
*Maciej Stefaniak,Michał Krutul,Jan Małaśnicki,Maciej Pióro,Jakub Krajewski,Sebastian Jaszczur,Marek Cygan,Kamil Adamczewski,Jan Ludziejewski*

Main category: cs.LG

TL;DR: 提出了一种名为Projected Compression的新模型压缩技术，通过投影模块减少模型权重，同时保持计算效率。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模的增加，推理时间和计算需求也随之增长，因此需要有效的模型压缩方法。

Method: 训练额外的可训练投影权重，保留原始模型参数，并将投影合并为低维矩阵，从而减少模型大小。

Result: 实验表明，该方法在高质量模型上优于硬剪枝和重新训练方法，且性能随token数量增加而提升。

Conclusion: Projected Compression是一种高效且可扩展的模型压缩方法。

Abstract: Large language models have steadily increased in size to achieve improved
performance; however, this growth has also led to greater inference time and
computational demands. Consequently, there is rising interest in model size
reduction methods. To address this issue, we propose Projected Compression, a
novel model compression technique, that reduces model weights by utilizing
projection modules. Specifically, we first train additional trainable
projections weights and preserve access to all the original model parameters.
Subsequently, these projections are merged into a lower-dimensional product
matrix, resulting in a reduced-size standard Transformer-based model. Unlike
alternative approaches that require additional computational overhead, our
method matches the base model's per-token computation step in FLOPs.
Experimental results show that Projected Compression outperforms the comparable
hard pruning and retraining approach on higher quality models. Moreover, the
performance margin scales well with the number of tokens.

</details>


### [182] [Score-Based Model for Low-Rank Tensor Recovery](https://arxiv.org/abs/2506.22295)
*Zhengyun Cheng,Changhao Wang,Guanwen Zhang,Yi Xu,Wei Zhou,Xiangyang Ji*

Main category: cs.LG

TL;DR: 论文提出了一种基于分数匹配的模型，用于低秩张量分解，无需预定义结构或分布假设，通过神经网络学习能量函数，显著提升了张量完成和去噪的性能。


<details>
  <summary>Details</summary>
Motivation: 传统张量分解方法依赖预定义的结构假设（如CP或Tucker分解），但在实际场景中，这种先验知识往往不可得，且固定收缩规则的优化过程复杂且易导致精度损失。

Method: 设计了一个神经网络来学习能量函数，通过分数匹配优化以捕捉张量条目和共享因子的联合对数概率梯度，结合块坐标下降算法和平滑正则化实现张量完成和去噪。

Result: 实验结果表明，该方法在稀疏张量、连续时间张量和视觉数据等多种张量类型上均表现出显著的性能提升。

Conclusion: 提出的方法突破了传统狄拉克分布假设的限制，能够学习张量与共享因子之间的兼容性，为多路数据分析提供了更灵活的框架。

Abstract: Low-rank tensor decompositions (TDs) provide an effective framework for
multiway data analysis. Traditional TD methods rely on predefined structural
assumptions, such as CP or Tucker decompositions. From a probabilistic
perspective, these can be viewed as using Dirac delta distributions to model
the relationships between shared factors and the low-rank tensor. However, such
prior knowledge is rarely available in practical scenarios, particularly
regarding the optimal rank structure and contraction rules. The optimization
procedures based on fixed contraction rules are complex, and approximations
made during these processes often lead to accuracy loss. To address this issue,
we propose a score-based model that eliminates the need for predefined
structural or distributional assumptions, enabling the learning of
compatibility between tensors and shared factors. Specifically, a neural
network is designed to learn the energy function, which is optimized via score
matching to capture the gradient of the joint log-probability of tensor entries
and shared factors. Our method allows for modeling structures and distributions
beyond the Dirac delta assumption. Moreover, integrating the block coordinate
descent (BCD) algorithm with the proposed smooth regularization enables the
model to perform both tensor completion and denoising. Experimental results
demonstrate significant performance improvements across various tensor types,
including sparse and continuous-time tensors, as well as visual data.

</details>


### [183] [CoATA: Effective Co-Augmentation of Topology and Attribute for Graph Neural Networks](https://arxiv.org/abs/2506.22299)
*Tao Liu,Longlong Lin,Yunfeng Yu,Xi Ou,Youan Zhang,Zhiqiu Ye,Tao Jia*

Main category: cs.LG

TL;DR: CoATA是一个双通道GNN框架，通过联合增强拓扑结构和节点属性，并利用对比学习提升性能，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现实图中的噪声和不完整性严重影响了GNN的性能，现有方法仅关注单一维度的增强，忽略了拓扑和属性的深层交互。

Method: CoATA通过结构信号传播增强节点属性，构建节点-属性二分图优化结构，并引入对比学习进行相互校正。

Result: 在七个基准数据集上，CoATA优于十一种现有方法，验证了其有效性。

Conclusion: CoATA成功捕捉了拓扑与属性之间的协同关系，显著提升了GNN在噪声图中的表现。

Abstract: Graph Neural Networks (GNNs) have garnered substantial attention due to their
remarkable capability in learning graph representations. However, real-world
graphs often exhibit substantial noise and incompleteness, which severely
degrades the performance of GNNs. Existing methods typically address this issue
through single-dimensional augmentation, focusing either on refining topology
structures or perturbing node attributes, thereby overlooking the deeper
interplays between the two. To bridge this gap, this paper presents CoATA, a
dual-channel GNN framework specifically designed for the Co-Augmentation of
Topology and Attribute. Specifically, CoATA first propagates structural signals
to enrich and denoise node attributes. Then, it projects the enhanced attribute
space into a node-attribute bipartite graph for further refinement or
reconstruction of the underlying structure. Subsequently, CoATA introduces
contrastive learning, leveraging prototype alignment and consistency
constraints, to facilitate mutual corrections between the augmented and
original graphs. Finally, extensive experiments on seven benchmark datasets
demonstrate that the proposed CoATA outperforms eleven state-of-the-art
baseline methods, showcasing its effectiveness in capturing the synergistic
relationship between topology and attributes.

</details>


### [184] [Weakly-Supervised Domain Adaptation with Proportion-Constrained Pseudo-Labeling](https://arxiv.org/abs/2506.22301)
*Takumi Okuo,Shinnosuke Matsuo,Shota Harada,Kiyohito Tanaka,Ryoma Bise*

Main category: cs.LG

TL;DR: 提出了一种弱监督域适应方法，利用目标域的类别比例信息，通过比例约束的伪标签提升性能，无需额外标注。


<details>
  <summary>Details</summary>
Motivation: 解决医学领域中因数据分布差异导致的模型性能下降问题，特别是在类别比例不同的情况下。

Method: 基于目标域类别比例信息，为未标注数据分配伪标签（比例约束伪标签）。

Result: 在两个内窥镜数据集上表现优于半监督域适应方法，且在5%标注数据下仍有效，对噪声比例标签具有鲁棒性。

Conclusion: 该方法在真实场景中有效，尤其在医学数据领域具有应用潜力。

Abstract: Domain shift is a significant challenge in machine learning, particularly in
medical applications where data distributions differ across institutions due to
variations in data collection practices, equipment, and procedures. This can
degrade performance when models trained on source domain data are applied to
the target domain. Domain adaptation methods have been widely studied to
address this issue, but most struggle when class proportions between the source
and target domains differ. In this paper, we propose a weakly-supervised domain
adaptation method that leverages class proportion information from the target
domain, which is often accessible in medical datasets through prior knowledge
or statistical reports. Our method assigns pseudo-labels to the unlabeled
target data based on class proportion (called proportion-constrained
pseudo-labeling), improving performance without the need for additional
annotations. Experiments on two endoscopic datasets demonstrate that our method
outperforms semi-supervised domain adaptation techniques, even when 5% of the
target domain is labeled. Additionally, the experimental results with noisy
proportion labels highlight the robustness of our method, further demonstrating
its effectiveness in real-world application scenarios.

</details>


### [185] [Unfolding Generative Flows with Koopman Operators: Fast and Interpretable Sampling](https://arxiv.org/abs/2506.22304)
*Erkan Turan,Aristotelis Siozopoulos,Maks Ovsjanikov*

Main category: cs.LG

TL;DR: 提出了一种基于Koopman算子的方法，加速条件流匹配（CFM）并提升其可解释性，实现一步采样和高效分析生成行为。


<details>
  <summary>Details</summary>
Motivation: 传统CFM采样依赖非线性ODE求解，计算成本高且难以解释。现有方法虽提升速度，但未揭示生成过程的结构。

Method: 结合Koopman算子理论，将非线性流映射为线性演化，设计无解码器的Koopman-CFM架构，实现闭式一步采样。

Result: 在2D数据集和MNIST等基准测试中显著加速采样，Koopman生成器的谱特性为分析生成行为提供工具。

Conclusion: Koopman增强的流匹配结合高效采样与可解释性，为快速且可分析的生成建模提供了新方向。

Abstract: Conditional Flow Matching (CFM) offers a simulation-free framework for
training continuous-time generative models, bridging diffusion and flow-based
approaches. However, sampling from CFM still relies on numerically solving
non-linear ODEs which can be computationally expensive and difficult to
interpret. Recent alternatives address sampling speed via trajectory
straightening, mini-batch coupling or distillation. However, these methods
typically do not shed light on the underlying \textit{structure} of the
generative process. In this work, we propose to accelerate CFM and introduce an
interpretable representation of its dynamics by integrating Koopman operator
theory, which models non-linear flows as linear evolution in a learned space of
observables. We introduce a decoder-free Koopman-CFM architecture that learns
an embedding where the generative dynamics become linear, enabling closed-form,
one-step sampling via matrix exponentiation. This results in significant
speedups over traditional CFM as demonstrated on controlled 2D datasets and
real-world benchmarks, MNIST, Fashion-MNIST (F-MNIST), and the Toronto Face
Dataset (TFD). Unlike previous methods, our approach leads to a well-structured
Koopman generator, whose spectral properties, eigenvalues, and eigenfunctions
offer principled tools for analyzing generative behavior such as temporal
scaling, mode stability, and decomposition in Koopman latent space. By
combining sampling efficiency with analytical structure, Koopman-enhanced flow
matching offers a potential step toward fast and interpretable generative
modeling.

</details>


### [186] [Less Greedy Equivalence Search](https://arxiv.org/abs/2506.22331)
*Adiba Ejaz,Elias Bareinboim*

Main category: cs.LG

TL;DR: LGES是GES的改进版本，通过更针对性的搜索和利用先验假设，提高了计算速度和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决GES在计算成本和有限样本准确性上的局限性。

Method: 修改贪婪步骤，避免在条件独立变量间插入边，并利用先验假设和干预数据。

Result: LGES比GES快10倍，结构误差显著降低，且能纠正错误先验假设。

Conclusion: LGES在理论和实验中均优于GES，适用于观测和干预数据。

Abstract: Greedy Equivalence Search (GES) is a classic score-based algorithm for causal
discovery from observational data. In the sample limit, it recovers the Markov
equivalence class of graphs that describe the data. Still, it faces two
challenges in practice: computational cost and finite-sample accuracy. In this
paper, we develop Less Greedy Equivalence Search (LGES), a variant of GES that
retains its theoretical guarantees while partially addressing these
limitations. LGES modifies the greedy step: rather than always applying the
highest-scoring insertion, it avoids edge insertions between variables for
which the score implies some conditional independence. This more targeted
search yields up to a \(10\)-fold speed-up and a substantial reduction in
structural error relative to GES. Moreover, LGES can guide the search using
prior assumptions, while correcting these assumptions when contradicted by the
data. Finally, LGES can exploit interventional data to refine the learned
observational equivalence class. We prove that LGES recovers the true
equivalence class in the sample limit from observational and interventional
data, even with misspecified prior assumptions. Experiments demonstrate that
LGES outperforms GES and other baselines in speed, accuracy, and robustness to
misspecified assumptions. Our code is available at
https://github.com/CausalAILab/lges.

</details>


### [187] [A Framework for Multi-source Privacy Preserving Epidemic Analysis](https://arxiv.org/abs/2506.22342)
*Zihan Guan,Zhiyuan Zhao,Fengwei Tian,Dung Nguyen,Payel Bhattacharjee,Ravi Tandon,B. Aditya Prakash,Anil Vullikanti*

Main category: cs.LG

TL;DR: 本文提出了一种结合深度学习和流行病模型的框架，用于流行病预测和传播机制建模，同时整合了多种数据集（包括差分隐私保护的数据集），并通过合成金融数据集验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 多样化的数据集在流行病学和公共卫生分析中具有重要价值，但部分数据敏感，需隐私保护。差分隐私（DP）因其强保障成为标准。本文旨在开发一个框架，整合深度学习与流行病模型，利用多数据集（包括DP保护的数据）进行预测和建模。

Method: 开发了一个结合深度学习和流行病模型的框架，整合多数据集（包括DP保护的数据），并通过合成金融数据集进行验证。

Result: 实验表明，即使使用DP保护的数据集，该框架在流行病预测和传播机制建模中仍能提供显著价值。

Conclusion: 该框架成功整合了深度学习与流行病模型，利用多数据集（包括DP保护的数据）进行有效预测和建模，为敏感数据的应用提供了新思路。

Abstract: It is now well understood that diverse datasets provide a lot of value in key
epidemiology and public health analyses, such as forecasting and nowcasting,
development of epidemic models, evaluation and design of interventions and
resource allocation. Some of these datasets are often sensitive, and need
adequate privacy protections. There are many models of privacy, but
Differential Privacy (DP) has become a de facto standard because of its strong
guarantees, without making models about adversaries. In this paper, we develop
a framework the integrates deep learning and epidemic models to simultaneously
perform epidemic forecasting and learning a mechanistic model of epidemic
spread, while incorporating multiple datasets for these analyses, including
some with DP guarantees. We demonstrate our framework using a realistic but
synthetic financial dataset with DP; such a dataset has not been used in such
epidemic analyses. We show that this dataset provides significant value in
forecasting and learning an epidemic model, even when used with DP guarantees.

</details>


### [188] [Sheaf-Based Decentralized Multimodal Learning for Next-Generation Wireless Communication Systems](https://arxiv.org/abs/2506.22374)
*Abdulmomen Ghalkha,Zhuojun Tian,Chaouki Ben Issaid,Mehdi Bennis*

Main category: cs.LG

TL;DR: 提出了一种名为Sheaf-DMFL的去中心化多模态学习框架，利用层理论增强多模态设备协作，并通过注意力机制进一步优化。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习算法仅适用于单模态数据且模型架构统一，无法充分利用多模态数据，限制了其在现实场景中的应用。

Method: 通过层理论捕捉客户端任务层间的内在关联，并引入注意力机制优化多模态相关性。

Result: 在真实世界链路阻塞预测和毫米波波束成形场景中，Sheaf-DMFL-Att表现出优越性能。

Conclusion: Sheaf-DMFL框架有效解决了多模态数据协作问题，提升了异构无线通信系统的决策准确性。

Abstract: In large-scale communication systems, increasingly complex scenarios require
more intelligent collaboration among edge devices collecting various multimodal
sensory data to achieve a more comprehensive understanding of the environment
and improve decision-making accuracy. However, conventional federated learning
(FL) algorithms typically consider unimodal datasets, require identical model
architectures, and fail to leverage the rich information embedded in multimodal
data, limiting their applicability to real-world scenarios with diverse
modalities and varying client capabilities. To address this issue, we propose
Sheaf-DMFL, a novel decentralized multimodal learning framework leveraging
sheaf theory to enhance collaboration among devices with diverse modalities.
Specifically, each client has a set of local feature encoders for its different
modalities, whose outputs are concatenated before passing through a
task-specific layer. While encoders for the same modality are trained
collaboratively across clients, we capture the intrinsic correlations among
clients' task-specific layers using a sheaf-based structure. To further enhance
learning capability, we propose an enhanced algorithm named Sheaf-DMFL-Att,
which tailors the attention mechanism within each client to capture
correlations among different modalities. A rigorous convergence analysis of
Sheaf-DMFL-Att is provided, establishing its theoretical guarantees. Extensive
simulations are conducted on real-world link blockage prediction and mmWave
beamforming scenarios, demonstrate the superiority of the proposed algorithms
in such heterogeneous wireless communication systems.

</details>


### [189] [Probabilistic Optimality for Inference-time Scaling](https://arxiv.org/abs/2506.22376)
*Youkang Wang,Jian Wang,Rubing Chen,Xiao-Yong Wei,Qing Li*

Main category: cs.LG

TL;DR: 提出了一个概率框架，为推理时扩展提供理论基础，并开发了动态确定最优样本数量的算法OptScale，显著减少采样开销。


<details>
  <summary>Details</summary>
Motivation: 现有并行采样方法缺乏理论基础，需解决这一空白。

Method: 提出概率框架，假设样本独立同分布，推导理论下限，开发OptScale算法动态确定样本数量。

Result: 在数学推理基准测试中，OptScale显著减少采样开销，性能优于或与现有方法相当。

Conclusion: 为推理时扩展提供了理论基础和实用解决方案，填补了LLM高效部署的关键空白。

Abstract: Inference-time scaling has emerged as a powerful technique for enhancing the
reasoning performance of Large Language Models (LLMs). However, existing
approaches often rely on heuristic strategies for parallel sampling, lacking a
principled foundation. To address this gap, we propose a probabilistic
framework that formalizes the optimality of inference-time scaling under the
assumption that parallel samples are independently and identically distributed
(i.i.d.), and where the Best-of-N selection strategy follows a probability
distribution that can be estimated. Within this framework, we derive a
theoretical lower bound on the required number of samples to achieve a target
performance level, providing the first principled guidance for
compute-efficient scaling. Leveraging this insight, we develop
\textsc{OptScale}, a practical algorithm that dynamically determines the
optimal number of sampled responses. \textsc{OptScale} employs a language
model-based predictor to estimate probabilistic prior parameters, enabling the
decision of the minimal number of samples needed that satisfy predefined
performance thresholds and confidence levels. Extensive experiments on
mathematical reasoning benchmarks (including MATH-500, GSM8K, AIME, and AMC)
demonstrate that \textsc{OptScale} significantly reduces sampling overhead
while remaining better or on par with state-of-the-art reasoning performance.
Our work offers both a theoretical foundation and a practical solution for
principled inference-time scaling, addressing a critical gap in the efficient
deployment of LLMs for complex reasoning.

</details>


### [190] [Towards Distributed Neural Architectures](https://arxiv.org/abs/2506.22389)
*Aditya Cowsik,Tianyu He,Andrey Gromov*

Main category: cs.LG

TL;DR: 论文提出了一种分布式神经架构（DNA），通过动态路由和模块化设计，在视觉和语言任务中实现高效计算和参数共享。


<details>
  <summary>Details</summary>
Motivation: 传统稀疏方法（如Mixture-of-Experts）的局限性促使研究者探索更灵活的模块化架构，以动态适应输入内容。

Method: DNA通过初始化包含多种模块（如Transformer、MLP等）和路由器的原型架构，允许输入动态选择路径。训练中学习计算和通信模式。

Result: DNA在性能上与密集基线相当，并能学习计算效率和参数共享。路径分布符合幂律，部分模块表现出专业化。

Conclusion: DNA展示了动态计算分配和模块专业化的潜力，为高效模型设计提供了新方向。

Abstract: We introduce and train distributed neural architectures (DNA) in vision and
language domains. DNAs are initialized with a proto-architecture that consists
of (transformer, MLP, attention, etc.) modules and routers. Any token (or
patch) can traverse any series of modules in any order. DNAs are a natural
generalization of the sparse methods such as Mixture-of-Experts,
Mixture-of-Depths, parameter sharing, etc. Computation and communication
patterns of DNA modules are learnt end-to-end during training and depend on the
content and context of each token (or patch). These patterns can be shaped by
further requirements added to the optimization objective such as compute/memory
efficiency or load balancing. We empirically show that (i) trained DNAs are
competitive with the dense baselines in both domains and (ii) compute
efficiency/parameter sharing can be learnt from data. Next, we analyze the
emergent connectivity and computation patterns in the trained DNAs. We find
that the paths that tokens take through the models are themselves distributed
according to a power-law. We show that some paths (or, equivalently, groups of
modules) show emergent specialization. Finally, we demonstrate that models
learn to allocate compute and active parameters in an interpretable way.

</details>


### [191] [Multi-View Contrastive Learning for Robust Domain Adaptation in Medical Time Series Analysis](https://arxiv.org/abs/2506.22393)
*YongKyung Oh,Alex Bui*

Main category: cs.LG

TL;DR: 提出了一种基于多视图对比学习的新框架，用于医学时间序列的跨领域适应，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 医学时间序列的跨领域适应面临复杂时间依赖性和动态分布变化的挑战，现有方法难以全面捕捉时间动态。

Method: 采用多视图对比学习整合时间模式、导数动态和频域特征，通过独立编码器和分层融合机制学习特征不变表示。

Result: 在多种医学数据集（EEG、ECG、EMG）上验证，显著优于现有迁移学习方法。

Conclusion: 该框架提升了模型的鲁棒性和泛化能力，为医疗AI系统的实际部署提供了可行方案。

Abstract: Adapting machine learning models to medical time series across different
domains remains a challenge due to complex temporal dependencies and dynamic
distribution shifts. Current approaches often focus on isolated feature
representations, limiting their ability to fully capture the intricate temporal
dynamics necessary for robust domain adaptation. In this work, we propose a
novel framework leveraging multi-view contrastive learning to integrate
temporal patterns, derivative-based dynamics, and frequency-domain features.
Our method employs independent encoders and a hierarchical fusion mechanism to
learn feature-invariant representations that are transferable across domains
while preserving temporal coherence. Extensive experiments on diverse medical
datasets, including electroencephalogram (EEG), electrocardiogram (ECG), and
electromyography (EMG) demonstrate that our approach significantly outperforms
state-of-the-art methods in transfer learning tasks. By advancing the
robustness and generalizability of machine learning models, our framework
offers a practical pathway for deploying reliable AI systems in diverse
healthcare settings.

</details>


### [192] [Exploration from a Primal-Dual Lens: Value-Incentivized Actor-Critic Methods for Sample-Efficient Online RL](https://arxiv.org/abs/2506.22401)
*Tong Yang,Bo Dai,Lin Xiao,Yuejie Chi*

Main category: cs.LG

TL;DR: 本文提出了一种基于原始-对偶优化的新方法（VAC），用于解决在线强化学习中探索与利用的平衡问题，并提供了理论性能保证。


<details>
  <summary>Details</summary>
Motivation: 在线强化学习在复杂函数逼近（如Transformer和深度神经网络）中的应用日益重要，但探索与利用的平衡仍是一个长期挑战。本文受乐观正则化的启发，试图通过原始-对偶优化视角解决这一问题。

Method: 提出了一种新的价值激励演员-评论家（VAC）方法，通过优化一个单一目标整合探索与利用，促进状态-动作和策略估计与数据一致且能提高价值函数。

Result: VAC方法在有限和无限时间范围的线性MDP中具有接近最优的遗憾保证，并可推广到一般函数逼近场景。

Conclusion: VAC方法为在线强化学习中的探索与利用问题提供了一种高效且理论支持的新解决方案。

Abstract: Online reinforcement learning (RL) with complex function approximations such
as transformers and deep neural networks plays a significant role in the modern
practice of artificial intelligence. Despite its popularity and importance,
balancing the fundamental trade-off between exploration and exploitation
remains a long-standing challenge; in particular, we are still in lack of
efficient and practical schemes that are backed by theoretical performance
guarantees. Motivated by recent developments in exploration via optimistic
regularization, this paper provides an interpretation of the principle of
optimism through the lens of primal-dual optimization. From this fresh
perspective, we set forth a new value-incentivized actor-critic (VAC) method,
which optimizes a single easy-to-optimize objective integrating exploration and
exploitation -- it promotes state-action and policy estimates that are both
consistent with collected data transitions and result in higher value
functions. Theoretically, the proposed VAC method has near-optimal regret
guarantees under linear Markov decision processes (MDPs) in both finite-horizon
and infinite-horizon settings, which can be extended to the general function
approximation setting under appropriate assumptions.

</details>


### [193] [CLoVE: Personalized Federated Learning through Clustering of Loss Vector Embeddings](https://arxiv.org/abs/2506.22427)
*Randeep Bhatia,Nikos Papadis,Murali Kodialam,TV Lakshman,Sayak Chakrabarty*

Main category: cs.LG

TL;DR: CLoVE是一种用于聚类联邦学习（CFL）的新算法，通过损失向量嵌入对客户端进行聚类，无需已知客户端分配，适用于监督和无监督任务。


<details>
  <summary>Details</summary>
Motivation: 解决聚类联邦学习中客户端分配未知的挑战，利用损失值相似性识别客户端集群。

Method: 利用客户端数据的模型损失生成嵌入，迭代分离不同集群的客户端，并通过联邦聚合优化集群特定模型。

Result: 理论证明CLoVE能准确恢复集群，实验显示其在多种非独立同分布设置下实现高精度集群恢复和模型准确性。

Conclusion: CLoVE简单、鲁棒，适用于实际应用，在聚类联邦学习中表现优异。

Abstract: We propose CLoVE (Clustering of Loss Vector Embeddings), a novel algorithm
for Clustered Federated Learning (CFL). In CFL, clients are naturally grouped
into clusters based on their data distribution. However, identifying these
clusters is challenging, as client assignments are unknown. CLoVE utilizes
client embeddings derived from model losses on client data, and leverages the
insight that clients in the same cluster share similar loss values, while those
in different clusters exhibit distinct loss patterns. Based on these
embeddings, CLoVE is able to iteratively identify and separate clients from
different clusters and optimize cluster-specific models through federated
aggregation. Key advantages of CLoVE over existing CFL algorithms are (1) its
simplicity, (2) its applicability to both supervised and unsupervised settings,
and (3) the fact that it eliminates the need for near-optimal model
initialization, which makes it more robust and better suited for real-world
applications. We establish theoretical convergence bounds, showing that CLoVE
can recover clusters accurately with high probability in a single round and
converges exponentially fast to optimal models in a linear setting. Our
comprehensive experiments comparing with a variety of both CFL and generic
Personalized Federated Learning (PFL) algorithms on different types of datasets
and an extensive array of non-IID settings demonstrate that CLoVE achieves
highly accurate cluster recovery in just a few rounds of training, along with
state-of-the-art model accuracy, across a variety of both supervised and
unsupervised PFL tasks.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [194] [Stochastic Neural Control Barrier Functions](https://arxiv.org/abs/2506.21697)
*Hongchao Zhang,Manan Tayal,Jackson Cox,Pushpak Jagtap,Shishir Kolathaya,Andrew Clark*

Main category: eess.SY

TL;DR: 本文提出了一种可验证安全的随机神经控制屏障函数（SNCBFs）合成方法，填补了随机环境下NCBF研究的空白，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在确定性环境下的神经控制屏障函数（NCBFs），而随机环境下的SNCBFs研究较少，本文旨在填补这一空白。

Method: 提出了两种合成框架：针对平滑SNCBFs的无验证合成框架，以及适用于平滑和ReLU SNCBFs的验证循环合成框架。

Result: 在倒立摆、Darboux和独轮车模型中验证了所提框架的有效性。

Conclusion: 本文提出的方法为随机环境下的安全控制提供了新的解决方案，并展示了其实际应用潜力。

Abstract: Control Barrier Functions (CBFs) are utilized to ensure the safety of control
systems. CBFs act as safety filters in order to provide safety guarantees
without compromising system performance. These safety guarantees rely on the
construction of valid CBFs. Due to their complexity, CBFs can be represented by
neural networks, known as neural CBFs (NCBFs). Existing works on the
verification of the NCBF focus on the synthesis and verification of NCBFs in
deterministic settings, leaving the stochastic NCBFs (SNCBFs) less studied. In
this work, we propose a verifiably safe synthesis for SNCBFs. We consider the
cases of smooth SNCBFs with twice-differentiable activation functions and
SNCBFs that utilize the Rectified Linear Unit or ReLU activation function. We
propose a verification-free synthesis framework for smooth SNCBFs and a
verification-in-the-loop synthesis framework for both smooth and ReLU SNCBFs.
and we validate our frameworks in three cases, namely, the inverted pendulum,
Darboux, and the unicycle model.

</details>


### [195] [Online design of experiments by active learning for nonlinear system identification](https://arxiv.org/abs/2506.21754)
*Kui Xie,Alberto Bemporad*

Main category: eess.SY

TL;DR: 研究使用主动学习策略生成输入激励信号，用于线性和非线性自回归及状态空间模型的系统辨识。


<details>
  <summary>Details</summary>
Motivation: 提高系统辨识的样本效率，解决输入和输出约束问题。

Method: 将静态模型回归的主动学习方法扩展到动态场景，结合卡尔曼滤波器递归更新模型参数。

Result: 在不同非线性系统辨识基准上，所提方法比随机激励具有更高的样本效率。

Conclusion: 主动学习策略在动态系统辨识中具有显著优势。

Abstract: We investigate the use of active-learning (AL) strategies to generate the
input excitation signal at runtime for system identification of linear and
nonlinear autoregressive and state-space models. We adapt various existing AL
approaches for static model regression to the dynamic context, coupling them
with a Kalman filter to update the model parameters recursively, and also cope
with the presence of input and output constraints. We show the increased sample
efficiency of the proposed approaches with respect to random excitation on
different nonlinear system identification benchmarks.

</details>


### [196] [Complex Phase Analysis of Power Grid Dynamics](https://arxiv.org/abs/2506.22054)
*Jakob Niehues,Anna Büttner,Anne Riegler,Frank Hellmann*

Main category: eess.SY

TL;DR: 论文提出了一种基于复相位的鲁棒建模方法，用于解决可再生能源电网中逆变器线性模型因参考轨迹变化而失效的问题。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源比例增加，电网形成逆变器的精确高效建模对系统稳定性至关重要，但传统线性方法依赖参考轨迹，易因小偏差失效。

Method: 利用复相位提供独立于参考相位和频率的鲁棒表述，保持线性化下的不变性。

Result: 该方法实现了实际条件下的鲁棒系统辨识，并为逆变器电网的稳定性分析提供了有力工具。

Conclusion: 复相位方法为电网稳定性分析提供了鲁棒且有效的解决方案。

Abstract: With an increasing share of renewable energy sources, accurate and efficient
modeling of grid-forming inverters is becoming crucial for system stability.
Linear methods are a powerful tool for understanding dynamics close to an
operating point, but usually depend on the reference trajectory. Thus, small
deviations can render linear models invalid over time, posing a significant
challenge in practice, and complicating theoretical analysis. As a solution, we
show that the complex phase offers a robust formulation independent of
reference phases and frequencies, thus preserving invariance properties under
linearization. This enables robust system identification during realistic
conditions and opens the road to powerful stability analysis of inverter-based
grids.

</details>


### [197] [Linear-Quadratic Discrete-Time Dynamic Games with Unknown Dynamics](https://arxiv.org/abs/2506.22073)
*Shengyuan Huang,Xiaoguang Yang,Zhigang Cao,Wenjun Mei*

Main category: eess.SY

TL;DR: 论文研究了离散时间线性二次博弈中未知动态系统的反馈纳什均衡（FNE）存在性与唯一性条件，提出了基于离线数据的计算方法和收敛性分析。


<details>
  <summary>Details</summary>
Motivation: 解决未知动态系统的博弈问题，提供基于离线数据的FNE计算框架，简化计算并分析收敛性。

Method: 通过离线数据推导FNE的存在条件，提出有限步线性方程求解算法，并分析无限时域博弈的收敛性。

Result: 证明了未知动态系统与已知动态系统的FNE等价性，提出了有限步计算FNE的算法，并分析了无限时域博弈的收敛速率。

Conclusion: 论文为未知动态系统的博弈问题提供了理论支持与实用算法，适用于有限和无限时域场景。

Abstract: Considering linear-quadratic discrete-time games with unknown
input/output/state (i/o/s) dynamics and state, we provide necessary and
sufficient conditions for the existence and uniqueness of feedback Nash
equilibria (FNE) in the finite-horizon game, based entirely on offline
input/output data. We prove that the finite-horizon unknown-dynamics game and
its corresponding known-dynamics game have the same FNEs, and provide detailed
relationships between their respective FNE matrices. To simplify the
computation of FNEs, we provide an invertibility condition and a corresponding
algorithm that computes one FNE by solving a finite number of linear equation
systems using offline data. For the infinite-horizon unknown-dynamics game,
limited offline data restricts players to computing optimal strategies only
over a finite horizon. We prove that the finite-horizon strategy ``watching $T$
steps into the future and moving one step now,'' which is commonly used in
classical optimal control, exhibits convergence in both the FNE matrices and
the total costs in the infinite-horizon unknown-dynamics game, and further
provide an analysis of the convergence rate of the total cost. The
corresponding algorithm for the infinite-horizon game is proposed and its
efficacy is demonstrated through a non-scalar numerical example.

</details>


### [198] [Learning Distributed Safe Multi-Agent Navigation via Infinite-Horizon Optimal Graph Control](https://arxiv.org/abs/2506.22117)
*Fenglan Wang,Xinguo Shu,Lei He,Lin Zhao*

Main category: eess.SY

TL;DR: 提出了一种基于无限时域CBF约束的分布式多智能体导航方法，通过HJB学习和GNN参数化，实现安全与性能的动态权衡。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在安全性和目标达成之间的保守性和次优性问题，特别是在有限感知范围和密集障碍环境中。

Method: 采用无限时域CBF约束的优化图控制方法，结合HJB学习和GNN参数化，动态调整安全与性能的权衡。

Result: 仿真和实际实验显示，该方法显著提高了安全性和任务成功率，具有强扩展性和泛化能力。

Conclusion: HJB-GNN学习框架在复杂环境中表现出色，适用于大规模团队和未知环境。

Abstract: Distributed multi-agent navigation faces inherent challenges due to the
competing requirements of maintaining safety and achieving goal-directed
behavior, particularly for agents with limited sensing range operating in
unknown environments with dense obstacles. Existing approaches typically
project predefined goal-reaching controllers onto control barrier function
(CBF) constraints, often resulting in conservative and suboptimal trade-offs
between safety and goal-reaching performance. We propose an infinite-horizon
CBF-constrained optimal graph control formulation for distributed safe
multi-agent navigation. By deriving the analytical solution structure, we
develop a novel Hamilton-Jacobi-Bellman (HJB)-based learning framework to
approximate the solution. In particular, our algorithm jointly learns a CBF and
a distributed control policy, both parameterized by graph neural networks
(GNNs), along with a value function that robustly guides agents toward their
goals. Moreover, we introduce a state-dependent parameterization of Lagrange
multipliers, enabling dynamic trade-offs between safety and performance. Unlike
traditional short-horizon, quadratic programming-based CBF methods, our
approach leverages long-horizon optimization to proactively avoid deadlocks and
navigate complex environments more effectively. Extensive simulation results
demonstrate substantial improvements in safety and task success rates across
various agent dynamics, with strong scalability and generalization to
large-scale teams in previously unseen environments. Real-world experiments
using Crazyflie drone swarms on challenging antipodal position-swapping tasks
further validate the practicality, generalizability, and robustness of the
proposed HJB-GNN learning framework.

</details>


### [199] [A Matlab-based Toolbox for Automatic EMT Modeling and Small-Signal Stability Analysis of Modern Power Systems](https://arxiv.org/abs/2506.22201)
*Josep Arevalo-Soler,Dionysios Moutevelis,Elia Mateu-Barriendos,Onur Alican,Carlos Collados-Rodriguez,Marc Cheah-Mañe,Eduardo Prieto-Araujo,Oriol Gomis-Bellmunt*

Main category: eess.SY

TL;DR: 论文介绍了一个基于Matlab的工具箱，用于混合AC/DC电力系统的小信号分析，支持电磁暂态模型，提供模态、阻抗和无源性分析功能。


<details>
  <summary>Details</summary>
Motivation: 电力系统中电力转换器的密集集成引入了新的动态现象和不稳定性，同时转换器作为传统AC电网与新兴DC电网的接口，形成了混合AC/DC网络，需要新的稳定性分析工具。

Method: 开发了一个Matlab工具箱，支持自动化建模，提供模态、阻抗和无源性分析功能，适用于混合AC/DC电力系统的稳定性研究。

Result: 工具箱通过不同规模和拓扑的基于转换器的系统案例研究，展示了其在稳定性分析中的能力。

Conclusion: 该工具箱为混合AC/DC电力系统的小信号分析提供了有效的工具，支持多种分析方法，适用于复杂系统的稳定性研究。

Abstract: The intensive integration of power converters is changing the way that power
systems operate, leading to the emergence of new types of dynamic phenomena and
instabilities. At the same time, converters act as an interface between
traditional AC grids and their more recent DC counterparts, giving rise to
hybrid AC/DC networks. These conditions increase the necessity for stability
analysis tools that can simultaneously account for the newly-introduced dynamic
phenomena and can also be applied for the stability study of hybrid networks.
This paper presents a Matlab-based toolbox for small-signal analysis of hybrid
AC/DC power systems considering electromagnetic-transient (EMT) models. The
toolbox allows the automatized modeling of the system from the input data and
offers options for modal, impedance and passivity analyses. In the paper, the
structure and internal processes of the toolbox are duly discussed, together
with all its features, both main and complementary. Its capabilities for
stability analysis are demonstrated via comprehensive case studies of
converter-based system of various size and topology.

</details>


### [200] [Data-Driven Intrusion Detection in Vehicles: Integrating Unscented Kalman Filter (UKF) with Machine Learning](https://arxiv.org/abs/2506.22404)
*Shuhao Bian,Milad Farsi,Nasser L. Azad,Chris Hobbs*

Main category: eess.SY

TL;DR: 提出了一种结合无迹卡尔曼滤波和机器学习的新型框架，用于车辆攻击检测，无需精确建模。


<details>
  <summary>Details</summary>
Motivation: 在CPS中，缺乏系统参数知识时准确识别攻击是挑战，尤其在ADAS中，车辆动力学参数难以获取。

Method: 结合无迹卡尔曼滤波（UKF）和机器学习算法，避免精确建模需求。

Result: 通过模拟DoS攻击验证了框架的有效性和实用性。

Conclusion: 该框架提高了攻击检测的适应性和准确性，适用于车辆系统。

Abstract: In the realm of Cyber-Physical System (CPS), accurately identifying attacks
without detailed knowledge of the system's parameters remains a major
challenge. When it comes to Advanced Driver Assistance Systems (ADAS),
identifying the parameters of vehicle dynamics could be impractical or
prohibitively costly. To tackle this challenge, we propose a novel framework
for attack detection in vehicles that effectively addresses the uncertainty in
their dynamics. Our method integrates the widely used Unscented Kalman Filter
(UKF), a well-known technique for nonlinear state estimation in dynamic
systems, with machine learning algorithms. This combination eliminates the
requirement for precise vehicle modeling in the detection process, enhancing
the system's adaptability and accuracy. To validate the efficacy and
practicality of our proposed framework, we conducted extensive comparative
simulations by introducing Denial of Service (DoS) attacks on the vehicle
systems' sensors and actuators.

</details>


### [201] [Economic Model Predictive Control with a Non-Fixed Reference Trajectory for Optimal Microgrid Dispatch](https://arxiv.org/abs/2506.22406)
*Avik Ghosh,Adil Khurram,Jan Kleissl,Sonia Martinez*

Main category: eess.SY

TL;DR: 本文提出了一种无需预先知道最优经济稳态或周期轨迹的经济模型预测控制（EMPC）方法，适用于微电网实时调度，证明其经济性能不劣于已知的非固定参考轨迹。


<details>
  <summary>Details</summary>
Motivation: 传统EMPC方法依赖于预先知道最优经济稳态或周期轨迹，而实际微电网调度中这些信息可能不存在或无法提前获取，因此需要一种更通用的方法。

Method: 提出一种针对确定性离散非线性时变系统的EMPC框架，无需预先假设最优经济稳态或周期轨迹，并通过终端成本和区域假设保证性能。

Result: 在满足假设条件下，该方法的渐近平均经济成本不劣于任何已知的非固定参考轨迹。微电网调度仿真显示其能有效降低月度电费。

Conclusion: 该方法为微电网实时调度提供了一种无需预先最优轨迹的EMPC解决方案，实际应用中表现优于传统方法。

Abstract: Economic Model Predictive Control (EMPC), instead of stabilizing a reference
trajectory/state in the objective function like a Tracking MPC, optimizes the
economic performance over the prediction horizon, making it attractive for
economical microgrid (MG) dispatch. However, the demand charge component in the
monthly electricity cost, make it difficult to be encapsulated in additive
stage costs, and can make solutions violate the principle of optimality if
naively introduced in the objective function. Moreover, previous EMPC based
works mostly rely on a-priori knowledge of an optimal economic steady state or
optimal periodic trajectory for performance guarantees, which are not useful or
possibly don't exist respectively, for real-time economical MG dispatch where
load/generation forecasts are known only 24-48 h in advance. This paper, first,
proposes an EMPC formulation for a generic deterministic discrete non-linear
time varying system with hard state and input constraints, without any a-priori
requirements of an optimal economic steady state or optimal periodic
trajectory. It is proved that under mild assumptions on terminal cost and
region, the asymptotic average economic cost of the proposed method is no worse
than the asymptotic average economic cost of any other non-fixed arbitrary
reference trajectory which is known only until the current time-step. The EMPC
framework is then leveraged for optimal MG dispatch by showing that the problem
can be reformulated to satisfy the assumptions required for the asymptotic
performance guarantee. Realistic simulations at the Port of San Diego MG
demonstrated that the proposed method can also reduce monthly electricity costs
in closed-loop with respect to reference trajectories generated by directly
optimizing the electricity cost function over the prediction horizon or by
tracking an ideal grid import curve in a majority of the cases.

</details>


### [202] [Spherical Pendulum with Quad-Rotor Thrust Vectoring Actuation -- A Novel Mechatronics and Control Benchmark Platform](https://arxiv.org/abs/2506.22410)
*Yuchen Li,Omar Curiel,Sheng-Fan Wen,Tsu-Chin Tsao*

Main category: eess.SY

TL;DR: 论文介绍了一种新型控制平台，结合了2自由度摆和四旋翼无人机，用于机电和非线性控制教育与研究。


<details>
  <summary>Details</summary>
Motivation: 多旋翼无人机在工业中广泛应用，但在控制教育中未普及。结合摆和无人机的平台提供了多自由度动力学研究的机会。

Method: 采用小扰动线性化（SPL）、状态反馈线性化（SFL）和部分反馈线性化（PFL）三种策略，并通过仿真和实验验证性能。

Result: 通过阶跃响应时间规范和轨迹跟踪的均方根误差评估性能，验证了闭环系统在外部干扰下的鲁棒性。

Conclusion: 论文展示了基于非线性模型的控制方法的优势与局限性，为机电和非线性控制教育提供了新平台。

Abstract: Motor-actuated pendulums have been established as arguably the most common
laboratory prototypes used in control system education because of the relevance
to robot manipulator control in industry. Meanwhile, multi-rotor drones like
quadcopters have become popular in industrial applications but have not been
broadly employed in control education laboratory. Platforms with pendulums and
multi-rotor copters present classical yet intriguing multi-degree of freedom
(DoF) dynamics and coordinate systems for the control system investigation. In
this paper, we introduce a novel control platform in which a 2-DoF pendulum
capable of azimuth and elevation rotation is actuated through vectored thrust
generated by a quadcopter. Designed as a benchmark for mechatronics and
nonlinear control education and research, the system integrates detailed
mechatronic implementation with different control strategies. Specifically, we
apply and compare small perturbation linearization (SPL), state feedback
linearization (SFL), and partial feedback linearization (PFL) to the nonlinear
system dynamics. The performances are evaluated by time specifications of step
response and Root-Mean-Square (RMS) error of trajectory tracking. The
robustness of the closed-loop system is validated under external disturbances,
and both simulation and experimental results are presented to highlight the
strengths and limitations of the nonlinear model-based control approaches.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [203] [ICP-3DGS: SfM-free 3D Gaussian Splatting for Large-scale Unbounded Scenes](https://arxiv.org/abs/2506.21629)
*Chenhao Zhang,Yezhi Shen,Fengqing Zhu*

Main category: cs.GR

TL;DR: 论文提出了一种结合ICP与优化细化方法的新技术ICP-3DGS，用于解决神经渲染方法在户外场景中依赖预处理相机位姿的问题，并在大规模场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 神经渲染方法（如NeRFs和3DGS）依赖预处理的相机位姿和3D结构先验，这在户外场景中难以获取。

Method: 结合ICP与优化细化进行相机位姿估计，并引入基于体素的场景稠密化方法指导重建。

Result: ICP-3DGS在相机位姿估计和新视角合成方面优于现有方法，适用于不同规模的室内外场景。

Conclusion: 该方法有效解决了户外场景中的相机位姿估计问题，并提升了重建质量。

Abstract: In recent years, neural rendering methods such as NeRFs and 3D Gaussian
Splatting (3DGS) have made significant progress in scene reconstruction and
novel view synthesis. However, they heavily rely on preprocessed camera poses
and 3D structural priors from structure-from-motion (SfM), which are
challenging to obtain in outdoor scenarios. To address this challenge, we
propose to incorporate Iterative Closest Point (ICP) with optimization-based
refinement to achieve accurate camera pose estimation under large camera
movements. Additionally, we introduce a voxel-based scene densification
approach to guide the reconstruction in large-scale scenes. Experiments
demonstrate that our approach ICP-3DGS outperforms existing methods in both
camera pose estimation and novel view synthesis across indoor and outdoor
scenes of various scales. Source code is available at
https://github.com/Chenhao-Z/ICP-3DGS.

</details>


### [204] [SkinningGS: Editable Dynamic Human Scene Reconstruction Using Gaussian Splatting Based on a Skinning Model](https://arxiv.org/abs/2506.21632)
*Da Li,Donggang Jia,Markus Hadwiger,Ivan Viola*

Main category: cs.GR

TL;DR: 该论文提出了一种基于点云解耦和联合优化的方法，用于从单目动态视频中重建交互式人体和背景，实现了高质量重建并降低了资源消耗。


<details>
  <summary>Details</summary>
Motivation: 从单目动态视频中重建交互式人体和背景具有挑战性，传统方法在细节捕捉和资源消耗上存在不足。

Method: 采用点云解耦和联合优化策略，引入位置纹理细分SMPL模型，结合CNN预测人体点云特征，减少点云数量。

Result: 方法在重建指标上优于HUGS，实时渲染速度达100 FPS，资源消耗更低，并可扩展到动物场景重建。

Conclusion: 该方法在高质量重建和效率上表现优异，具有广泛的应用潜力。

Abstract: Reconstructing an interactive human avatar and the background from a
monocular video of a dynamic human scene is highly challenging. In this work we
adopt a strategy of point cloud decoupling and joint optimization to achieve
the decoupled reconstruction of backgrounds and human bodies while preserving
the interactivity of human motion. We introduce a position texture to subdivide
the Skinned Multi-Person Linear (SMPL) body model's surface and grow the human
point cloud. To capture fine details of human dynamics and deformations, we
incorporate a convolutional neural network structure to predict human body
point cloud features based on texture. This strategy makes our approach free of
hyperparameter tuning for densification and efficiently represents human points
with half the point cloud of HUGS. This approach ensures high-quality human
reconstruction and reduces GPU resource consumption during training. As a
result, our method surpasses the previous state-of-the-art HUGS in
reconstruction metrics while maintaining the ability to generalize to novel
poses and views. Furthermore, our technique achieves real-time rendering at
over 100 FPS, $\sim$6$\times$ the HUGS speed using only Linear Blend Skinning
(LBS) weights for human transformation. Additionally, this work demonstrates
that this framework can be extended to animal scene reconstruction when an
accurately-posed model of an animal is available.

</details>


### [205] [SAR-GS: 3D Gaussian Splatting for Synthetic Aperture Radar Target Reconstruction](https://arxiv.org/abs/2506.21633)
*Aobo Li,Zhengxin Lei,Jiangtao Wei,Feng Xu*

Main category: cs.GR

TL;DR: 提出了一种SAR目标重建的新方法SDGR，结合高斯泼溅和映射投影算法，通过优化高斯基元参数实现3D重建，并在模拟和真实数据集上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: SAR图像中复杂电磁散射机制导致目标重建困难，受3D高斯泼溅在光学领域成功的启发，提出适用于SAR的SDGR方法。

Method: 结合高斯泼溅和映射投影算法计算散射强度，通过SDGR生成模拟SAR图像，优化高斯基元参数，并使用自定义CUDA梯度流加速计算。

Result: 实验验证了SDGR在模拟和真实数据集上的有效性，能够重建目标的几何结构和散射特性。

Conclusion: SDGR为SAR成像领域的3D重建提供了新解决方案。

Abstract: Three-dimensional target reconstruction from synthetic aperture radar (SAR)
imagery is crucial for interpreting complex scattering information in SAR data.
However, the intricate electromagnetic scattering mechanisms inherent to SAR
imaging pose significant reconstruction challenges. Inspired by the remarkable
success of 3D Gaussian Splatting (3D-GS) in optical domain reconstruction, this
paper presents a novel SAR Differentiable Gaussian Splatting Rasterizer (SDGR)
specifically designed for SAR target reconstruction. Our approach combines
Gaussian splatting with the Mapping and Projection Algorithm to compute
scattering intensities of Gaussian primitives and generate simulated SAR images
through SDGR. Subsequently, the loss function between the rendered image and
the ground truth image is computed to optimize the Gaussian primitive
parameters representing the scene, while a custom CUDA gradient flow is
employed to replace automatic differentiation for accelerated gradient
computation. Through experiments involving the rendering of simplified
architectural targets and SAR images of multiple vehicle targets, we validate
the imaging rationality of SDGR on simulated SAR imagery. Furthermore, the
effectiveness of our method for target reconstruction is demonstrated on both
simulated and real-world datasets containing multiple vehicle targets, with
quantitative evaluations conducted to assess its reconstruction performance.
Experimental results indicate that our approach can effectively reconstruct the
geometric structures and scattering properties of targets, thereby providing a
novel solution for 3D reconstruction in the field of SAR imaging.

</details>


### [206] [A Design Space for Visualization Transitions of 3D Spatial Data in Hybrid AR-Desktop Environments](https://arxiv.org/abs/2506.22250)
*Yucheng Lu,Tobias Rau,Benjamin Lee,Andreas Köhn,Michael Sedlmair,Christian Sandor,Tobias Isenberg*

Main category: cs.GR

TL;DR: 论文提出了一个设计空间，用于在混合增强现实（AR）-桌面环境中实现3D空间数据集外观的动画过渡，以减少用户认知负担并连接不同维度的数据表示。


<details>
  <summary>Details</summary>
Motivation: 混合界面结合传统和沉浸式显示，以在不同环境中最佳展示2D和3D数据表示。过渡动画的设计旨在减少用户认知负担并明确不同表示之间的联系。

Method: 通过空间编码管道描述3D数据的转换过程，并设计过渡动画以平滑连接不同管道。设计空间总结了过渡选择的关键因素。

Result: 通过三个案例研究（天文学、放射学和化学）验证了设计空间的有效性，并总结了相关经验。

Conclusion: 提出的设计空间简化了过渡动画的决策过程，并为未来设计提供了灵感。

Abstract: We present a design space for animated transitions of the appearance of 3D
spatial datasets in a hybrid Augmented Reality (AR)-desktop context. Such
hybrid interfaces combine both traditional and immersive displays to facilitate
the exploration of 2D and 3D data representations in the environment in which
they are best displayed. One key aspect is to introduce transitional animations
that change between the different dimensionalities to illustrate the connection
between the different representations and to reduce the potential cognitive
load on the user. The specific transitions to be used depend on the type of
data, the needs of the application domain, and other factors. We summarize
these as a transition design space to simplify the decision-making process and
provide inspiration for future designs. First, we discuss 3D visualizations
from a spatial perspective: a spatial encoding pipeline, where 3D data sampled
from the physical world goes through various transformations, being mapped to
visual representations, and then being integrated into a hybrid AR-desktop
environment. The transition design then focuses on interpolating between two
spatial encoding pipelines to provide a smooth experience. To illustrate the
use of our design space, we apply it to three case studies that focus on
applications in astronomy, radiology, and chemistry; we then discuss lessons
learned from these applications.

</details>
